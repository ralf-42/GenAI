{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMyvxhTIYwaoo1MNbtwZltN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 11: LangChain: Agents\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"markdown","source":["# 1 | Übersicht\n","---"],"metadata":{"id":"oYvUY6gMBKO1"}},{"cell_type":"markdown","metadata":{"id":"gbCp2xP2a-Fd"},"source":["# 7.1: LangChain Agents\n","\n","LangChain allows the use of [agents](https://python.langchain.com/v0.1/docs/modules/agents/), which revolutionize the way we interact with language models by transforming them into dynamic decision-makers. Unlike traditional chains, where each step is meticulously programmed, agents leverage the inherent reasoning capabilities of language models to choose their own paths. Imagine an intelligent system that not only understands the context but also determines the most effective sequence of actions to achieve a goal. This adaptability marks a significant departure from rigid, pre-defined workflows. By acting as a reasoning engine, the language model assesses each situation and decides which actions to take and in what order, offering unparalleled flexibility and efficiency. This chapter delves into the fascinating world of lang-chain agents, exploring how they harness the power of language models to autonomously navigate complex tasks, adapt to changing conditions, and deliver sophisticated solutions with minimal human intervention.\n","\n","LangChain suppors multiple [agent types](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/). You will interface with these agents via two different methods:\n","\n","* **Chat Models**: Designed to take in messages and output messages, requiring a specific prompting strategy for optimal performance.\n","* **LLMs**: Intended to take in a string and output a string, using a different prompting strategy to achieve the best results.\n","\n","Some of the other important features for agent types include:\n","\n","* **Supports Chat History**: Indicates if an agent can function as a chatbot, typically requiring advanced models.\n","* **Supports Multi-Input Tools**: Indicates if an agent can use tools requiring multiple inputs, often unsupported by earlier models.\n","* **Supports Parallel Function Calling**: Indicates if an agent can call multiple tools simultaneously, requiring more advanced models.\n","\n","The LangChain agent types can be summarized as follows:\n","\n","|Agent Type|Interface|Chat<br>History|Multi-Input<br>Tools|Parallel<br>Function Calling|When to use|\n","|--|--|--|--|--|--|\n","|Tool Calling|chat|✅|✅|✅|Used in this course, also tool-calling agents.\n","|XML|LLM|✅|||Use with XML models, such as Anthropic\n","|Structured Chat|chat|✅|✅||If you need to support tools with multiple inputs.\n","|JSON Chat|chat|✅|||If you are using a model good at JSON|\n","|ReAct|LLM|✅|||Complex reasoning|\n","|Self-Ask w/Search|LLM||||If you are using a simple model and only have one search tool|\n","\n","\n","In this course, we will focus primarily on tool-calling agents, which are designed to interact with external tools and APIs to perform specific tasks, such as data retrieval, processing, or executing actions based on user inputs. Tool-calling agents are highly versatile and are essential for building applications that require integration with various external systems. Besides tool-calling agents, there are two other important types: ReAct agents and Self-Ask with Search agents. ReAct agents combine reasoning and acting capabilities, making them suitable for complex decision-making and task automation scenarios where the agent needs to logically process information and take appropriate actions. Self-Ask with Search agents, on the other hand, are designed to enhance the language model's capabilities by integrating search functionalities, allowing the agent to retrieve up-to-date information from external sources. This makes them ideal for applications requiring accurate and current data retrieval, such as news aggregation, fact-checking, and research tools. Each type of agent serves a unique purpose, and understanding their use cases will enable you to select the appropriate agent for your specific application needs. We will also cover how to create an entirely custom agent.\n","\n","## Key Components of Agents\n","\n","Agents use a language model to decide on a sequence of actions. Unlike chains, where actions are predefined in the code, agents utilize a language model as a reasoning engine to determine the actions and their order.\n","\n","* **AgentAction**: An AgentAction is a dataclass that defines the action an agent should take. It includes a tool property, specifying the name of the tool to be invoked, and a tool_input property, providing the input for that tool.\n","\n","* **AgentFinish**: AgentFinish signifies the final result from an agent, ready to be returned to the user. It contains a return_values key-value mapping, typically holding an output key with a string representing the agent's response.\n","\n","* **Intermediate Steps**: Intermediate steps represent previous agent actions and their corresponding outputs during the current run. These steps are crucial for informing future iterations, allowing the agent to track completed tasks. This is typed as a List (Tuple[AgentAction, Any), with observation being flexible and often a string.\n","\n","## Agent Chain Structure\n","\n","The agent is responsible for deciding the next step, usually powered by a language model, a prompt, and an output parser. Different agents use various prompting styles, input encoding methods, and output parsing techniques. For a comprehensive list of built-in agents, refer to the agent types section. Custom agents can also be created for more control.\n","\n","* **Agent Inputs**: Inputs to an agent are key-value mappings, with intermediate_steps being the only required key, corresponding to the intermediate steps mentioned earlier. The PromptTemplate typically transforms these pairs into a format suitable for the LLM.\n","\n","* **Agent Outputs**: The outputs can be the next action(s) to take or the final response to send to the user (AgentActions or AgentFinish). Concretely, this can be typed as Union (AgentAction, List[AgentAction], AgentFinish). The output parser converts the raw LLM output into one of these types.\n","\n","## The AgentExecutor\n","The agent executor is the runtime that calls the agent, executes chosen actions, passes the action outputs back to the agent, and repeats the process. This runtime handles complexities such as:\n","\n","* Selecting non-existent tools\n","* Managing tool errors\n","* Parsing tool invocation outputs\n","* Logging and observability at all levels (agent decisions, tool calls)\n","\n","## Agent Tools\n","Tools are functions that an agent can invoke. The Tool abstraction consists of two components:\n","\n","The input schema for the tool, informing the LLM of the necessary parameters.\n","The function to run, typically a Python function.\n","\n","## Agent Toolkits\n","For common tasks, agents often require a set of related tools. LangChain provides toolkits—groups of 3-5 tools for specific objectives. For example, the GitHub toolkit includes tools for searching issues, reading files, and commenting. LangChain offers various toolkits to get started. For a full list, see the toolkits integrations section.\n","\n","## Basic Agent Exmaple\n","\n","Let's now take a look at a basic agent. An agent in this context is a system designed to perform specific tasks by leveraging tools and models. At a high level, this agent uses a language model to process inputs and make use of external tools to gather information. In our example, the agent is set up to answer questions using a search tool (DuckDuckGo) and a language model (OpenAI's ChatGPT). DuckDuckGo is used here because it is simple to integrate and does not require API keys. We will later explore how the agent is created and how it interacts with the tools and the language model to produce responses."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81f56071-c3ff-4187-88bd-8d1c1d7deec4","id":"GaHdThAAa-Fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': 'current value of the DJIA'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3mDow Jones Industrial Average + Add to watchlist + Add an alert. DJI:DJI. Dow Jones Industrial Average. Actions. Add to watchlist; Add an alert; Price (USD) 39,411.21; Today's Change 260.88 / 0.67%; Shares traded 387.00m; ... Share price information may be rounded up/down and therefore not entirely accurate. Dow Jones Today: Get all information on the Dow Jones Index including historical chart, news and constituents. The Dow Jones Industrial Average ( DJINDICES:^DJI) is a stock index that tracks 30 of the largest U.S. companies. Created in 1896, it is one of the oldest stock indexes, and its performance is ... The observations for the Dow Jones Industrial Average represent the daily index value at market close. The market typically closes at 4 PM ET, except for holidays when it sometimes closes early. The Dow Jones Industrial Average provides a view of the US stock market and economy. Originally, the index was made up of 12 stocks, it now contains 30 ... Dow Jones Industrial Average - DJIA: The Dow Jones Industrial Average (DJIA) is a price-weighted average of 30 significant stocks traded on the New York Stock Exchange (NYSE) and the NASDAQ . The ...\u001b[0m\u001b[32;1m\u001b[1;3mThe current value of the Dow Jones Industrial Average (DJIA) is 39,411.21.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'What is the currnet value of the DJIA?',\n"," 'output': 'The current value of the Dow Jones Industrial Average (DJIA) is 39,411.21.'}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from re import VERBOSE\n","from langchain import hub\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import AgentExecutor\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.2,\n","        n=1\n","    )\n","\n","search_tool = DuckDuckGoSearchRun()\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [search_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\": \"What is the currnet value of the DJIA?\"})"]},{"cell_type":"markdown","metadata":{"id":"gElGqUd2a-Fe"},"source":["\n","The code sets up a basic agent to answer questions by integrating a language model and a search tool. Initially, it imports necessary modules and initializes the language model (ChatOpenAI) with specified parameters such as model type and temperature. The DuckDuckGoSearchRun tool is instantiated for performing web searches. A prompt template is pulled from a repository to guide the agent's responses. The agent is then created using the create_tool_calling_agent function, which combines the language model, tools, and prompt. Input data is provided to test the agent with a question about the president of the United States. The AgentExecutor class is used to manage the agent's execution, allowing it to process further queries, such as checking the current value of the DJIA, with verbosity enabled to provide detailed output during execution. This setup demonstrates the integration of a language model with a search tool to perform information retrieval and question-answering tasks."]},{"cell_type":"markdown","metadata":{"id":"SqFJDrxLa-Fe"},"source":["# Module 7 Assignment\n","\n","You can find the first assignment here: [assignment 7](https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class7.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# 7.2: LangChain Agent Tools\n","\n","\n","LangChain agents are versatile entities designed to perform specific tasks autonomously. Central to their functionality are [tools](https://python.langchain.com/v0.1/docs/modules/tools/), which are specialized components that agents can utilize to accomplish their objectives. These tools can range from data retrieval and processing utilities to interactive interfaces for user engagement. By leveraging these tools, LangChain agents can efficiently execute complex workflows, automate routine tasks, and provide intelligent solutions tailored to user needs. Whether it's querying databases, parsing documents, or interacting with APIs, the strategic use of tools enables LangChain agents to enhance productivity and deliver precise outcomes.\n","\n","\n","Large Language Models (LLMs) inherently lack access to real-time information such as the current date and time, stock market data, and breaking news. This limitation stems from their design, which relies on pre-existing datasets that do not include ongoing updates. Additionally, LLMs are not equipped to perform mathematical calculations directly, which can restrict their utility in scenarios requiring precise numerical operations. To overcome these constraints, LLMs can employ specialized tools. For instance, search engine tools enable LLMs to retrieve the latest information from the web, ensuring up-to-date responses. Similarly, tools designed for mathematical computation can assist LLMs in accurately processing and solving mathematical problems, thereby enhancing their overall capability and accuracy.\n","\n","* [Available Langchain Tools](https://python.langchain.com/v0.2/docs/integrations/tools/)\n","* [Available Langchain Toolkits](https://python.langchain.com/v0.2/docs/integrations/toolkits/)\n","\n","## Tools for Math\n","\n","\n","We will begin our exploration of LangChain tools by using a tool specifically designed for math. Large Language Models (LLMs), like ChatGPT, are generally poor at performing mathematical calculations without the assistance of specialized tools. This is because LLMs are trained primarily on textual data and lack the precision required for accurate arithmetic operations. Consequently, they often produce inaccurate results when asked to perform math independently. To see how a LLM actually performs mathematics, I asked ChatGPT and it gave a decent high-level summary.\n","\n","> Large Language Models (LLMs), like me, do not inherently perform arithmetic calculations the same way a calculator or dedicated algorithm would. Instead, we generate responses based on patterns in the data we've been trained on. Here's a simplified explanation of how we handle such tasks:\n",">\n","> Pattern Recognition: During training, LLMs are exposed to vast amounts of text data, which includes examples of arithmetic and mathematical reasoning. We learn patterns and structures in these examples, enabling us to approximate calculations.\n",">\n","> Token Prediction: When asked to perform a calculation, an LLM doesn't actually \"calculate\" in the traditional sense. Instead, it predicts the most likely sequence of tokens (numbers, in this case) that should follow based on the input. This prediction is influenced by the training data but does not involve real arithmetic operations.\n",">\n","> Approximation and Heuristics: For smaller or simpler calculations, the model might generate the correct answer because it has seen enough examples during training. For larger or more complex calculations, the model might generate an approximate answer or even make a guess based on learned patterns.\n",">\n","> For example, if you ask an LLM to multiply 872947493 by 7492374932, it will try to generate a plausible sequence of digits based on what it has seen in the training data, but this sequence is unlikely to be correct without an actual computational algorithm.\n",">\n",">Here’s a brief comparison of how a traditional method (e.g., a calculator or algorithm) and an LLM approach such a problem:\n",">\n","> * Traditional Method: Uses precise algorithms to perform each step of the multiplication (e.g., long multiplication or fast algorithms like the Karatsuba algorithm).\n","> * LLM Method: Predicts the next sequence of digits based on patterns and probabilities from the training data.\n","So, while an LLM might \"attempt\" to give an answer, it lacks the precision and algorithmic foundation to guarantee accuracy for complex arithmetic without dedicated computational tools.\n","\n","To see this in action, let's ask an LLM to perform a mathematical operation. We will choose numbers that were unlikely in the LLM's training data.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5x_qovp1E13","outputId":"064aabbf-fd90-495d-db7d-3e984214bb2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["content='8273 times 1821 equals 15,086,213.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 17, 'total_tokens': 31}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None} id='run-3a675778-1103-4384-8350-8082c63cca8e-0' usage_metadata={'input_tokens': 17, 'output_tokens': 14, 'total_tokens': 31}\n"]}],"source":["from langchain_openai import ChatOpenAI\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.2,\n","        n=1\n","    )\n","\n","print(llm.invoke(\"What is 8273 times 1821?\"))"]},{"cell_type":"markdown","metadata":{"id":"c4ilDY5oB4dT"},"source":["The resulting number appears reasonable, but that's the point. LLMs are trained to produce believable results, not necessarily correct ones. To verify the LLM, we'll have Python perform this calculation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-4t2gN51jom","outputId":"69b84bf5-a6db-4444-c8ab-4ba4811e15b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["15065133\n"]}],"source":["print(8273 * 1821)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXJis_ZV1qpl","outputId":"4a836215-91d7-45ba-c066-b59aaabe21b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["9700\n"]}],"source":["print( abs(15065133 - 15055433 ) )\n"]},{"cell_type":"markdown","metadata":{"id":"2t2lZcP1CVT9"},"source":["We can see that the LLM was several thousand off. Unfortunately, LangChain does not include a calculator tool, at least as of summer 2024. We will look at two approaches. First, we will use the LangChain-provided PythonREPL. The following code shows how to use PythonREPL."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"u3O0SkxSwPFk","outputId":"1c4f8341-cd07-446f-d5d9-2d352177138f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.agents import Tool\n","from langchain_experimental.utilities import PythonREPL\n","\n","python_repl = PythonREPL()\n","\n","python_repl.run(\"print(1+1)\")"]},{"cell_type":"markdown","metadata":{"id":"6MO5-3uBFvqO"},"source":["It begins by importing necessary modules and classes from the LangChain, LangChain OpenAI, and LangChain Community libraries.\n","A tool for executing Python commands (repl_tool) is created using the Tool class, with a description indicating its purpose as a Python shell that requires valid Python commands. The function python_repl.run is assigned to execute the commands.\n","\n","The prompt for the agent is pulled from a hub, specified by the identifier \"hwchase17/openai-functions-agent\".\n","\n","An agent is then created using the create_tool_calling_agent function, which takes the language model (llm), the tools (here, just repl_tool), and the prompt. This agent is wrapped in an AgentExecutor with the verbose mode enabled to provide detailed logs of the execution process.\n","Finally, the agent is invoked with an input command to calculate the product of 8273 and 1821."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5UI3eL30iEw","outputId":"2b7d4f21-3932-4f57-956d-ba4e94e4ed68"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langsmith/client.py:5515: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n","  prompt = loads(json.dumps(prompt_object.manifest))\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `python_repl` with `{'input': '8273 * 1821'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m15065133\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( 8273 \\times 1821 \\) is \\( 15,065,133 \\).\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","{'input': 'What is 8273 * 1821?', 'output': 'The result of \\\\( 8273 \\\\times 1821 \\\\) is \\\\( 15,065,133 \\\\).'}\n"]}],"source":["from langchain import hub\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent\n","from langchain.agents import AgentExecutor\n","from langchain.tools import StructuredTool\n","from pydantic import BaseModel\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=0.2,\n","    n=1\n",")\n","\n","# Define a Pydantic schema for the input arguments\n","class PythonReplInput(BaseModel):\n","    input: str\n","\n","# Define the tool using StructuredTool with an args_schema\n","def run_python_code(input: str, **kwargs):\n","    try:\n","        # Safely evaluate the input string as a Python expression\n","        result = eval(input)\n","        return str(result)\n","    except Exception as e:\n","        return str(e)\n","\n","repl_tool = StructuredTool(\n","    name=\"python_repl\",\n","    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n","    func=run_python_code,  # Use the custom Python REPL function\n","    args_schema=PythonReplInput  # Define the expected input schema\n",")\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [repl_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","# Pass a string Python command as input\n","result = agent_executor.invoke({\"input\": \"What is 8273 * 1821?\"})\n","\n","print(result)\n"]},{"cell_type":"markdown","metadata":{"id":"7-iL2vLrGYDL"},"source":["## Create a Cusom Math Tool\n","\n","The Python REPL tool we just used can execute any Python command. Therefore, it can be a security concern if we only wish to perform math calculations. In this section, we will see how to create a custom tool that can only perform basic math calculations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0Fux9SZGfu0","outputId":"69e761a2-3fc8-4917-b8df-c3046a9e3f7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Result: 3.0\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-7-34b3ab86af62>:38: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n","  result = chain(inputs)\n"]}],"source":["from langchain_openai import OpenAI\n","import numpy as np\n","from langchain.chains.base import Chain\n","\n","class SafeCalculator:\n","    def calculate(self, expression):\n","        try:\n","            # Evaluate the mathematical expression using NumPy\n","            result = eval(expression, {\"__builtins__\": None}, {\"np\": np})\n","            return result\n","        except Exception as e:\n","            return str(e)\n","\n","class CalculatorChain(Chain):\n","    calculator: SafeCalculator\n","\n","    def _call(self, inputs):\n","        expression = inputs[\"expression\"]\n","        result = self.calculator.calculate(expression)\n","        return {\"result\": result}\n","\n","    @property\n","    def input_keys(self):\n","        return [\"expression\"]\n","\n","    @property\n","    def output_keys(self):\n","        return [\"result\"]\n","\n","# Initialize the safe calculator tool\n","safe_calculator = SafeCalculator()\n","\n","# Example usage\n","chain = CalculatorChain(calculator=safe_calculator)\n","expression = \"3 * (2 + 5) / 7\"\n","inputs = {\"expression\": expression}\n","result = chain(inputs)\n","print(f\"Result: {result['result']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VN_jww59Ick9","outputId":"f1a6aae6-5e50-4cdd-a22e-c61231f43484"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `safe_calc` with `{'input': '8273 * 1821'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m15065133\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( 8273 \\times 1821 \\) is \\( 15,065,133 \\).\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","{'input': '8273 * 1821', 'output': 'The result of \\\\( 8273 \\\\times 1821 \\\\) is \\\\( 15,065,133 \\\\).'}\n"]}],"source":["from langchain import hub\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent\n","from langchain.agents import AgentExecutor\n","from langchain.tools import StructuredTool\n","from pydantic import BaseModel\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=0.2,\n","    n=1\n",")\n","\n","# Define a Pydantic schema for the input arguments\n","class MathExpressionInput(BaseModel):\n","    input: str\n","\n","# Define a safe calculator function\n","def safe_calculator(input: str, **kwargs):\n","    try:\n","        # Safely evaluate the input math expression\n","        result = eval(input)\n","        return str(result)\n","    except Exception as e:\n","        return str(e)\n","\n","# Define the tool using StructuredTool with args_schema\n","safe_math_tool = StructuredTool(\n","    name=\"safe_calc\",\n","    description=\"A math calculator used to evaluate mathematical expressions. Input should be a valid math expression, similar to Python.\",\n","    func=safe_calculator,  # Use the safe calculator function\n","    args_schema=MathExpressionInput  # Define the expected input schema\n",")\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [safe_math_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","# Pass a mathematical expression as input\n","result = agent_executor.invoke({\"input\": \"8273 * 1821\"})\n","\n","print(result)\n"]},{"cell_type":"markdown","metadata":{"id":"6EHuS9I9FkSB"},"source":["# 7.3: LangChain-Abruf- und Suchtools\n","\n","In diesem Abschnitt werden wir uns zwei Arten der Abfrage für die Verwendung mit LangChain-Agenten ansehen: Such- und Abfragetools. Suchtools ermöglichen Ihrem Agenten den Zugriff auf Suchmaschinen wie Google, um dem Agenten aktuelle Informationen bereitzustellen. Darüber hinaus können Sie RAG verwenden, um das Wissen Ihres Agenten mit einem vektorisierten Dokumentspeicher zu erweitern, ähnlich wie bei früheren RAG-Beispielen in diesem Kurs.\n","\n","## Nutzung der Duck Duck Go-Suche\n","\n","DuckDuckGo ist eine Suchmaschine, die mit einem starken Fokus auf die Privatsphäre der Benutzer entwickelt wurde. Im Gegensatz zu vielen herkömmlichen Suchmaschinen verfolgt DuckDuckGo Ihre Suchvorgänge nicht und speichert keine persönlichen Daten, wodurch ein sichereres und privateres Online-Erlebnis gewährleistet wird. Auch wenn Sie vielleicht noch nie von DuckDuckGo gehört haben, erfreut es sich aufgrund seines unkomplizierten Suchansatzes und seines Engagements für die Privatsphäre der Benutzer großer Beliebtheit.\n","\n","Für viele Beispiele in diesem Kurs werden wir [DuckDuckGo](https://duckduckgo.com/) aus mehreren wichtigen Gründen verwenden. Erstens ist die API kostenlos zugänglich und erfordert keinen Authentifizierungsschlüssel, was den Prozess vereinfacht und es uns ermöglicht, direkt mit dem Programmieren zu beginnen, ohne uns mit komplexen Setups herumschlagen zu müssen. Zweitens hilft uns die Verwendung von DuckDuckGo dabei, Datenschutzprobleme im Auge zu behalten und die Bedeutung des Schutzes personenbezogener Daten bei unseren digitalen Interaktionen zu verstehen. Diese praktische Erfahrung wird nicht nur unsere technischen Fähigkeiten verbessern, sondern auch unser Wissen über die vielfältigen Tools erweitern, die im digitalen Ökosystem verfügbar sind."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"J6FMfJ5mBV-9","outputId":"1c052a9d-8f54-454c-bc1d-68a1df947f97"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Joe Biden (born November 20, 1942, Scranton, Pennsylvania, U.S.) 46th president of the United States (2021- ) and 47th vice president of the United States (2009-17) in the Democratic administration of Pres. Barack Obama. He previously represented Delaware in the U.S. Senate (1973-2009). Basic Qualifications: Age, Citizenship and Residency. According to the Constitution, there are just three basic qualifications for being president: Age: The person must be at least 35 years old. Former President Donald Trump and President Joe Biden faced off on Thursday night during the first presidential debate of the 2024 race for the White House. The CNN Presidential Debate marks the ... The president of the United States is the: U.S. head of state; Chief executive of the federal government; Commander-in-Chief of the armed forces; Current president. The 46th and current president of the United States is Joseph R. Biden, Jr. He was sworn into office on January 20, 2021. Former U.S. presidents. The United States has had 45 former ... 1 In elections from 1789 to 1804, each elector voted for two individuals without indicating which was to be president and which was to be vice president. 2 In early elections, electors were chosen by legislatures, not by popular vote, in many states. 3 Candidates winning no electoral votes and less than 2 percent of the popular vote are ...'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_community.tools import DuckDuckGoSearchRun\n","\n","search_tool = DuckDuckGoSearchRun()\n","search_tool.run(\"Who is the president of the USA?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMtU-gGpEj6v","outputId":"fe230924-17ce-4875-d90e-81aeb00eef1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': 'current value of DJIA'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3mDow Jones Industrial Average + Add to watchlist + Add an alert. DJI:DJI. Dow Jones Industrial Average. Actions. Add to watchlist; Add an alert; Price (USD) 39,411.21; Today's Change 260.88 / 0.67%; Shares traded 387.00m; ... Share price information may be rounded up/down and therefore not entirely accurate. Dow Jones Today: Get all information on the Dow Jones Index including historical chart, news and constituents. The Dow Jones Industrial Average ( DJINDICES:^DJI) is a stock index that tracks 30 of the largest U.S. companies. Created in 1896, it is one of the oldest stock indexes, and its performance is ... Headlines for Dow Jones Industrial Average (Dow Jones Global:DJIA) News for Dow Jones Industrial Average. Thursday, June 27, 2024. 04:44 PM ET. Hedge funds are dumping tech stocks despite their recent rally, says Goldman Sachs MarketWatch. ... Historical and current end-of-day data provided by FACTSET. The observations for the Dow Jones Industrial Average represent the daily index value at market close. The market typically closes at 4 PM ET, except for holidays when it sometimes closes early. The Dow Jones Industrial Average provides a view of the US stock market and economy. Originally, the index was made up of 12 stocks, it now contains 30 ...\u001b[0m\u001b[32;1m\u001b[1;3m39411.21\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'Return the value of the DJIA as a floating point number, return just the number, no text or comments.',\n"," 'output': '39411.21'}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from langchain import hub\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import AgentExecutor\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.2,\n","        n=1\n","    )\n","\n","search_tool = DuckDuckGoSearchRun()\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [search_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\": \"Return the value of the DJIA as a floating point number, return just the number, no text or comments.\"})"]},{"cell_type":"markdown","metadata":{"id":"pxDQ8M_YHC71"},"source":["## Verwenden der Tavily-Suche\n","\n","Wir werden nun untersuchen, wie man [Tavily](https://tavily.com/) mit LangChain verwendet. Während sich dieser Kurs aufgrund des kostenlosen Zugriffs hauptsächlich auf die Verwendung von DuckDuckGo konzentriert, ist es wichtig zu beachten, dass Tavily auch eine kostenlose Version anbietet. Der kostenlose Plan von Tavily ermöglicht es Benutzern, bis zu 1.000 API-Aufrufe pro Monat durchzuführen, ohne dass eine Kreditkarte erforderlich ist. Damit ist es für diejenigen zugänglich, die die erweiterten Suchfunktionen nutzen möchten, die auf große Sprachmodelle (LLMs) zugeschnitten sind.\n","\n","Die Verwendung von Tavily kann mehrere Vorteile bieten. Erstens ist Tavily für LLMs optimiert und liefert hochrelevante, sachliche und kontextbezogen passende Suchergebnisse. Diese Optimierung trägt dazu bei, Halluzinationen zu reduzieren und die allgemeinen Entscheidungsfähigkeiten von KI-Agenten zu verbessern. Zweitens unterstützt Tavily die Retrieval-Augmented Generation (RAG), die für die Gewährleistung der Genauigkeit und Relevanz der von LLMs verwendeten Informationen von entscheidender Bedeutung ist.\n","\n","Darüber hinaus sorgt die nahtlose Integration von Tavily in beliebte KI-Frameworks wie LangChain und LlamaIndex dafür, dass Entwickler es problemlos in ihre bestehenden Arbeitsabläufe integrieren können. Die Effizienz und Geschwindigkeit der Suchfunktionen von Tavily, kombiniert mit seiner umfassenden Abdeckung durch die Aggregation von Daten aus mehreren Quellen, machen es zu einem unschätzbaren Werkzeug für KI-gesteuerte Anwendungen. Während DuckDuckGo für viele Benutzer eine praktische und kostengünstige Wahl bleibt, kann das Ausprobieren der erweiterten Funktionen von Tavily die Leistung und Genauigkeit Ihrer KI-Modelle erheblich verbessern.\n","\n","Der folgende Code zeigt eine Beispielsuchabfrage, die Tavily präsentiert wird. Der LLM würde diese Ergebnisse verarbeiten, um zusätzliche Informationen für die Bildung einer Antwort zu erhalten.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElbjAT_sJhlv","outputId":"5cb4601c-49a8-4b74-ec3c-f894d8b81c2c"},"outputs":[{"data":{"text/plain":["[{'url': 'https://www.today.com/news/what-is-burning-man-flood-death-rcna103231',\n","  'content': '\"\\nAn update on BurningMan.org posted the night of Sept. 3 offered those still on site a \"Wet Playa Survival Guide\" with tips, as well as an update saying that conditions were \"improving\" and that roads in Black Rock City were expected to open on Sept. 4 for \"Exodus.\"\\n\"Thank goodness this community knows how to take care of each other,\" the Instagram page for Burning Man Information Radio wrote on a post predicting more rain.\\nNeal Katyal, Chris Rock and others detail their ‘escape’ from Black Rock City\\nComedian Chris Rock and Diplo, producer and DJ,\\xa0were among this year\\'s Burning Man attendees. Why are people stranded at Burning Man?\\nEach year participants in the Burning Man event gather for nine days in an \"annual experiment in temporary community dedicated to Radical Self-expression and Radical Self-reliance,\" according to burningman.org.\\nHeld in Nevada since 1991, the festival sees dreamers, artists, tech founders and celebrities — among others — converge to create a temporary community in the desert.\\n By Sept. 1, organizers tweeted on X that the more than 70,000 attendees of Burning Man should \"help each other stay safe\" and that the gate and airport in and out of the area was closed due to the impossibility for vehicles to \"traverse the playa. In 2014, a 29-year-old woman was hit by a bus outside of Black Rock City, and a motorcycle accident claimed the life of a friend of the Burning Man founders back in 1996, according to an article in the Reno Gazette Journal.\\n \"A fan offered Chris Rock and I a ride out of burning man in the back of a pick up,\" Diplo wrote in a text overlay of the video.\\n'},\n"," {'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331',\n","  'content': '\"\\nTop Stories\\nMacy\\'s Thanksgiving Day Parade temporarily halted by pro-Palestinian protesters\\nGuns N\\' Roses singer Axl Rose accused of alleged 1989 sexual assault by former model\\nFBI: Rainbow Bridge crash, explosion not connected to terrorism\\nToxic chemical spill from Kentucky train derailment forces residents to flee homes\\nHezbollah fires rockets at north Israel after an airstrike kills 5 of the group\\'s senior fighters\\nABC News Live\\n24/7 coverage of breaking news and live events ABC News\\nVideo\\nLive\\nShows\\nElection 2024\\n538\\nStream on\\nBurning Man flooding: What happened to stranded festivalgoers?\\n In response to the unusual weather, event organizers shut down traffic in or out of what is called Black Rock City -- where the festival is held in the desert -- including the local airport.\\n MORE: These US regions will experience scorching temperatures for the remainder of Labor Day weekend\\nOn Sunday, mobile cell trailers to boost cell service and charging stations were placed around the festival grounds amid the recovery efforts, according to organizers.\\n This is typically the driest time of the year for the desert, and it does not take much rain to make the desert floor a mud bath.\\n'},\n"," {'url': 'https://apnews.com/article/burning-man-flooding-nevada-stranded-3971a523f4b993f8f35e158fd1a17a1e',\n","  'content': 'This photo, provided by Maxar Technologies, shows an overview of the center camp at the Burning Man festival on Monday, Sept. 4, 2023, in the Black Rock Desert north of Reno, Nev. Partygoers stranded for days at the counterculture festival by a late summer storm were allowed to start leaving Monday afternoon after muddy roads dried up enough for them to begin their exodus from the northern Nevada desert. This photo, provided by Maxar Technologies, shows an overview of the center camp at the Burning Man festival on Monday, Sept. 4, 2023, in the Black Rock Desert north of Reno, Nev. Partygoers stranded for days at the counterculture festival by a late summer storm were allowed to start leaving Monday afternoon after muddy roads dried up enough for them to begin their exodus from the northern Nevada desert. This photo, provided by Maxar Technologies, shows an overview of traffic leaving the Burning Man festival on Monday, Sept. 4, 2023, in the Black Rock Desert north of Reno, Nev. Partygoers stranded for days at the counterculture festival by a late summer storm were allowed to start leaving Monday afternoon after muddy roads dried up enough for them to begin their exodus from the northern Nevada desert. This photo, provided by Maxar Technologies, shows an overview of traffic leaving the Burning Man festival on Monday, Sept. 4, 2023, in the Black Rock Desert north of Reno, Nev. Partygoers stranded for days at the counterculture festival by a late summer storm were allowed to start leaving Monday afternoon after muddy roads dried up enough for them to begin their exodus from the northern Nevada desert. This photo, provided by Maxar Technologies, shows an overview of traffic leaving the Burning Man festival on Monday, Sept. 4, 2023, in the Black Rock Desert north of Reno, Nev. Partygoers stranded for days at the counterculture festival by a late summer storm were allowed to start leaving Monday afternoon after muddy roads dried up enough for them to begin their exodus from the northern Nevada desert.'},\n"," {'url': 'https://www.cnn.com/2023/09/05/us/burning-man-storms-shelter-exodus-tuesday/index.html',\n","  'content': \"CNN values your feedback\\nBurning Man attendees make a mass exodus after a dramatic weekend that left thousands stuck in the Nevada desert\\nThousands of Burning Man attendees finally made their mass exodus after intense rain over the weekend flooded camp sites and filled them with thick, ankle-deep mud – stranding more than 70,000 free-spirited revelers as they waited for the Nevada desert city to dry out.\\n Burning Man organizers lift driving ban after heavy rains left the event smothered in mud and trapped thousands\\nThe area was still muddy and parts were still difficult to navigate, organizers warned, and the wait time to leave the city Monday night was about seven hours. Diplo hitchhiked ride out of rain-drenched Burning Man after walking miles 'through the mud' and actually made it to his DC concert\\n“Quite a wet start to September for much of eastern CA-western NV,” the National Weather Service in Reno wrote on X. ” “As soon as the tents started getting water-logged or unlivable, people in RVs started taking in some of the tenters, so everybody was warm,” Kaz Qamruddin, who attended the event, told CNN’s Brianna Keilar Monday.\\n From wood blocks to 'poop buckets,' how Burning Man organizers told festivalgoers to prepare for heavy rain\\nAmong the early departures was music DJ Diplo, who told CNN he walked several miles in the muddy desert Saturday morning along with other celebrities, including Chris Rock, Cindy Crawford, Kaia Gerber and Austin Butler.\"},\n"," {'url': 'https://www.nbcnews.com/news/us-news/live-blog/live-updates-burning-man-flooding-keeps-thousands-stranded-nevada-site-rcna103193',\n","  'content': \"Profile\\nSections\\ntv\\nFeatured\\nMore From NBC\\nFollow NBC News\\nnews Alerts\\nThere are no new alerts at this time\\nBurning Man flooding keeps thousands stranded at Nevada site as authorities investigate 1 death\\nBurning Man attendees struggling to get home\\n70,000+ stuck at Burning Man: When will they be able to get out?\\n Thousands still stranded at Burning Man after torrential rain\\nBurning Man revelers unfazed by deluge and deep mud\\nReuters\\nThousands of Burning Man attendees partied hard on Sunday despite downpours that turned the Nevada desert where the annual arts and music festival takes place into a sea of sticky mud and led officials to order the multitudes to shelter in place.\\n Neal Katyal warns hiking in the mud\\ncan be 'worse than walking on ice'\\nDoha Madani\\nNeal Katyal, the former acting U.S. solicitor general, is among the Burning Man attendees who decided to take the risk and hike out of the festival grounds.\\n Videos posted to his Instagram story show Diplo walking through mud before, he says, he hitchhiked to Gerlach and Reno to make a flight to Washington, D.C.\\n“I just got done DJ’ing for three hours, after walking f---ing for four hours out of the desert and taking a flight, mud still on my face,” he said in a video posted to his Instagram story last night.\\n Burning Man memes are swamping social media\\nAngela Yang\\nAs heavy rain turns Burning Man 2023 into a muddy mess, a deluge of unsympathetic jokes has swamped the internet outside Black Rock City, the temporary location built annually for the nine-day festival in the remote desert of Nevada.\\n\"}]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_community.tools.tavily_search import TavilySearchResults\n","\n","tool = TavilySearchResults()\n","tool.invoke({\"query\": \"What happened in the latest burning man floods\"})"]},{"cell_type":"markdown","metadata":{"id":"t7c-cr1lw00B"},"source":["Wir sehen jetzt, dass wir es genau so als Tool hinzufügen können, wie wir DuckDuckGo verwendet haben."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7R7IUTkLG-6","outputId":"424862d9-4d88-45f3-fbdd-2c399cdb6b55"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `tavily_search_results_json` with `{'query': 'oldest world leader 2021'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.pewresearch.org/short-reads/2024/05/01/as-biden-and-trump-seek-reelection-who-are-the-oldest-and-youngest-current-world-leaders/', 'content': \"Joe Biden, at 81, is the oldest American president, a distinction he's held since entering office at age 78. As Biden runs for reelection in 2024, he is the ninth oldest national leader in the world, according to a Pew Research Center analysis of sitting leaders in 187 United Nations member states. Former President Donald Trump, who is ...\"}, {'url': 'https://en.wikipedia.org/wiki/List_of_oldest_living_state_leaders', 'content': 'The oldest living former state leader is Guillermo Rodríguez of Ecuador at the age of 100 years, 236 days. Leaders currently in office are in bold in green, with Paul Biya of Cameroon being the oldest currently serving head of state. Gallery. ... 11 Jan 2021: 12:'}, {'url': 'https://247wallst.com/special-report/2021/07/04/countries-with-the-oldest-leaders-2/', 'content': \"In April 2021, Guelleh was elected to a fifth term, receiving over 97% of the vote. ... Mahmoud Abbas is one of the world's oldest leaders at age 85. He has served as president of Palestine ...\"}, {'url': 'https://en.wikipedia.org/wiki/List_of_current_state_leaders_by_date_of_assumption_of_office', 'content': \"The longest-serving current leader, Hassanal Bolkiah, has ruled since 1967. This is a list of current state leaders ordered by their continuous tenure in a position of national leadership. For countries in which the head of state and head of government are separate, both offices are listed. For leaders who held the same office prior to their state's independence, the start of their tenure is ...\"}, {'url': 'https://www.scmp.com/news/world/united-states-canada/article/3108943/joe-biden-almost-78-here-are-worlds-oldest-leaders', 'content': \"By the time Joe Biden is sworn on January 20, 2021, he will be 78 years and 61 days old. He would be America's oldest president, ever. 'The Sphinx' The world's oldest elected leader is ...\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThe oldest world leader in 2021 is Paul Biya of Cameroon.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'Who is the oldest world leader?',\n"," 'output': 'The oldest world leader in 2021 is Paul Biya of Cameroon.'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from langchain import hub\n","from langchain.agents import create_tool_calling_agent\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import AgentExecutor\n","\n","search_tool = TavilySearchResults()\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [search_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\": \"Who is the oldest world leader?\"})"]},{"cell_type":"markdown","metadata":{"id":"jnZ55G07JdKD"},"source":["## Verwenden von Agenten mit Abruf\n","\n","Wir können die Abfrage auch für Agenten nutzen. Wir werden das RAG-System verwenden, das wir zuvor verwendet haben, um zufällig generierte biografische Skizzen für Personen zu erstellen, die bei fünf fiktiven Unternehmen arbeiten. Wir verwenden dieselben Schritte wie zuvor, um diese Dokumente in einen LangChain-Retriever zu laden."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693,"referenced_widgets":["b9aa56c933dd424e91cded560eab2b6c","14c8f4a1523b416496cd5806d8daef16","ec881675761e4bd8877a6a564257db7b","593f1f2086c84d4699d0bf49efa480cd","8ba4499234e849278c5f6a79973d60a7","1195dd1710104201a7ffcbe9cd95eb77","bf7c6e5bd5b84d0397f987c4f3d4756a","7440c4775cf44cf2852f1ff4628df7bb","2751d6230ad641d19daa5fa0b8695b78","d667c049f84140d19af2f18d6b077e99","95acfbc0076041449267f53a244ff50b","e28536f4023e4b4cbdc3a0c707e5d767","e4284baedeb44518ac1a0fadc2039239","cba2d9d1f49647a1a9ae788bd62dd463","d28d61b7515c401b87d95274ae8665e6","54b8e1e7745b4c14808811764653cc44","dbc34d823b76402eaa807d2ffcbc188b","5814071ff1594fa495f52d3f08a45ddd","dbf0d5479bad450eaee3469ccbc78266","9b3a4bb139014994bb5cd223d187d3c3","542cf1e7f97b47e6bfdd3a53c72cfeb8","db4866cd13b847d5bcd0740adf0a360d","bb36ed730ba741fc8f057a6afad0bc3c","5a1316e2937d485a846b325d4621b105","848b562117f54bf1829ba3b23178f37b","ec9bfbfb5a3f4a8ca968b8bd5512d0d0","5524c249a35b4a31ace03aebe7b9a3b8","bbb8d70382ff4f209ccce033a65cbcd7","103404e2caf348de9ad61645a01e0638","6a4fdbf5375746b8b2c789358ba4b4a0","2190e7f771ea419192f017cffd06e828","ecad524eee434058a364f24913d893e6","4ce919e491c44178aaeb5f467e0221e7","1fc72fbaf1fe40659b5acd814861657f","c048feb6b5d14f65998a76b50d73e8f3","9e56b35669fa48628b73b16ea95666ff","1dadf8056af74caabcf77000f8240d19","0b16a0d035ca4c4aa9e1aaf36c1d6e52","a3d3646f96644fe7aace4d640ad7ca2b","dc0cf96e68824adcb8f522f8a4f34490","4cf0593b91fe40e2b8e1fb28a08bccf9","e5a34584f329418ebc91b165f54f9cd0","b4c64a5553b2431d825871d790030391","455842d26a844434a9b9064ad7e0a8e3","1019bd0e23304b8bb299d31bcdc47bda","27f1b070c5e04586b836c8c6b9f6b66d","9421b1214e88484e9d1d3ac0de8fa10a","f50ec74e8300458c94f6454b1a92a51f","28c94d155ead49dba98fd87b702400d9","52903ecc75da48169cc0295395e0176e","526c5e491c0d4534abc88e9a10663fd0","a4d03b2853744903a371386e48fc6ea3","407aba77602e4faca43224042fbae6a9","98eb121dd18d4107a32d7ad1d8910cad","668f854b1888440eaf9b2add49aef163","192fbbefd9924aa8b080f1f23840ac36","d55dfb33a1fc47269c79aacc4c650a4b","ef719ec54bbd443baa5ca146f9d53f34","d2a3d63ebbd1410ba80e1ca80528da4d","c0c2373e17ee480b86b1df3ba17c5432","7043c807e10e4d55a160514ecb2a8f0e","c9a1699c646c45bdb07111e4f78f76b4","23aad9b7f48e401e87cf47c1df65e9ca","5d72d0b41b99443ea3d4c12555125c09","fac04d5e83304008abfac5547f14af65","b7493344f0264516b2e1b28ef935e21d","0d75e3fc355941c8a1497d9b8d90b6f2","240d296a9e6e4b7a8615dca1cfac815f","c10e1c99d7f24b12a222ec4d7e220c32","384ba2e0f5054cf2a7a033cc689ef485","5990e13488d84efaa9f353cfa2ec13c8","8659289dab5b4d90810623f9d4bf96dc","cf2658cf8d8a42dabfc24c1b6a437028","0b049badc3bc4867a82ef775763e0314","5083db240e4c44b69b3de17bff3ebf42","3b7261e5ffbd49dba8b7939132d4355d","ba63b3990c234f87857e07768c714691","b35b14bb08c34d8485592e134e1bfa92","45a9b0d13e8341308ad14abba45cb381","43d9baa177a24ea3818144e32ec9d8c4","fbb220b4de7e4c09ad2974ec4728f95a","5de72dcb9af743aeb8382a18681ced22","987c799ef70546e4bfa9fdfc8ece100c","4fa7fdd334cf4f1c941b2dcb470bffbf","ddc53f89b7a54ed989fd6fd36547600c","113fae1c0c8743239bb183b8d4f14c85","56316c7da0c44c9db341684a1f3125b8","6efe8d87b41148bba8f43966703aab5a","7ec7b6557eeb40cab5f8dd007796ff14","88adc633e7014aae93c463701def630a","6feb2d10e90c4c8791a9a84803fdb66c","6e599746cf8c4f649ea573358155a01f","99812ef854154260812f8f4e2abc6553","b22cc2110e884029832b9439c38b0485","1923e723b33d4cad972838c536bcfa45","25f7e2dfd6594b01bfc70ca1b259531b","bb25b05f6de34967b3064d814289c979","3a617228aa244db1bc370b098c625c5b","3cef2d7d720b4c8a877bfe9d1b5e3a4a","f709afd09ea6404f84f3be61fa709e29","9dfdc4f5c6604860bdcc31caff9b864a","5d9c0bef4bbd45859a85d7b75083b0b9","27759ba443a84432a2ca7b871c0a28ed","515d481e3dfe4d5f9fd01275c108abca","cec6d53a996d4aae9efc83caccae9b6e","977996ad263442fabe4f4b66b1e1945d","8f895801fe774c308a623de0c07399a2","0530bb33cedb4853bf9a1906081da045","a37b63d9ab2c45359fbc5975c4be45a0","ef6deef18eda403093cf5083276c7998","8a533e56d0f843009d35beaee92887ab","e17fc6284160494e8dfb770dedb6fcab","8df89b7dadae45c89d9445d44eba1ec1","a50a8837e7b547a8a24bc49a792aaee1","f32682df9b4244d89a1fa043c1395cfd","161f509865cb4c778fbf49a38e8e5ac1","cd0ca08212cc4ea6a04919fae8354120","21905f45f90147a39dbad45c78bef411","4b91e69dcbd14cce941ee840ec427ab1","d83a7d38e8ca46d687e7a6034e86f43c","e6a41e80e5d5419db539c0342be52725"]},"id":"NpDENVjcmCkp","outputId":"a270a813-9e13-4853-87a5-60e61a6fd37d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading: https://data.heatonresearch.com/data/t81-559/bios/DD.txt\n","Reading: https://data.heatonresearch.com/data/t81-559/bios/FT.txt\n","Reading: https://data.heatonresearch.com/data/t81-559/bios/GS.txt\n","Reading: https://data.heatonresearch.com/data/t81-559/bios/NGS.txt\n","Reading: https://data.heatonresearch.com/data/t81-559/bios/TI.txt\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n","  warn_deprecated(\n","/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9aa56c933dd424e91cded560eab2b6c","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e28536f4023e4b4cbdc3a0c707e5d767","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb36ed730ba741fc8f057a6afad0bc3c","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fc72fbaf1fe40659b5acd814861657f","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1019bd0e23304b8bb299d31bcdc47bda","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"192fbbefd9924aa8b080f1f23840ac36","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d75e3fc355941c8a1497d9b8d90b6f2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b35b14bb08c34d8485592e134e1bfa92","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ec7b6557eeb40cab5f8dd007796ff14","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f709afd09ea6404f84f3be61fa709e29","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a533e56d0f843009d35beaee92887ab","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from langchain.chains.summarize import load_summarize_chain\n","from langchain.document_loaders import TextLoader\n","from langchain import OpenAI, PromptTemplate\n","from langchain_openai import ChatOpenAI\n","from IPython.display import display_markdown\n","from langchain.indexes import VectorstoreIndexCreator\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores.inmemory import InMemoryVectorStore\n","from langchain.schema import Document\n","import requests\n","\n","urls = [\n","    \"https://data.heatonresearch.com/data/t81-559/bios/DD.txt\",\n","    \"https://data.heatonresearch.com/data/t81-559/bios/FT.txt\",\n","    \"https://data.heatonresearch.com/data/t81-559/bios/GS.txt\",\n","    \"https://data.heatonresearch.com/data/t81-559/bios/NGS.txt\",\n","    \"https://data.heatonresearch.com/data/t81-559/bios/TI.txt\"\n","]\n","\n","def chunk_text(text, chunk_size, overlap):\n","    chunks = []\n","    for i in range(0, len(text), chunk_size - overlap):\n","        chunks.append(text[i:i + chunk_size])\n","    return chunks\n","\n","chunk_size = 900\n","overlap = 300\n","\n","documents = []\n","\n","for url in urls:\n","print(f\"Lesen: {url}\")\n","    response = requests.get(url)\n","    response.raise_for_status()  # Stellen Sie sicher, dass uns schlechte Antworten auffallen\n","    content = response.text\n","    chunks = chunk_text(content, chunk_size, overlap)\n","    for chunk in chunks:\n","        document = Document(page_content=chunk)\n","        documents.append(document)\n","\n","from langchain_text_splitters import CharacterTextSplitter\n","from langchain_community.embeddings.sentence_transformer import (\n","    SentenceTransformerEmbeddings,\n",")\n","from langchain.vectorstores import Chroma\n","\n","text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n","docs = text_splitter.split_documents(documents)\n","\n","embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","db = Chroma.from_documents(docs, embedding_function)\n","retriever = db.as_retriever()"]},{"cell_type":"markdown","metadata":{"id":"e44nhhKmzqs5"},"source":["Wir testen, ob der Retriever Text finden kann, der mit einer der betrügerischen Mitarbeiterinnen, Samantha Doyle, verknüpft ist."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfDLEw-lm9vm","outputId":"064f8b71-b6fd-4b83-f26f-d5a602b0beec"},"outputs":[{"data":{"text/plain":["Document(page_content='the next generation of female tech leaders.\\n\\nSamantha Doyle is a seasoned Project Manager at Global Solutions, an innovative tech company known for pioneering smart city technologies. With over a decade of experience in the tech industry, Samantha has played a pivotal role in leading her team through successful launches of multiple high-profile sustainability projects. She holds a Masterâ\\x80\\x99s degree in Systems Engineering from MIT and has a passion for integrating eco-friendly practices into urban development. Outside of her professional life, Samantha is an avid rock climancer and enjoys mentoring young women interested in STEM careers, often volunteering her time at local high schools and community centers. Her dedication to both her career and community has made her a respected leader at Global Solutions and an influential figure in her field.\\n\\nSamantha Clarke is a seasoned Project Ma')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["retriever.invoke(\"who is Samantha Doyle\")[0]"]},{"cell_type":"markdown","metadata":{"id":"hYMPUH3Qz7Xs"},"source":["Wir konstruieren nun das Tool und geben dem Agenten, wie Sie sehen, auch Anweisungen, wann er diesen Retriever verwenden soll."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5nTFqTWsh-B"},"outputs":[],"source":["from langchain.tools.retriever import create_retriever_tool\n","\n","retriever_tool = create_retriever_tool(\n","    retriever,\n","    \"langsmith_search\",\n","    \"Search for information about people who work for several companies. For any questions about people you do not know, you must use this tool!\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"_4H0Y3B90GGG"},"source":["Wir können dem Agenten nun eine Frage stellen, die sowohl die Suche als auch die RAG-Dokumente verwendet. Die folgende Frage:\n","\n","> Wie sind die Berufsaussichten für Samantha Doyles Karriere im Jahr 2024? Senden Sie uns eine zwei Sätze umfassende Einschätzung ihrer beruflichen Zukunft.\n","\n","Diese Frage erfordert die RAG-Daten, um Samanthas Job zu bestimmen. Anschließend wird die Suchmaschine verwendet, um die aktuellen Aussichten für diesen Job im Jahr 2024 zu finden."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LByUXwW9PI56","outputId":"09081f08-6c14-4e8f-fbeb-77b2fe3e2570"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `langsmith_search` with `{'query': 'job prospects for Samantha Doyle in 2024'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mmen interested in STEM careers, aiming to inspire the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Project Manager at Global Solutions, an innovative tech company known for pioneering smart city technologies. With over a decade of experience in the tech industry, Samantha has been instrumental in leading her team through several high-profile international projects, significantly enhancing urban infrastructure and sustainability in cities across Europe and Asia. A graduate of MIT with a degree in Systems Engineering, her expertise lies in integrating complex systems with emerging technologies to create seamless, efficient solutions. Outside of her professional life, Samantha is an avid rock climber and volunteers her time mentoring young women interested in STEM careers, aiming to inspire the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Pr\n","\n","women interested in STEM careers, aiming to inspire the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Project Manager at Global Solutions, an innovative tech company known for pioneering smart city technologies. With over a decade of experience in the tech industry, Samantha has been instrumental in leading her team through several high-profile international projects, significantly enhancing urban infrastructure and sustainability in cities across Europe and Asia. A graduate of MIT with a degree in Systems Engineering, her expertise lies in integrating complex data systems with user-friendly interfaces. Outside of her professional life, Samantha is an avid rock climber and volunteers her time mentoring young women interested in STEM careers, aiming to inspire the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Project Manager at Global Solut\n","\n","utions with user-friendly interfaces has earned her multiple awards for innovation and leadership. Outside of her professional life, Samantha is an avid rock climber and volunteers her time mentoring young women interested in STEM careers, aiming to inspire the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Project Manager at Global Solutions, an innovative tech company known for pioneering solutions in artificial intelligence and big data analytics. With over a decade of experience in the tech industry, Samantha has played a pivotal role in leading her team through successful launches of several high-profile projects aimed at enhancing cybersecurity measures for multinational corporations. A graduate of MIT with a degree in Computer Science, her expertise and forward-thinking approach have not only earned her multiple awards for leadership and innovation but also\n","\n","the next generation of female tech leaders.\n","\n","Samantha Doyle is a seasoned Project Manager at Global Solutions, an innovative tech company known for pioneering smart city technologies. With over a decade of experience in the tech industry, Samantha has played a pivotal role in leading her team through successful launches of multiple high-profile sustainability projects. She holds a Masterâs degree in Systems Engineering from MIT and has a passion for integrating eco-friendly practices into urban development. Outside of her professional life, Samantha is an avid rock climancer and enjoys mentoring young women interested in STEM careers, often volunteering her time at local high schools and community centers. Her dedication to both her career and community has made her a respected leader at Global Solutions and an influential figure in her field.\n","\n","Samantha Clarke is a seasoned Project Ma\u001b[0m\u001b[32;1m\u001b[1;3mSamantha Doyle, a seasoned Project Manager at Global Solutions, is well-positioned for a successful career future in 2024. With over a decade of experience in leading high-profile international projects and expertise in integrating complex systems with emerging technologies, her innovative approach and leadership skills are likely to continue driving her success in the tech industry. Additionally, her dedication to mentoring young women in STEM careers showcases her commitment to inspiring the next generation of female tech leaders, further solidifying her impact and influence in the field.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': \"What are the job prospects in 2024 for Samantha Doyle's career? Return just a 2-sentence assessment of her career future.\",\n"," 'output': 'Samantha Doyle, a seasoned Project Manager at Global Solutions, is well-positioned for a successful career future in 2024. With over a decade of experience in leading high-profile international projects and expertise in integrating complex systems with emerging technologies, her innovative approach and leadership skills are likely to continue driving her success in the tech industry. Additionally, her dedication to mentoring young women in STEM careers showcases her commitment to inspiring the next generation of female tech leaders, further solidifying her impact and influence in the field.'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from langchain import hub\n","from langchain.agents import create_tool_calling_agent\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import AgentExecutor\n","\n","MODEL = 'gpt-4o-mini'\n","\n","search_tool = search_tool = DuckDuckGoSearchRun()\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [search_tool, retriever_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\": \"What are the job prospects in 2024 for Samantha Doyle's career? Return just a 2-sentence assessment of her career future.\"})"]},{"cell_type":"markdown","metadata":{"id":"JZUcbIxeFql1"},"source":["# 7.4: Erstellen von LangChain-Agenten\n","\n","\n","In diesem Kapitel stellen wir ein umfassendes Modul vor, das die Fähigkeiten eines vollständigen LangChain-Agenten mit Websuch-, Abfrage- und Speicherfunktionen demonstriert. Dieser Agent ist darauf ausgelegt, Fragen zu beantworten, indem er die aktuellste Dokumentation zu LangChain durch Retrieval-Augmented Generation (RAG) nutzt und die Grenzen des Wissens des Basismodells überschreitet. Durch die Integration von Websuche und -abruf in Echtzeit kann der Agent auf die neuesten Informationen zugreifen und diese integrieren, wodurch sichergestellt wird, dass seine Antworten genau und aktuell sind. Darüber hinaus ermöglicht die Speicherkomponente dem Agenten, relevante Informationen zu behalten und abzurufen, wodurch seine Fähigkeit verbessert wird, fundierte und kontextrelevante Antworten zu geben. In diesem Modul lernen die Leser, wie man einen intelligenten Agenten erstellt, der nicht nur Anfragen versteht und verarbeitet, sondern auch seine Wissensdatenbank kontinuierlich aktualisiert, um mit den neuesten Fortschritten in LangChain Schritt zu halten.\n","\n","Wir beginnen mit dem Importieren der für unseren LangChain-Agenten erforderlichen Bibliotheken und Module, einschließlich derer für die Websuche, Abfrage und Speicherverwaltung. Genau wie in den vorherigen Kapiteln erstellen wir ein OpenAI-Sprachmodell (LLM), das als Grundlage für unseren Agenten dient. Dieses Modell wird für die Interpretation und Generierung von menschenähnlichem Text auf der Grundlage der empfangenen Eingaben von entscheidender Bedeutung sein. Durch die Nutzung des OpenAI-LLM stellen wir sicher, dass unser Agent über eine robuste und vielseitige Sprachverständnisfähigkeit verfügt, die durch die Integration von Echtzeit-Websuch- und -abruffunktionen noch weiter verbessert wird. Dieses Setup ermöglicht es dem Agenten, auf die aktuellsten und relevantesten Informationen zuzugreifen und diese zu nutzen und umfassende und genaue Antworten auf Benutzeranfragen zu liefern.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuSzXAi7XhmT","outputId":"19eb8ddf-e5d9-4356-aa97-db74365ef918"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}],"source":["from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_openai import ChatOpenAI\n","from langchain import hub\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain.tools.retriever import create_retriever_tool\n","from langchain.agents import create_tool_calling_agent\n","from langchain.agents import AgentExecutor\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.2,\n","        n=1\n","    )"]},{"cell_type":"markdown","metadata":{"id":"nrKUtES1xInM"},"source":["\n","In diesem Abschnitt verwenden wir Retrieval-Augmented Generation (RAG), um auf die neueste Version der LangChain-Dokumentation zuzugreifen, die aktueller ist als die Daten, mit denen das grundlegende Modell ursprünglich trainiert wurde. Wir beginnen mit der Erstellung einer WebBaseLoader-Instanz, um Inhalte von der URL https://docs.smith.langchain.com/overview zu laden und stellen so sicher, dass wir mit der aktuellsten Dokumentation arbeiten. Sobald der Inhalt geladen ist, verwenden wir RecursiveCharacterTextSplitter, um den Text in kleinere, handhabbare Blöcke von jeweils 1000 Zeichen aufzuteilen, mit einer Überlappung von 200 Zeichen, um den Kontext beizubehalten. Diese Blöcke werden dann mit OpenAIEmbeddings() in Einbettungen umgewandelt und wir indizieren diese Einbettungen mit FAISS (Facebook AI Similarity Search), um eine effiziente Ähnlichkeitssuche durchzuführen. Schließlich erstellen wir einen Retriever aus dem FAISS-Index, der es unserem LangChain-Agenten ermöglicht, die Dokumenteinbettungen abzufragen und die relevantesten Dokumentationsblöcke als Antwort auf Benutzerfragen abzurufen. Dieser Ansatz stellt sicher, dass unser Agent die neuesten Informationen nutzen kann, was seine Fähigkeit verbessert, genaue und aktuelle Antworten zu geben."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPYRfk33su71"},"outputs":[],"source":["loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n","docs = loader.load()\n","documents = RecursiveCharacterTextSplitter(\n","    chunk_size=1000, chunk_overlap=200\n",").split_documents(docs)\n","vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n","retriever = vector.as_retriever()"]},{"cell_type":"markdown","metadata":{"id":"twXh4cQHxMqb"},"source":["Wir senden nun eine einfache Abfrage an den Retriever, um zu sehen, welche Daten er zur Beantwortung der Frage zurückgibt. Die zurückgegebenen Daten stammen von der Website und sind noch nicht von einem LLM verarbeitet worden."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mh9Wn2HAcFz5","outputId":"ea34e71b-36bb-455d-ab7d-8d7af83f4bce"},"outputs":[{"data":{"text/plain":["Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["retriever.invoke(\"how to upload a dataset\")[0]"]},{"cell_type":"markdown","metadata":{"id":"IYY0XPDrxhmp"},"source":["Um Zugriff auf die gerade heruntergeladenen Webdaten zu ermöglichen, verwenden wir ein Agent-Retriever-Tool. Dieses Tool wird erstellt, indem der zuvor erstellte Retriever mit der Klasse VectorStoreRetrieverTool umschlossen wird, wobei als Name „Documentation“ und als Zweck eine kurze Beschreibung angegeben wird. Durch die Integration dieses Agent-Retriever-Tools kann unser LangChain-Agent die Webdaten effektiv zum Generieren von Antworten nutzen. Der ZeroShotAgent wird dann mit diesem Tool konfiguriert und der Agent mit AgentExecutor initialisiert. Dieses Setup ermöglicht es unserem Agenten, die relevantesten Informationen aus der neuesten LangChain-Dokumentation abzurufen und zu verarbeiten, und stellt sicher, dass er Anfragen genau und umfassend beantworten kann."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iH68G5AMcOCA"},"outputs":[],"source":["retriever_tool = create_retriever_tool(\n","    retriever,\n","    \"langsmith_search\",\n","    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"t5_lEQWJxzcj"},"source":["Wir demonstrieren auch eine Abfrage für die Tavily-Suche. Dadurch können wir die heruntergeladenen Daten mit Ad-hoc-Websuchen erweitern, um sowohl das Basismodell als auch die RAG-Datenquelle zu verbessern."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tI0U0PtsIKC","outputId":"e1999af9-b7ee-4515-beeb-2a7ba3436b16"},"outputs":[{"data":{"text/plain":["[{'url': 'https://www.weatherapi.com/',\n","  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1719777546, 'localtime': '2024-06-30 12:59'}, 'current': {'last_updated_epoch': 1719776700, 'last_updated': '2024-06-30 12:45', 'temp_c': 22.2, 'temp_f': 72.0, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 13.6, 'wind_kph': 22.0, 'wind_degree': 270, 'wind_dir': 'W', 'pressure_mb': 1016.0, 'pressure_in': 29.99, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 55, 'cloud': 0, 'feelslike_c': 24.6, 'feelslike_f': 76.4, 'windchill_c': 17.4, 'windchill_f': 63.3, 'heatindex_c': 17.4, 'heatindex_f': 63.3, 'dewpoint_c': 11.9, 'dewpoint_f': 53.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 4.0, 'gust_mph': 18.1, 'gust_kph': 29.2}}\"},\n"," {'url': 'https://www.msn.com/en-us/weather/topstories/san-francisco-bay-area-june-30-2024/vi-BB1p9I3z',\n","  'content': 'Drop A Flavor Bomb On Your Buttered Noodles With One Secret Sauce'},\n"," {'url': 'https://world-weather.info/forecast/usa/san_francisco/june-2024/',\n","  'content': 'Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed ⚡ San Francisco Weather Forecast for June 2024 - day/night 🌡️ temperatures, precipitations - World-Weather.info.'},\n"," {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/june-weather/347629',\n","  'content': 'Get the monthly weather forecast for San Francisco, CA, including daily high/low, historical averages, to help you plan ahead.'},\n"," {'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94145/date/2024-6-30',\n","  'content': 'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area.'}]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["search = TavilySearchResults()\n","\n","search.invoke(\"what is the weather in SF\")"]},{"cell_type":"markdown","metadata":{"id":"eSBVXZ0QyAdQ"},"source":["Als Nächstes richten wir den LangChain-Agenten ein, indem wir verschiedene Tools integrieren und den Agenten so konfigurieren, dass er sie effektiv nutzen kann. Wir beginnen mit der Definition einer Liste von Tools, die unser Websuchtool und das zuvor erstellte Retriever-Tool enthält. Als Nächstes ziehen wir mit hub.pull(\"hwchase17/openai-functions-agent\") eine vordefinierte Eingabeaufforderung aus dem LangChain-Hub, die strukturierte Nachrichten bereitstellt, die die Interaktionen des Agenten leiten. Mit dieser Eingabeaufforderung erstellen wir mit der Funktion create_tool_calling_agent einen Tool-aufrufenden Agenten und übergeben dabei unser Sprachmodell (LLM), die Liste der Tools und die Eingabeaufforderung. Schließlich initialisieren wir den Agent-Executor mit AgentExecutor, geben den Agenten und die Tools an und aktivieren den ausführlichen Modus für eine detaillierte Protokollierung. Diese Einrichtung stellt sicher, dass unser LangChain-Agent gut ausgestattet ist, um sowohl die Websuch- als auch die Retrieval-Funktionen zu nutzen und genaue und aktuelle Antworten bereitzustellen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dQix3CKsN7X"},"outputs":[],"source":["tools = [search, retriever_tool]\n","\n","# Holen Sie sich die zu verwendende Eingabeaufforderung – Sie können diese ändern!\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","prompt.messages\n","\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"qy7KYYAPynxP"},"source":["Wir können sehen, wie der Agent auf eine einfache, triviale Eingabeaufforderung reagiert."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mf6hbRpLbdj9","outputId":"6a0c06f1-68b2-4e5f-c5fb-ce5948399699"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["agent_executor.invoke({\"input\": \"hi!\"})\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4ck1qk-NysM-"},"source":["Als nächstes stellen wir ihm eine Frage zu Langsmith. Wir sehen, dass der Agent mehrere Tools verwendet."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEXPEYqMsQ8p","outputId":"747d2c78-dc00-48dc-d306-a1dfa97902cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n","\n","Skip to main contentGo to API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingLangGraph CloudQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\n","\n","score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\n","\n","\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. LangSmith works independently, so the use of LangChain is not necessary. Here are some steps to get started with LangSmith for testing:\n","\n","1. Install LangSmith using Python or TypeScript:\n","   - Python: `pip install -U langsmith`\n","   - TypeScript: `yarn add langchain langsmith`\n","\n","2. Create an API key:\n","   - Head to the Settings page and click on Create API Key.\n","\n","3. Set up your environment:\n","   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and optionally `OPENAI_API_KEY`.\n","\n","4. Log your first trace:\n","   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\n","\n","LangSmith also offers features like creating datasets, examples, and evaluators for testing purposes. It allows you to evaluate your models and test cases efficiently. For more detailed information, you can refer to the LangSmith documentation and tutorials on their website.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'how can langsmith help with testing?',\n"," 'output': 'LangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. LangSmith works independently, so the use of LangChain is not necessary. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith using Python or TypeScript:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and optionally `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\\n\\nLangSmith also offers features like creating datasets, examples, and evaluators for testing purposes. It allows you to evaluate your models and test cases efficiently. For more detailed information, you can refer to the LangSmith documentation and tutorials on their website.'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"]},{"cell_type":"markdown","metadata":{"id":"G8yXee8-y1Cf"},"source":["Wir können ihm auch eine Frage zu aktuellen Ereignissen stellen, woraufhin der Agent zum Suchtool geht."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9CHdOOn2sRlL","outputId":"c91f1743-f95c-45a1-a7c2-ade3c0f8fe84"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.cbsnews.com/philadelphia/news/pa-weather-today-june-8-2024-philadelphia-jersey-shore/', 'content': \"Watch CBS News Beautiful, sunny weather around Philadelphia and Jersey Shore Saturday, rain could return Sunday By Tammie Souza June 8, 2024 / 9:43 AM EDT / CBS Philadelphia PHILADELPHIA (CBS) -- High pressure is in control of the weather here in the Philadelphia area, and it will be a sunny, wonderful day with a light breeze and a high of 83 degrees in the city.  We hit 88 degrees by Thursday and could be passing 90 degrees on Friday and the heat dome over the western U.S. slides east toward us at the end of the week.  Friday could be the start of a stretch of 90-degree days in Philadelphia, even though we haven't even reached the start of astronomical summer yet - that's on June 20 at 4:51 p.m.  68 NEXT Weather Radars Hourly Forecast First published on June 8, 2024 / 9:43 AM EDT \"}, {'url': 'https://www.gjsentinel.com/news/western_colorado/north-ave-back-open-after-law-enforcement-incident/article_f4f03298-034c-11ef-882f-3b2bfc4cc368.html', 'content': 'Low near 50F. Winds SE at 10 to 15 mph. Chance of Rain: 22% Sunrise: 06:15:05 AM Sunset: 08:07:39 PM Humidity: 25% Wind: WSW @ 15 mph UV Index: 8 Very High Partly cloudy skies. Chance of Rain: 63% Sunrise: 06:19:59 AM Sunset: 08:03:49 PM Humidity: 74% Wind: N @ 10 mph UV Index: 3 Moderate Showers in the evening, then partly cloudy overnight. Chance of Rain: 3% Sunrise: 06:16:17 AM Sunset: 08:06:42 PM Humidity: 25% Wind: NW @ 14 mph UV Index: 8 Very High Clear to partly cloudy. Chance of Rain: 24% Sunrise: 06:18:44 AM Sunset: 08:04:47 PM Humidity: 53% Wind: N @ 9 mph UV Index: 8 Very High A few clouds. Chance of Rain: 2% Sunrise: 06:17:30 AM Sunset: 08:05:44 PM Humidity: 32% Wind: SSW @ 13 mph UV Index: 8 Very High A few clouds.'}, {'url': 'https://www.elkintribune.com/apg_sister_paper/yadkin/foreign-investors-must-report-u-s-agricultural-land-holdings/article_a45930c4-0505-58b8-b0d7-14837282eddc.html', 'content': 'Featured Local Savings Recommended for you Trending Now Local Events Chance of Rain: 7% Sunrise: 06:31:38 AM Sunset: 08:09:43 PM Humidity: 63% Wind: SSW @ 9 mph UV Index: 0 Chance of Rain: 58% Sunrise: 06:25:13 AM Sunset: 08:14:49 PM Humidity: 76% Wind: SSE @ 6 mph UV Index: 6 High Considerable cloudiness with occasional rain showers. Chance of Rain: 16% Sunrise: 06:27:16 AM Sunset: 08:13:08 PM Humidity: 58% Wind: SE @ 7 mph UV Index: 7 High Considerable cloudiness with occasional rain showers. Chance of Rain: 58% Sunrise: 06:26:14 AM Sunset: 08:13:59 PM Humidity: 79% Wind: SE @ 6 mph UV Index: 4 Moderate Cloudy with occasional rain showers. Chance of Rain: 24% Sunrise: 06:30:31 AM Sunset: 08:10:34 PM Humidity: 66% Wind: SSW @ 10 mph UV Index: 5 Moderate Cloudy skies early, then partly cloudy after midnight.'}, {'url': 'http://www.sfchronicle.com/weather-forecast/article/california-thunderstorm-dry-lightning-19532152.php', 'content': \"Here's a timeline of impacts Your Daily Puzzles Pile-Up Poker Cross|word Flipart SpellTower Top of the News Exclusive: This troubled S.F. neighborhood could get a monthly block party with outdoor drinking San Francisco has seen the most dramatic drop in solar adoption across California Northern California thunderstorm, dry lightning threat peaks today Giants honor Willie Mays in touching tribute at Oracle Park: ‘He was our guy’ Best Italian restaurants in the Bay Area About Contact Services Account The North Bay, East Bay and Sacramento Valley have the highest chances of thunderstorms during the morning and early afternoon, with the threat shifting northeastward to the Sierra Nevada by the evening. He joins the Chronicle from the University of Washington where he was previously the president of the campus weather forecasting team and an editor at the student newspaper, The Daily UW.  He joins the Chronicle from the University of Washington where he was previously the president of the campus weather forecasting team and an editor at the student newspaper, The Daily UW.  Highs will be in the low 60s in Daly City, Pacifica and Half Moon Bay, mid-to upper 60s in South San Francisco and San Bruno and the mid- to upper 70s in San Mateo and Redwood City.\"}, {'url': 'https://www.cbsnews.com/philadelphia/news/sunny-start-philadelphia-wednesday-weather-passing-storms-possible-new-jersey-delaware/', 'content': \"High of 84, low of 58, warm and sunny Monday: High of 79, low of 65, some sun and a shower Tuesday: High of 84, low of 66, chance for a thunderstorm First published on May 29, 2024 / 5:57 AM EDT  Watch CBS News Sunny start in Philadelphia Wednesday, but some passing storms possible this afternoon By Kate Bilo Updated on: May 29, 2024 / 6:00 AM EDT / CBS Philadelphia PHILADELPHIA (CBS) -- Wednesday starts out with lots of sunshine across the Delaware Valley and high temperatures near 78 degrees.  A few shower chances linger overnight and into Thursday morning, and there's a chance for a sprinkle of a few clouds, but generally the rest of the day will be warm and sunny.  High of 75, low of 58, sunny and cooler Friday: High of 78, low of 55, beautiful day!  The city could get a few rumbles of thunder, but Delaware and the Jersey Shore appear to have the greatest chance of seeing more thunder, lightning and heavier downpours by about 7:30-8 p.m. \"}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently in the low 60s in Daly City, Pacifica, and Half Moon Bay, mid-to upper 60s in South San Francisco and San Bruno, and the mid-to upper 70s in San Mateo and Redwood City. There is a threat of thunderstorms in the North Bay, East Bay, and Sacramento Valley during the morning and early afternoon, with the threat shifting northeastward to the Sierra Nevada by the evening.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'whats the weather in sf?',\n"," 'output': 'The weather in San Francisco is currently in the low 60s in Daly City, Pacifica, and Half Moon Bay, mid-to upper 60s in South San Francisco and San Bruno, and the mid-to upper 70s in San Mateo and Redwood City. There is a threat of thunderstorms in the North Bay, East Bay, and Sacramento Valley during the morning and early afternoon, with the threat shifting northeastward to the Sierra Nevada by the evening.'}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"]},{"cell_type":"markdown","metadata":{"id":"FHvwUtjld_r4"},"source":["## Chatverlauf/Speicher hinzufügen\n","\n","Um die Fähigkeiten unseres LangChain-Agenten zu verbessern, fügen wir einen Chat-Speicher hinzu, damit er sich an frühere Interaktionen erinnern und den Kontext während einer Konversation beibehalten kann. Diese Ergänzung ermöglicht es dem Agenten, kohärentere und kontextbezogenere Antworten zu geben. Wir beginnen mit dem Importieren der erforderlichen Module zum Verwalten von Chat-Nachrichtenverläufen. Dann erstellen wir eine Instanz von ChatMessageHistory, um die während der Konversation ausgetauschten Nachrichten zu speichern. Indem wir unseren vorhandenen Agent-Executor mit RunnableWithMessageHistory umschließen, integrieren wir die Chat-Speicherfunktionalität. Dieses Setup stellt sicher, dass jede Sitzung einen Nachrichtenverlauf beibehalten kann, was reibungslosere und natürlichere Interaktionen mit dem Agenten ermöglicht. Der folgende Codeausschnitt veranschaulicht diese Implementierung:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qHqnYNYZTS3"},"outputs":[],"source":["from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","message_history = ChatMessageHistory()\n","\n","agent_with_chat_history = RunnableWithMessageHistory(\n","    agent_executor,\n","    # Dies ist erforderlich, da in den meisten realen Szenarien eine Sitzungs-ID erforderlich ist\n","    # Es wird hier nicht wirklich verwendet, da wir eine einfache im Speicher befindliche ChatMessageHistory verwenden.\n","    lambda session_id: message_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"9pr4wfiPzc33"},"source":["Wir werden jetzt den Speicher testen. Ich beginne damit, mich vorzustellen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebpiuCU_dhsJ","outputId":"a9c1414e-254f-4e81-9b91-0406226af020"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mHello Jeff! How can I assist you today?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': \"hi! I'm Jeff\",\n"," 'chat_history': [],\n"," 'output': 'Hello Jeff! How can I assist you today?'}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["agent_with_chat_history.invoke(\n","    {\"input\": \"hi! I'm Jeff\"},\n","    # Dies ist erforderlich, da in den meisten realen Szenarien eine Sitzungs-ID erforderlich ist\n","    # Es wird hier nicht wirklich verwendet, da wir eine einfache im Speicher befindliche ChatMessageHistory verwenden.\n","    config={\"configurable\": {\"session_id\": \"x123\"}},\n",")"]},{"cell_type":"markdown","metadata":{"id":"rNNKcKWozhEr"},"source":["Als nächstes stelle ich ihm eine Frage und wir sehen, dass es sich daran erinnert, wer ich bin."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PeWelJPdmn9","outputId":"8b9b6d5f-0acd-4da0-e700-d0db2287713e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n","\n","Skip to main contentGo to API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingLangGraph CloudQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\n","\n","score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\n","\n","\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. Here are some steps to get started with LangSmith for testing:\n","\n","1. Install LangSmith:\n","   - Python: `pip install -U langsmith`\n","   - TypeScript: `yarn add langchain langsmith`\n","\n","2. Create an API key:\n","   - Head to the Settings page and click on Create API Key.\n","\n","3. Set up your environment:\n","   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2` and `LANGCHAIN_API_KEY`.\n","\n","4. Log your first trace:\n","   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing.\n","\n","By following these steps, you can leverage LangSmith for testing your applications effectively.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'how can LangSmith help with testing',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Jeff\"),\n","  AIMessage(content='Hello Jeff! How can I assist you today?')],\n"," 'output': 'LangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2` and `LANGCHAIN_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing.\\n\\nBy following these steps, you can leverage LangSmith for testing your applications effectively.'}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["agent_with_chat_history.invoke(\n","    {\"input\": \"how can LangSmith help with testing\"},\n","    # Dies ist erforderlich, da in den meisten realen Szenarien eine Sitzungs-ID erforderlich ist\n","    # Es wird hier nicht wirklich verwendet, da wir eine einfache im Speicher befindliche ChatMessageHistory verwenden.\n","    config={\"configurable\": {\"session_id\": \"x123\"}},\n",")"]},{"cell_type":"markdown","metadata":{"id":"whx-u4lCzm5B"},"source":["Wir können den Speicher weiter überprüfen und testen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Wgx_TVhdyX5","outputId":"e6a84bdc-099a-4e13-d851-5c6c7efbefc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYou are Jeff, and you just asked me about how LangSmith can help with testing. If you have any more questions or need further assistance, feel free to let me know!\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'Who am I? What did I just ask you about?!',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Jeff\"),\n","  AIMessage(content='Hello Jeff! How can I assist you today?'),\n","  HumanMessage(content='how can LangSmith help with testing'),\n","  AIMessage(content='LangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2` and `LANGCHAIN_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing.\\n\\nBy following these steps, you can leverage LangSmith for testing your applications effectively.')],\n"," 'output': 'You are Jeff, and you just asked me about how LangSmith can help with testing. If you have any more questions or need further assistance, feel free to let me know!'}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["agent_with_chat_history.invoke(\n","    {\"input\": \"Who am I? What did I just ask you about?!\"},\n","    # Dies ist erforderlich, da in den meisten realen Szenarien eine Sitzungs-ID erforderlich ist\n","    # Es wird hier nicht wirklich verwendet, da wir eine einfache im Speicher befindliche ChatMessageHistory verwenden.\n","    config={\"configurable\": {\"session_id\": \"x123\"}},\n",")"]},{"cell_type":"markdown","metadata":{"id":"O7Zxv8hZFxl8"},"source":["# 7.5: Benutzerdefinierte LangChain-Agenten\n","\n","In diesem Abschnitt befassen wir uns mit der Erstellung von benutzerdefinierten Agenten in LangChain. Durch die Entwicklung maßgeschneiderter Tools können wir die Funktionalität unserer Agenten verbessern, um komplexere Aufgaben zu bewältigen. Diese benutzerdefinierten Agenten ermöglichen es uns, Lösungen an spezifische Anforderungen anzupassen und so anspruchsvollere Interaktionen und Problemlösungsfunktionen zu ermöglichen. Durch die Nutzung des flexiblen Frameworks von LangChain können wir diese benutzerdefinierten Tools nahtlos integrieren, um einzigartige Herausforderungen zu bewältigen und die Leistung zu optimieren und so eine robustere und anpassungsfähigere Lösung für komplexe Szenarien bereitzustellen.\n","\n","## Ein einfaches benutzerdefiniertes Tool\n","\n","Wir beginnen mit einem sehr einfachen Tool: einem Knopf, den das Sprachmodell (LLM) drücken kann. Indem wir diesen Knopf bereitstellen, können wir beobachten und bestätigen, dass das LLM tatsächlich damit interagieren kann. Diese grundlegende Interaktion dient als grundlegender Schritt und demonstriert die grundlegenden Fähigkeiten des LLM, Befehle auszuführen. Der folgende Code erstellt ein LLM, wie wir es zuvor getan haben, sodass wir auf dieser grundlegenden Interaktion aufbauen und schrittweise komplexere Tools und Funktionen integrieren können."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RvXin2X3O0K"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","MODEL = 'gpt-4o-mini'\n","\n","llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.2,\n","        n=1\n","    )\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x4tbtkpECGyD"},"source":["Im bereitgestellten Code erstellen wir ein einfaches Agent-Tool, das zum Drücken einer Taste entwickelt wurde. Wir beginnen mit dem Importieren der Tool-Klasse aus dem LangChain-Agentenmodul. Die Kernfunktionalität ist in der Funktion press_button definiert, die ein einzelnes Argument, value, annimmt. Wenn diese Funktion aufgerufen wird, druckt sie den bereitgestellten Wert und gibt die Zeichenfolge „Die Taste leuchtet rot!“ zurück.\n","\n","Als nächstes instanziieren wir ein Tool-Objekt namens button_tool. Wir geben seinen Namen als „button_machine“ an und geben eine Beschreibung an, die seinen Zweck erklärt: Es ist ein großer roter Knopf, der gedrückt werden kann und bei entsprechender Aufforderung einen einzelnen Wert akzeptiert. Der Parameter func wird auf unsere press_button-Funktion gesetzt, wodurch die Aktion des Tools mit unserem definierten Verhalten verknüpft wird. Dieses Setup ermöglicht es dem LLM, mit dem Knopf-Tool zu interagieren, indem es es drückt und die entsprechende Reaktion beobachtet."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTylRLZJ4fZc"},"outputs":[],"source":["from langchain.agents import Tool\n","\n","def press_button(value):\n","print(f\"*************{Wert}\")\n","  return \"The button glows red!\"\n","\n","button_tool = Tool(\n","    name=\"button_machine\",\n","    description=\"A big red button that you can push. You can send a single value to the button, if asked. \",\n","    func=press_button,\n",")"]},{"cell_type":"markdown","metadata":{"id":"TcT-dmNBCbNy"},"source":["In diesem Code konstruieren wir einen Agenten und weisen ihn an, die zuvor definierte Taste zu drücken. Wir beginnen mit dem Importieren der erforderlichen Module und Funktionen, einschließlich Hub von LangChain, create_tool_calling_agent und AgentExecutor. Anschließend ziehen wir eine Eingabeaufforderung aus dem LangChain-Hub, die als Vorlage für die Interaktionen unseres Agenten dient.\n","\n","Wir definieren eine Liste mit dem Namen Tools, die unser zuvor erstelltes Buttontool enthält. Mithilfe der Funktion create_tool_calling_agent erstellen wir einen Agenten, der die von uns angegebenen Tools verwenden kann, geleitet von der Pulled-Eingabeaufforderung. Die Klasse AgentExecutor wird dann verwendet, um einen Agent_Executor zu instanziieren, der den Agenten mit den Tools verknüpft und eine ausführliche Ausgabe für einen besseren Einblick in die Interaktionen ermöglicht.\n","\n","Zum Schluss rufen wir den Agenten mit dem Eingabebefehl auf: „Drücken Sie den großen roten Knopf und sagen Sie mir, was passiert.“ Dieser Befehl weist den Agenten an, das Knopfwerkzeug zu verwenden, und demonstriert so die Fähigkeit des Agenten, die definierte Aktion auszuführen und Feedback zum Ergebnis zu geben."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlU1rtdH4gJv","outputId":"c89ab740-d983-4e57-e60c-0fa2f3761321"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langsmith/client.py:5515: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n","  prompt = loads(json.dumps(prompt_object.manifest))\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `button_machine` with `{'config': {'tags': ['big red button'], 'run_name': 'Push the Big Red Button'}}`\n","\n","\n","\u001b[0m*************{'tags': ['big red button'], 'run_name': 'Push the Big Red Button'}\n","\u001b[36;1m\u001b[1;3mThe button glows red!\u001b[0m\u001b[32;1m\u001b[1;3mWhen you push the big red button, it glows red!\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Push the big red button, tell me what happens.',\n"," 'output': 'When you push the big red button, it glows red!'}"]},"metadata":{},"execution_count":4}],"source":["from langchain import hub\n","from langchain.agents import create_tool_calling_agent\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import AgentExecutor\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [button_tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\": \"Push the big red button, tell me what happens.\"})"]},{"cell_type":"markdown","metadata":{"id":"R6nAGgIY3FFA"},"source":["## Einen einfachen Roboter mit Werkzeugen steuern\n","\n","\n","In diesem Code erstellen wir ein komplexeres Tool mit drei Schaltflächen, die die Bewegung eines kleinen Autos steuern. Wir definieren eine CarTool-Klasse, die die Position (x, y) und Richtung (Nord, Ost, Süd, West) des Autos initialisiert. Die Klasse erstellt außerdem ein Tool-Objekt namens control_panel mit einer Beschreibung, die die Funktionen der drei Schaltflächen erklärt: rot, grün und gelb.\n","\n","Die Klasse CarTool enthält Methoden, um das Auto vorwärts zu bewegen (move_forward), nach links abzubiegen (turn_left) und nach rechts abzubiegen (turn_right). Die Methode press_button verarbeitet Tastendrücke nach Farbe. Durch Drücken der roten Taste bewegt sich das Auto eine Einheit in die aktuelle Richtung vorwärts. Durch Drücken der grünen Taste dreht sich das Auto um 90 Grad nach links und durch Drücken der gelben Taste dreht sich das Auto um 90 Grad nach rechts. Wenn eine ungültige Tastenfarbe gedrückt wird, wird eine Fehlermeldung zurückgegeben.\n","\n","Darüber hinaus liefert die Methode get_position die aktuelle Position und Richtung des Autos. Das Anwendungsbeispiel am Ende zeigt, wie man mit dem CarTool das Auto durch Drücken verschiedener Tasten und die Verarbeitung ungültiger Eingaben steuern kann."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tol8GOGD87U3","outputId":"bf20d698-b5d6-4534-a943-3429baf9ab77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current car position: (0, 1, 'north')\n","The button glows red, you move forward one unit.\n","Current car position: (0, 1, 'west')\n","The button glows green, you turn 90 degrees to the left.\n","Current car position: (0, 1, 'north')\n","The button glows yellow, you turn 90 degrees to the right.\n","Current car position: (0, 1, 'north')\n","The button buzzes, error.\n"]}],"source":["from langchain.tools import StructuredTool\n","from pydantic import BaseModel\n","from langchain import hub\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent\n","from langchain.agents import AgentExecutor\n","\n","# Definieren Sie ein Pydantic-Schema für die Tastendruckeingabe\n","class ButtonPressInput(BaseModel):\n","    button_color: str\n","\n","class CarTool:\n","    def __init__(self):\n","        self.x = 0\n","        self.y = 0\n","        self.direction = 'north'\n","        self.directions = ['north', 'east', 'south', 'west']\n","        self.tool = StructuredTool(\n","            name=\"control_panel\",\n","            description=\"\"\"Three buttons, red, green and yellow that you can push.\n","            The red button moves you forward 1 unit.\n","            The green button turns left 90 degrees,\n","            the yellow button turns right 90 degrees.\"\"\",\n","            func=self.press_button,\n","            args_schema=ButtonPressInput  # Definieren Sie das erwartete Eingabeschema\n","        )\n","\n","    def move_forward(self):\n","        if self.direction == 'north':\n","            self.y += 1\n","        elif self.direction == 'east':\n","            self.x += 1\n","        elif self.direction == 'south':\n","            self.y -= 1\n","        elif self.direction == 'west':\n","            self.x -= 1\n","\n","    def turn_left(self):\n","        current_index = self.directions.index(self.direction)\n","        self.direction = self.directions[(current_index - 1) % 4]\n","\n","    def turn_right(self):\n","        current_index = self.directions.index(self.direction)\n","        self.direction = self.directions[(current_index + 1) % 4]\n","\n","    def press_button(self, button_color: str):\n","        button_color = button_color.strip().lower()\n","        if button_color == 'red':\n","            self.move_forward()\n","            result = \"The button glows red, you move forward one unit.\"\n","        elif button_color == 'green':\n","            self.turn_left()\n","            result = \"The button glows green, you turn 90 degrees to the left.\"\n","        elif button_color == 'yellow':\n","            self.turn_right()\n","            result = \"The button glows yellow, you turn 90 degrees to the right.\"\n","        else:\n","            result = \"The button buzzes, error.\"\n","\n","print(f\"Aktuelle Fahrzeugposition: {self.get_position()}\")\n","        return result\n","\n","    def get_position(self):\n","        return self.x, self.y, self.direction\n","\n","# Beispielverwendung\n","car_tool = CarTool()\n","\n","try:\n","    print(car_tool.tool.func('red'))  # Vorwärts gehen\n","    print(car_tool.tool.func('green'))  # Biegen Sie links ab\n","    print(car_tool.tool.func('yellow'))  # Biegen Sie rechts ab\n","    print(car_tool.tool.func('blue'))  # Ungültige Schaltflächenfarbe, löst ValueError aus\n","except ValueError as e:\n","    print(e)\n"]},{"cell_type":"markdown","metadata":{"id":"Vi3Aa0EvC_AW"},"source":["Wir konstruieren nun einen Agenten und stellen diesem Werkzeug die Aufgabe zu, das Auto aufzufordern, sich in einem Rechteck zu bewegen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHVfoXVcGGHK","outputId":"8537e404-2855-4e55-8e67-1138b766b2b9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'red'}`\n","\n","\n","\u001b[0mCurrent car position: (0, 2, 'north')\n","\u001b[36;1m\u001b[1;3mThe button glows red, you move forward one unit.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'green'}`\n","\n","\n","\u001b[0mCurrent car position: (0, 2, 'west')\n","\u001b[36;1m\u001b[1;3mThe button glows green, you turn 90 degrees to the left.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'red'}`\n","\n","\n","\u001b[0mCurrent car position: (-1, 2, 'west')\n","\u001b[36;1m\u001b[1;3mThe button glows red, you move forward one unit.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'green'}`\n","\n","\n","\u001b[0mCurrent car position: (-1, 2, 'south')\n","\u001b[36;1m\u001b[1;3mThe button glows green, you turn 90 degrees to the left.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'red'}`\n","\n","\n","\u001b[0mCurrent car position: (-1, 1, 'south')\n","\u001b[36;1m\u001b[1;3mThe button glows red, you move forward one unit.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'green'}`\n","\n","\n","\u001b[0mCurrent car position: (-1, 1, 'east')\n","\u001b[36;1m\u001b[1;3mThe button glows green, you turn 90 degrees to the left.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'red'}`\n","\n","\n","\u001b[0mCurrent car position: (0, 1, 'east')\n","\u001b[36;1m\u001b[1;3mThe button glows red, you move forward one unit.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `control_panel` with `{'button_color': 'green'}`\n","\n","\n","\u001b[0mCurrent car position: (0, 1, 'north')\n","\u001b[36;1m\u001b[1;3mThe button glows green, you turn 90 degrees to the left.\u001b[0m\u001b[32;1m\u001b[1;3mThe car has moved in a rectangle as follows:\n","\n","1. Moved forward 1 unit.\n","2. Turned 90 degrees to the left.\n","3. Moved forward 1 unit.\n","4. Turned 90 degrees to the left.\n","5. Moved forward 1 unit.\n","6. Turned 90 degrees to the left.\n","7. Moved forward 1 unit.\n","8. Turned 90 degrees to the left.\n","\n","The car is now back at its starting position, having completed a rectangular path.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Push the buttons in a way that causes the car to move in a rectangle.',\n"," 'output': 'The car has moved in a rectangle as follows:\\n\\n1. Moved forward 1 unit.\\n2. Turned 90 degrees to the left.\\n3. Moved forward 1 unit.\\n4. Turned 90 degrees to the left.\\n5. Moved forward 1 unit.\\n6. Turned 90 degrees to the left.\\n7. Moved forward 1 unit.\\n8. Turned 90 degrees to the left.\\n\\nThe car is now back at its starting position, having completed a rectangular path.'}"]},"metadata":{},"execution_count":6}],"source":["# LLM initialisieren und einen Agenten erstellen\n","MODEL = 'gpt-4o-mini'\n","llm = ChatOpenAI(model=MODEL, temperature=0.2, n=1)\n","\n","prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n","\n","tools = [car_tool.tool]\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","# Rufen Sie den Agenten auf, um das Auto zu steuern\n","agent_executor.invoke({\"input\": \"Push the buttons in a way that causes the car to move in a rectangle.\"})\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"6lsC9cNjV8cM"},"execution_count":null,"outputs":[]}]}