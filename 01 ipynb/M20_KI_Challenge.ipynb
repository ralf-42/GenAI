{"cells":[{"cell_type":"markdown","id":"ef0f8d00","metadata":{"id":"ef0f8d00"},"source":["![GenAI Banner](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)\n"]},{"cell_type":"markdown","source":["\n","<p><font size=\"5\" color='grey'> <b>\n","KI-Challenge\n","</b></font></p>\n","\n","---"],"metadata":{"id":"GntqKmkx33QR"},"id":"GntqKmkx33QR"},{"cell_type":"markdown","source":["\n","\n","# 1 | √úberblick zur KI-Challenge\n","---"],"metadata":{"id":"Fp0AoJKP30fG"},"id":"Fp0AoJKP30fG"},{"cell_type":"markdown","source":["\n","\n","Die KI-Challenge dient als praktische Anwendung und Integration der in den Kursmodulen erlernten Konzepte und Techniken. Ziel ist es, eine funktionsf√§hige KI-Anwendung zu entwickeln, die mehrere Aspekte der generativen KI kombiniert und einen praktischen Nutzen bietet.\n","\n","## 1.1 Lernziele"],"metadata":{"id":"TNprMcD44ATq"},"id":"TNprMcD44ATq"},{"cell_type":"markdown","source":["\n","\n","- Integration mehrerer Technologien aus den Basismodulen\n","- Praktische Anwendung von LLM-basierten L√∂sungen\n","- Entwicklung einer vollst√§ndigen End-to-End-Anwendung\n","- Pr√§sentation und Dokumentation der eigenen L√∂sung\n","\n","## 1.2 Voraussetzungen"],"metadata":{"id":"08Mp1AOC4B8N"},"id":"08Mp1AOC4B8N"},{"cell_type":"markdown","source":["\n","\n","- Abschluss der Basismodule (Module 1-12)\n","- Module aus dem Bereich Erweiterung\n","- Kenntnisse in Python und LangChain\n","- Zugriff auf API-Keys (OpenAI, Hugging Face)\n","- Grundlegende Vertrautheit mit Gradio f√ºr UI-Entwicklung\n","\n","# 2 | Projektoptionen\n","---"],"metadata":{"id":"u8BtUku94DL2"},"id":"u8BtUku94DL2"},{"cell_type":"markdown","source":["\n","\n","Zur Auswahl stehen vier verschiedene Projekttypen, die jeweils unterschiedliche Aspekte der generativen KI betonen. W√§hlen Sie eine Option aus oder kombinieren Sie Elemente verschiedener Optionen.\n","\n","## 2.1 Dokumentenanalyse-Assistent"],"metadata":{"id":"AgPfXYvB4FBH"},"id":"AgPfXYvB4FBH"},{"cell_type":"markdown","source":["\n","\n","**Beschreibung:** Ein System, das PDF-Dokumente, Word-Dateien oder Textdateien verarbeitet und intelligente Zusammenfassungen, Antworten auf Fragen oder strukturierte Analysen liefert.\n","\n","**Kernelemente:**\n","- RAG-Pipeline mit Vektordatenbank (ChromaDB)\n","- Dokumentenverarbeitung und Chunking\n","- Intelligentes Prompting f√ºr die Analyse\n","- Benutzeroberfl√§che mit Gradio\n","\n","**Erwartete Module:**\n","- Modul 4 (LangChain)\n","- Modul 7 (Output Parser)\n","- Modul 8 (RAG)\n","- Modul 11 (Gradio)\n","\n","## 2.2 Multimodaler Assistent"],"metadata":{"id":"s2PcLayb4GcA"},"id":"s2PcLayb4GcA"},{"cell_type":"markdown","source":["\n","\n","**Beschreibung:** Ein Assistent, der Bild, Text und optional Audio verarbeiten kann, um komplexe Aufgaben zu erf√ºllen oder Informationen zu analysieren.\n","\n","**Kernelemente:**\n","- Integration von Bild- und Texterkennung\n","- Multimodale Prompt-Strategien\n","- Kontextbewusste Antworten\n","- Interaktive Benutzeroberfl√§che\n","\n","**Erwartete Module:**\n","- Modul 5 (LLMs und Transformer)\n","- Modul 6 (Chat und Memory)\n","- Modul 9 (Multimodal Bild)\n","- Modul 14 (optional: Multimodal Audio)\n","\n","## 2.3 Agentenbasiertes System"],"metadata":{"id":"yY2KGAqt4IER"},"id":"yY2KGAqt4IER"},{"cell_type":"markdown","source":["\n","\n","**Beschreibung:** Ein System mit mehreren spezialisierten Agenten, die zusammenarbeiten, um komplexe Aufgaben zu l√∂sen oder Workflow-Prozesse zu automatisieren.\n","\n","**Kernelemente:**\n","- Multi-Agenten-Architektur\n","- Werkzeugintegration (APIs, Datenbanken)\n","- Planung und Zielverfolgung\n","- Benutzerinteraktion und Transparenz\n","\n","**Erwartete Module:**\n","- Modul 3 (Codieren mit GenAI)\n","- Modul 10 (Agents)\n","- Modul 12 (Lokale Modelle)\n","- Modul 18 (optional: Advanced Prompt Engineering)\n","\n","## 2.4 Dom√§nenen Fachexperte"],"metadata":{"id":"Xa9sAZ6W4MYB"},"id":"Xa9sAZ6W4MYB"},{"cell_type":"markdown","source":["\n","\n","**Beschreibung:** Ein spezialisierter Assistent f√ºr ein bestimmtes Fachgebiet (z.B. Recht, Medizin, Finanzen, Marketing), der tiefgreifendes Fachwissen bereitstellt und dom√§nenspezifische Aufgaben l√∂st.\n","\n","**Kernelemente:**\n","- Fachspezifische Wissensdatenbank\n","- Spezialisierte Prompts und Output-Strukturen\n","- Benutzeroberfl√§che f√ºr Fachexperten\n","- Optional: Feinabstimmung eines bestehenden Modells\n","\n","**Erwartete Module:**\n","- Modul 2 (Grundlagen Modellansteuerung)\n","- Modul 8 (RAG)\n","- Modul 16 (optional: Fine-Tuning)\n","- Modul 19 (optional: EU AI Act/Ethik)\n","\n","# 3 | Projekt-Setup\n","---"],"metadata":{"id":"RRkyw5Hq4P9I"},"id":"RRkyw5Hq4P9I"},{"cell_type":"markdown","source":["\n","\n","Hier finden Sie den Code f√ºr das grundlegende Setup Ihres Projekts, √§hnlich wie in den Kursmodulen."],"metadata":{"id":"oOCse_QV4R03"},"id":"oOCse_QV4R03"},{"cell_type":"code","execution_count":null,"id":"9dcaa45c","metadata":{"cellView":"form","id":"9dcaa45c"},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  Colab-Umfeld</font> </br></p>\n","# Installierte Python Version\n","import sys\n","print(f\"Python Version: \",sys.version)\n","# Installierte LangChain Bibliotheken\n","print()\n","print(\"Installierte LangChain Bibliotheken:\")\n","\n","!pip list | grep '^langchain'\n","# Unterdr√ºckt die \"DeprecationWarning\" von LangChain f√ºr die Memory-Funktionen\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langsmith.client\")"]},{"cell_type":"code","execution_count":null,"id":"969e87a4","metadata":{"cellView":"form","id":"969e87a4"},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  SetUp API-Keys (setup_api_keys)</font> </br></p>\n","def setup_api_keys():\n","    \"\"\"Konfiguriert alle ben√∂tigten API-Keys aus Google Colab userdata\"\"\"\n","    from google.colab import userdata\n","    import os\n","    from os import environ\n","\n","    # Dictionary der ben√∂tigten API-Keys\n","    keys = {\n","        'OPENAI_API_KEY': 'OPENAI_API_KEY',\n","        'HF_TOKEN': 'HF_TOKEN',\n","        # Weitere Keys bei Bedarf\n","    }\n","\n","    # Keys in Umgebungsvariablen setzen\n","    for env_var, key_name in keys.items():\n","        environ[env_var] = userdata.get(key_name)\n","\n","    return {k: environ[k] for k in keys.keys()}\n","\n","# Verwendung\n","all_keys = setup_api_keys()\n","# Bei Bedarf einzelne Keys direkt zugreifen\n","# WEATHER_API_KEY = all_keys['WEATHER_API_KEY']"]},{"cell_type":"markdown","id":"c1160047","metadata":{"id":"c1160047"},"source":["# 4 | Projektstruktur\n","---"]},{"cell_type":"markdown","source":["\n","\n","Eine erfolgreiche KI-Challenge sollte folgende Komponenten enthalten:"],"metadata":{"id":"XnkxJ1uR4Ul2"},"id":"XnkxJ1uR4Ul2"},{"cell_type":"markdown","source":["\n","\n","## 4.1 Problemdefinition und Anforderungen\n","\n","\n","- Klare Beschreibung des Problems oder der Aufgabe\n","- Definition der Anforderungen und Erfolgskriterien\n","- Abgrenzung des Projektumfangs\n","\n"],"metadata":{"id":"Ls5GtntQ4box"},"id":"Ls5GtntQ4box"},{"cell_type":"markdown","source":["## 4.2 Datenstrukturen und Modellauswahl\n","\n","- Auswahl und Begr√ºndung der verwendeten Modelle\n","- Datenstrukturen und Datenvorbereitung\n","- Embedding-Strategien (bei RAG-Anwendungen)\n","\n"],"metadata":{"id":"-VKfYqzv4Zyq"},"id":"-VKfYqzv4Zyq"},{"cell_type":"markdown","source":["## 4.3 Implementierung der Kernfunktionalit√§t\n","\n","- LangChain-Pipelines oder -Ketten\n","- Prompt-Engineering und Templates\n","- Integration mit externen APIs oder Datenquellen\n","\n"],"metadata":{"id":"YYK275D_4e1o"},"id":"YYK275D_4e1o"},{"cell_type":"markdown","source":["## 4.4 Benutzeroberfl√§che und Interaktion\n","\n","- Gradio-Interface f√ºr die Interaktion\n","- Benutzerf√ºhrung und Feedback\n","- Fehlerbehandlung und Robustheit\n","\n"],"metadata":{"id":"CFRsUnGQ4gen"},"id":"CFRsUnGQ4gen"},{"cell_type":"markdown","source":["## 4.5 Evaluation und Tests\n","\n","- Testf√§lle f√ºr verschiedene Szenarien\n","- Bewertung der Modellleistung\n","- Benutzerfeedback und Verbesserungen\n","\n"],"metadata":{"id":"rYVs7ITs4huz"},"id":"rYVs7ITs4huz"},{"cell_type":"markdown","source":["## 4.6 Dokumentation und Pr√§sentation\n","\n","- Projektdokumentation (Markdown oder PDF)\n","- Code-Kommentare und Erkl√§rungen\n","- Pr√§sentation der Ergebnisse\n","\n"],"metadata":{"id":"kQstyJKa4jMg"},"id":"kQstyJKa4jMg"},{"cell_type":"markdown","source":["# 5 | Bewertungskriterien\n","---"],"metadata":{"id":"K5VKtyxi4kiV"},"id":"K5VKtyxi4kiV"},{"cell_type":"markdown","source":["\n","\n","Die KI-Challenge kann anhand folgender Kriterien bewertet:\n","\n","| Kriterium | Beschreibung | Gewichtung |\n","|-----------|--------------|------------|\n","| Funktionalit√§t | Die Anwendung erf√ºllt die definierten Anforderungen und funktioniert zuverl√§ssig | 30% |\n","| Integration | Erfolgreiche Kombination mehrerer Technologien und Module aus dem Kurs | 25% |\n","| Code-Qualit√§t | Sauberer, lesbarer und gut strukturierter Code mit angemessenen Kommentaren | 15% |\n","| Innovation | Kreative L√∂sungsans√§tze und eigenst√§ndige Weiterentwicklung der Konzepte | 15% |\n","| Dokumentation | Vollst√§ndige und verst√§ndliche Dokumentation des Projekts | 15% |\n"],"metadata":{"id":"I2gl0PNO4lvs"},"id":"I2gl0PNO4lvs"},{"cell_type":"markdown","source":["\n","# 6 | Beispielprojekt: Doku-Assi\n","---"],"metadata":{"id":"Jp33Cjt74o1t"},"id":"Jp33Cjt74o1t"},{"cell_type":"markdown","source":["\n","\n","Als Orientierung dient hier ein vereinfachtes Beispiel f√ºr einen Dokumentenanalyse-Assistenten:"],"metadata":{"id":"UOL3wE-K4qGI"},"id":"UOL3wE-K4qGI"},{"cell_type":"code","execution_count":null,"id":"8c594b9b","metadata":{"lines_to_next_cell":2,"id":"8c594b9b"},"outputs":[],"source":["# Import der ben√∂tigten Bibliotheken\n","import os\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.chat_models import ChatOpenAI\n","from langchain.retrievers.multi_query import MultiQueryRetriever\n","from langchain.chains import ConversationalRetrievalChain\n","import gradio as gr\n","\n","# API-Keys einrichten\n","os.environ[\"OPENAI_API_KEY\"] = \"Ihr-OpenAI-Key\"\n","\n","# Funktion zum Laden und Verarbeiten von Dokumenten\n","def load_and_process_document(file_path):\n","    \"\"\"\n","    L√§dt ein PDF-Dokument und bereitet es f√ºr die Verarbeitung vor\n","\n","    Args:\n","        file_path: Pfad zur PDF-Datei\n","\n","    Returns:\n","        Chroma-Vektordatenbank mit den Dokumentenchunks\n","    \"\"\"\n","    # PDF laden\n","    loader = PyPDFLoader(file_path)\n","    pages = loader.load()\n","\n","    # Text in Chunks aufteilen\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=1000,\n","        chunk_overlap=100\n","    )\n","    chunks = text_splitter.split_documents(pages)\n","\n","    # Embeddings erstellen und Vektorstore initialisieren\n","    embeddings = OpenAIEmbeddings()\n","    vectorstore = Chroma.from_documents(\n","        documents=chunks,\n","        embedding=embeddings\n","    )\n","\n","    return vectorstore\n","\n","# Chat-Modell und Retrieval-Kette initialisieren\n","def setup_qa_chain(vectorstore):\n","    \"\"\"\n","    Erstellt eine Konversations-Retrieval-Kette f√ºr Frage-Antwort-Interaktionen\n","\n","    Args:\n","        vectorstore: Chroma-Vektordatenbank\n","\n","    Returns:\n","        ConversationalRetrievalChain f√ºr QA\n","    \"\"\"\n","    # LLM initialisieren\n","    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n","\n","    # Retriever mit Multi-Query-Strategie\n","    retriever = MultiQueryRetriever.from_llm(\n","        vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n","        llm\n","    )\n","\n","    # QA-Kette erstellen\n","    qa_chain = ConversationalRetrievalChain.from_llm(\n","        llm=llm,\n","        retriever=retriever,\n","        return_source_documents=True\n","    )\n","\n","    return qa_chain\n","\n","# Gradio-Interface f√ºr die Benutzerinteraktion\n","def create_interface():\n","    \"\"\"\n","    Erstellt ein Gradio-Interface f√ºr die Benutzerinteraktion\n","\n","    Returns:\n","        Gradio-Interface\n","    \"\"\"\n","    # Zustandsvariablen\n","    state = {\n","        \"qa_chain\": None,\n","        \"chat_history\": []\n","    }\n","\n","    # PDF-Upload-Funktion\n","    def upload_pdf(file):\n","        try:\n","            vectorstore = load_and_process_document(file.name)\n","            state[\"qa_chain\"] = setup_qa_chain(vectorstore)\n","            state[\"chat_history\"] = []\n","            return \"Dokument erfolgreich geladen und verarbeitet!\"\n","        except Exception as e:\n","            return f\"Fehler beim Laden des Dokuments: {str(e)}\"\n","\n","    # Frage-Antwort-Funktion\n","    def ask_question(question):\n","        if state[\"qa_chain\"] is None:\n","            return \"Bitte laden Sie zuerst ein Dokument hoch.\"\n","\n","        try:\n","            result = state[\"qa_chain\"](\n","                {\"question\": question, \"chat_history\": state[\"chat_history\"]}\n","            )\n","\n","            # Chat-Historie aktualisieren\n","            state[\"chat_history\"].append((question, result[\"answer\"]))\n","\n","            # Quellen hinzuf√ºgen\n","            sources = set()\n","            for doc in result[\"source_documents\"]:\n","                page_content = doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content\n","                sources.add(f\"Quelle (Seite {doc.metadata.get('page', 'N/A')}): {page_content}\")\n","\n","            sources_text = \"\\n\\n\".join(sources)\n","            full_response = f\"{result['answer']}\\n\\n---\\n\\nVerwendete Quellen:\\n{sources_text}\"\n","\n","            return full_response\n","        except Exception as e:\n","            return f\"Fehler bei der Verarbeitung der Frage: {str(e)}\"\n","\n","    # Gradio-Interface erstellen\n","    with gr.Blocks(title=\"Dokumentenanalyse-Assistent\") as interface:\n","        gr.Markdown(\"# üìö Dokumentenanalyse-Assistent\")\n","        gr.Markdown(\"Laden Sie ein PDF-Dokument hoch und stellen Sie Fragen dazu.\")\n","\n","        with gr.Row():\n","            with gr.Column():\n","                file_input = gr.File(label=\"PDF-Dokument hochladen\")\n","                upload_button = gr.Button(\"Dokument verarbeiten\")\n","                status_text = gr.Textbox(label=\"Status\", interactive=False)\n","\n","            with gr.Column():\n","                question_input = gr.Textbox(label=\"Ihre Frage zum Dokument\", placeholder=\"Stellen Sie eine Frage zum Inhalt des Dokuments...\")\n","                answer_output = gr.Textbox(label=\"Antwort\", interactive=False, lines=15)\n","                ask_button = gr.Button(\"Frage stellen\")\n","\n","        # Ereignisbehandlung\n","        upload_button.click(upload_pdf, inputs=[file_input], outputs=[status_text])\n","        ask_button.click(ask_question, inputs=[question_input], outputs=[answer_output])\n","\n","    return interface\n","\n","# Hauptfunktion\n","def main():\n","    interface = create_interface()\n","    interface.launch(share=True)\n","\n","# Ausf√ºhrung\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","id":"f57f1703","metadata":{"id":"f57f1703"},"source":["# 7 | Ressourcen und Hilfestellung\n","---"]},{"cell_type":"markdown","source":["\n","\n","Folgende Ressourcen k√∂nnen bei der Entwicklung des KI-Challenge hilfreich sein:\n","\n","- **Dokumentation:**\n","  - [LangChain Dokumentation](https://python.langchain.com/docs/get_started/introduction)\n","  - [OpenAI API Dokumentation](https://platform.openai.com/docs/api-reference)\n","  - [Hugging Face Dokumentation](https://huggingface.co/docs)\n","  - [Gradio Dokumentation](https://www.gradio.app/docs/interface)\n","\n","- **Beispielprojekte und Tutorials:**\n","  - LangChain Cookbook im GitHub-Repository\n","  - Beispiel-Implementierungen aus den Kursmodulen\n","  - Hugging Face Spaces f√ºr Beispielanwendungen\n","\n","- **Online-Tools:**\n","  - GenAI Tutor auf ChatGPT\n","  - ChatBots, wie ChatGPT oder Gemini\n","  - ...\n","\n","\n","Fragen oder Problemen w√§hrend der Projektentwicklung k√∂nnen im `Kurs-Forum` besprochen werden."],"metadata":{"id":"OTDYAE7N4s3h"},"id":"OTDYAE7N4s3h"},{"cell_type":"markdown","id":"395e6a5d","metadata":{"id":"395e6a5d"},"source":["<p><font color='green' size=\"7\">\n","\n","  üèÖ Viel Spa√ü & Erfolg!\n","\n","</font></p>"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}