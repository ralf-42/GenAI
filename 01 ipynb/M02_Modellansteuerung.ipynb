{"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"8x1hrQqQ27a3"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 02: Grundlagen Modellansteuerung\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/ralf-42/GenAI/blob/main/01%20ipynb/M02_Modellansteuerung.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"],"metadata":{"id":"_bPnjE4mHxeC"}},{"cell_type":"markdown","source":["# **1 <font color='orange'>|</font> Überblick**\n","---\n"],"metadata":{"id":"PHDCKRbtgVXy"}},{"cell_type":"markdown","source":["Die rasante Entwicklung im Bereich der künstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei großen Sprachmodellen (LLMs) geführt. Diese Modelle können menschenähnlichen Text generieren, Sprachen übersetzen und komplexe Fragen beantworten. Doch wie genau steuert man diese Modelle, um die gewünschten Ergebnisse zu erzielen? In diesem Modul werden wir drei gängige Methoden der Modellansteuerung untersuchen: Prompting, Retrieval-Augmented Generation (RAG) und Fine-Tuning.\n","\n"],"metadata":{"id":"lSg1eGf95Vz1"}},{"cell_type":"markdown","source":["## **1.1 <font color='orange'>|</font> Prompting**\n","---"],"metadata":{"id":"owVDrCRD5hoI"}},{"cell_type":"markdown","source":["\n","\n","Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte \"Prompt\", gegeben, der die gewünschte Ausgabe beschreibt. Die Qualität der Ausgabe hängt stark von der Qualität des Prompts ab. Ein gut formulierter Prompt sollte klar, prägnant und spezifisch sein.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt einen Prompt in das LLM ein.\n","+ Das LLM verarbeitet den Prompt und generiert eine Antwort basierend auf seinem Training und den im Prompt enthaltenen Informationen\n","\n","**Arten von Prompts:**\n","\n","Es gibt verschiedene Arten von Prompts, die verwendet werden können, um bestimmte Reaktionen vom Modell hervorzurufen:\n","\n","+ Verbale Prompts: Dies sind gesprochene oder geschriebene Anweisungen. Zum Beispiel: \"Schreibe eine kurze Geschichte über eine Katze, die zum Mond fliegt.\"\n","+ Visuelle Prompts: Dies können Bilder oder andere visuelle Elemente sein. Zum Beispiel: Ein Bild einer Katze, die in den Weltraum startet, könnte als Prompt für eine Geschichte über eine Katze dienen, die zum Mond fliegt.\n","\n","**Prompt Chaining:**\n","\n","Prompt Chaining ist eine Technik, bei der eine Reihe von Prompts verwendet wird, um das Modell durch mehrere Schritte zu führen oder komplexere Ausgaben zu generieren. Zum Beispiel könnte ein erster Prompt das Modell anweisen, eine Liste von Themen zu generieren, ein zweiter Prompt es dann auffordern, eines dieser Themen auszuwählen und einen Aufsatz darüber zu schreiben.\n","\n","**Einsatzszenarien:**\n","\n","Prompting eignet sich besonders für Aufgaben, die schnell und flexibel erledigt werden müssen, wie z. B.:\n","\n","+ Textgenerierung\n","+ Übersetzung\n","+ Zusammenfassung\n","+ Brainstorming\n","+ Beantwortung allgemeiner Fragen\n","+ ..."],"metadata":{"id":"o7lp262M4u0Z"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Eingabeaufforderungen verstehen\n","</font></p>"],"metadata":{"id":"DlkRGwcR3rBp"}},{"cell_type":"markdown","source":["\n","\n","Wir werden uns die vier Hauptkomponenten der meisten Eingabeaufforderungen ansehen. Viele Eingabeaufforderungen erfordern nicht alle vier Elemente. Ihre Form hängt von der Aufgabe ab. Wir werden bald weitere Beispiele behandeln. Die meisten Eingabeaufforderungen bestehen aus den folgenden Teilen:\n","\n","* **Anweisungen** Beschreibt eine Aufgabe für das Modell. Dies kann eine Aufgabenbeschreibung oder eine Anweisung zur Ausführung des Modells sein.\n","* **Kontext** Externe Informationen zur Orientierung des Modells.\n","* **Eingabedaten** Die Eingabe, für die wir eine Antwort wünschen.\n","* **Ausgabeindikator** Normalerweise gibt der letzte Teil der Eingabeaufforderung an, dass die Ausgabe des Modells folgen soll."],"metadata":{"id":"nUJCfQ_-71Ti"}},{"cell_type":"markdown","source":["Nachfolgend sehen Sie ein Beispiel für eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n","\n","```\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage für Körpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8 herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die Nachverfolgung mühelos. Die Funktionen zur Essensplanung und Kalorienzählung der App sind unglaublich benutzerfreundlich. Ich bin absolut begeistert! Außerdem hat die Waage ein elegantes, modernes Erscheinungsbild, das wirklich attraktiv ist.\n","Zusammenfassung: ...\n","```\n","\n","Diese Eingabeaufforderung erzeugt möglicherweise die folgende Ausgabe:\n","\n","```\n","Die intelligente digitale Personenwaage wird für ihre schnelle Einrichtung, die einfache Synchronisierung mit ihrer App auf älteren Telefonen zur mühelosen Nachverfolgung, die benutzerfreundlichen Funktionen zur Essensplanung und Kalorienzählung sowie ihr schlankes, modernes Design hoch gelobt.\n","```"],"metadata":{"id":"rj5-ap_p4Htg"}},{"cell_type":"markdown","source":["**Anweisung:** Fassen Sie die folgende Produktbewertung in einem Satz zusammen:   \n","**Kontext:** Produkt: Intelligente digitale Personenwaage für Körpergewicht, Fett, BMI, Muskelmassezusammensetzung   \n","**Eingabedaten:** Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8 herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die Nachverfolgung mühelos. Die Funktionen zur Essensplanung und Kalorienzählung der App sind unglaublich benutzerfreundlich. Ich bin absolut begeistert! Außerdem hat die Waage ein elegantes, modernes Erscheinungsbild, das wirklich attraktiv ist.   \n","**Ausgabeindikator:** Zusammenfassung: ..."],"metadata":{"id":"x9aWyG4I5Ek8"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Zero-Shot-Prompt-Muster\n","</font></p>"],"metadata":{"id":"bZx_1oke3vCw"}},{"cell_type":"markdown","source":["\n","\n","Zero-Shot-Prompting beschreibt die Technik, bei der wir einem LLM eine Aufgabe präsentieren, ohne ihm weitere Beispiele zu geben. Wir erwarten daher, dass es die Aufgabe ausführt, ohne vorher einen „Versuch“ zur Aufgabe zu bekommen. Daher „Zero-Shot“-Prompting. Moderne LLMs zeigen, dass Programmierer eine bemerkenswerte Zero-Shot-Leistung erzielen können und dass eine positive Korrelation zwischen Modellgröße und Zero-Shot-Leistung besteht.\n","\n","```\n","Human:\n","Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n","Assistant: the chemical1 and chemical 2 are:\n","```\n","\n","Das Modell könnte die folgende Ausgabe erzeugen:\n","\n","```\n","Sulfuric acid (H₂SO₄) reacts with sodium chloride (NaCl) to produce:\n","\n","+ Chemical 1: Hydrogen chloride (HCl)\n","+ Chemical 2: Sodium bisulfate (NaHSO₄) (or Sodium sulfate (Na₂SO₄) depending on the reaction conditions)\n","```\n","\n"],"metadata":{"id":"AI2Y4qcF78j4"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Few-Shot-Prompting-Muster\n","</font></p>"],"metadata":{"id":"nLFUY2x632cr"}},{"cell_type":"markdown","source":["\n","\n","Beim Few-Shot-Prompting werden dem Modell anhand von Beispielen mehr Informationen über die anstehenden Aufgaben gegeben. Es kann für kontextbezogenes Lernen verwendet werden, indem Beispiele der Aufgabe und des gewünschten Ergebnisses bereitgestellt werden. Daher können wir das Modell anhand der Beispiele konditionieren, damit es den Aufgabenanweisungen genauer folgt.\n","\n","Sie können die folgende Eingabeaufforderung verwenden, um die Stimmung von Tweets mithilfe des Eingabeaufforderungsmusters „Few-Shot“ als positiv oder negativ zu klassifizieren.\n","\n","```\n","Tweet: „Habe das Jobangebot bekommen, auf das ich gewartet habe. Überglücklich!“ Stimmung: Positiv\n","Tweet: „Habe meine Fahrprüfung beim ersten Versuch bestanden. Ich bin so glücklich!“ Stimmung: Positiv\n","Tweet: „Der Film war reine Zeitverschwendung. Nie wieder.“ Stimmung: Negativ\n","Tweet: „Steckte stundenlang im Stau. Warum ich?“ Stimmung: Negativ\n","Tweet: „Was für ein schöner Morgen, um in den Tag zu starten!“ Stimmung:\n","```\n","\n","Der LLM würde diese Aufforderung wahrscheinlich wie folgt fortsetzen:\n","\n","```\n","Positive\n","```\n"],"metadata":{"id":"BTX8nsvE8CSr"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code Beispiel\n","</font></p>"],"metadata":{"id":"yD8yi1td35er"}},{"cell_type":"code","source":["!uv pip install --system -q langchain_openai"],"metadata":{"id":"dXE534fDMNHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","OPENAI_API_KEY = userdata.get('OpenAI-API-Key')\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"],"metadata":{"id":"imil8moAL7e0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMF-rtxgRAea"},"outputs":[],"source":["from langchain_core.messages import HumanMessage, SystemMessage\n","from langchain_core.prompts.chat import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    SystemMessagePromptTemplate,\n",")\n","from langchain_openai import ChatOpenAI\n","\n","messages = [\n","    SystemMessage(\n","        content=\"You are a helpful assistant that.\"\n","    ),\n","    HumanMessage(\n","        content=\\\n","\"\"\"\n","Human:\n","Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n","Assistant: the chemical1 and chemical 2 are:\n","\"\"\"\n","    ),\n","]\n","\n","MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  # Modell=\"gpt-4o-mini\",\n","  temperature= 0.0,\n","  n= 1,\n","  max_tokens= 256)\n","\n","print(\"Model response:\")\n","output = llm.invoke(messages)\n","print(output.content)\n","print(\"-----------\")\n","print(output.response_metadata)"]},{"cell_type":"markdown","source":["🤿DeepDive in Modul 14"],"metadata":{"id":"FqlYM5ONIXne"}},{"cell_type":"markdown","source":["## **1.2 <font color='orange'>|</font> RAG**\n","---"],"metadata":{"id":"L0grUpA56y3K"}},{"cell_type":"markdown","source":["RAG (Retrieval-Augmented Generation) ist eine hybride Methode, die die Stärken von LLMs mit denen von Information-Retrieval-Systemen kombiniert. Dabei greift das LLM auf externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n","+ Das System sucht mithilfe von Embedding Language Models und Vektor Datenbanken in externen Wissensdatenbanken nach relevanten Informationen.\n","+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n","+ Das LLM generiert eine Antwort basierend auf der Anfrage und dem Kontext.\n","\n","\n","**Einsatzszenarien:**\n","\n","RAG eignet sich besonders für Aufgaben, die aktuelle oder domänenspezifische Informationen erfordern, wie z. B.:\n","\n","+ Kundensupport mit Zugriff auf Produktdatenbanken\n","+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n","+ Finanzplanung mit Zugriff auf Marktdaten\n","+ Beantwortung von Fragen zu Unternehmensinformationen\n","\n"],"metadata":{"id":"EbmfDWKg4xmC"}},{"cell_type":"markdown","source":["🤿DeepDive in Modul 07"],"metadata":{"id":"sp6RcCyJH4l4"}},{"cell_type":"markdown","source":["## **1.3 <font color='orange'>|</font> Fine-Tuning**\n","---"],"metadata":{"id":"iQpWHr88612f"}},{"cell_type":"markdown","source":["Fine-Tuning ist eine Methode, bei der ein bereits trainiertes LLM auf einer kleineren, aufgabenspezifischen Datenmenge weiter trainiert wird. Dadurch kann das Modell an spezifische Anforderungen angepasst und seine Leistung für diese Aufgaben verbessert werden.\n","\n","**Funktionsweise:**\n","\n","+ Ein vortrainiertes LLM wird ausgewählt.\n","+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n","+ Das LLM wird auf dieser Datenmenge weiter trainiert.\n","+ Die Parameter des LLM werden angepasst, um die Leistung für die spezifische Aufgabe zu optimieren.\n","\n","**Methoden des Fine-Tunings:**\n","\n","Es gibt verschiedene Methoden, um ein LLM zu fine-tunen:\n","\n","+ Instruction Fine-Tuning: Das Modell wird mit Beispielen trainiert, die zeigen, wie es auf bestimmte Anfragen reagieren soll. Zum Beispiel könnte man dem Modell Anweisungen wie \"Fasse diesen Text zusammen\" geben, gefolgt von dem eigentlichen Text.\n","+ Weitere Methoden: Es gibt noch weitere Fine-Tuning-Methoden, die je nach Anwendungsfall und Zielsetzung eingesetzt werden können.\n","\n","\n","**Einsatzszenarien:**\n","\n","Fine-Tuning eignet sich besonders für Aufgaben, die eine hohe Genauigkeit und Domänenspezialisierung erfordern, wie z. B.:\n","\n","+ Sentimentanalyse\n","+ Textklassifizierung\n","+ Spam-Erkennung\n","+ Personalisierte Kundeninteraktionen\n","\n"],"metadata":{"id":"WEyWOZtP40s0"}},{"cell_type":"markdown","source":["🤿DeepDive in Modul 13"],"metadata":{"id":"_EjuZ4MrIGYg"}},{"cell_type":"markdown","source":["\n","# **2 <font color='orange'>|</font> Entscheidungskriterien**\n","---"],"metadata":{"id":"EU_aZQuK5kfc"}},{"cell_type":"markdown","source":["Die Wahl der geeigneten Methode hängt von verschiedenen Faktoren ab, darunter:"],"metadata":{"id":"w4I1UPS97apC"}},{"cell_type":"markdown","source":["\n","| Kriterium | Prompting | RAG | Fine-Tuning |\n","|-----------|-----------|-----|-------------|\n","| **Komplexität** | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>Änderungen am Modell. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n","| **Effizienz** | Hoch<br><br>Prompting ermöglicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Mittel<br><br>RAG benötigt zusätzliche<br>Schritte für den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n","| **Genauigkeit** | Niedrig<br><br>Die Genauigkeit hängt stark<br>von der Qualität des<br>Prompts ab. | Mittel<br><br>RAG bietet höhere<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>Führt zu höherer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n","| **Flexibilität** | Hoch<br><br>Sehr flexibel und für<br>verschiedene Aufgaben<br>einsetzbar. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsfähig. |\n","| **Ressourcen-<br>bedarf** | Niedrig<br><br>Benötigt nur minimale<br>Ressourcen für die<br>Ausführung. | Mittel<br><br>Ressourcen für Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>für Training. |\n","| **Datenbedarf** | Niedrig<br><br>Keine zusätzlichen<br>Trainingsdaten<br>erforderlich. | Mittel<br><br>Benötigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Benötigt große Mengen an<br>spezifischen<br>Trainingsdaten. |\n","| **Beschreibung** | Einfache Methode mit<br>Textanweisungen für das<br>Modell. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datensätzen. |\n","\n"],"metadata":{"id":"rSAuP0cW54O1"}},{"cell_type":"markdown","source":["\n","# **3 <font color='orange'>|</font> Trade-offs**\n","---"],"metadata":{"id":"mbzWylUi5qtI"}},{"cell_type":"markdown","source":["\n","\n","Bei der Wahl zwischen den verschiedenen Modellansteuerungstechniken gibt es immer Trade-offs, die berücksichtigt werden müssen:\n","\n","- **Kosteneffizienz**: Fine-Tuning ist kostspieliger, da es nicht nur erhebliche Rechenressourcen erfordert, sondern auch Zeit, um ein Modell zu trainieren. RAG bietet einen Mittelweg, da es externe Daten nutzt, ohne dass ein vollständiges Modell neu trainiert werden muss. Prompting ist hingegen am kostengünstigsten, da es keine zusätzlichen Trainingsphasen erfordert.\n","\n","- **Flexibilität**: Fine-Tuning bietet die höchste Flexibilität, da es das Modell vollständig an die speziellen Anforderungen anpassen kann. RAG bietet ebenfalls Flexibilität, allerdings hängt die Qualität der Ergebnisse stark von der Qualität der externen Daten ab. Prompting ist flexibler in der Formulierung der Anfragen, hat jedoch in komplexen Szenarien oft Einschränkungen in der Präzision und Tiefe der Antworten.\n","\n","- **Generalität vs. Spezifität**: Modelle, die nur mit Prompting betrieben werden, sind in der Regel allgemeiner und weniger präzise in der Bearbeitung spezifischer Anfragen. Fine-Tuning ermöglicht die Anpassung an spezifische Anforderungen, reduziert jedoch die Generalisierbarkeit auf andere Domänen. RAG bietet eine Balance, da es externe Daten zur Verbesserung der Antwortqualität verwendet, ohne die Generalität des zugrundeliegenden Modells zu stark zu beeinflussen.\n","\n"],"metadata":{"id":"1vLsxmbW6EBG"}},{"cell_type":"markdown","source":["\n","# **4 <font color='orange'>|</font> Aktuelle Trends**\n","---"],"metadata":{"id":"09Mm70YV7xIO"}},{"cell_type":"markdown","source":["Im Bereich der Modellansteuerung gibt es einige aktuelle Trends und Entwicklungen:\n","\n","**Prompting:**\n","\n","+ Multimodales Prompting: LLMs werden in die Lage versetzt, mit verschiedenen Datenformaten wie Bildern, Videos und Ton umzugehen.\n","+ Ethische Aspekte: Es wird verstärkt Wert auf die Vermeidung von Verzerrungen und die Förderung von Fairness und Inklusivität in den Antworten gelegt.\n","\n","**RAG:**\n","\n","+ Produktionsreife RAG-Systeme: Der Fokus liegt auf der Entwicklung von robusten und skalierbaren RAG-Systemen für den Einsatz in Unternehmen.\n","+ Datenschutz und Sicherheit: Es werden neue Methoden entwickelt, um den Datenschutz und die Sicherheit von RAG-Systemen zu gewährleisten.\n","\n","**Fine-Tuning:**\n","\n","+ Skalierbarkeit: Es werden neue Techniken entwickelt, um das Fine-Tuning von immer größeren Modellen zu ermöglichen.\n","+ Effizienz: Es wird an Methoden geforscht, um den Ressourcenbedarf für das Fine-Tuning zu reduzieren.\n"],"metadata":{"id":"sZhei2Cc77Za"}},{"cell_type":"markdown","source":["\n","# **5 <font color='orange'>|</font> Fazit**\n","---"],"metadata":{"id":"0fyU6AbP5vTv"}},{"cell_type":"markdown","source":["![RAG](https://raw.githubusercontent.com/ralf-42/Image/main/GenAI/rag_klein.jpg)"],"metadata":{"id":"CcRUTiyTTOrg"}},{"cell_type":"markdown","source":["\n","[Zoom](https://raw.githubusercontent.com/ralf-42/Image/main/GenAI/rag.jpg)"],"metadata":{"id":"csSxOSAzTXVt"}},{"cell_type":"markdown","source":["Prompting, RAG und Fine-Tuning sind drei wichtige Methoden zur Steuerung von LLMs. Jede Methode hat ihre eigenen Stärken und Schwächen und eignet sich für unterschiedliche Einsatzszenarien. Die Wahl der besten Methode hängt von den spezifischen Anforderungen der jeweiligen Aufgabe ab. Aktuelle Trends und Entwicklungen zielen darauf ab, die Effizienz, Genauigkeit und Skalierbarkeit dieser Methoden zu verbessern und ethische Aspekte stärker zu berücksichtigen. In der Praxis werden die einzelnen Ansätze oft in Kombination eingesetzt.\n","\n","\n"],"metadata":{"id":"fDeHyj_u6FbC"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1736181733357}],"toc_visible":true,"collapsed_sections":["PHDCKRbtgVXy","owVDrCRD5hoI","L0grUpA56y3K","iQpWHr88612f","EU_aZQuK5kfc","mbzWylUi5qtI","09Mm70YV7xIO","0fyU6AbP5vTv"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}