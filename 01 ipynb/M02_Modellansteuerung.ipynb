{"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"8x1hrQqQ27a3"}},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Grundlagen Modellansteuerung\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>Umgebung einrichten</font> </br></p>\n","!uv pip install --system --prerelease allow -q git+https://github.com/ralf-42/genai_lib\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"metadata":{"cellView":"form","id":"PwDTz3VqPy8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | √úberblick\n","---\n"],"metadata":{"id":"PHDCKRbtgVXy"}},{"cell_type":"markdown","source":["Die rasante Entwicklung im Bereich der k√ºnstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei gro√üen Sprachmodellen (LLMs) gef√ºhrt. Diese Modelle k√∂nnen menschen√§hnlichen Text generieren, Sprachen √ºbersetzen und komplexe Fragen beantworten. Doch wie genau steuert man diese Modelle, um die gew√ºnschten Ergebnisse zu erzielen? In diesem Modul werden drei g√§ngige Methoden der Modellansteuerung untersucht: Prompting, Retrieval-Augmented Generation (RAG) und Fine-Tuning.\n","\n"],"metadata":{"id":"lSg1eGf95Vz1"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/rag_klein.jpg\" width=\"500\n","\" alt=\"Avatar\">"],"metadata":{"id":"0ZU3f3j0SK1v"}},{"cell_type":"markdown","source":["üîÑ **1. Prompting**\n","\n","* **Was passiert?**    \n","  Das Modell wird **nicht ver√§ndert**, sondern durch **clever gestaltete Eingaben** (Prompts) zu einer gew√ºnschten Leistung gebracht.\n","\n","* **Modellanpassung?**   \n","  ‚úÖ *indirekte, tempor√§re Anpassung*   \n","  ‚ùå *keine √Ñnderung des Modells selbst*\n","\n","* **Beispiel:**\n","  *‚ÄûDu bist ein Experte f√ºr Medizinrecht. Antworte nur mit rechtlich abgesicherten Aussagen.‚Äú*\n","\n","* **Vorteil:** Schnell, flexibel, keine Trainingskosten\n","\n","* **Nachteil:** Begrenzte Steuerbarkeit, kein echtes ‚ÄûLernen‚Äú\n","\n"],"metadata":{"id":"Paxb_tdwSu4A"}},{"cell_type":"markdown","source":["\n","\n","üìö **2. RAG (Retrieval-Augmented Generation)**\n","\n","* **Was passiert?**   \n","  Das Modell bekommt Zugriff auf externe Wissensquellen (z.‚ÄØB. PDF, Datenbank, Vektorensuche) ‚Äì diese Infos werden **zur Laufzeit in den Prompt eingef√ºgt**.\n","\n","* **Modellanpassung?**   \n","  ‚úÖ *strukturelle Anpassung durch Architektur*   \n","  ‚ùå *Modell selbst bleibt unver√§ndert*\n","\n","* **Beispiel:**   \n","  Eine Frage zu internen Firmenrichtlinien wird durch Retrieval aus dem Firmen-Wiki beantwortet.\n","\n","* **Vorteil:** Aktuelle & dom√§nenspezifische Infos, ohne das Modell zu ver√§ndern\n","\n","* **Nachteil:** Qualit√§t h√§ngt stark von der Dokumentenstruktur und Vektorsuche ab\n","\n"],"metadata":{"id":"cZkE97MxTFtL"}},{"cell_type":"markdown","source":["\n","\n","üß† **3. Fine-Tuning (Nachtraining auf Basisdaten)**\n","\n","* **Was passiert?**   \n","  Das Modell wird mit eigenen Beispielen **nachtrainiert**, um z.‚ÄØB. den Tonfall, Fachsprache oder Verhalten gezielt zu √§ndern.\n","\n","* **Modellanpassung?**   \n","  ‚úÖ *tiefe, permanente Modellanpassung*   \n","  üõ†Ô∏è *reelles ‚ÄûLernen‚Äú auf Parameter-Ebene*\n","\n","* **Beispiel:**   \n","  Ein Modell wird mit tausenden juristischen F√§llen nachtrainiert, um bessere Schrifts√§tze zu erzeugen.\n","\n","* **Vorteil:** Sehr genaue Steuerung m√∂glich, konsistentes Verhalten\n","\n","* **Nachteil:** Aufw√§ndig, teuer, ben√∂tigt viele Daten + GPU-Ressourcen\n","\n","\n"],"metadata":{"id":"MKkizmu3THgM"}},{"cell_type":"markdown","source":["| Technik         | Modellparameter<br> ge√§ndert? | Anpassungstiefe        | Beispiel                           |\n","| --------------- | ------------------------- | ---------------------- | ---------------------------------- |\n","| **Prompting**   | ‚ùå nein                    | leicht (oberfl√§chlich) | Rollenanweisung im Prompt          |\n","| **RAG**         | ‚ùå nein                    | mittel (strukturell)   | Infos aus PDF automatisch einf√ºgen |\n","| **Fine-Tuning** | ‚úÖ ja                      | tief (parametrisch)    | Modell kennt neue Fachbegriffe     |\n"],"metadata":{"id":"X2s-Hi-oSnSk"}},{"cell_type":"markdown","source":["# 2 | Prompting\n","---"],"metadata":{"id":"owVDrCRD5hoI"}},{"cell_type":"markdown","source":["Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte `Prompt`, gegeben, der die gew√ºnschte Ausgabe beschreibt. Die Qualit√§t der Ausgabe h√§ngt stark von der Qualit√§t des Prompts ab. Ein gut formulierter Prompt sollte klar, pr√§gnant und spezifisch sein.\n"],"metadata":{"id":"o7lp262M4u0Z"}},{"cell_type":"markdown","source":["[Say What You See](https://artsandculture.google.com/experiment/say-what-you-see/jwG3m7wQShZngw)"],"metadata":{"id":"pehjX4of6Vht"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Prompt-Elemente\n","</font></p>"],"metadata":{"id":"DlkRGwcR3rBp"}},{"cell_type":"markdown","source":["Eingabeaufforderungen bestehen in der Regel aus vier wesentlichen Elementen, die je nach Aufgabe variieren k√∂nnen. Die Hauptbestandteile sind:\n","\n","* **Anweisungen** ‚Äì Definieren die Aufgabe des Modells, entweder als Aufgabenbeschreibung oder als konkrete Handlungsanweisung.  \n","* **Kontext** ‚Äì Liefert erg√§nzende Informationen, um das Modell bei der Bearbeitung zu unterst√ºtzen.  \n","* **Eingabedaten** ‚Äì Enthalten die spezifischen Informationen, zu denen eine Antwort generiert werden soll.  \n","* **Ausgabeindikator** ‚Äì Signalisiert den √úbergang zur erwarteten Modellantwort.  \n","\n","Weitere Beispiele zur Anwendung dieser Struktur folgen sp√§ter."],"metadata":{"id":"nUJCfQ_-71Ti"}},{"cell_type":"markdown","source":["Nachfolgend ein Beispiel f√ºr eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n","\n","```\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\n","\n","Zusammenfassung: ...\n","```\n","\n","Diese Eingabeaufforderung erzeugt m√∂glicherweise die folgende Ausgabe:\n","\n","```\n","Die intelligente digitale Personenwaage wird f√ºr ihre schnelle Einrichtung, die einfache\n","Synchronisierung mit ihrer App auf √§lteren Telefonen zur m√ºhelosen Nachverfolgung, die\n","benutzerfreundlichen Funktionen zur Essensplanung und Kalorienz√§hlung sowie ihr schlankes, modernes\n","Design hoch gelobt.\n","```"],"metadata":{"id":"rj5-ap_p4Htg"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code-Beispiel\n","</font></p>"],"metadata":{"id":"yD8yi1td35er"}},{"cell_type":"code","source":["from openai import OpenAI, chat\n","\n","client = OpenAI()\n","\n","user_input = \"\"\"\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\"\"\"\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n","    {\"role\": \"user\", \"content\": user_input}\n","  ]\n",")\n","\n","mprint('## ü§ñ KI:')\n","mprint(completion.choices[0].message.content)"],"metadata":{"id":"HEx8kcdlOKl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | Retrieval-Augmented Generation\n","---"],"metadata":{"id":"L0grUpA56y3K"}},{"cell_type":"markdown","source":["RAG (Retrieval-Augmented Generation) ist eine **hybride Methode**, die die St√§rken von **LLMs** mit denen von **Information-Retrieval-Systemen** **kombiniert**. Dabei greift das LLM auf llm-externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n","+ Das System sucht in externe Wissens nach relevanten Informationen.\n","+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n","+ Das LLM generiert eine Antwort basierend auf der Anfrage **und** dem Kontext.\n","\n","\n","**Einsatzszenarien:**\n","\n","RAG eignet sich besonders f√ºr Aufgaben, die aktuelle oder dom√§nenspezifische Informationen erfordern, wie z. B.:\n","\n","+ Kundensupport mit Zugriff auf Produktdatenbanken\n","+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n","+ Finanzplanung mit Zugriff auf Marktdaten\n","+ Beantwortung von Fragen zu Unternehmensinformationen\n","\n"],"metadata":{"id":"EbmfDWKg4xmC"}},{"cell_type":"markdown","source":["# 4 | Fine-Tuning\n","---"],"metadata":{"id":"iQpWHr88612f"}},{"cell_type":"markdown","source":["Fine-Tuning ist eine Methode, bei der ein bereits **trainiertes LLM** auf einer kleineren, **aufgabenspezifischen** Datenmenge weiter trainiert wird. Dadurch kann das Modell an **spezifische** **Anforderungen** angepasst und seine Leistung f√ºr diese Aufgaben verbessert werden.\n","\n","**Funktionsweise:**\n","\n","+ Ein vortrainiertes LLM wird ausgew√§hlt.\n","+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n","+ Das LLM wird auf dieser Datenmenge trainiert.\n","+ Die Parameter des LLM werden angepasst, um die Leistung f√ºr die spezifische Aufgabe zu optimieren.\n","\n","\n","**Einsatzszenarien:**\n","\n","Fine-Tuning eignet sich besonders f√ºr Aufgaben, die eine hohe Genauigkeit und **Dom√§nenspezialisierung** erfordern, wie z. B.:\n","\n","+ fachlich spezialisierte LLMs (Recht, Medizin, ...)\n","+ Sentimentanalyse\n","+ Textklassifizierung\n","+ Spam-Erkennung\n","+ Personalisierte Kundeninteraktionen\n","\n"],"metadata":{"id":"WEyWOZtP40s0"}},{"cell_type":"markdown","source":["\n","# 5 | Entscheidungskriterien\n","---"],"metadata":{"id":"EU_aZQuK5kfc"}},{"cell_type":"markdown","source":["Die Wahl der geeigneten Methode h√§ngt von verschiedenen Faktoren ab, darunter:"],"metadata":{"id":"w4I1UPS97apC"}},{"cell_type":"markdown","source":["\n","| Kriterium | Prompting | RAG | Fine-Tuning |\n","|-----------|-----------|-----|-------------|\n","| **Komplexit√§t** | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>√Ñnderungen am Modell. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n","| **Effizienz** | Hoch<br><br>Prompting erm√∂glicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Mittel<br><br>RAG ben√∂tigt zus√§tzliche<br>Schritte f√ºr den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n","| **Genauigkeit** | Niedrig<br><br>Die Genauigkeit h√§ngt stark<br>von der Qualit√§t des<br>Prompts ab. | Mittel<br><br>RAG bietet h√∂here<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>F√ºhrt zu h√∂herer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n","| **Flexibilit√§t** | Hoch<br><br>Sehr flexibel und f√ºr<br>verschiedene Aufgaben<br>einsetzbar. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsf√§hig. |\n","| **Ressourcen-<br>bedarf** | Niedrig<br><br>Ben√∂tigt nur minimale<br>Ressourcen f√ºr die<br>Ausf√ºhrung. | Mittel<br><br>Ressourcen f√ºr Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>f√ºr Training. |\n","| **Datenbedarf** | Niedrig<br><br>Keine zus√§tzlichen<br>Trainingsdaten<br>erforderlich. | Mittel<br><br>Ben√∂tigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Ben√∂tigt gro√üe Mengen an<br>spezifischen<br>Trainingsdaten. |\n","| **Beschreibung** | Einfache Methode mit<br>Textanweisungen f√ºr das<br>Modell. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datens√§tzen. |\n","\n"],"metadata":{"id":"rSAuP0cW54O1"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1736181733357}],"collapsed_sections":["PHDCKRbtgVXy","owVDrCRD5hoI","L0grUpA56y3K","iQpWHr88612f","EU_aZQuK5kfc"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}