{"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"8x1hrQqQ27a3"}},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Grundlagen Modellansteuerung\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfdhPIzcEYRG","cellView":"form","collapsed":true},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  Colab-Umfeld</font> </br></p>\n","# Installierte Python Version\n","import sys\n","print(f\"Python Version: \",sys.version)\n","# Installierte LangChain Bibliotheken\n","print()\n","print(\"Installierte LangChain Bibliotheken:\")\n","\n","!pip list | grep '^langchain'\n","# Unterdr√ºckt die \"DeprecationWarning\" von LangChain f√ºr die Memory-Funktionden\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langsmith.client\")"]},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  SetUp API-Keys (setup_api_keys)</font> </br></p>\n","def setup_api_keys():\n","    \"\"\"Konfiguriert alle ben√∂tigten API-Keys aus Google Colab userdata\"\"\"\n","    from google.colab import userdata\n","    import os\n","    from os import environ\n","\n","    # Dictionary der ben√∂tigten API-Keys\n","    keys = {\n","        'OPENAI_API_KEY': 'OPENAI_API_KEY',\n","        'HF_TOKEN': 'HF_TOKEN',\n","        # Weitere Keys bei Bedarf\n","    }\n","\n","    # Keys in Umgebungsvariablen setzen\n","    for env_var, key_name in keys.items():\n","        environ[env_var] = userdata.get(key_name)\n","\n","    return {k: environ[k] for k in keys.keys()}\n","\n","# Verwendung\n","all_keys = setup_api_keys()\n","# Bei Bedarf einzelne Keys direkt zugreifen\n","# WEATHER_API_KEY = all_keys['WEATHER_API_KEY']"],"metadata":{"cellView":"form","id":"WD3Wwr6sESX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | √úberblick\n","---\n"],"metadata":{"id":"PHDCKRbtgVXy"}},{"cell_type":"markdown","source":["Die rasante Entwicklung im Bereich der k√ºnstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei gro√üen Sprachmodellen (LLMs) gef√ºhrt. Diese Modelle k√∂nnen menschen√§hnlichen Text generieren, Sprachen √ºbersetzen und komplexe Fragen beantworten. Doch wie genau steuert man diese Modelle, um die gew√ºnschten Ergebnisse zu erzielen? In diesem Modul werden drei g√§ngige Methoden der Modellansteuerung untersucht: Prompting, Retrieval-Augmented Generation (RAG) und Fine-Tuning.\n","\n"],"metadata":{"id":"lSg1eGf95Vz1"}},{"cell_type":"markdown","source":["# 2 | Prompting\n","---"],"metadata":{"id":"owVDrCRD5hoI"}},{"cell_type":"markdown","source":["Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte `Prompt`, gegeben, der die gew√ºnschte Ausgabe beschreibt. Die Qualit√§t der Ausgabe h√§ngt stark von der Qualit√§t des Prompts ab. Ein gut formulierter Prompt sollte klar, pr√§gnant und spezifisch sein.\n"],"metadata":{"id":"o7lp262M4u0Z"}},{"cell_type":"markdown","source":["[Say What You See](https://artsandculture.google.com/experiment/say-what-you-see/jwG3m7wQShZngw)"],"metadata":{"id":"pehjX4of6Vht"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Prompt-Elemente\n","</font></p>"],"metadata":{"id":"DlkRGwcR3rBp"}},{"cell_type":"markdown","source":["Eingabeaufforderungen bestehen in der Regel aus vier wesentlichen Elementen, die je nach Aufgabe variieren k√∂nnen. Die Hauptbestandteile sind:\n","\n","* **Anweisungen** ‚Äì Definieren die Aufgabe des Modells, entweder als Aufgabenbeschreibung oder als konkrete Handlungsanweisung.  \n","* **Kontext** ‚Äì Liefert erg√§nzende Informationen, um das Modell bei der Bearbeitung zu unterst√ºtzen.  \n","* **Eingabedaten** ‚Äì Enthalten die spezifischen Informationen, zu denen eine Antwort generiert werden soll.  \n","* **Ausgabeindikator** ‚Äì Signalisiert den √úbergang zur erwarteten Modellantwort.  \n","\n","Weitere Beispiele zur Anwendung dieser Struktur folgen sp√§ter."],"metadata":{"id":"nUJCfQ_-71Ti"}},{"cell_type":"markdown","source":["Nachfolgend ein Beispiel f√ºr eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n","\n","```\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\n","\n","Zusammenfassung: ...\n","```\n","\n","Diese Eingabeaufforderung erzeugt m√∂glicherweise die folgende Ausgabe:\n","\n","```\n","Die intelligente digitale Personenwaage wird f√ºr ihre schnelle Einrichtung, die einfache\n","Synchronisierung mit ihrer App auf √§lteren Telefonen zur m√ºhelosen Nachverfolgung, die\n","benutzerfreundlichen Funktionen zur Essensplanung und Kalorienz√§hlung sowie ihr schlankes, modernes\n","Design hoch gelobt.\n","```"],"metadata":{"id":"rj5-ap_p4Htg"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code-Beispiel\n","</font></p>"],"metadata":{"id":"yD8yi1td35er"}},{"cell_type":"code","source":["from openai import OpenAI, chat\n","from IPython.display import display, Markdown\n","\n","client = OpenAI()\n","\n","user_prompt = \"\"\"\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\"\"\"\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n","    {\"role\": \"user\", \"content\": user_prompt}\n","  ]\n",")\n","\n","display(Markdown('## ü§ñ KI:'))\n","display(Markdown(completion.choices[0].message.content))"],"metadata":{"id":"HEx8kcdlOKl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | Retrieval-Augmented Generation\n","---"],"metadata":{"id":"L0grUpA56y3K"}},{"cell_type":"markdown","source":["RAG (Retrieval-Augmented Generation) ist eine **hybride Methode**, die die St√§rken von **LLMs** mit denen von **Information-Retrieval-Systemen** **kombiniert**. Dabei greift das LLM auf llm-externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n","+ Das System sucht in externe Wissens nach relevanten Informationen.\n","+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n","+ Das LLM generiert eine Antwort basierend auf der Anfrage **und** dem Kontext.\n","\n","\n","**Einsatzszenarien:**\n","\n","RAG eignet sich besonders f√ºr Aufgaben, die aktuelle oder dom√§nenspezifische Informationen erfordern, wie z. B.:\n","\n","+ Kundensupport mit Zugriff auf Produktdatenbanken\n","+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n","+ Finanzplanung mit Zugriff auf Marktdaten\n","+ Beantwortung von Fragen zu Unternehmensinformationen\n","\n"],"metadata":{"id":"EbmfDWKg4xmC"}},{"cell_type":"markdown","source":["# 4 | Fine-Tuning\n","---"],"metadata":{"id":"iQpWHr88612f"}},{"cell_type":"markdown","source":["Fine-Tuning ist eine Methode, bei der ein bereits **trainiertes LLM** auf einer kleineren, **aufgabenspezifischen** Datenmenge weiter trainiert wird. Dadurch kann das Modell an **spezifische** **Anforderungen** angepasst und seine Leistung f√ºr diese Aufgaben verbessert werden.\n","\n","**Funktionsweise:**\n","\n","+ Ein vortrainiertes LLM wird ausgew√§hlt.\n","+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n","+ Das LLM wird auf dieser Datenmenge trainiert.\n","+ Die Parameter des LLM werden angepasst, um die Leistung f√ºr die spezifische Aufgabe zu optimieren.\n","\n","\n","**Einsatzszenarien:**\n","\n","Fine-Tuning eignet sich besonders f√ºr Aufgaben, die eine hohe Genauigkeit und **Dom√§nenspezialisierung** erfordern, wie z. B.:\n","\n","+ fachlich spezialisierte LLMs (Recht, Medizin, ...)\n","+ Sentimentanalyse\n","+ Textklassifizierung\n","+ Spam-Erkennung\n","+ Personalisierte Kundeninteraktionen\n","\n"],"metadata":{"id":"WEyWOZtP40s0"}},{"cell_type":"markdown","source":["\n","# 5 | Entscheidungskriterien\n","---"],"metadata":{"id":"EU_aZQuK5kfc"}},{"cell_type":"markdown","source":["Die Wahl der geeigneten Methode h√§ngt von verschiedenen Faktoren ab, darunter:"],"metadata":{"id":"w4I1UPS97apC"}},{"cell_type":"markdown","source":["\n","| Kriterium | Prompting | RAG | Fine-Tuning |\n","|-----------|-----------|-----|-------------|\n","| **Komplexit√§t** | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>√Ñnderungen am Modell. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n","| **Effizienz** | Hoch<br><br>Prompting erm√∂glicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Mittel<br><br>RAG ben√∂tigt zus√§tzliche<br>Schritte f√ºr den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n","| **Genauigkeit** | Niedrig<br><br>Die Genauigkeit h√§ngt stark<br>von der Qualit√§t des<br>Prompts ab. | Mittel<br><br>RAG bietet h√∂here<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>F√ºhrt zu h√∂herer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n","| **Flexibilit√§t** | Hoch<br><br>Sehr flexibel und f√ºr<br>verschiedene Aufgaben<br>einsetzbar. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsf√§hig. |\n","| **Ressourcen-<br>bedarf** | Niedrig<br><br>Ben√∂tigt nur minimale<br>Ressourcen f√ºr die<br>Ausf√ºhrung. | Mittel<br><br>Ressourcen f√ºr Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>f√ºr Training. |\n","| **Datenbedarf** | Niedrig<br><br>Keine zus√§tzlichen<br>Trainingsdaten<br>erforderlich. | Mittel<br><br>Ben√∂tigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Ben√∂tigt gro√üe Mengen an<br>spezifischen<br>Trainingsdaten. |\n","| **Beschreibung** | Einfache Methode mit<br>Textanweisungen f√ºr das<br>Modell. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datens√§tzen. |\n","\n"],"metadata":{"id":"rSAuP0cW54O1"}},{"cell_type":"markdown","source":["# 6 | Auswahl Modellansteuerung"],"metadata":{"id":"iM17hLC0wWrl"}},{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/GenAI/rag_klein.jpg)\n","\n"],"metadata":{"id":"LN8mIeZ2vhXJ"}},{"cell_type":"markdown","source":["\n","\n","Bei der Wahl zwischen den verschiedenen Modellansteuerungstechniken gibt es immer Trade-offs, die ber√ºcksichtigt werden m√ºssen:\n","\n","- **Kosteneffizienz**: Fine-Tuning ist kostspieliger, da es nicht nur erhebliche Rechenressourcen erfordert, sondern auch Zeit, um ein Modell zu trainieren. RAG bietet einen Mittelweg, da es externe Daten nutzt, ohne dass ein vollst√§ndiges Modell neu trainiert werden muss. Prompting ist hingegen am kosteng√ºnstigsten, da es keine zus√§tzlichen Trainingsphasen erfordert.\n","\n","- **Flexibilit√§t**: Fine-Tuning bietet die h√∂chste Flexibilit√§t, da es das Modell vollst√§ndig an die speziellen Anforderungen anpassen kann. RAG bietet ebenfalls Flexibilit√§t, allerdings h√§ngt die Qualit√§t der Ergebnisse stark von der Qualit√§t der externen Daten ab. Prompting ist flexibler in der Formulierung der Anfragen, hat jedoch in komplexen Szenarien oft Einschr√§nkungen in der Pr√§zision und Tiefe der Antworten.\n","\n","- **Generalit√§t vs. Spezifit√§t**: Modelle, die nur mit Prompting betrieben werden, sind in der Regel allgemeiner und weniger pr√§zise in der Bearbeitung spezifischer Anfragen. Fine-Tuning erm√∂glicht die Anpassung an spezifische Anforderungen, reduziert jedoch die Generalisierbarkeit auf andere Dom√§nen. RAG bietet eine Balance, da es externe Daten zur Verbesserung der Antwortqualit√§t verwendet, ohne die Generalit√§t des zugrundeliegenden Modells zu stark zu beeinflussen.\n","\n"],"metadata":{"id":"1vLsxmbW6EBG"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1736181733357}],"collapsed_sections":["PHDCKRbtgVXy","owVDrCRD5hoI","L0grUpA56y3K","iQpWHr88612f","EU_aZQuK5kfc","iM17hLC0wWrl"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}