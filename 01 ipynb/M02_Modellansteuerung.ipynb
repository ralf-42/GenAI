{"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"8x1hrQqQ27a3"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 02: Grundlagen Modellansteuerung\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/ralf-42/GenAI/blob/main/01%20ipynb/M02_Modellansteuerung.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"],"metadata":{"id":"_bPnjE4mHxeC"}},{"cell_type":"markdown","source":["# **1 <font color='orange'>|</font> √úberblick**\n","---\n"],"metadata":{"id":"PHDCKRbtgVXy"}},{"cell_type":"markdown","source":["Die rasante Entwicklung im Bereich der k√ºnstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei gro√üen Sprachmodellen (LLMs) gef√ºhrt. Diese Modelle k√∂nnen menschen√§hnlichen Text generieren, Sprachen √ºbersetzen und komplexe Fragen beantworten. Doch wie genau steuert man diese Modelle, um die gew√ºnschten Ergebnisse zu erzielen? In diesem Modul werden wir drei g√§ngige Methoden der Modellansteuerung untersuchen: Prompting, Retrieval-Augmented Generation (RAG) und Fine-Tuning.\n","\n"],"metadata":{"id":"lSg1eGf95Vz1"}},{"cell_type":"markdown","source":["## **1.1 <font color='orange'>|</font> Prompting**\n","---"],"metadata":{"id":"owVDrCRD5hoI"}},{"cell_type":"markdown","source":["\n","\n","Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte \"Prompt\", gegeben, der die gew√ºnschte Ausgabe beschreibt. Die Qualit√§t der Ausgabe h√§ngt stark von der Qualit√§t des Prompts ab. Ein gut formulierter Prompt sollte klar, pr√§gnant und spezifisch sein.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt einen Prompt in das LLM ein.\n","+ Das LLM verarbeitet den Prompt und generiert eine Antwort basierend auf seinem Training und den im Prompt enthaltenen Informationen\n","\n","**Arten von Prompts:**\n","\n","Es gibt verschiedene Arten von Prompts, die verwendet werden k√∂nnen, um bestimmte Reaktionen vom Modell hervorzurufen:\n","\n","+ Verbale Prompts: Dies sind gesprochene oder geschriebene Anweisungen. Zum Beispiel: \"Schreibe eine kurze Geschichte √ºber eine Katze, die zum Mond fliegt.\"\n","+ Visuelle Prompts: Dies k√∂nnen Bilder oder andere visuelle Elemente sein. Zum Beispiel: Ein Bild einer Katze, die in den Weltraum startet, k√∂nnte als Prompt f√ºr eine Geschichte √ºber eine Katze dienen, die zum Mond fliegt.\n","\n","**Prompt Chaining:**\n","\n","Prompt Chaining ist eine Technik, bei der eine Reihe von Prompts verwendet wird, um das Modell durch mehrere Schritte zu f√ºhren oder komplexere Ausgaben zu generieren. Zum Beispiel k√∂nnte ein erster Prompt das Modell anweisen, eine Liste von Themen zu generieren, ein zweiter Prompt es dann auffordern, eines dieser Themen auszuw√§hlen und einen Aufsatz dar√ºber zu schreiben.\n","\n","**Einsatzszenarien:**\n","\n","Prompting eignet sich besonders f√ºr Aufgaben, die schnell und flexibel erledigt werden m√ºssen, wie z. B.:\n","\n","+ Textgenerierung\n","+ √úbersetzung\n","+ Zusammenfassung\n","+ Brainstorming\n","+ Beantwortung allgemeiner Fragen\n","+ ..."],"metadata":{"id":"o7lp262M4u0Z"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Eingabeaufforderungen verstehen\n","</font></p>"],"metadata":{"id":"DlkRGwcR3rBp"}},{"cell_type":"markdown","source":["\n","\n","Wir werden uns die vier Hauptkomponenten der meisten Eingabeaufforderungen ansehen. Viele Eingabeaufforderungen erfordern nicht alle vier Elemente. Ihre Form h√§ngt von der Aufgabe ab. Wir werden bald weitere Beispiele behandeln. Die meisten Eingabeaufforderungen bestehen aus den folgenden Teilen:\n","\n","* **Anweisungen** Beschreibt eine Aufgabe f√ºr das Modell. Dies kann eine Aufgabenbeschreibung oder eine Anweisung zur Ausf√ºhrung des Modells sein.\n","* **Kontext** Externe Informationen zur Orientierung des Modells.\n","* **Eingabedaten** Die Eingabe, f√ºr die wir eine Antwort w√ºnschen.\n","* **Ausgabeindikator** Normalerweise gibt der letzte Teil der Eingabeaufforderung an, dass die Ausgabe des Modells folgen soll."],"metadata":{"id":"nUJCfQ_-71Ti"}},{"cell_type":"markdown","source":["Nachfolgend sehen Sie ein Beispiel f√ºr eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n","\n","```\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8 herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes Erscheinungsbild, das wirklich attraktiv ist.\n","Zusammenfassung: ...\n","```\n","\n","Diese Eingabeaufforderung erzeugt m√∂glicherweise die folgende Ausgabe:\n","\n","```\n","Die intelligente digitale Personenwaage wird f√ºr ihre schnelle Einrichtung, die einfache Synchronisierung mit ihrer App auf √§lteren Telefonen zur m√ºhelosen Nachverfolgung, die benutzerfreundlichen Funktionen zur Essensplanung und Kalorienz√§hlung sowie ihr schlankes, modernes Design hoch gelobt.\n","```"],"metadata":{"id":"rj5-ap_p4Htg"}},{"cell_type":"markdown","source":["**Anweisung:** Fassen Sie die folgende Produktbewertung in einem Satz zusammen:   \n","**Kontext:** Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung   \n","**Eingabedaten:** Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8 herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes Erscheinungsbild, das wirklich attraktiv ist.   \n","**Ausgabeindikator:** Zusammenfassung: ..."],"metadata":{"id":"x9aWyG4I5Ek8"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Zero-Shot-Prompt-Muster\n","</font></p>"],"metadata":{"id":"bZx_1oke3vCw"}},{"cell_type":"markdown","source":["\n","\n","Zero-Shot-Prompting beschreibt die Technik, bei der wir einem LLM eine Aufgabe pr√§sentieren, ohne ihm weitere Beispiele zu geben. Wir erwarten daher, dass es die Aufgabe ausf√ºhrt, ohne vorher einen ‚ÄûVersuch‚Äú zur Aufgabe zu bekommen. Daher ‚ÄûZero-Shot‚Äú-Prompting. Moderne LLMs zeigen, dass Programmierer eine bemerkenswerte Zero-Shot-Leistung erzielen k√∂nnen und dass eine positive Korrelation zwischen Modellgr√∂√üe und Zero-Shot-Leistung besteht.\n","\n","```\n","Human:\n","Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n","Assistant: the chemical1 and chemical 2 are:\n","```\n","\n","Das Modell k√∂nnte die folgende Ausgabe erzeugen:\n","\n","```\n","Sulfuric acid (H‚ÇÇSO‚ÇÑ) reacts with sodium chloride (NaCl) to produce:\n","\n","+ Chemical 1: Hydrogen chloride (HCl)\n","+ Chemical 2: Sodium bisulfate (NaHSO‚ÇÑ) (or Sodium sulfate (Na‚ÇÇSO‚ÇÑ) depending on the reaction conditions)\n","```\n","\n"],"metadata":{"id":"AI2Y4qcF78j4"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Few-Shot-Prompting-Muster\n","</font></p>"],"metadata":{"id":"nLFUY2x632cr"}},{"cell_type":"markdown","source":["\n","\n","Beim Few-Shot-Prompting werden dem Modell anhand von Beispielen mehr Informationen √ºber die anstehenden Aufgaben gegeben. Es kann f√ºr kontextbezogenes Lernen verwendet werden, indem Beispiele der Aufgabe und des gew√ºnschten Ergebnisses bereitgestellt werden. Daher k√∂nnen wir das Modell anhand der Beispiele konditionieren, damit es den Aufgabenanweisungen genauer folgt.\n","\n","Sie k√∂nnen die folgende Eingabeaufforderung verwenden, um die Stimmung von Tweets mithilfe des Eingabeaufforderungsmusters ‚ÄûFew-Shot‚Äú als positiv oder negativ zu klassifizieren.\n","\n","```\n","Tweet: ‚ÄûHabe das Jobangebot bekommen, auf das ich gewartet habe. √úbergl√ºcklich!‚Äú Stimmung: Positiv\n","Tweet: ‚ÄûHabe meine Fahrpr√ºfung beim ersten Versuch bestanden. Ich bin so gl√ºcklich!‚Äú Stimmung: Positiv\n","Tweet: ‚ÄûDer Film war reine Zeitverschwendung. Nie wieder.‚Äú Stimmung: Negativ\n","Tweet: ‚ÄûSteckte stundenlang im Stau. Warum ich?‚Äú Stimmung: Negativ\n","Tweet: ‚ÄûWas f√ºr ein sch√∂ner Morgen, um in den Tag zu starten!‚Äú Stimmung:\n","```\n","\n","Der LLM w√ºrde diese Aufforderung wahrscheinlich wie folgt fortsetzen:\n","\n","```\n","Positive\n","```\n"],"metadata":{"id":"BTX8nsvE8CSr"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code Beispiel\n","</font></p>"],"metadata":{"id":"yD8yi1td35er"}},{"cell_type":"code","source":["!uv pip install --system -q langchain_openai"],"metadata":{"id":"dXE534fDMNHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","OPENAI_API_KEY = userdata.get('OpenAI-API-Key')\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"],"metadata":{"id":"imil8moAL7e0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMF-rtxgRAea"},"outputs":[],"source":["from langchain_core.messages import HumanMessage, SystemMessage\n","from langchain_core.prompts.chat import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    SystemMessagePromptTemplate,\n",")\n","from langchain_openai import ChatOpenAI\n","\n","messages = [\n","    SystemMessage(\n","        content=\"You are a helpful assistant that.\"\n","    ),\n","    HumanMessage(\n","        content=\\\n","\"\"\"\n","Human:\n","Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n","Assistant: the chemical1 and chemical 2 are:\n","\"\"\"\n","    ),\n","]\n","\n","MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schl√ºssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  # Modell=\"gpt-4o-mini\",\n","  temperature= 0.0,\n","  n= 1,\n","  max_tokens= 256)\n","\n","print(\"Model response:\")\n","output = llm.invoke(messages)\n","print(output.content)\n","print(\"-----------\")\n","print(output.response_metadata)"]},{"cell_type":"markdown","source":["ü§øDeepDive in Modul 14"],"metadata":{"id":"FqlYM5ONIXne"}},{"cell_type":"markdown","source":["## **1.2 <font color='orange'>|</font> RAG**\n","---"],"metadata":{"id":"L0grUpA56y3K"}},{"cell_type":"markdown","source":["RAG (Retrieval-Augmented Generation) ist eine hybride Methode, die die St√§rken von LLMs mit denen von Information-Retrieval-Systemen kombiniert. Dabei greift das LLM auf externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n","+ Das System sucht mithilfe von Embedding Language Models und Vektor Datenbanken in externen Wissensdatenbanken nach relevanten Informationen.\n","+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n","+ Das LLM generiert eine Antwort basierend auf der Anfrage und dem Kontext.\n","\n","\n","**Einsatzszenarien:**\n","\n","RAG eignet sich besonders f√ºr Aufgaben, die aktuelle oder dom√§nenspezifische Informationen erfordern, wie z. B.:\n","\n","+ Kundensupport mit Zugriff auf Produktdatenbanken\n","+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n","+ Finanzplanung mit Zugriff auf Marktdaten\n","+ Beantwortung von Fragen zu Unternehmensinformationen\n","\n"],"metadata":{"id":"EbmfDWKg4xmC"}},{"cell_type":"markdown","source":["ü§øDeepDive in Modul 07"],"metadata":{"id":"sp6RcCyJH4l4"}},{"cell_type":"markdown","source":["## **1.3 <font color='orange'>|</font> Fine-Tuning**\n","---"],"metadata":{"id":"iQpWHr88612f"}},{"cell_type":"markdown","source":["Fine-Tuning ist eine Methode, bei der ein bereits trainiertes LLM auf einer kleineren, aufgabenspezifischen Datenmenge weiter trainiert wird. Dadurch kann das Modell an spezifische Anforderungen angepasst und seine Leistung f√ºr diese Aufgaben verbessert werden.\n","\n","**Funktionsweise:**\n","\n","+ Ein vortrainiertes LLM wird ausgew√§hlt.\n","+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n","+ Das LLM wird auf dieser Datenmenge weiter trainiert.\n","+ Die Parameter des LLM werden angepasst, um die Leistung f√ºr die spezifische Aufgabe zu optimieren.\n","\n","**Methoden des Fine-Tunings:**\n","\n","Es gibt verschiedene Methoden, um ein LLM zu fine-tunen:\n","\n","+ Instruction Fine-Tuning: Das Modell wird mit Beispielen trainiert, die zeigen, wie es auf bestimmte Anfragen reagieren soll. Zum Beispiel k√∂nnte man dem Modell Anweisungen wie \"Fasse diesen Text zusammen\" geben, gefolgt von dem eigentlichen Text.\n","+ Weitere Methoden: Es gibt noch weitere Fine-Tuning-Methoden, die je nach Anwendungsfall und Zielsetzung eingesetzt werden k√∂nnen.\n","\n","\n","**Einsatzszenarien:**\n","\n","Fine-Tuning eignet sich besonders f√ºr Aufgaben, die eine hohe Genauigkeit und Dom√§nenspezialisierung erfordern, wie z. B.:\n","\n","+ Sentimentanalyse\n","+ Textklassifizierung\n","+ Spam-Erkennung\n","+ Personalisierte Kundeninteraktionen\n","\n"],"metadata":{"id":"WEyWOZtP40s0"}},{"cell_type":"markdown","source":["ü§øDeepDive in Modul 13"],"metadata":{"id":"_EjuZ4MrIGYg"}},{"cell_type":"markdown","source":["\n","# **2 <font color='orange'>|</font> Entscheidungskriterien**\n","---"],"metadata":{"id":"EU_aZQuK5kfc"}},{"cell_type":"markdown","source":["Die Wahl der geeigneten Methode h√§ngt von verschiedenen Faktoren ab, darunter:"],"metadata":{"id":"w4I1UPS97apC"}},{"cell_type":"markdown","source":["\n","| Kriterium | Prompting | RAG | Fine-Tuning |\n","|-----------|-----------|-----|-------------|\n","| **Komplexit√§t** | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>√Ñnderungen am Modell. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n","| **Effizienz** | Hoch<br><br>Prompting erm√∂glicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Mittel<br><br>RAG ben√∂tigt zus√§tzliche<br>Schritte f√ºr den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n","| **Genauigkeit** | Niedrig<br><br>Die Genauigkeit h√§ngt stark<br>von der Qualit√§t des<br>Prompts ab. | Mittel<br><br>RAG bietet h√∂here<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>F√ºhrt zu h√∂herer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n","| **Flexibilit√§t** | Hoch<br><br>Sehr flexibel und f√ºr<br>verschiedene Aufgaben<br>einsetzbar. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsf√§hig. |\n","| **Ressourcen-<br>bedarf** | Niedrig<br><br>Ben√∂tigt nur minimale<br>Ressourcen f√ºr die<br>Ausf√ºhrung. | Mittel<br><br>Ressourcen f√ºr Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>f√ºr Training. |\n","| **Datenbedarf** | Niedrig<br><br>Keine zus√§tzlichen<br>Trainingsdaten<br>erforderlich. | Mittel<br><br>Ben√∂tigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Ben√∂tigt gro√üe Mengen an<br>spezifischen<br>Trainingsdaten. |\n","| **Beschreibung** | Einfache Methode mit<br>Textanweisungen f√ºr das<br>Modell. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datens√§tzen. |\n","\n"],"metadata":{"id":"rSAuP0cW54O1"}},{"cell_type":"markdown","source":["\n","# **3 <font color='orange'>|</font> Trade-offs**\n","---"],"metadata":{"id":"mbzWylUi5qtI"}},{"cell_type":"markdown","source":["\n","\n","Bei der Wahl zwischen den verschiedenen Modellansteuerungstechniken gibt es immer Trade-offs, die ber√ºcksichtigt werden m√ºssen:\n","\n","- **Kosteneffizienz**: Fine-Tuning ist kostspieliger, da es nicht nur erhebliche Rechenressourcen erfordert, sondern auch Zeit, um ein Modell zu trainieren. RAG bietet einen Mittelweg, da es externe Daten nutzt, ohne dass ein vollst√§ndiges Modell neu trainiert werden muss. Prompting ist hingegen am kosteng√ºnstigsten, da es keine zus√§tzlichen Trainingsphasen erfordert.\n","\n","- **Flexibilit√§t**: Fine-Tuning bietet die h√∂chste Flexibilit√§t, da es das Modell vollst√§ndig an die speziellen Anforderungen anpassen kann. RAG bietet ebenfalls Flexibilit√§t, allerdings h√§ngt die Qualit√§t der Ergebnisse stark von der Qualit√§t der externen Daten ab. Prompting ist flexibler in der Formulierung der Anfragen, hat jedoch in komplexen Szenarien oft Einschr√§nkungen in der Pr√§zision und Tiefe der Antworten.\n","\n","- **Generalit√§t vs. Spezifit√§t**: Modelle, die nur mit Prompting betrieben werden, sind in der Regel allgemeiner und weniger pr√§zise in der Bearbeitung spezifischer Anfragen. Fine-Tuning erm√∂glicht die Anpassung an spezifische Anforderungen, reduziert jedoch die Generalisierbarkeit auf andere Dom√§nen. RAG bietet eine Balance, da es externe Daten zur Verbesserung der Antwortqualit√§t verwendet, ohne die Generalit√§t des zugrundeliegenden Modells zu stark zu beeinflussen.\n","\n"],"metadata":{"id":"1vLsxmbW6EBG"}},{"cell_type":"markdown","source":["\n","# **4 <font color='orange'>|</font> Aktuelle Trends**\n","---"],"metadata":{"id":"09Mm70YV7xIO"}},{"cell_type":"markdown","source":["Im Bereich der Modellansteuerung gibt es einige aktuelle Trends und Entwicklungen:\n","\n","**Prompting:**\n","\n","+ Multimodales Prompting: LLMs werden in die Lage versetzt, mit verschiedenen Datenformaten wie Bildern, Videos und Ton umzugehen.\n","+ Ethische Aspekte: Es wird verst√§rkt Wert auf die Vermeidung von Verzerrungen und die F√∂rderung von Fairness und Inklusivit√§t in den Antworten gelegt.\n","\n","**RAG:**\n","\n","+ Produktionsreife RAG-Systeme: Der Fokus liegt auf der Entwicklung von robusten und skalierbaren RAG-Systemen f√ºr den Einsatz in Unternehmen.\n","+ Datenschutz und Sicherheit: Es werden neue Methoden entwickelt, um den Datenschutz und die Sicherheit von RAG-Systemen zu gew√§hrleisten.\n","\n","**Fine-Tuning:**\n","\n","+ Skalierbarkeit: Es werden neue Techniken entwickelt, um das Fine-Tuning von immer gr√∂√üeren Modellen zu erm√∂glichen.\n","+ Effizienz: Es wird an Methoden geforscht, um den Ressourcenbedarf f√ºr das Fine-Tuning zu reduzieren.\n"],"metadata":{"id":"sZhei2Cc77Za"}},{"cell_type":"markdown","source":["\n","# **5 <font color='orange'>|</font> Fazit**\n","---"],"metadata":{"id":"0fyU6AbP5vTv"}},{"cell_type":"markdown","source":["![RAG](https://raw.githubusercontent.com/ralf-42/Image/main/GenAI/rag_klein.jpg)"],"metadata":{"id":"CcRUTiyTTOrg"}},{"cell_type":"markdown","source":["\n","[Zoom](https://raw.githubusercontent.com/ralf-42/Image/main/GenAI/rag.jpg)"],"metadata":{"id":"csSxOSAzTXVt"}},{"cell_type":"markdown","source":["Prompting, RAG und Fine-Tuning sind drei wichtige Methoden zur Steuerung von LLMs. Jede Methode hat ihre eigenen St√§rken und Schw√§chen und eignet sich f√ºr unterschiedliche Einsatzszenarien. Die Wahl der besten Methode h√§ngt von den spezifischen Anforderungen der jeweiligen Aufgabe ab. Aktuelle Trends und Entwicklungen zielen darauf ab, die Effizienz, Genauigkeit und Skalierbarkeit dieser Methoden zu verbessern und ethische Aspekte st√§rker zu ber√ºcksichtigen. In der Praxis werden die einzelnen Ans√§tze oft in Kombination eingesetzt.\n","\n","\n"],"metadata":{"id":"fDeHyj_u6FbC"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1736181733357}],"toc_visible":true,"collapsed_sections":["PHDCKRbtgVXy","owVDrCRD5hoI","L0grUpA56y3K","iQpWHr88612f","EU_aZQuK5kfc","mbzWylUi5qtI","09Mm70YV7xIO","0fyU6AbP5vTv"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}