# Multimodales RAG Modul (Version 3.0)

## Ãœbersicht

Das **Multimodale RAG Modul** ist ein produktionsreifes Retrieval-Augmented Generation (RAG) System, das Text- und Bilddokumente in einer einheitlichen Vektordatenbank verwaltet und intelligent durchsucht.

**Hauptmerkmale:**
- ğŸ” **Hybride Suche**: Kombination aus Text-Embeddings (OpenAI) und Bild-Embeddings (CLIP)
- ğŸ–¼ï¸ **Automatische Bildbeschreibungen**: KI-generierte Beschreibungen via GPT-4o-mini
- ğŸ¯ **Multimodale Suchrichtungen**: Textâ†’Text, Textâ†’Bild, Bildâ†’Bild, Bildâ†’Text
- ğŸ“¦ **ChromaDB Backend**: Persistente Vektordatenbank mit separaten Collections
- ğŸ—ï¸ **Funktionale Architektur**: Klare Trennung von Konfiguration, Komponenten und Logik

---

## Installation

```python
# Erforderliche Pakete
pip install langchain langchain-openai langchain-chroma
pip install sentence-transformers chromadb
pip install markitdown pillow openai
```

---

## Schnellstart

```python
from multimodal_rag_modul import (
    init_rag_system_enhanced,
    process_directory,
    multimodal_search,
    search_text_by_image,
    search_similar_images
)

# 1. System initialisieren
rag = init_rag_system_enhanced()

# 2. Dokumente und Bilder verarbeiten
stats = process_directory(
    rag,
    './files',
    include_images=True,
    auto_describe_images=True
)

# 3. Multimodale Suche durchfÃ¼hren
result = multimodal_search(rag, "Was sind Cyborgs?")
print(result)
```

---

## Suchfunktionen

### 1. Text â†’ Text/Bild Suche

```python
# Klassische textbasierte Suche mit optionaler Bildanreicherung
result = multimodal_search(
    rag,
    query="Roboter mit Emotionen",
    k_text=3,          # Anzahl Text-Ergebnisse
    k_images=3,        # Anzahl Bild-Ergebnisse
    enable_cross_modal=True
)
```

**Liefert:**
- LLM-generierte Antwort basierend auf Textdokumenten
- Relevante Textquellen mit Ã„hnlichkeitswerten
- Visuell passende Bilder via CLIP
- Cross-Modal gefundene Bilder Ã¼ber Textbeschreibungen

---

### 2. Bild â†’ Bild Suche

```python
# Finde visuell Ã¤hnliche Bilder
similar_images = search_similar_images(
    rag,
    query_image_path="./mein_roboter.jpg",
    k=5
)

for img in similar_images:
    print(f"{img['filename']}: {img['similarity']}")
    print(f"  Beschreibung: {img['description']}")
```

**Nutzt:**
- CLIP-Embeddings fÃ¼r visuelle Ã„hnlichkeit
- Cosinus-Ã„hnlichkeit im Embedding-Raum

---

### 3. Bild â†’ Text Suche (NEU in v3.0)

```python
# Finde Textinformationen zu einem Bild
result = search_text_by_image(
    rag,
    query_image_path="./cyborg_bild.png",
    k=3,        # Anzahl Ã¤hnlicher Bilder
    k_text=3    # Anzahl Text-Dokumente
)
```

**Funktionsweise:**
1. Findet visuell Ã¤hnliche Bilder via CLIP
2. Holt deren Beschreibungen aus der Datenbank
3. **NEU**: Nutzt Beschreibungen fÃ¼r semantische Textsuche
4. Findet relevante Text-Dokumente basierend auf Bildinhalten
5. Generiert Zusammenfassung aus Bildern UND Texten

**Ausgabe:**
- ğŸ“„ LLM-Zusammenfassung (Bilder + Texte)
- ğŸ–¼ï¸ Ã„hnliche Bilder mit Beschreibungen
- ğŸ“š Relevante Text-Dokumente mit Ã„hnlichkeitswerten

---

## Architektur

### Datenmodell

```
ChromaDB (./multimodal_rag_db/)
â”œâ”€â”€ texts_collection (OpenAI Embeddings)
â”‚   â”œâ”€â”€ Text-Dokumente (doc_type: "text_document")
â”‚   â”‚   â””â”€â”€ Chunks mit Metadaten
â”‚   â””â”€â”€ Bildbeschreibungen (doc_type: "image_description")
â”‚       â””â”€â”€ GPT-4o-mini generierte Beschreibungen
â”‚
â””â”€â”€ images_collection (CLIP Embeddings)
    â””â”€â”€ Bilder mit Cross-References zu text_collection
```

### Komponenten

**RAGConfig**
- Zentrale Konfigurationsklasse
- Anpassbare Parameter (chunk_size, models, thresholds)

**RAGComponents**
- Container fÃ¼r alle System-Komponenten
- Text-Embeddings, CLIP-Model, LLMs, Collections

**Hauptfunktionen**
- `init_rag_system_enhanced()`: System-Initialisierung
- `process_directory()`: Bulk-Import von Dateien
- `add_text_document()`: Einzelnes Dokument hinzufÃ¼gen
- `add_image_with_description()`: Bild mit Auto-Beschreibung
- `search_texts()`: Text-Suche inkl. Bildbeschreibungen
- `search_images()`: CLIP-basierte Bildsuche
- `search_similar_images()`: Bildâ†’Bild Ã„hnlichkeitssuche
- `search_text_by_image()`: Bildâ†’Text Suche (NEU)
- `multimodal_search()`: Erweiterte multimodale Suche

---

## UnterstÃ¼tzte Dateiformate

### Text-Dokumente
- `.txt` - Plain Text
- `.md` - Markdown
- `.pdf` - PDF-Dokumente
- `.docx` - Word-Dokumente
- `.html` - HTML-Dateien

### Bilder
- `.jpg` / `.jpeg`
- `.png`
- `.gif`
- `.bmp`

---

## Konfigurationsoptionen

```python
from multimodal_rag_modul import RAGConfig

# Benutzerdefinierte Konfiguration
config = RAGConfig(
    chunk_size=200,                    # Text-Chunk-GrÃ¶ÃŸe
    chunk_overlap=20,                  # Overlap zwischen Chunks
    text_threshold=1.2,                # Text-Ã„hnlichkeits-Schwellwert
    image_threshold=0.8,               # Bild-Ã„hnlichkeits-Schwellwert
    clip_model='clip-ViT-B-32',       # CLIP-Modell
    text_model='text-embedding-3-small',  # OpenAI Embedding-Modell
    llm_model='gpt-4o-mini',          # LLM fÃ¼r Textgenerierung
    vision_model='gpt-4o-mini',       # Vision-LLM fÃ¼r Bildbeschreibungen
    db_path='./custom_rag_db'        # Datenbank-Pfad
)

rag = init_rag_system_enhanced(config)
```

---

## ModalitÃ¤tsmatrix

| Eingabe (Query) | Ausgabe | Funktion | Status |
|-----------------|---------|----------|--------|
| **Text** | Text + Bilder | `multimodal_search()` | âœ… |
| **Text** | Nur Text | `search_texts()` | âœ… |
| **Text** | Nur Bilder | `search_images()` | âœ… |
| **Bild** | Ã„hnliche Bilder | `search_similar_images()` | âœ… |
| **Bild** | Text + Bilder | `search_text_by_image()` | âœ… |

---

## Performance-Optimierungen

### Implementiert in v3.0

1. **Batch-Retrieval**: Vermeidung von N+1 Query-Problem
   - Cross-Modal-Retrieval in einem einzigen Batch-Call

2. **Effiziente Filterung**: Trennung von Text-Dokumenten und Bildbeschreibungen
   - Direkte Filterung Ã¼ber Metadaten

3. **Score-Normalisierung**: ChromaDB L2-Distanz â†’ Ã„hnlichkeitswert
   - Konsistente Ã„hnlichkeitswerte (0-1 Range)

4. **Optimierte Embeddings**: Wiederverwendung von bereits berechneten Embeddings
   - Keine doppelte Embedding-Berechnung

---

## AnwendungsfÃ¤lle

### 1. Multimodale Wissensdatenbank
- Verwalte Produktkataloge mit Bildern und Beschreibungen
- Durchsuche technische Dokumentation mit Diagrammen
- Bilde-zu-Text Retrieval fÃ¼r wissenschaftliche Paper

### 2. Content Discovery
- "Finde Ã¤hnliche Produkte zu diesem Bild"
- "Welche Textinformationen passen zu diesem Screenshot?"
- "Zeige verwandte Artikel mit Bildern"

### 3. Forschung & Analyse
- Visuelle Ã„hnlichkeitsanalyse in Bildarchiven
- Semantische Suche Ã¼ber Multimodale Daten
- Cross-Modal Information Retrieval

---

## Fehlerbehebungen (v3.0)

### ChromaDB Where-Klausel Fix
**Problem**: ChromaDB erwartet `$and` Operator bei mehreren Filterbedingungen

**LÃ¶sung**:
```python
# Vorher (fehlerhaft)
components.text_collection.get(
    where={"source": path, "doc_type": "image_description"}
)

# Nachher (korrekt)
components.text_collection.get(
    where={
        "$and": [
            {"source": path},
            {"doc_type": "image_description"}
        ]
    }
)
```

---

## API-Referenz

### System-Management

**`init_rag_system_enhanced(config=None)`**
- Initialisiert das RAG-System
- Parameter: Optional RAGConfig Instanz
- Returns: RAGComponents

**`get_system_status(components)`**
- Gibt System-Status zurÃ¼ck
- Returns: Dict mit Statistiken

**`cleanup_database(db_path='./multimodal_rag_db')`**
- LÃ¶scht die Datenbank komplett

### Dokument-Verarbeitung

**`add_text_document(components, file_path)`**
- FÃ¼gt ein Text-Dokument hinzu
- Returns: bool (Erfolg)

**`add_image_with_description(components, image_path, auto_describe=True)`**
- FÃ¼gt Bild mit Beschreibung hinzu
- Returns: (success: bool, text_doc_id: str)

**`process_directory(components, directory, include_images=True, auto_describe_images=True)`**
- Verarbeitet alle Dateien rekursiv
- Returns: Dict mit Statistiken

---

## Lizenz

MIT License - Copyright (c) 2025 Ralf

---

## Version History

### v3.0 (Oktober 2025)
- âœ¨ NEU: `search_text_by_image()` mit Text-Dokumenten-Suche
- ğŸ› FIX: ChromaDB where-Klausel fÃ¼r mehrere Bedingungen
- âš¡ Performance: N+1 Query Problem behoben
- ğŸ“Š Erweiterte LLM-Prompts fÃ¼r bessere Zusammenfassungen

### v2.0
- Bildâ†’Bild Suche via CLIP
- Automatische Bildbeschreibungen
- Cross-Modal Retrieval

### v1.0
- Basis RAG-System
- Text-Suche
- ChromaDB Integration

---

## Support & Kontakt

- **Repository**: [GenAI/01 ipynb/multimodal_rag_modul.py](.)
- **Autor**: Enhanced by Claude
- **Datum**: Oktober 2025
