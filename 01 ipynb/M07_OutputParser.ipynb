{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["i0xOygLv6LaK","oYvUY6gMBKO1","6ls-Rt2LwCfT","wR5J9U9bg5Br","MQFjKL7uDgfA","Q6PFBjUSDo_N","hzCTsn14DyU0","3TjZs_TRht1n"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","OutputParser\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfdhPIzcEYRG","cellView":"form","collapsed":true},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  Colab-Umfeld</font> </br></p>\n","# Installierte Python Version\n","import sys\n","print(f\"Python Version: \",sys.version)\n","# Installierte LangChain Bibliotheken\n","print()\n","\n","print(\"Installierte LangChain Bibliotheken:\")\n","!pip list | grep '^langchain'\n","# Unterdr√ºckt die \"DeprecationWarning\" von LangChain f√ºr die Memory-Funktionden\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langsmith.client\")\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"langchain\")"]},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  SetUp API-Keys (setup_api_keys)</font> </br></p>\n","def setup_api_keys():\n","    \"\"\"Konfiguriert alle ben√∂tigten API-Keys aus Google Colab userdata\"\"\"\n","    from google.colab import userdata\n","    import os\n","    from os import environ\n","\n","    # Dictionary der ben√∂tigten API-Keys\n","    keys = {\n","        'OPENAI_API_KEY': 'OPENAI_API_KEY',\n","        'HF_TOKEN': 'HF_TOKEN',\n","        # Weitere Keys bei Bedarf\n","    }\n","\n","    # Keys in Umgebungsvariablen setzen\n","    for env_var, key_name in keys.items():\n","        environ[env_var] = userdata.get(key_name)\n","\n","    return {k: environ[k] for k in keys.keys()}\n","\n","# Verwendung\n","all_keys = setup_api_keys()\n","# Bei Bedarf einzelne Keys direkt zugreifen\n","# WEATHER_API_KEY = all_keys['WEATHER_API_KEY']"],"metadata":{"cellView":"form","id":"WD3Wwr6sESX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | OutputParser\n","---"],"metadata":{"id":"i0xOygLv6LaK"}},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["LangChain stellt eine Vielzahl von Ausgabeparsern bereit, die speziell darauf ausgelegt sind, Informationen aus den Ergebnissen gro√üer Sprachmodelle (LLMs) effizient zu extrahieren und zu strukturieren. Diese Parser sind essenzielle Bestandteile der LangChain-Architektur und h√§ufig zentrale Elemente sogenannter LangChain-Ketten. Solche Ketten bestehen aus konfigurierbaren Abfolgen von Operationen, die Modellausgaben verarbeiten und f√ºr weiterf√ºhrende Anwendungen nutzbar machen.\n","\n","\n","**Warum sind OutputParser so wichtig?**\n","+ LLMs geben standardm√§√üig unstrukturierte Texte zur√ºck.\n","+ OutputParser sind n√∂tig, um das LLM-Output strukturiert weiterzuverarbeiten.\n","+ Besonders bei komplexen Anwendungen (z. B. Ketten mit mehreren Modellen, Agenten oder RAG-Systemen) m√ºssen die Antworten klar definiert sein."]},{"cell_type":"markdown","source":["**√úbersicht LangChain-Parser:**\n","\n","<br>\n","\n","| **Name**                  | **Beschreibung**                                                                 | **Supports Streaming** | **Input-Typ**         | **Output-Typ**           |\n","|---------------------------|----------------------------------------------------------------------------------|-------------------------|-----------------------|--------------------------|\n","| **ListOutputParser**      | Wandelt eine durch Kommas getrennte Liste in eine Python-Liste um.               | Nein                    | `str`                | `list[str]`             |\n","| **DateTimeParser**        | Wandelt eine Datums- oder Zeitzeichenkette in ein Python-Datetime-Objekt um.     | Nein                    | `str`                | `datetime.datetime`     |\n","| **StructuredOutputParser**| Wandelt Text basierend auf einem Schema in ein Dictionary um.                    | Nein                    | `str`                | `Dict[str, str]`        |\n","| **JSON Parser**           | Gibt ein JSON-Objekt basierend auf einem Pydantic-Modell zur√ºck.                 | Ja                      | `str`                | `Message` (JSON Objekt) |\n","| **XML Parser**            | Wandelt XML-Ausgaben in ein Dictionary von Tags um.                              | Ja                      | `str`                | `dict`                 |\n","| **CSV Parser**            | Gibt eine Liste von durch Kommas getrennten Werten zur√ºck.                       | Ja                      | `str`                | `List[str]`            |\n","| **OutputFixingParser**    | Versucht, fehlerhafte Ausgaben zu korrigieren, indem es ein anderes LLM aufruft. | Ja                      | Wraps anderer Parser  | Abh√§ngig vom Parser     |\n","| **RetryWithErrorParser**  | Wiederholt die Eingabe bei Fehlern und sendet urspr√ºngliche Anweisungen mit.     | Ja                      | Wraps anderer Parser  | Abh√§ngig vom Parser     |\n","| **Pydantic Parser**       | Gibt Daten basierend auf einem benutzerdefinierten Pydantic-Modell zur√ºck.       | Ja                      | `str`                | `pydantic.BaseModel`   |\n","| **YAML Parser**           | Wie der Pydantic Parser, aber verwendet YAML zur Kodierung.                      | Ja                      | `str`                | `pydantic.BaseModel`   |\n","| **PandasDataFrame Parser**| Gibt Daten zur√ºck, die f√ºr Pandas DataFrames geeignet sind.                       | Ja                      | `str`                | `dict`                 |\n","| **Enum Parser**           | Wandelt die Antwort in einen der angegebenen Enum-Werte um.                     | Ja                      | `str`                | `Enum`                 |\n","\n","<br>\n","\n","Diese Parser erm√∂glichen es, die Ausgaben von Sprachmodellen (LLMs) in strukturierte und nutzbare Formate umzuwandeln, was besonders f√ºr Anwendungen mit spezifischen Anforderungen n√ºtzlich ist.\n"],"metadata":{"id":"DO2-q2e0a9sV"}},{"cell_type":"markdown","source":["# 2 | Strukturierter Parser (einfach)\n","---"],"metadata":{"id":"oYvUY6gMBKO1"}},{"cell_type":"markdown","metadata":{"id":"HMLrKTqgSRkM"},"source":["\n","Der **Structured Output Parser** in LangChain erm√∂glicht die strukturierte Verarbeitung der Ausgaben gro√üer Sprachmodelle (LLMs). Dies ist besonders hilfreich, wenn Informationen aus mehreren Feldern extrahiert und kategorisiert werden m√ºssen. Durch die Segmentierung der Modellausgabe in definierte Bereiche wird die Interpretation und Handhabung der Daten vereinfacht.\n","\n","W√§hrend der **Pydantic/JSON-Parser** eine leistungsf√§higere L√∂sung f√ºr komplexe Datenstrukturen darstellt, eignet sich der **Structured Output Parser** besonders f√ºr Umgebungen mit begrenzten Rechenressourcen oder f√ºr Modelle mit geringer Leistungsf√§higkeit. Er bietet eine einfache und effiziente M√∂glichkeit, die Ausgabe zu strukturieren, ohne das System zu stark zu belasten.\n","\n","Der erste Schritt bei der Nutzung dieses Parsers besteht in der Erstellung eines **ResponseSchemas**, das definiert, welche Werte extrahiert werden sollen. Jeder Wert wird dabei detailliert beschrieben. Anschlie√üend wird der **StructuredOutputParser** aus einer Liste dieser Schemata erstellt."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvzHRtXd3hEd"},"outputs":[],"source":["# Abschnitt 0: Install\n","!uv pip install --system --prerelease allow -q langchain-core langchain_community langchain_openai gradio"]},{"cell_type":"code","source":["# Abschnitt 1: Importe\n","from IPython.display import display, Markdown\n","\n","# Neue strukturierte Imports f√ºr aktuelle LangChain-Versionen\n","from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough"],"metadata":{"id":"_m84Eigb4LDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Abschnitt 2: Konstanten definieren\n","MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0.0\n","\n","QUESTION = \"Was ist Machine Learning?\""],"metadata":{"id":"ZUJwhu1LNmMe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","Ohne Nachbearbeitung mit einem Parser\n","</font></p>"],"metadata":{"id":"jMvv2MQNrggb"}},{"cell_type":"code","source":["llm = ChatOpenAI(model=MODEL, temperature=TEMPERATURE)"],"metadata":{"id":"78SUuguIrrSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = llm.invoke(QUESTION)"],"metadata":{"id":"MWmROWbwrrPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for r in response:\n","    print(r)"],"metadata":{"id":"ezuKTok2rrMb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","Mit Nachbearbeitung mit einem Parser\n","</font></p>"],"metadata":{"id":"CovCEerkv8Eb"}},{"cell_type":"code","source":["chain = llm | StrOutputParser()\n","response = chain.invoke(QUESTION)"],"metadata":{"id":"9t7QNRv3rrJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"id":"6CkTZi6LusDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | Strukturieter Parser (mittel)"],"metadata":{"id":"6ls-Rt2LwCfT"}},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","Structured Output Parser (mittel)\n","</font></p>"],"metadata":{"id":"n2igGVtTXE3I"}},{"cell_type":"markdown","source":["**Schritt 1:** Der **Parser** definiert ein Schema f√ºr die erwartete Ausgabe und verarbeitet die Antwort des LLMs in ein strukturiertes Format (z.B. ein Python-Dictionary)."],"metadata":{"id":"Dt428mOkTD3J"}},{"cell_type":"code","source":["# 1. Parser-Schema definieren\n","RESPONSE_SCHEMAS = [\n","    ResponseSchema(name=\"question\", description=\"Frage des Benutzers\"),\n","    ResponseSchema(name=\"answer\", description=\"Antwort auf die Frage des Benutzers\"),\n","    ResponseSchema(name=\"source\", description=\"Verwendete Quelle (Website) f√ºr die Antwort\")\n","]\n","\n","# 2. Parser erstellen\n","parser = StructuredOutputParser.from_response_schemas(RESPONSE_SCHEMAS)\n","\n","# 3. Formatierungs Instruktion zu diesem Parser f√ºr das Prompt erstellen\n","FORMAT_INSTRUCTIONS = parser.get_format_instructions()"],"metadata":{"id":"Hc9NtLEdNnr_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3AD6gq-_jWew"},"source":["Wir k√∂nnen die einzelnen Elemente anzeigen, die wir zum Abrufen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCVMfLjvjWew"},"outputs":[],"source":["print(RESPONSE_SCHEMAS)"]},{"cell_type":"code","source":["print(parser)"],"metadata":{"id":"35ReNN3ukLdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(FORMAT_INSTRUCTIONS)"],"metadata":{"id":"tb3Xo6ZGkO8q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Schritt 2:** Verwendung des Schemas mit der Formatierungs Instruktion in einem Prompt."],"metadata":{"id":"aZWHfFm6TXir"}},{"cell_type":"code","source":["# 1. System-Prompt mit den Variablen (f-format) erstellen\n","SYSTEM_PROMPT = \"\"\"\n","    Beantworte die folgende Frage so pr√§zise wie m√∂glich.\n","    Gib auch die Quelle deiner Information an.\n","\n","    Frage: {question}\n","\n","    {format_instructions}\n","\"\"\"\n","\n","# 2. Prompt-Template generieren\n","prompt = PromptTemplate(\n","    template=SYSTEM_PROMPT,\n","    input_variables=[\"question\"],\n","    partial_variables={\"format_instructions\": FORMAT_INSTRUCTIONS}\n",")"],"metadata":{"id":"VLGsxKXFTLbW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtH3oH7vjRHL"},"source":["Wir k√∂nnen die Eingabeaufforderung anzeigen, die wir zum Abrufen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffp8vPsjjRHM"},"outputs":[],"source":["print(SYSTEM_PROMPT)"]},{"cell_type":"code","source":["print(prompt)"],"metadata":{"id":"uJq_paoikWgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funktion zur Aufbereitung der Druck-Ausgabe\n","def markdown_out(result):\n","    display(Markdown(f\"**üßë Mensch**\"))\n","    display(Markdown(f\"{result['question']}\"))\n","    display(Markdown(f\"**ü§ñ KI:**\"))\n","    display(Markdown(f\"{result['answer']}\"))\n","    display(Markdown(f\"**Quelle:** {result['source']}\"))"],"metadata":{"id":"uaWn2wPJGmus"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Einbindung des Parser in unterschiedliche Chain-Strukturen.\n","</font></p>"],"metadata":{"id":"XJcx6t4HXZbY"}},{"cell_type":"markdown","source":["**Variante 0:** Ohne Chain-Struktur"],"metadata":{"id":"CBQ90Au9Y4Ab"}},{"cell_type":"code","source":["# LLM definieren - ohne weitere Kette\n","llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n","\n","# Aufruf\n","llm_response = llm.invoke(prompt.format(question=QUESTION))\n","\n","# Antwort parsen\n","result = parser.parse(llm_response.content)\n","\n","markdown_out(parsed_response)"],"metadata":{"id":"fXB-iqLyTi18"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Variante 2:** Chain mit direkte Eingabe als Dictionary"],"metadata":{"id":"yhR3N3tPX5x9"}},{"cell_type":"code","source":["chain = (\n","    prompt\n","    | llm\n","    | parser\n",")\n","\n","# Aufruf mit Dictionary\n","result = chain.invoke({\"question\": \"Was ist Machine Learning?\"})\n","markdown_out(result)"],"metadata":{"id":"RIM9uWjhYjfd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Variante 3:** Chain mit Dictionary-Transformation `RunnablePassthrough`"],"metadata":{"id":"NWP7LkqoX50f"}},{"cell_type":"code","source":["# Chain mit Dictionary-Transformation\n","from langchain_core.runnables import RunnablePassthrough\n","\n","chain = (\n","    {\"question\": RunnablePassthrough()}  # Wandelt String in Dictionary um\n","    | prompt\n","    | llm\n","    | parser\n",")\n","\n","# Aufruf mit einfachem String\n","result = chain.invoke(QUESTION)\n","markdown_out(result)"],"metadata":{"id":"nUz7fytPYATz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wR5J9U9bg5Br"},"source":["# 4 | Strukturierter Parser (komplex)\n","---"]},{"cell_type":"markdown","source":["Nun wird ein Beispiel mit einer gr√∂√üeren Anzahl an Werten getestet. Das folgende Programm nimmt Texte in beliebigen Sprachen entgegen und √ºbersetzt sie ins Englische, Spanische und Chinesische."],"metadata":{"id":"nN1AWb1m9OK4"}},{"cell_type":"markdown","source":["**Schritt 1:** Der **Parser** definiert ein Schema f√ºr die erwartete Ausgabe und verarbeitet die Antwort des LLMs in ein strukturiertes Format (z.B. ein Python-Dictionary)."],"metadata":{"id":"lpn8vHKwcEui"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9snGgL4riemY"},"outputs":[],"source":["RESPONSE_SCHEMAS = [\n","    ResponseSchema(name=\"detected\", description=\"Die Sprache ist Nutzer-Eingabe\"),\n","    ResponseSchema(name=\"german\", description=\"German translation\"),\n","    ResponseSchema(name=\"english\", description=\"English translation\"),\n","    ResponseSchema(name=\"spanish\", description=\"Spanish translation\"),\n","    ResponseSchema(name=\"chinese\", description=\"Chinese translation\"),\n","]\n","parser = StructuredOutputParser.from_response_schemas(RESPONSE_SCHEMAS)\n","\n","FORMAT_INSTRUCTIONS = parser.get_format_instructions()"]},{"cell_type":"markdown","source":["**Schritt 2:** Verwendung des Schemas mit der Formatierungs Instruktion in einem Prompt."],"metadata":{"id":"zyAeqALjcbFt"}},{"cell_type":"code","source":["# 1. System-Prompt mit den Variablen (f-format) erstellen\n","SYSTEM_PROMPT = \"\"\"\n","    √úbersetze in die angegebenen Sprachen.\\n{format_instructions}\\n{question}\n","\"\"\"\n","\n","# 2. Prompt-Template generieren\n","prompt = PromptTemplate(\n","    template=SYSTEM_PROMPT,\n","    input_variables=[\"question\"],\n","    partial_variables={\"format_instructions\": FORMAT_INSTRUCTIONS}\n",")"],"metadata":{"id":"WXr_0z9PcbFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Variante 2:** Chain mit direkte Eingabe als *Dictionary*"],"metadata":{"id":"8emVa-S1cuPI"}},{"cell_type":"markdown","metadata":{"id":"sa6_dAk2ugre"},"source":["Zun√§chst wird ein deutscher Satz getestet, um zu beobachten, wie die √úbersetzung in die drei Zielsprachen erfolgt."]},{"cell_type":"code","source":["chain = prompt | llm | parser\n","question = \"Wann wurde Python eingef√ºhrt?\"\n","chain.invoke({\"question\": question})"],"metadata":{"id":"01rQuqfdbv1o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dann wird ein franz√∂sischer Satz getestet, um zu beobachten, wie die √úbersetzung in die drei Zielsprachen erfolgt."],"metadata":{"id":"3lYL9wUcemex"}},{"cell_type":"code","source":["chain = prompt | llm | parser\n","question = \"Who rides so late through night and wind?\"\n","chain.invoke({\"question\": question})"],"metadata":{"id":"4qF-a2PbeNET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = chain.invoke({\"question\": question})"],"metadata":{"id":"_QZ8OvijgblY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MQFjKL7uDgfA"},"source":["# 5 | Datenformat Parser\n","---"]},{"cell_type":"markdown","source":["LangChain bietet eine breite Palette an Parsern, die unterschiedliche Datenformate verarbeiten k√∂nnen, was seine Einsatzm√∂glichkeiten erheblich erweitert. Es unterst√ºtzt unter anderem die nahtlose Integration von Pandas-Datenrahmen, kommagetrennten Listen, JSON-Strukturen sowie Datums- und Zeitobjekten. Diese Flexibilit√§t erm√∂glicht eine effiziente Anpassung an verschiedene Arten von Dateneingaben und macht LangChain zu einem leistungsstarken Werkzeug f√ºr die Analyse und Verarbeitung von Daten. Im Folgenden werden einige dieser Parser genauer betrachtet, ihre praktischen Anwendungen demonstriert und aufgezeigt, wie sie zur Optimierung von Prozessen und zur Gewinnung wertvoller Erkenntnisse beitragen k√∂nnen."],"metadata":{"id":"Q1oRFrLCx8eW"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","CSV\n","</font></p>"],"metadata":{"id":"EBERl78zyIzh"}},{"cell_type":"markdown","source":["Der **CommaSeparatedListOutputParser** erm√∂glicht die Umwandlung von LLM-Ausgaben in eine durch Kommas getrennte Liste und extrahiert diese als native Python-Liste. Dies ist besonders n√ºtzlich, wenn strukturierte Daten aus einem Sprachmodell extrahiert und f√ºr weitere Verarbeitungsschritte verwendet werden sollen. Indem der Parser die Ausgabe direkt in eine Listenstruktur √ºberf√ºhrt, erleichtert er die Handhabung und Weiterverarbeitung der generierten Daten in verschiedenen Anwendungen."],"metadata":{"id":"aptyNpJ0ynir"}},{"cell_type":"code","source":["# Abschnitt 1: Importe\n","from langchain.output_parsers import CommaSeparatedListOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Abschnitt 2: Konstanten definieren\n","MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0\n","\n","# Abschnitt 3: Parser und Prompt\n","output_parser = CommaSeparatedListOutputParser()\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","chat_prompt = PromptTemplate(\n","    template=\"List ten {subject}.\\n{format_instructions}\",\n","    input_variables=[\"subject\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","# Abschnitt 4: Chat-Komponenten initialisieren\n","chat_model = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")\n","\n","# Abschnitt 5: Funktionen definieren\n","def generate_list(subject: str):\n","    \"\"\"  Generiert eine Liste mit zehn Elementen zu einem gegebenen Thema.  \"\"\"\n","    chain = chat_prompt | chat_model | output_parser\n","    return chain.invoke({\"subject\": subject})\n","\n","# Abschnitt 6: Hauptprogramm\n","def main():\n","    \"\"\"Startet die Hauptkonversation und gibt eine Liste von St√§dten aus.\"\"\"\n","    cities = generate_list(\"St√§dte\")\n","    print(type(cities), cities)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"PT2ZjJv_2tBt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mE2avWGaysc3"},"source":["<p><font color='black' size=\"5\">\n","JSON\n","</font></p>"]},{"cell_type":"markdown","source":["Die Ausgabe des LLM kann in einem JSON-Format strukturiert werden."],"metadata":{"id":"S69wM83z-1Hh"}},{"cell_type":"code","source":["#\n","# Variante mit Prompt\n","#\n","from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n","\n","prompt = (\n","    \"Bitte gib mir eine Person mit Name und Alter im JSON-Format zur√ºck, z.B. \"\n","    '{\"name\": \"Max\", \"age\": 30}'\n",")\n","\n","response = llm.invoke(prompt)\n","print(\"Antwort vom Modell:\")\n","print(response)"],"metadata":{"id":"KIYp-bKe5t3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","# Variante mit JsonOutputParser\n","#\n","from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers.json import JsonOutputParser\n","\n","# Einfaches JSON-Schema\n","schema = {\n","        \"name\": {\"type\": \"string\"},\n","        \"age\": {\"type\": \"integer\"}\n","}\n","\n","# JsonOutputParser mit dem Schema erstellen\n","parser = JsonOutputParser(schema=schema)\n","\n","# OpenAI LLM initialisieren\n","llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n","\n","# Modell fragen, Antwort soll JSON sein\n","prompt = (\n","    \"Please give as an answert name and age of a person in json-Format\"\n",")\n","\n","response = llm.invoke(prompt)\n","# print(\"Antwort vom Modell:\")\n","# print(response)\n","\n","# Antwort parsen\n","result = parser.invoke(response)\n","print(\"Geparstes Ergebnis:\")\n","print(result)"],"metadata":{"id":"0dJs83IJ5t6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In diesem Beispiel wird ein Satz erkannt, der als Englisch identifiziert wird, und anschlie√üend ins Spanische, Franz√∂sische und Chinesische √ºbersetzt."],"metadata":{"id":"njnSr9msG424"}},{"cell_type":"code","source":["# Abschnitt 1: Importe\n","from langchain_core.output_parsers import JsonOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Abschnitt 2: Funktionen\n","def translate_text(text: str) -> dict:\n","    \"\"\"√úbersetzt den Text in mehrere Sprachen\"\"\"\n","    # Parser ohne Pydantic-Modell konfigurieren\n","    parser = JsonOutputParser()\n","    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n","\n","    # Prompt erstellen mit direkten Anweisungen zum JSON-Format\n","    prompt_template = \"\"\"\n","    √úbersetze die Benutzereingabe in mehrere Sprachen und gib das Ergebnis als JSON zur√ºck.\n","\n","    Dein JSON sollte folgende Felder enthalten:\n","    - detected: Die erkannte Ausgangssprache\n","    - german: Die deutsche √úbersetzung\n","    - spanish: Die spanische √úbersetzung\n","    - french: Die franz√∂sische √úbersetzung\n","    - chinese: Die chinesische √úbersetzung\n","\n","    Benutzereingabe: {input}\n","    \"\"\"\n","\n","    prompt = PromptTemplate(\n","        template=prompt_template,\n","        input_variables=[\"input\"]\n","    )\n","\n","    # Kette ausf√ºhren\n","    chain = prompt | llm | parser\n","    return chain.invoke({\"input\": text})\n","\n","# Abschnitt 3: Hauptprogramm\n","# Beispieltext √ºbersetzen und Ergebnisse ausgeben\n","result = translate_text(\"What is your name?\")\n","\n","print()\n","display(Markdown(f\"**Erkannte Sprache:** {result['detected']}\"))\n","display(Markdown(f\"**Deutsch:** {result['german']}\"))\n","display(Markdown(f\"**Spanisch:** {result['spanish']}\"))\n","display(Markdown(f\"**Franz√∂sisch:** {result['french']}\"))\n","display(Markdown(f\"**Chinesisch:** {result['chinese']}\"))"],"metadata":{"id":"PYO2u9vKgyC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ausgabe json-Format\n","import json\n","print(json.dumps(result, indent=2, ensure_ascii=False))"],"metadata":{"id":"coWJgUUZlmxb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y09-epHS5McO"},"source":["<p><font color='black' size=\"5\">\n","Datum/Uhrzeit\n","</font></p>"]},{"cell_type":"markdown","source":["Langchain bietet mit dem **DatetimeOutputParser** eine spezielle Funktion zur Interpretation von Datums- und Zeitangaben aus Texten. Sie erkennt unterschiedliche Formate und wandelt diese in ein standardisiertes Zeitformat um. Dies ist besonders hilfreich f√ºr Anwendungen wie Terminplanung, Datenanalyse oder andere Bereiche, in denen eine pr√§zise Verarbeitung zeitlicher Informationen erforderlich ist. Der **DatetimeOutputParser** erleichtert die Verarbeitung von Datums- und Uhrzeitangaben und tr√§gt dazu bei, dass Anwendungen zeitbezogene Daten effizient verwalten und nutzen k√∂nnen."],"metadata":{"id":"-zDlyRDUM4qS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRuzzhXF5Oa1"},"outputs":[],"source":["# Abschnitt 1: Importe\n","from langchain.output_parsers import DatetimeOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import OpenAI\n","\n","# Abschnitt 2: Konstanten\n","TEMPLATE = \"\"\"Beantworte die Frage zu genau wie m√∂glich.\n","Wenn Du die Frage nach dem Datum nicht beantworten kannst, dann geben mir das Datum 01.01.1111.\n","\n","{question}\n","\n","{format_instructions}\"\"\"\n","\n","# Abschnitt 3: Komponenten initialisieren\n","llm = ChatOpenAI(\n","    model=\"gpt-4o-mini\",\n","    temperature=0.2,\n","    n=1\n",")\n","\n","output_parser = DatetimeOutputParser()\n","prompt = PromptTemplate(\n","    template=TEMPLATE,\n","    input_variables=['question'],\n","    partial_variables={'format_instructions': output_parser.get_format_instructions()}\n",")"]},{"cell_type":"markdown","metadata":{"id":"roqInbqGFdUb"},"source":["Wir k√∂nnen die Eingabeaufforderung anzeigen, die wir zum Abrufen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HecixPQl6kYk"},"outputs":[],"source":["print(prompt)"]},{"cell_type":"markdown","metadata":{"id":"kg5ZkOetFiPx"},"source":["Wir erstellen die Kette, die wir zum Parsen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2w5gYty_5pKd"},"outputs":[],"source":["chain = prompt | llm | output_parser"]},{"cell_type":"markdown","metadata":{"id":"dD-gNvBHFooj"},"source":["Wir werden nach zwei Daten fragen, einem realen und einem fiktiven."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ymu48Ggg518q"},"outputs":[],"source":["output = chain.invoke({\"question\": \"Wann wurde die Progammiersprache Python eingef√ºhrt?\"}) # 20.02.1991\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOPWYpxr6As1"},"outputs":[],"source":["output = chain.invoke({\"question\": \"An welchem Tag startet der Krieg im Videospiel Fallout?\"}) #  23.10.2077\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"Q6PFBjUSDo_N"},"source":["\n","# 6 | Pydantic Parser\n","---"]},{"cell_type":"markdown","source":["Pydantic ist eine Python-Bibliothek zur Datenvalidierung und Einstellungsverwaltung, die auf den Typanmerkungen von Python basiert. Sie erm√∂glicht eine effiziente und einfache Validierung sowie Umwandlung von Daten und nutzt dabei das standardisierte Typisierungssystem von Python.\n","\n","**Wichtige Funktionen von Pydantic:**\n","- **Datenvalidierung:** √úberpr√ºft, ob Daten den erwarteten Formaten entsprechen, und konvertiert sie bei Bedarf in die korrekten Typen.\n","- **Unterst√ºtzung f√ºr Code-Editoren:** Dank der Nutzung von Python-Typanmerkungen bieten moderne Editoren Funktionen wie Autovervollst√§ndigung und Typpr√ºfung f√ºr Pydantic-Modelle.\n","- **Fehlermeldungen:** Detaillierte und verst√§ndliche Fehlermeldungen helfen, Probleme bei der Datenvalidierung gezielt zu identifizieren.\n","- **Einstellungsverwaltung:** Erleichtert das Laden und Verwalten von Konfigurationsparametern aus verschiedenen Quellen, darunter Umgebungsvariablen und JSON-Dateien.\n","- **Erweiterbarkeit:** Modelle lassen sich durch Methoden und Eigenschaften anpassen, und benutzerdefinierte Validierungen k√∂nnen mithilfe von Pydantic-Dekoratoren hinzugef√ºgt werden.\n","- **Integration mit anderen Bibliotheken:** Besonders in Verbindung mit FastAPI verbessert Pydantic die Verwaltung und Validierung von API-Daten erheblich.\n","\n","Aufgrund seiner Flexibilit√§t und Benutzerfreundlichkeit ist Pydantic besonders n√ºtzlich f√ºr Webentwicklung und datenintensive Anwendungen, bei denen eine zuverl√§ssige Datenverarbeitung erforderlich ist."],"metadata":{"id":"ZB7QnNtDzaiz"}},{"cell_type":"markdown","source":["\n","\n","**Pydantic in LangChain:**    \n","LangChain, eine Bibliothek zur Entwicklung von Anwendungen mit Sprachmodellen, nutzt Pydantic f√ºr die strukturierte Verarbeitung von Modellantworten. Der **PydanticOutputParser** gew√§hrleistet, dass die Ausgaben eines Sprachmodells einer vorgegebenen Struktur entsprechen. Dies ist besonders vorteilhaft f√ºr Anwendungen, bei denen konsistente Datenformate entscheidend sind ‚Äì beispielsweise bei der Datenextraktion, API-Antworten oder der automatisierten Weiterverarbeitung von Modell-Ausgaben."],"metadata":{"id":"oxlZwhl-SfMX"}},{"cell_type":"markdown","source":["Der Code nachfolgende demonstriert die Verwendung von Pydantic zur Validierung strukturierter Daten am Beispiel von Kochrezepten. Diese Implementierung zeigt, wie Datenstrukturen definiert, validiert und gegen spezifische Regeln gepr√ºft werden k√∂nnen.\n","\n","**Anwendungsszenario:**   \n","Stellen Sie sich vor, Sie entwickeln eine Koch-App oder eine Rezeptdatenbank, bei der die Qualit√§t und Konsistenz der eingegebenen Rezepte entscheidend ist. Der Code bildet das Herzst√ºck einer Validierungsschicht, die sicherstellt, dass alle Rezepte den definierten Standards entsprechen:\n","\n","**Datenstruktur-Validierung:**\n","+ Jedes Rezept muss bestimmte Pflichtfelder enthalten (Name, Schwierigkeitsgrad, Zubereitungszeit, Zutaten).\n","+ Typpr√ºfung: Die Felder m√ºssen den korrekten Datentyp aufweisen (z.B. Zubereitungszeit als ganze Zahl).\n","+ Inhaltliche Validierung: Der Schwierigkeitsgrad darf nur bestimmte Werte annehmen, die Zubereitungszeit muss in einem realistischen Bereich liegen.\n"],"metadata":{"id":"D2TvCYBhqCp0"}},{"cell_type":"code","source":["# Import\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","from pydantic import BaseModel, Field\n","from typing import List\n","\n","# 1. Datenstruktur definieren\n","class Rezept(BaseModel):\n","    name: str = Field(description=\"Name des Gerichts\")\n","    schwierigkeitsgrad: str = Field(description=\"Schwierigkeitsgrad (leicht/mittel/schwer)\")\n","    zubereitungszeit: int = Field(description=\"Zubereitungszeit in Minuten\")\n","    zutaten: List[str] = Field(description=\"Liste der ben√∂tigten Zutaten\")\n","\n","# 2. Parser erstellen\n","parser = PydanticOutputParser(pydantic_object=Rezept)\n","\n","# 3. LLM initialisieren\n","llm = ChatOpenAI(temperature=0.2)  # Niedrige Temperatur f√ºr konsistentere Ergebnisse\n","\n","# 4. Prompt-Template erstellen\n","prompt_text = \"\"\"\n","Erstelle ein strukturiertes Rezept f√ºr das folgende Gericht.\n","\n","{format_instructions}\n","\n","Gericht: {gericht}\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    template=prompt_text,\n","    input_variables=[\"gericht\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",")\n","\n","# 5. Funktion zum Abfragen des Rezepts\n","def rezept_abfragen(gericht_name):\n","    try:\n","        # Prompt formatieren\n","        formatted_prompt = prompt.format(gericht=gericht_name)\n","\n","        # LLM-Antwort abrufen und parsen\n","        antwort = llm.invoke(formatted_prompt)\n","        rezept_objekt = parser.parse(antwort.content)\n","        return rezept_objekt\n","    except Exception as e:\n","        print(f\"‚ùå Fehler bei der Rezeptabfrage: {e}\")\n","        return None\n","\n","# 6. Separate Funktion zur √úberpr√ºfung des Rezepts\n","def rezept_pruefen(rezept_objekt):\n","    try:\n","        if rezept_objekt is None:\n","            raise ValueError(\"Kein Rezeptobjekt vorhanden\")\n","\n","        # √úberpr√ºfung der Struktur und Datentypen\n","        assert isinstance(rezept_objekt.name, str), \"Name ist kein String\"\n","        assert isinstance(rezept_objekt.schwierigkeitsgrad, str), \"Schwierigkeitsgrad ist kein String\"\n","        assert isinstance(rezept_objekt.zubereitungszeit, int), \"Zubereitungszeit ist keine Zahl\"\n","        assert isinstance(rezept_objekt.zutaten, list), \"Zutaten ist keine Liste\"\n","        assert len(rezept_objekt.zutaten) > 0, \"Zutaten-Liste ist leer\"\n","\n","        # Inhaltliche √úberpr√ºfung\n","        assert rezept_objekt.schwierigkeitsgrad.lower() in [\"leicht\", \"mittel\", \"schwer\"], \\\n","            \"Schwierigkeitsgrad muss 'leicht', 'mittel' oder 'schwer' sein\"\n","        assert 5 <= rezept_objekt.zubereitungszeit <= 240, \\\n","            \"Zubereitungszeit sollte zwischen 5 und 240 Minuten liegen\"\n","\n","        print(\"‚úÖ √úberpr√ºfung erfolgreich!\")\n","        return True\n","    except Exception as e:\n","        print(f\"‚ùå Fehler bei der √úberpr√ºfung: {e}\")\n","        return False"],"metadata":{"id":"lAp6ftC4nq1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 7. Normale Ausf√ºhrung mit einem echten Rezept\n","def test_mit_echtem_rezept():\n","    print(\"=== Test mit echtem Rezept ===\")\n","    gericht_name = \"Spaghetti Carbonara\"\n","    rezept = rezept_abfragen(gericht_name)\n","\n","    if rezept and rezept_pruefen(rezept):\n","        print(f\"\\nRezept: {rezept.name}\")\n","        print(f\"Schwierigkeitsgrad: {rezept.schwierigkeitsgrad}\")\n","        print(f\"Zubereitungszeit: {rezept.zubereitungszeit} Minuten\")\n","        print(\"Zutaten:\")\n","        for zutat in rezept.zutaten:\n","            print(f\"- {zutat}\")"],"metadata":{"id":"ECbX1FuBsT7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_mit_echtem_rezept()"],"metadata":{"id":"P2YZn-Bxsawu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 8. Dummy-Case f√ºr Fehlererzeugung\n","def test_mit_fehler_rezept():\n","    print(\"\\n=== Test mit Dummy-Fehler-Rezept ===\")\n","    # Erstellen eines fehlerhaften Rezeptobjekts\n","    from pydantic import create_model\n","\n","    # Fehlerhafte Zubereitungszeit (als String statt int)\n","    fehlerhaftes_rezept = Rezept(\n","        name=\"Fehlerrezept\",\n","        schwierigkeitsgrad=\"unm√∂glich\",  # Ung√ºltiger Schwierigkeitsgrad\n","        zubereitungszeit=300,  # Zu lange Zubereitungszeit\n","        zutaten=[]  # Leere Zutatenliste\n","    )\n","\n","    if rezept_pruefen(fehlerhaftes_rezept) == False:\n","        print(\"Der Fehlertest war erfolgreich: Die Validierung hat die Fehler erkannt!\")"],"metadata":{"id":"kt9ufk_qsVuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_mit_fehler_rezept()"],"metadata":{"id":"0XAECoF8secr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzCTsn14DyU0"},"source":["# 7 | Eigene Parser\n","---"]},{"cell_type":"markdown","source":["In bestimmten Szenarien kann es sinnvoll sein, einen benutzerdefinierten Parser zu erstellen, um die Modellausgabe eindeutig zu formatieren.  \n","\n","Daf√ºr bietet sich die Verwendung von **RunnableLambda** oder **RunnableGenerator** in LCEL an, was f√ºr viele F√§lle ein guten Ansatz ist.  "],"metadata":{"id":"DEXj9woZzzy0"}},{"cell_type":"markdown","metadata":{"id":"isGwPhF4GUM5"},"source":["<p><font color='black' size=\"5\">\n","Anwendungsfall\n","</font></p>"]},{"cell_type":"markdown","source":["\n","\n","Large Language Models (LLMs) wie GPT-4 k√∂nnen Text generieren, der Code und erkl√§rende Beschreibungen nahtlos vermischt. Dies kann zwar f√ºr Lern- und Dokumentationszwecke unglaublich n√ºtzlich sein, kann aber eine Herausforderung darstellen, wenn aus solchen Ausgaben mit gemischtem Inhalt nur der Code extrahiert und ausgef√ºhrt werden muss. Um dies zu beheben, implementieren wir eine einfache Funktion, die nicht-Python-Codezeilen aus einer gegebenen Textzeichenfolge entfernt.\n","\n","Bei diesem Ansatz werden regul√§re Ausdr√ºcke verwendet, um Zeilen zu identifizieren und beizubehalten, die der typischen Python-Syntax entsprechen, w√§hrend Zeilen verworfen werden, die beschreibender Text zu sein scheinen. Aufgrund der inh√§renten Komplexit√§t und Variabilit√§t sowohl von Python-Code als auch von nat√ºrlicher Sprache kann diese Methode jedoch nie perfekt sein. Sie basiert auf heuristischen Mustern, die Code manchmal f√§lschlicherweise als Text klassifizieren oder umgekehrt.\n","\n","Im n√§chsten Abschnitt werden wir untersuchen, wie ein anderes LLM beim Entfernen von Nicht-Python-Code helfen kann und m√∂glicherweise eine ausgefeiltere und genauere L√∂sung bietet. Das folgende Beispiel enth√§lt eine Mischung aus LLM-Kommentaren und generiertem Code.\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"sPq64ydYgJ42"}},{"cell_type":"code","source":["from langchain_core.runnables import RunnableLambda\n","from langchain_openai import ChatOpenAI\n","from IPython.display import display, Markdown\n","\n","\n","# 1. LLM-Modell definieren\n","llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9)\n","\n","# 2. Funktion zur Trennung von Erl√§uterung und Code\n","def parse_ai_message(ai_message):\n","    \"\"\"Trennt die Erl√§uterung und den Code aus einer AIMessage und gibt sie separat zur√ºck.\"\"\"\n","    text = ai_message.content  # Extrahiere den reinen Textinhalt der AIMessage\n","\n","    if \"```\" in text:\n","        # Trennen der Erl√§uterung und des Codes\n","        parts = text.split(\"```\")\n","        explanation = parts[0].strip()\n","        code = parts[1].strip() if len(parts) > 1 else \"\"\n","    else:\n","        # Falls kein Codeblock vorhanden ist, geben wir nur die Erl√§uterung zur√ºck\n","        explanation = text.strip()\n","        code = \"\"\n","\n","    return explanation, code  # R√ºckgabe von zwei separaten Werten\n","\n","# 3. RunnableLambda f√ºr das Parsing erstellen\n","parser = RunnableLambda(parse_ai_message)\n","\n","# 4. LLM und Parser verketten\n","chain = llm | parser\n","\n","# 5. Eingabe an die Pipeline senden und Ergebnis ausgeben\n","prompt = \"\"\"\n","    Erkl√§re mir, wie man eine einfache Funktion in Python erstellt und gib ein Beispiel.\n","    Verwende bei Formeln das Format $ Formel $\n","\"\"\"\n","explanation, code = chain.invoke(prompt)\n","\n","display(Markdown(\"## Erl√§uterung\"))\n","display(Markdown(explanation))\n","display(Markdown(\"## Code\"))\n","print(code)"],"metadata":{"id":"6wjQlnF7qeso"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TjZs_TRht1n"},"source":["# A | Aufgabe\n","---"]},{"cell_type":"markdown","source":["Die Aufgabestellungen unten bieten Anregungen, Sie k√∂nnen aber auch gerne eine andere Herausforderung angehen."],"metadata":{"id":"smOJ1YD15z_Q"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","JSON-Parser mit LangChain\n","</font></p>"],"metadata":{"id":"L5IWdaBS0UZD"}},{"cell_type":"markdown","source":["\n","**Ziel:** Verst√§ndnis f√ºr den Einsatz von `JsonOutputParser` in LangChain.\n","\n","**Aufgabe:**  \n","1. Nutze den `JsonOutputParser` von LangChain, um eine KI-Antwort in JSON zu formatieren.  \n","2. Lasse ein Language Model (z. B. OpenAI GPT) eine Liste von drei zuf√§lligen St√§dten in Deutschland generieren.  \n","3. Verwende den Parser, um die Ausgabe in ein JSON-Format umzuwandeln.\n","\n","**Erwartete Ausgabe (Beispiel):**\n","```json\n","{\n","  \"cities\": [\"Berlin\", \"Hamburg\", \"M√ºnchen\"]\n","}\n","```\n"],"metadata":{"id":"JTdhJeN8u99p"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Extraktion von Schl√ºsselwerten\n","</font></p>"],"metadata":{"id":"UCpw6-OHvHJJ"}},{"cell_type":"markdown","source":["\n","**Ziel:** Nutzung des `PydanticOutputParser`, um strukturierte Daten aus nat√ºrlicher Sprache zu extrahieren.\n","\n","**Aufgabe:**  \n","1. Definiere eine `Pydantic`-Datenklasse mit den Feldern: `name` (str), `alter` (int), `stadt` (str).  \n","2. Verwende ein Language Model, um aus einer gegebenen Beschreibung eine Person zu extrahieren.  \n","3. Parse die Antwort mit dem `PydanticOutputParser`.\n","\n","**Beispiel-Eingabe:**\n","> \"Max Mustermann ist 35 Jahre alt und lebt in Berlin.\"\n","\n","**Erwartete Ausgabe (Pydantic-Modell):**\n","```json\n","{\n","  \"name\": \"Max Mustermann\",\n","  \"alter\": 35,\n","  \"stadt\": \"Berlin\"\n","}\n","```"],"metadata":{"id":"geRHkOMCvKum"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Parser f√ºr Listenformate\n","</font></p>"],"metadata":{"id":"8-AzxHafvSE_"}},{"cell_type":"markdown","source":["\n","**Ziel:** Implementierung eines eigenen Parsers zur Umwandlung von KI-Ausgaben in Listen.\n","\n","**Aufgabe:**  \n","1. Erstelle eine eigene Parser-Klasse, die eine durch Kommas getrennte Liste in ein Listenformat umwandelt.  \n","2. Verwende diesen Parser, um eine Liste von f√ºnf beliebten B√ºchern aus einer Language-Model-Antwort zu extrahieren.\n","\n","**Beispiel-Eingabe:**\n","> \"Die Verwandlung, Faust, Der Prozess, Die Blechtrommel, Der Vorleser\"\n","\n","**Erwartete Ausgabe:**\n","```python\n","[\"Die Verwandlung\", \"Faust\", \"Der Prozess\", \"Die Blechtrommel\", \"Der Vorleser\"]\n","```"],"metadata":{"id":"ytCh-C2uvUFw"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kombination Parser & PromptTemplate\n","</font></p>"],"metadata":{"id":"I3LRv5YAviSF"}},{"cell_type":"markdown","source":["\n","**Ziel:** Verwendung von `StructuredOutputParser` in Kombination mit `PromptTemplate`.\n","\n","**Aufgabe:**  \n","1. Erstelle ein `PromptTemplate`, das eine strukturierte Antwort √ºber ein Land ausgibt (Name, Hauptstadt, Einwohnerzahl).  \n","2. Verwende den `StructuredOutputParser`, um die Antwort in ein Dictionary zu konvertieren.\n","\n","**Beispiel-Prompt:**\n","> \"Gib mir Informationen zu Frankreich im folgenden JSON-Format: { 'name': '...', 'hauptstadt': '...', 'einwohner': ... }.\"\n","\n","**Erwartete Ausgabe:**\n","```json\n","{\n","  \"name\": \"Frankreich\",\n","  \"hauptstadt\": \"Paris\",\n","  \"einwohner\": 67000000\n","}\n","```\n"],"metadata":{"id":"bZqMjEWavk_i"}}]}