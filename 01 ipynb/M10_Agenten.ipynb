{"cells":[{"cell_type":"markdown","id":"0684551f","metadata":{"id":"0684551f"},"source":["![GenAI Banner](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)\n"]},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Agenten\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"ogH-Fzpmbueo"},"id":"ogH-Fzpmbueo"},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>Umgebung einrichten</font> </br></p>\n","!uv pip install --system --prerelease allow -q git+https://github.com/ralf-42/genai_lib\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN', 'WEATHER_API_KEY', 'SERPAPI_API_KEY', 'TAVILY_API_KEY'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"metadata":{"cellView":"form","id":"XUp8KhfjqR2N"},"id":"XUp8KhfjqR2N","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bf088ba7","metadata":{"id":"bf088ba7"},"source":["# 1 | Unterschied LLM vs Agenten"]},{"cell_type":"markdown","source":["Der Unterschied zwischen einem LLM und einem Agenten ist wie der Unterschied zwischen einem Buch und einem Menschen mit Zugang zu Werkzeugen und Internet. Diese Unterscheidung ist entscheidend f√ºr das Verst√§ndnis moderner KI-Anwendungen.\n","\n","**Problem: Wo LLMs an ihre Grenzen sto√üen**\n","\n","Ein Large Language Model ist im Grunde ein sehr fortgeschrittenes Textverarbeitungsystem, das auf Basis seiner Trainingsdaten antwortet. Diese Begrenzung f√ºhrt zu vier grundlegenden Problemen:\n","\n","+ **Veraltete Informationen**: LLMs kennen nur Daten bis zu ihrem Trainingsstichtag. Fragen Sie nach aktuellen Ereignissen, B√∂rsenkursen oder dem heutigen Wetter, erhalten Sie veraltete oder keine Informationen.\n","\n","+ **Ungenaue Berechnungen**: W√§hrend LLMs einfache Mathematik verstehen, sind sie bei komplexeren Berechnungen oft ungenau. Sie \"raten\" Ergebnisse basierend auf Mustern, anstatt tats√§chlich zu rechnen.\n","\n","+ **Keine externe Interaktion**: Ein LLM kann nicht im Internet suchen, APIs aufrufen oder Dateien lesen. Es ist vollst√§ndig isoliert von der Au√üenwelt.\n","\n","+ **Fehlende Planung**: LLMs k√∂nnen keine mehrstufigen Prozesse durchf√ºhren, bei denen das Ergebnis eines Schritts den n√§chsten beeinflusst.\n","\n","<br>\n","\n","**L√∂sung: Agenten erweitern LLMs**\n","\n","Ein Agent l√∂st diese Probleme durch drei Schl√ºsselkomponenten: Er nutzt das LLM als \"Gehirn\" f√ºr Sprachverst√§ndnis und Reasoning, erweitert es aber um Tools f√ºr externe Interaktionen und implementiert einen iterativen Denkprozess.\n","\n","+ **Aktuelle Daten durch Tools**: Agenten k√∂nnen √ºber spezielle Werkzeuge auf aktuelle Informationen zugreifen - von Wetterapis bis zu Internetsuchmaschinen.\n","\n","+ **Pr√§zise Berechnungen**: Statt zu raten, verwenden Agenten Rechner-Tools f√ºr exakte mathematische Operationen.\n","\n","+ **Unbegrenzte Erweiterbarkeit**: Neue F√§higkeiten entstehen durch neue Tools - von Datenbankzugriff bis zu Bildbearbeitung.\n","\n","+ **Transparente Planung**: Der Denkprozess des Agenten ist sichtbar und nachvollziehbar, was Vertrauen und Debugging erm√∂glicht."],"metadata":{"id":"-Pieqmzvw1nn"},"id":"-Pieqmzvw1nn"},{"cell_type":"markdown","source":["# 2 | Direkter Vergleich\n","---"],"metadata":{"id":"9lDnaWpPxdUN"},"id":"9lDnaWpPxdUN"},{"cell_type":"markdown","source":["## 2.1 Setup und Tools\n","\n","Bevor wir vergleichen k√∂nnen, m√ºssen wir die notwendigen Tools f√ºr unseren Agenten definieren. Diese Tools repr√§sentieren die erweiterten F√§higkeiten, die einem einfachen LLM fehlen.\n","\n"],"metadata":{"id":"DkYGsPkJx0xc"},"id":"DkYGsPkJx0xc"},{"cell_type":"code","source":["# Installationen\n","!uv pip install --system --prerelease allow -q google-search-results"],"metadata":{"id":"ugD04qUtyVDX"},"id":"ugD04qUtyVDX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Einfache Tools definieren\n","from langchain_core.tools import Tool\n","from langchain_community.utilities.serpapi import SerpAPIWrapper\n","import requests\n","\n","def simple_calculator(expression):\n","    \"\"\"Einfacher Rechner - Das kann ein LLM oft nicht pr√§zise\"\"\"\n","    try:\n","        # Sicherheitscheck\n","        if any(x in expression for x in ['import', 'exec', '__']):\n","            return \"Unsichere Operation\"\n","        result = eval(expression)\n","        return f\"{expression} = {result}\"\n","    except:\n","        return \"Berechnungsfehler\"\n","\n","def get_weather(city):\n","    \"\"\"Aktuelle Wetterdaten - Das kann ein LLM GAR NICHT\"\"\"\n","    # Vereinfachte Demo-Version\n","    return f\"üå§Ô∏è Aktuelles Wetter in {city}: 22¬∞C, sonnig (Demo-Version)\"\n","\n","# Tool-Liste erstellen\n","serpapi = SerpAPIWrapper()\n","\n","tools = [\n","    Tool(\n","        name=\"internet_search\",\n","        func=serpapi.run,\n","        description=\"üåê INTERNETSUCHE - Aktuelle Informationen finden (was LLM NICHT kann)\"\n","    ),\n","    Tool(\n","        name=\"calculator\",\n","        func=simple_calculator,\n","        description=\"üî¢ RECHNER - Pr√§zise Berechnungen (was LLM oft falsch macht)\"\n","    ),\n","    Tool(\n","        name=\"weather\",\n","        func=get_weather,\n","        description=\"üå§Ô∏è WETTER - Echtzeitdaten abrufen (was LLM unm√∂glich ist)\"\n","    )\n","]\n","\n","print(\"‚úÖ Tools definiert:\")\n","for tool in tools:\n","    print(f\"   ‚Ä¢ {tool.name}: {tool.description}\")"],"metadata":{"id":"80D6VNn-yT5Y"},"id":"80D6VNn-yT5Y","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Vergleichstest"],"metadata":{"id":"O5uiRNfWynCU"},"id":"O5uiRNfWynCU"},{"cell_type":"markdown","source":["Wir verwenden eine Frage, die sowohl aktuelle Daten als auch eine Berechnung erfordert, um die Grenzen eines LLMs und die St√§rken eines Agenten zu demonstrieren."],"metadata":{"id":"bNWuv_Mmyy_o"},"id":"bNWuv_Mmyy_o"},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.agents import create_tool_calling_agent, AgentExecutor\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","import time\n","\n","# LLM Setup\n","llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0)\n","\n","# Test-Frage die Grenzen aufzeigt\n","test_question = \"Wie ist das Wetter in Berlin und was ist 2847 * 1923?\"\n","\n","mprint(\"### üß™ VERGLEICHSTEST\")\n","mprint(\"---\")\n","mprint(f\"**Frage:** {test_question}\")\n","print()\n","\n","# 1. EINFACHES LLM PROBIEREN\n","mprint(\"### 1Ô∏è‚É£ EINFACHES LLM:\")\n","mprint(\"---\")\n","\n","start_time = time.time()\n","llm_response = llm.invoke(test_question)\n","llm_time = time.time() - start_time\n","\n","mprint(f\"**Antwort:** {llm_response.content}\")\n","mprint(f\"**Zeit:** {llm_time:.2f}s\")\n","print()\n","mprint(\"### ‚ùå PROBLEME:\")\n","mprint(\"+ Keine aktuellen Wetterdaten\")\n","mprint(\"+ Berechnung m√∂glicherweise ungenau\")\n","mprint(\"+ Kann nicht √ºberpr√ºfen ob Antwort stimmt\")\n","print()\n","\n","# 2. AGENT MIT TOOLS\n","mprint(\"### 2Ô∏è‚É£ AGENT MIT TOOLS:\")\n","mprint(\"---\")\n","\n","# Agent erstellen\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Du bist ein hilfreicher Agent. Nutze Tools f√ºr aktuelle Daten und Berechnungen.\"),\n","    (\"human\", \"{input}\"),\n","    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n","])\n","\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(\n","    agent=agent,\n","    tools=tools,\n","    verbose=True,  # Zeigt Denkprozess\n","    return_intermediate_steps=True\n",")\n","\n","start_time = time.time()\n","agent_response = agent_executor.invoke({\"input\": test_question})\n","agent_time = time.time() - start_time\n","\n","mprint(f\"**Antwort:**  {agent_response['output']}\")\n","mprint(f\"**Zeit:** {agent_time:.2f}s\")\n","print()\n","mprint(\"### ‚úÖ VORTEILE:\")\n","mprint(\"+ Aktuelle Wetterdaten abgerufen\")\n","mprint(\"+ Pr√§zise Berechnung durchgef√ºhrt\")\n","mprint(\"+ Transparenter Denkprozess sichtbar\")\n","mprint(\"+ Schritte nachvollziehbar\")\n"],"metadata":{"id":"UhXf4Oh5y1tN"},"id":"UhXf4Oh5y1tN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Unterschiede"],"metadata":{"id":"r_Z7XTBky8Bj"},"id":"r_Z7XTBky8Bj"},{"cell_type":"markdown","source":["\n","\n","Die Unterschiede zwischen LLM und Agent lassen sich in f√ºnf Kernbereichen zusammenfassen, die den Paradigmenwechsel von statischer zu dynamischer KI verdeutlichen.\n","\n","**Vergleich der F√§higkeiten:**\n","\n","| Aspekt | Einfaches LLM | Agent |\n","|--------|---------------|-------|\n","| **Aktuelle Daten** | ‚ùå Nur Trainingsdaten | ‚úÖ √úber Tools |\n","| **Berechnungen** | ‚ö†Ô∏è Oft ungenau | ‚úÖ Pr√§zise Tools |\n","| **Externe APIs** | ‚ùå Unm√∂glich | ‚úÖ Beliebig erweiterbar |\n","| **Transparenz** | üîí Verborgen | üëÅÔ∏è Sichtbar |\n","| **Erweiterbarkeit** | ‚ùå Statisch | ‚úÖ Modular |\n"],"metadata":{"id":"i_nWQCHa04cu"},"id":"i_nWQCHa04cu"},{"cell_type":"markdown","source":["\n","**üéØ FAZIT:**\n","- **Agent = LLM + Tools + Reasoning**\n","- ‚û°Ô∏è Aus reaktiv wird proaktiv\n","- ‚û°Ô∏è Aus statisch wird dynamisch\n","- ‚û°Ô∏è Aus isoliert wird vernetzt\n"],"metadata":{"id":"ifSi5c34092O"},"id":"ifSi5c34092O"},{"cell_type":"markdown","source":["# 3 | Anatomie eines Agenten\n","---"],"metadata":{"id":"UkgEROmi1gRU"},"id":"UkgEROmi1gRU"},{"cell_type":"markdown","source":["\n","\n","Um Agenten effektiv einsetzen zu k√∂nnen, muss man  ihre innere Struktur verstehen. Ein Agent besteht aus vier Hauptkomponenten, die zusammenarbeiten, um komplexe Aufgaben zu l√∂sen. Diese Architektur erm√∂glicht es, die St√§rken von LLMs mit praktischen Werkzeugen zu kombinieren.\n","\n","**Die 4 Kern-Komponenten**\n","\n","Jede Komponente eines Agenten hat eine spezifische Rolle im Gesamtsystem. Das Verst√§ndnis dieser Rollen hilft beim Design eigener Agenten und bei der Fehlersuche.\n","\n","+ **LLM (Das Gehirn)**: Das Large Language Model fungiert als zentrale Intelligenz des Agenten. Es versteht die Benutzeranfrage, interpretiert Tool-Ergebnisse und entscheidet √ºber n√§chste Schritte. Ohne das LLM w√§re der Agent nur eine Sammlung unverbundener Werkzeuge.\n","\n","+ **Tools (Die H√§nde)**: Tools sind spezialisierte Funktionen, die dem Agenten erlauben, mit der Au√üenwelt zu interagieren. Sie k√∂nnen so einfach sein wie ein Rechner oder so komplex wie eine Datenbankverbindung. Jedes Tool erweitert die F√§higkeiten des Agenten erheblich.\n","\n","+ **Agent-Scratchpad (Das Ged√§chtnis)**: Das Scratchpad speichert Zwischenergebnisse und den Verlauf der Tool-Aufrufe. Es erm√∂glicht dem Agenten, aus vorherigen Schritten zu lernen und komplexe, mehrstufige Reasoning-Prozesse durchzuf√ºhren.\n","\n","+ **Executor (Der Koordinator)**: Der Executor orchestriert das Zusammenspiel aller Komponenten. Er entscheidet, wann Tools aufgerufen werden, wann genug Informationen gesammelt wurden und wann die finale Antwort generiert werden soll.\n","\n","\n","<br>\n","\n","**Der Agent-Denkprozess**\n","\n","Der Denkprozess eines Agenten ist fundamental anders als der eines LLMs. W√§hrend ein LLM linear von Eingabe zu Ausgabe arbeitet, durchl√§uft ein Agent einen iterativen Zyklus aus Reasoning, Tool-Nutzung und Bewertung.\n","\n","+ **Schritt 1 - Verstehen**: Der Agent analysiert die Benutzeranfrage und identifiziert, welche Informationen oder Aktionen ben√∂tigt werden. Dies geschieht durch das LLM, das die nat√ºrliche Sprache interpretiert.\n","\n","+ **Schritt 2 - Planen**: Basierend auf dem Verst√§ndnis der Anfrage plant der Agent, welche Tools in welcher Reihenfolge verwendet werden sollten. Diese Planung kann sich w√§hrend der Ausf√ºhrung √§ndern.\n","\n","+ **Schritt 3 - Ausf√ºhren**: Der Agent ruft das gew√§hlte Tool auf und erh√§lt ein Ergebnis. Dieses Ergebnis wird im Scratchpad gespeichert und steht f√ºr weitere Entscheidungen zur Verf√ºgung.\n","\n","+ **Schritt 4 - Bewerten**: Nach jedem Tool-Aufruf bewertet der Agent, ob gen√ºgend Informationen vorliegen oder weitere Schritte notwendig sind. Diese Bewertung bestimmt den weiteren Verlauf.\n","\n","+ **Schritt 5 - Iterieren oder Antworten**: Je nach Bewertung kehrt der Agent zu Schritt 2 zur√ºck oder generiert die finale Antwort. Diese Flexibilit√§t erm√∂glicht die L√∂sung komplexer, unvorhersehbarer Probleme.\n","\n"],"metadata":{"id":"ibKl3w4g1lwb"},"id":"ibKl3w4g1lwb"},{"cell_type":"markdown","source":["# 4 | Praktische Beispiele\n","---"],"metadata":{"id":"q87uSNxz2IG3"},"id":"q87uSNxz2IG3"},{"cell_type":"markdown","source":["Praktische Beispiele helfen dabei, die Konzepte von Agenten greifbar zu machen. Wir beginnen mit einfachen, fokussierten Agenten und steigern die Komplexit√§t schrittweise. Diese Progression zeigt, wie Agenten f√ºr verschiedene Anwendungsf√§lle optimiert werden k√∂nnen."],"metadata":{"id":"H2EsOov72LHT"},"id":"H2EsOov72LHT"},{"cell_type":"markdown","source":["\n","\n","## 4.1 Rechner-Agent"],"metadata":{"id":"TwBjcHFX2owm"},"id":"TwBjcHFX2owm"},{"cell_type":"markdown","source":["Ein Rechner-Agent demonstriert die Grundprinzipien der Agent-Architektur mit minimaler Komplexit√§t. Er zeigt, wie ein Agent eine spezifische Dom√§ne (Mathematik) abdecken kann, ohne von anderen Funktionen abgelenkt zu werden.\n","\n","\n","**üî¢ RECHNER-AGENT DEMO**\n","\n","**Konfiguration:** Agent nur mit Calculator-Tool ausgestattet\n","\n","**Test-Fragen und Ergebnisse:**\n","- **\"Was ist 15 * 23?\"** ‚Üí ‚úÖ 345\n","- **\"Berechne (100 + 50) * 3\"** ‚Üí ‚úÖ 450  \n","- **\"Was ist 2 hoch 10?\"** ‚Üí ‚úÖ 1024\n","\n","**Erkenntnisse:**\n","- **Fokussierung** auf eine Dom√§ne macht den Agenten zuverl√§ssiger\n","- **Wiederverwendbarkeit** derselben Tool-Logik f√ºr verschiedene Probleme\n","- **Transparenz** durch sichtbare Reasoning-Schritte\n","\n","\n","Dieser Agent zeigt drei wichtige Prinzipien: **Fokussierung** auf eine Dom√§ne macht den Agenten zuverl√§ssiger, **Wiederverwendbarkeit** derselben Tool-Logik f√ºr verschiedene Probleme, und **Transparenz** durch sichtbare Reasoning-Schritte."],"metadata":{"id":"rOyE-zIx2YPR"},"id":"rOyE-zIx2YPR"},{"cell_type":"markdown","source":["## 4.2 Recherche-Agent\n","\n","Ein Recherche-Agent erweitert die F√§higkeiten erheblich, indem er Zugang zu aktuellen Informationen erh√§lt. Dies zeigt, wie Agenten die fundamentale Begrenzung von LLMs (veraltete Trainingsdaten) √ºberwinden.\n","\n","\n","**üîç RECHERCHE-AGENT DEMO**\n","\n","**Konfiguration:** Agent nur mit Internet Search-Tool ausgestattet\n","\n","**Test-Frage:** \"Was sind die neuesten Nachrichten √ºber k√ºnstliche Intelligenz?\"\n","\n","**Verhalten:**\n","- Agent ruft automatisch das Internet Search-Tool auf\n","- Durchsucht aktuelle Nachrichtenquellen\n","- Fasst relevante Informationen zusammen\n","\n","**Beispiel-Ergebnis:**\n","\"Aktuelle KI-Entwicklungen umfassen Durchbr√ºche in der Sprachverarbeitung, neue Robotik-Anwendungen in der Industrie und verst√§rkte Diskussionen √ºber KI-Regulierung in Europa...\"\n","\n","**Key-Features:**\n","- **Aktualit√§t** durch Zugriff auf Live-Daten\n","- **Validierung** von Informationen durch mehrere Quellen\n","- **Kontextualisierung** von Suchergebnissen f√ºr die spezifische Anfrage\n","\n","\n","Der Recherche-Agent demonstriert **Aktualit√§t** durch Zugriff auf Live-Daten, **Validierung** von Informationen durch mehrere Quellen, und **Kontextualisierung** von Suchergebnissen f√ºr die spezifische Anfrage.\n","\n"],"metadata":{"id":"vpDZgw7E2sX6"},"id":"vpDZgw7E2sX6"},{"cell_type":"markdown","source":["## 4.3 Multi-Tool Agent"],"metadata":{"id":"WI02HY2I2xec"},"id":"WI02HY2I2xec"},{"cell_type":"markdown","source":["\n","\n","Ein Multi-Tool Agent kombiniert verschiedene F√§higkeiten und zeigt die wahre St√§rke der Agent-Architektur: die Orchestrierung mehrerer Tools zur L√∂sung komplexer, mehrdimensionaler Probleme.\n","\n","\n","**üõ†Ô∏è MULTI-TOOL AGENT DEMO**\n","\n","**Konfiguration:** Agent mit allen verf√ºgbaren Tools (Internet, Rechner, Wetter)\n","\n","**Komplexe Test-Anfrage:**\n","\"Ich plane eine Reise nach M√ºnchen n√§chste Woche. Kannst du das aktuelle Wetter dort pr√ºfen und berechnen was 3 Hotel√ºbernachtungen √† 120‚Ç¨ plus 2 Zugtickets √† 89‚Ç¨ kosten w√ºrden?\"\n","\n","**Agent-Verhalten:**\n","1. **Wetter-Tool** ‚Üí Aktuelle Wetterdaten f√ºr M√ºnchen abrufen\n","2. **Calculator-Tool** ‚Üí Reisekosten berechnen: (3 √ó 120‚Ç¨) + (2 √ó 89‚Ç¨) = 538‚Ç¨\n","3. **Synthese** ‚Üí Beide Informationen in koh√§rente Antwort zusammenfassen\n","\n","**Beispiel-Antwort:**\n","\"Das aktuelle Wetter in M√ºnchen betr√§gt 18¬∞C mit teilweise bew√∂lktem Himmel - ideal f√ºr eine St√§dtereise. Die Gesamtkosten f√ºr Ihre Reise belaufen sich auf 538‚Ç¨ (360‚Ç¨ f√ºr Hotels + 178‚Ç¨ f√ºr Zugtickets).\"\n","\n","**Besondere F√§higkeiten:**\n","- **Tool-Orchestrierung** durch intelligente Auswahl und Sequenzierung\n","- **Kontext-Erhaltung** zwischen verschiedenen Tool-Aufrufen\n","- **Synthesef√§higkeit** beim Kombinieren verschiedener Informationstypen\n","\n","\n","Dieser Agent zeigt **Tool-Orchestrierung** durch intelligente Auswahl und Sequenzierung, **Kontext-Erhaltung** zwischen verschiedenen Tool-Aufrufen, und **Synthesef√§higkeit** beim Kombinieren verschiedener Informationstypen."],"metadata":{"id":"n0a8_Kxz20J_"},"id":"n0a8_Kxz20J_"},{"cell_type":"markdown","source":["# 5 | Wann braucht man einen Agent?\n","---"],"metadata":{"id":"PXIIt7Hc3TPW"},"id":"PXIIt7Hc3TPW"},{"cell_type":"markdown","source":["Die Entscheidung zwischen einem einfachen LLM und einem Agenten h√§ngt von den spezifischen Anforderungen Ihrer Anwendung ab. Eine klare Entscheidungsmatrix hilft dabei, die richtige Technologie f√ºr den jeweiligen Anwendungsfall zu w√§hlen und Ressourcen effizient einzusetzen.\n","\n"],"metadata":{"id":"JS-ztBp43dPn"},"id":"JS-ztBp43dPn"},{"cell_type":"markdown","source":["Die Wahl der richtigen Technologie beginnt mit der Analyse der Aufgabenanforderungen. W√§hrend LLMs f√ºr viele Textverarbeitungsaufgaben ausreichen, sind Agenten unverzichtbar, wenn externe Interaktionen oder aktuelle Daten ben√∂tigt werden.\n","\n","**Verwenden Sie einen Agenten wenn:**\n","\n","+ Sie aktuelle oder dynamische Daten ben√∂tigen, die sich h√§ufig √§ndern (Aktienkurse, Wetter, Nachrichten). Agenten k√∂nnen √ºber APIs auf Live-Daten zugreifen und diese in ihre Antworten integrieren.\n","\n","+ Pr√§zise Berechnungen erforderlich sind, bei denen Genauigkeit kritisch ist. LLMs approximieren mathematische Operationen, w√§hrend Agenten echte Rechner-Tools verwenden.\n","\n","+ Externe Systeme angesprochen werden m√ºssen, wie Datenbanken, APIs oder andere Services. Agenten k√∂nnen diese Integrationen nahtlos abwickeln.\n","\n","+ Komplexe, mehrstufige Prozesse durchgef√ºhrt werden sollen, bei denen jeder Schritt vom vorherigen abh√§ngt. Der Agent-Reasoning-Loop ist f√ºr solche Szenarien optimiert.\n","\n","**Ein einfaches LLM reicht wenn:**\n","\n","+ Reine Textverarbeitung ohne externe Daten im Fokus steht. F√ºr Zusammenfassungen, √úbersetzungen oder Textanalysen sind LLMs optimal.\n","\n","+ Kreative Aufgaben gel√∂st werden sollen, wie das Schreiben von Geschichten, Gedichten oder Marketing-Texten. Hier sind die kreativen F√§higkeiten des LLMs gefragt.\n","\n","+ Erkl√§rungen oder Bildungsinhalt basierend auf allgemeinem Wissen ben√∂tigt werden. LLMs haben Zugang zu einem enormen Wissensfundus.\n","\n","+ Statische Code-Generierung ohne externe Abh√§ngigkeiten erforderlich ist. F√ºr einfache Programmieraufgaben sind LLMs sehr effektiv.\n","\n","<br>\n","\n","**Die Faustregel lautet**:    \n","Wenn Sie Tools, aktuelle Daten oder externe Interaktionen ben√∂tigen, w√§hlen Sie einen Agenten. F√ºr reine Textverarbeitung reicht ein LLM aus."],"metadata":{"id":"IyRu2Fbu3hrs"},"id":"IyRu2Fbu3hrs"},{"cell_type":"markdown","source":["# 6 | Hands-On: Agent bauen\n","---"],"metadata":{"id":"mjxVdnrO54qr"},"id":"mjxVdnrO54qr"},{"cell_type":"code","source":["!uv pip install --system --prerelease allow -q tavily-python wikipedia"],"metadata":{"id":"Bjx-GWiD6Glx"},"id":"Bjx-GWiD6Glx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import SystemMessage\n","from langchain.agents import Tool, AgentExecutor, create_tool_calling_agent\n","from langchain_openai import ChatOpenAI\n","from langchain.utilities import WikipediaAPIWrapper\n","from tavily import TavilyClient\n","import os"],"metadata":{"id":"QpitPzT_5XZA"},"id":"QpitPzT_5XZA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tools definieren\n","\n","def read_file(filename):\n","    try:\n","        with open(filename, 'r') as f:\n","            return f.read()\n","    except:\n","        return f\"Datei {filename} nicht gefunden\"\n","\n","def write_file(content):\n","    filename, text = content.split(\"|\", 1)\n","    with open(filename, 'w') as f:\n","        f.write(text)\n","    return f\"Datei {filename} geschrieben\"\n","\n","# Tavily Web-Suche\n","tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))  # API-Key als Umgebungsvariable setzen\n","\n","def web_search(query):\n","    try:\n","        result = tavily.search(query=query, search_depth=\"basic\")\n","        return f\"Suchergebnis: {result['results'][0]['content']}\"\n","    except Exception as e:\n","        return f\"Fehler bei Tavily-Suche: {e}\"\n","\n","# Wikipedia-Suche\n","def wiki_search(term):\n","    wiki = WikipediaAPIWrapper()\n","    try:\n","        return wiki.run(term)\n","    except Exception as e:\n","        return f\"Wikipedia-Fehler: {e}\"\n","\n","custom_tools = [\n","    Tool(name=\"read_file\", func=read_file, description=\"Datei lesen\"),\n","    Tool(name=\"write_file\", func=write_file, description=\"Datei schreiben (Format: datei.txt|inhalt)\"),\n","    Tool(name=\"search\", func=web_search, description=\"F√ºhre eine Websuche mit Tavily durch\"),\n","    Tool(name=\"wiki\", func=wiki_search, description=\"Frage einen Begriff in Wikipedia nach\")\n","]"],"metadata":{"id":"T1sytIXk51g6"},"id":"T1sytIXk51g6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modell und ChatPrompt-Template definieren\n","model_name = \"gpt-4o-mini\"\n","temperature = 0.0\n","\n","llm = ChatOpenAI(model=model_name, temperature=temperature)\n","\n","# Prompt als Template definieren\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Du bist ein hilfreicher Assistent mit Zugriff auf Tools.\"),\n","    (\"human\", \"{input}\"),\n","    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","])"],"metadata":{"id":"A6DiRUdy7k9g"},"id":"A6DiRUdy7k9g","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# üîß Agenten-Logik\n","agent_runnable = create_tool_calling_agent(llm, custom_tools, prompt)\n","\n","# Agenten erstellen\n","custom_agent = AgentExecutor(\n","    agent=agent_runnable,\n","    tools=custom_tools,\n","    verbose=True,\n",")"],"metadata":{"id":"BqAF4lzd9kIA"},"id":"BqAF4lzd9kIA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# üîß Test\n","input = \"\"\"\n","Erstelle eine Datei 'notiz.txt' mit dem Inhalt 'Agenten k√∂nnen autonom agieren. ü§ñ',\n","lies sie dann wieder,\n","suche nach 'Python Programmierung' im Web.\n","was steht zu Taylor Swift auf Wikipedia\n","\"\"\"\n","\n","response = custom_agent.invoke({\"input\": input})"],"metadata":{"id":"Cij3QmiE9ri5"},"id":"Cij3QmiE9ri5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["mprint(\"## üõ†Ô∏è Hands-On Agent\")\n","mprint(\"---\")\n","mprint(\"**Input:**\")\n","mprint(response['input'])\n","mprint(\"**Output**:\")\n","mprint(response['output'])"],"metadata":{"id":"7c8FJ78F5fbn"},"id":"7c8FJ78F5fbn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# A | Aufgabe\n","---"],"metadata":{"id":"Pzc1rzQlNV8J"},"id":"Pzc1rzQlNV8J"},{"cell_type":"markdown","source":["Die Aufgabestellungen unten bieten Anregungen, Sie k√∂nnen aber auch gerne eine andere Herausforderung angehen."],"metadata":{"id":"QQUImb-86GUw"},"id":"QQUImb-86GUw"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kalkulation\n","</font></p>"],"metadata":{"id":"gkF5wVxdx_iA"},"id":"gkF5wVxdx_iA"},{"cell_type":"markdown","source":["Gegeben ist eine Datei, die eine Reihe von Gleichungen enth√§lt.\n","Der Dateiname ist GenAI/02 data/gleichungen.txt\n","\n","**Gleichung:**    \n","41748459 - 87226336    \n","92995162 * 46769739    \n","61530438 * 56074589    \n","95329602 + 45418854    \n","412907 + 3731910    \n","...\n","\n","Verwenden Sie einen LangChain-Agenten mit einem Tool, um jede dieser Gleichungen zu berechnen, und erstellen Sie eine Datei √§hnlich dieser:\n","\n","**Ergebnisse:**  \n","41748459 - 87226336 = 45477877   \n","92995162 * 46769739 = 4349359455002718   \n","61530438 * 56074589 = 3450294021839982   \n","95329602 + 45418854 = 140748456   \n","412907 + 3731910 = 4144817   \n","... ...\n","\n"],"metadata":{"id":"Y5y-OP9OemcW"},"id":"Y5y-OP9OemcW"},{"cell_type":"markdown","id":"518d7d5a","metadata":{"id":"518d7d5a"},"source":["# B | Model Context Protocol (MCP)\n","---\n"]},{"cell_type":"markdown","source":["\n","**Wichtige Ressourcen:**\n","\n","[Anthropic MCP](https://www.anthropic.com/news/model-context-protocol)\n","\n","[OpenAI MCP](https://openai.github.io/openai-agents-python/mcp/)\n","\n","[MCPServer](https://github.com/modelcontextprotocol/servers)\n","\n"],"metadata":{"id":"w6nFlzHDwuJy"},"id":"w6nFlzHDwuJy"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","5.1 Was ist MCP?\n","</font></p>"],"metadata":{"id":"zs4LhIqxwqMP"},"id":"zs4LhIqxwqMP"},{"cell_type":"markdown","source":["\n","Ein Protokoll ist ein Regelwerk, das bestimmt, wie zwei Systeme miteinander kommunizieren. Protokolle regeln die Daten√ºbertragung in Computernetzwerken, bei der Internetkommunikation und zwischen Softwaresystemen.\n","\n","**Zum Beispiel:**\n","\n","+ HTTP (Hypertext Transfer Protocol): Erm√∂glicht Websites die Kommunikation mit Browsern.\n","+ TCP/IP (Transmission Control Protocol/Internetprotokoll): Definiert, wie Datenpakete im Internet geroutet werden.\n","+ JSON-RPC (Aufrufen von Remoteprozeduren): Ein Protokoll, das den Datenaustausch im JSON-Format erm√∂glicht.    \n","\n","Das **Model Context Protocol (MCP)** ist ein offenes Protokoll, das es gro√üen Sprachmodellen (LLMs) erm√∂glicht, sich auf standardisierte Weise in externe Datenquellen und Tools zu integrieren. Dieses von Anthropic entwickelte Protokoll macht es KI-Modellen leicht, nahtlos mit einer Vielzahl von Tools und Datenquellen zusammenzuarbeiten.\n","\n","Es soll die Interaktion von KI-Modellen, insbesondere Large Language Models (LLMs) und autonomen Agenten, mit externen Datenquellen und Tools zu **standardisieren und zu vereinfachen**. Ziel ist es, einen **einheitlichen Rahmen** zu schaffen, der es KI-Agenten erm√∂glicht, auf strukturierte Daten aus verschiedenen Quellen wie Datenbanken, APIs, Cloud-Speicher und Unternehmensanwendungen auf standardisierte Weise zuzugreifen, diese zu verarbeiten und darauf zu reagieren, **ohne dass f√ºr jede Quelle spezifische API-Integrationen erforderlich sind**.\n","\n"],"metadata":{"id":"55pocnEnww4g"},"id":"55pocnEnww4g"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","5.2 Warum wurde MCP entwickelt?\n","</font></p>"],"metadata":{"id":"xQnjvh7HwyuL"},"id":"xQnjvh7HwyuL"},{"cell_type":"markdown","source":["\n","\n","Die Notwendigkeit von MCP ergibt sich aus den **Ineffizienzen und Herausforderungen** aktueller KI-API-Interaktionen. Derzeit ist der Aufbau von KI-Agenten, die Daten aus verschiedenen Quellen abrufen, **fragmentiert, repetitiv und schwer zu skalieren**. Jedes Tool spricht seine eigene Sprache und erfordert **individuelle Integrationen**. MCP zielt darauf ab, diese Komplexit√§t zu reduzieren und den **Entwicklungsaufwand zu minimieren**.\n","\n"],"metadata":{"id":"NevFl-6xw0lH"},"id":"NevFl-6xw0lH"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","5.3 Wie funktioniert MCP?\n","</font></p>"],"metadata":{"id":"dsTGqA4Zw3io"},"id":"dsTGqA4Zw3io"},{"cell_type":"markdown","source":["\n","\n","MCP basiert auf einer **Client-Server-Architektur**.\n","\n","*   **MCP-Clients** sind typischerweise KI-Agenten, Anwendungen oder Systeme, die strukturierte Daten ben√∂tigen. Beispiele hierf√ºr sind Claude Desktop, Cursor, Windsurf und Frameworks wie Langchain und Pydantic AI.\n","*   **MCP-Server** fungieren als **Vermittler**, die Daten von verschiedenen APIs, Datenbanken oder Unternehmenssystemen abrufen und diese in einem **einheitlichen Format** an die Clients zur√ºckgeben.\n","\n","Der Interaktionsprozess folgt einem strukturierten **Anfrage-Antwort-Zyklus**:\n","\n","1.  Der KI-Agent (Client) sendet eine **strukturierte Anfrage** an den MCP-Server, in der die ben√∂tigten Daten oder die auszuf√ºhrende Aktion in einem standardisierten Format definiert sind.\n","2.  Der MCP-Server **verarbeitet** diese Anfrage, authentifiziert sie, pr√ºft die Berechtigungen und ermittelt, welche externen Systeme abgefragt werden m√ºssen.\n","3.  Die eigentlichen **Datenabfragen** an die verschiedenen Quellen k√∂nnen parallel erfolgen.\n","4.  Die **Antworten** der verschiedenen Quellen werden vom MCP-Server in einem **einheitlichen, strukturierten Format standardisiert**, das f√ºr KI-Modelle leicht zu verarbeiten ist.\n","\n","Ein wesentliches Konzept von MCP ist die **Reflection**. Dies bedeutet, dass ein MCP-Client einen MCP-Server nach seinen **verf√ºgbaren Tools und Ressourcen** fragen kann, ohne vorherige Kenntnisse dieser Schnittstellen zu ben√∂tigen.\n","\n","[Interaktive Visualisierung des MCP-Prozesses](https://claude.site/artifacts/1ba26344-3819-427d-9080-98381785f8df)\n","\n"],"metadata":{"id":"XI9msU-Dw5i1"},"id":"XI9msU-Dw5i1"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","5.4 Kernkonzepte\n","</font></p>\n"],"metadata":{"id":"sfl6-F7xw8OR"},"id":"sfl6-F7xw8OR"},{"cell_type":"markdown","source":["\n","*   **Tools:** Funktionen, die das Modell nutzen kann, um Aktionen durchzuf√ºhren (z. B. Websuchen, Datenbankabfragen).\n","*   **Ressourcen:** Anh√§nge oder Daten, die dem Modell zur Verf√ºgung gestellt werden (z. B. Dateien, Datenbankinhalte).\n","*   **Prompts:** Vorlagen, die Clients f√ºr Anfragen an das Modell verwenden k√∂nnen.\n","\n"],"metadata":{"id":"CwJNrxKtw_rE"},"id":"CwJNrxKtw_rE"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","5.5 Vorteile von MCP\n","</font></p>"],"metadata":{"id":"bYE_S93Ow-at"},"id":"bYE_S93Ow-at"},{"cell_type":"markdown","source":["\n","*   **Vereinfachte Integrationen** und **reduzierte Komplexit√§t**.\n","*   **Verbesserte Skalierbarkeit** und **Wiederverwendbarkeit** von Integrationen.\n","*   **Erh√∂hte Interoperabilit√§t** zwischen KI-Modellen und externen Systemen.\n","*   **Zeitersparnis f√ºr Entwickler** durch weniger benutzerdefinierte API-Implementierungen.\n","*   Potenzial f√ºr eine **zentrale Authentifizierung** (zuk√ºnftig)."],"metadata":{"id":"_ONCUz4txA0z"},"id":"_ONCUz4txA0z"},{"cell_type":"markdown","source":["[Interaktive Visualisierung](https://claude.site/artifacts/1ba26344-3819-427d-9080-98381785f8df)"],"metadata":{"id":"OeTr_m93LVEB"},"id":"OeTr_m93LVEB"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code-Beispiel zur Interaktion\n","</font></p>"],"metadata":{"id":"k6reCVSRO5WY"},"id":"k6reCVSRO5WY"},{"cell_type":"code","execution_count":null,"id":"3c002ac7","metadata":{"lines_to_next_cell":0,"id":"3c002ac7"},"outputs":[],"source":["import json\n","import uuid\n","from typing import Dict, Any\n","\n","class MCPClient:\n","    \"\"\"Einfacher MCP-Client f√ºr die Kommunikation mit MCP-Servern.\"\"\"\n","\n","    def __init__(self, client_id: str, api_key: str):\n","        self.client_id = client_id\n","        self.api_key = api_key\n","        self.headers = {\n","            \"Authorization\": f\"Bearer {api_key}\",\n","            \"Client-ID\": client_id\n","        }\n","\n","    def create_request(self, tool_name: str, parameters: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Erstellt eine strukturierte MCP-Anfrage.\"\"\"\n","        request_data = {\n","            \"protocol_version\": \"1.0\",\n","            \"request_id\": str(uuid.uuid4()),\n","            \"tool\": {\n","                \"name\": tool_name,\n","                \"parameters\": parameters\n","            }\n","        }\n","        return request_data\n","\n","    def send_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Sendet eine MCP-Anfrage an den MCP-Server.\"\"\"\n","        # In einer realen Implementierung w√ºrde hier ein HTTP-Request erfolgen\n","        return {\"status\": \"success\", \"result\": {}}  # Platzhalter\n","\n","\n","class MCPServer:\n","    \"\"\"Simulierter MCP-Server zum Testen der Interaktion.\"\"\"\n","\n","    def __init__(self):\n","        self.registered_tools = {\n","            \"weather_info\": self._get_weather_data,\n","            \"database_query\": self._execute_database_query,\n","            \"text_translation\": self._translate_text\n","        }\n","\n","    def validate_request(self, request: Dict[str, Any]) -> bool:\n","        \"\"\"√úberpr√ºft, ob die Anfrage dem MCP-Protokoll entspricht.\"\"\"\n","        required_fields = [\"protocol_version\", \"request_id\", \"tool\"]\n","        if not all(field in request for field in required_fields):\n","            return False\n","\n","        if \"name\" not in request[\"tool\"] or request[\"tool\"][\"name\"] not in self.registered_tools:\n","            return False\n","\n","        return True\n","\n","    def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Verarbeitet eine validierte MCP-Anfrage.\"\"\"\n","        if not self.validate_request(request):\n","            return {\"error\": \"Ung√ºltige Anfrage\", \"status\": \"error\"}\n","\n","        tool_name = request[\"tool\"][\"name\"]\n","        parameters = request[\"tool\"].get(\"parameters\", {})\n","\n","        # Tool ausf√ºhren\n","        tool_func = self.registered_tools[tool_name]\n","        result = tool_func(parameters)\n","\n","        # Antwort standardisieren\n","        response = {\n","            \"request_id\": request[\"request_id\"],\n","            \"status\": \"success\",\n","            \"result\": result\n","        }\n","        return response\n","\n","    def _get_weather_data(self, params: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Simuliert den Abruf von Wetterdaten von einem externen Dienst.\"\"\"\n","        return {\n","            \"city\": params.get(\"city\", \"Berlin\"),\n","            \"temperature\": 22,\n","            \"condition\": \"sonnig\",\n","            \"humidity\": 65\n","        }\n","\n","    def _execute_database_query(self, params: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Simuliert eine Datenbankabfrage.\"\"\"\n","        return {\n","            \"rows\": [\n","                {\"id\": 1, \"name\": \"Produkt A\", \"price\": 29.99},\n","                {\"id\": 2, \"name\": \"Produkt B\", \"price\": 49.99}\n","            ],\n","            \"total_rows\": 2\n","        }\n","\n","    def _translate_text(self, params: Dict[str, Any]) -> Dict[str, Any]:\n","        \"\"\"Simuliert einen √úbersetzungsdienst.\"\"\"\n","        target_lang = params.get(\"target_language\", \"en\")\n","\n","        translations = {\n","            \"en\": \"Hello world\",\n","            \"fr\": \"Bonjour le monde\",\n","            \"de\": \"Hallo Welt\"\n","        }\n","\n","        return {\n","            \"original_text\": params.get(\"text\", \"\"),\n","            \"translated_text\": translations.get(target_lang, \"√úbersetzung nicht verf√ºgbar\"),\n","            \"target_language\": target_lang\n","        }\n","\n","\n","class LLMApplication:\n","    \"\"\"LLM-Anwendung, die den MCP-Client verwendet.\"\"\"\n","\n","    def __init__(self, mcp_client: MCPClient):\n","        self.mcp_client = mcp_client\n","\n","    def process_user_query(self, query: str) -> str:\n","        \"\"\"Verarbeitet eine Nutzeranfrage mit MCP f√ºr zus√§tzliche Daten.\"\"\"\n","        if \"wetter\" in query.lower():\n","            # Extrahiere Stadt (vereinfacht)\n","            city = \"Berlin\"\n","\n","            # Erstelle und sende MCP-Anfrage\n","            request = self.mcp_client.create_request(\"weather_info\", {\"city\": city})\n","            response = self.mcp_client.send_request(request)\n","\n","            if response.get(\"status\") == \"success\":\n","                weather_data = response.get(\"result\", {})\n","                return self._format_weather_response(weather_data)\n","            return \"Entschuldigung, ich konnte keine Wetterdaten abrufen.\"\n","\n","        elif \"√ºbersetze\" in query.lower():\n","            text = \"Hallo, wie geht es dir?\"\n","            target_lang = \"en\"\n","\n","            request = self.mcp_client.create_request(\"text_translation\", {\n","                \"text\": text,\n","                \"target_language\": target_lang\n","            })\n","            response = self.mcp_client.send_request(request)\n","\n","            if response.get(\"status\") == \"success\":\n","                translation_data = response.get(\"result\", {})\n","                return self._format_translation_response(translation_data)\n","            return \"Entschuldigung, ich konnte den Text nicht √ºbersetzen.\"\n","\n","        return \"Ich verstehe Ihre Anfrage. Wie kann ich Ihnen helfen?\"\n","\n","    def _format_weather_response(self, weather_data: Dict[str, Any]) -> str:\n","        \"\"\"Formatiert Wetterdaten f√ºr die Anzeige.\"\"\"\n","        return (f\"Das aktuelle Wetter in {weather_data.get('city')}: \"\n","                f\"{weather_data.get('temperature')}¬∞C, {weather_data.get('condition')}.\")\n","\n","    def _format_translation_response(self, translation_data: Dict[str, Any]) -> str:\n","        \"\"\"Formatiert √úbersetzungsdaten f√ºr die Anzeige.\"\"\"\n","        return (f\"√úbersetzung ({translation_data.get('target_language')}): \"\n","                f\"{translation_data.get('translated_text')}\")\n","\n","\n","def run_example():\n","    \"\"\"F√ºhrt ein Beispiel der MCP-Interaktion aus.\"\"\"\n","    print(\"=== MCP-Interaktionsbeispiel ===\\n\")\n","\n","    # MCP-Server initialisieren\n","    server = MCPServer()\n","\n","    # MCP-Client initialisieren\n","    client = MCPClient(\n","        client_id=\"llm_app_123\",\n","        api_key=\"sk_test_12345\"\n","    )\n","\n","    # LLM-Anwendung initialisieren\n","    llm_app = LLMApplication(client)\n","\n","    # Mock f√ºr send_request\n","    def mock_send_request(request_data):\n","        print(\"\\n[1] LLM-Anwendung erstellt MCP-Anfrage:\")\n","        print(json.dumps(request_data, indent=2))\n","\n","        print(\"\\n[2] MCP-Client sendet Anfrage an MCP-Server\")\n","\n","        print(\"\\n[3] MCP-Server validiert die Anfrage\")\n","        valid = server.validate_request(request_data)\n","        print(f\"Anfrage ist g√ºltig: {valid}\")\n","\n","        print(\"\\n[4] MCP-Server verarbeitet die Anfrage und kommuniziert mit externen Systemen\")\n","        response = server.process_request(request_data)\n","\n","        print(\"\\n[5] Externe Systeme liefern Daten an MCP-Server\")\n","\n","        print(\"\\n[6] MCP-Server standardisiert die Antwort:\")\n","        print(json.dumps(response, indent=2))\n","\n","        print(\"\\n[7] MCP-Server sendet Antwort an MCP-Client\")\n","\n","        print(\"\\n[8] MCP-Client stellt Kontext der LLM-Anwendung zur Verf√ºgung\")\n","\n","        return response\n","\n","    # √úberschreiben der Methode\n","    client.send_request = mock_send_request\n","\n","    # Beispiel-Nutzeranfrage\n","    query = \"Wie ist das Wetter in Berlin?\"\n","\n","    print(f\"\\nNutzer fragt: '{query}'\")\n","    print(\"\\n[0] LLM-Anwendung analysiert die Nutzeranfrage\")\n","\n","    # LLM verarbeitet die Anfrage und nutzt MCP\n","    response = llm_app.process_user_query(query)\n","\n","    print(\"\\n[9] LLM-Anwendung nutzt den Kontext zur Beantwortung\")\n","    print(f\"\\nAntwort an den Nutzer: '{response}'\")\n","\n","\n","if __name__ == \"__main__\":\n","    run_example()"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Fazit\n","</font></p>\n"],"metadata":{"id":"ioHO4YiNKxDE"},"id":"ioHO4YiNKxDE"},{"cell_type":"markdown","source":["\n","\n","\n","Das Model Context Protocol (MCP) stellt einen vielversprechenden Ansatz dar, um die Integration von KI-Modellen mit der Au√üenwelt zu **standardisieren und zu vereinfachen**. Durch die Definition eines gemeinsamen Protokolls und die Bereitstellung von Konzepten wie Tools und Ressourcen erm√∂glicht MCP die Entwicklung **flexiblerer, skalierbarer und wiederverwendbarer** KI-Anwendungen. Obwohl es noch Herausforderungen zu bew√§ltigen gibt, hat MCP das Potenzial, die Art und Weise, wie KI-Agenten mit Daten und Tools interagieren, **grundlegend zu ver√§ndern**."],"metadata":{"id":"79FfrbNOLf5o"},"id":"79FfrbNOLf5o"}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"collapsed_sections":["bf088ba7","9lDnaWpPxdUN","DkYGsPkJx0xc","O5uiRNfWynCU","r_Z7XTBky8Bj","UkgEROmi1gRU","q87uSNxz2IG3","TwBjcHFX2owm","vpDZgw7E2sX6","WI02HY2I2xec","PXIIt7Hc3TPW","mjxVdnrO54qr","Pzc1rzQlNV8J","518d7d5a"]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}