{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pC9A-LaYhsta","GFfOERAQb0og","Ol51wGB6cCZj","tG34OSP_SliL","fiQSIwXXcOCH","y57B93v5AEOI"],"toc_visible":true,"authorship_tag":"ABX9TyMTOJNjJnBLLGZXRgFmEB4G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"8\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"MDvedNTt20Db"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Einführung in Generative AI\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfdhPIzcEYRG","cellView":"form","collapsed":true},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  Colab-Umfeld</font> </br></p>\n","# Installierte Python Version\n","import sys\n","print(f\"Python Version: \",sys.version)\n","# Installierte LangChain Bibliotheken\n","print()\n","print(\"Installierte LangChain Bibliotheken:\")\n","!pip list | grep '^langchain'\n","# Unterdrückt die \"DeprecationWarning\" von LangChain für die Memory-Funktionden\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langsmith.client\")"]},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  SetUp API-Keys (setup_api_keys)</font> </br></p>\n","\n","def setup_api_keys():\n","    \"\"\"Konfiguriert alle benötigten API-Keys aus Google Colab userdata\"\"\"\n","\n","    # Dictionary der benötigten API-Keys\n","    keys = {\n","        'OPENAI_API_KEY': 'OPENAI_API_KEY',\n","        'HF_TOKEN': 'HF_TOKEN',\n","        # Weitere Keys bei Bedarf\n","    }\n","\n","    # Keys in Umgebungsvariablen setzen\n","    for env_var, key_name in keys.items():\n","        environ[env_var] = userdata.get(key_name)\n","\n","    return {k: environ[k] for k in keys.keys()}\n","\n","# Verwendung\n","from google.colab import userdata\n","import os\n","from os import environ\n","\n","all_keys = setup_api_keys()\n","# Bei Bedarf einzelne Keys direkt zugreifen\n","# WEATHER_API_KEY = all_keys['WEATHER_API_KEY']"],"metadata":{"cellView":"form","id":"WD3Wwr6sESX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# **1 <font color='orange'>|</font> Kursüberblick**\n","---"]},{"cell_type":"markdown","source":["In diesem Kurs wird vermittelt, wie Generative Künstliche Intelligenz (GenAI) angewendet wird. Der Fokus liegt hauptsächlich auf Text-zu-Text-Modellen (wie ChatGPT) und Text-zu-Bild-Modellen (wie Stable Diffusion). Die Teilnehmer:innen des Kurses werden Modelle erstellen und ausführen.\n","\n","\n","Generative KI wird als eine Untergruppe der Technologien der künstlichen Intelligenz beschrieben, die in der Lage sind, neue Inhalte zu generieren, einschließlich Texte, Bilder, Musik und sogar synthetische Daten. Im Kern verwendet generative KI komplexe Algorithmen, um Muster, Stile oder Logik aus umfangreichen Datensätzen zu extrahieren. Dieses erworbene Verständnis wird dann genutzt, um Originalausgaben zu erstellen, die das gelernte Material nachahmen.\n","\n","Die Technologie findet vielfältige Anwendungsmöglichkeiten, beispielsweise bei der Erstellung realistisch aussehender Bilder, die real nicht existieren, beim Komponieren von Musik, beim Generieren menschenähnlicher Textantworten oder bei der Entwicklung neuer Videospielumgebungen. Die Stärke der generativen KI besteht darin, bestehende Formen und Stile zu replizieren und durch das Mischen von Elementen auf innovative Weise die Grenzen der Kreativität und der automatisierten Inhaltserstellung zu erweitern.\n","\n"],"metadata":{"id":"aVlQfdrVcYdm"}},{"cell_type":"markdown","metadata":{"id":"GFfOERAQb0og"},"source":["# **2 <font color='orange'>|</font> Überblick generative KI**\n","---"]},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Text-zu-Text-Modelle\n","</font></p>"],"metadata":{"id":"E0UhGX1ieJQI"}},{"cell_type":"markdown","source":["Text-zu-Text-Sprachmodelle stellen einen bahnbrechenden Fortschritt im Bereich der generativen künstlichen Intelligenz dar und bieten ein breites Anwendungsspektrum, das von automatisierter Schreibhilfe bis hin zu hochentwickelten Konversationsagenten reicht. Im Kern verarbeiten diese Modelle Eingabetext und erzeugen Ausgabetext, der der jeweiligen Aufgabe entspricht, sei es das Übersetzen zwischen Sprachen, das Zusammenfassen langer Dokumente oder das Generieren kreativer Inhalte. Diese Modelle basieren auf Deep-Learning-Algorithmen und werden anhand riesiger Textdatenkorpora trainiert, wodurch sie die Nuancen der menschlichen Sprache erfassen und nachbilden können. Ihre Fähigkeit, Kontext zu verstehen und kohärenten, kontextrelevanten Text zu generieren, macht sie zu vielseitigen Werkzeugen sowohl im professionellen als auch im kreativen Bereich.\n","\n","**Beispiele:**\n","\n","[ChatGPT](https://chat.openai.com)   \n","[Perplexity](https://)\n","\n"],"metadata":{"id":"cZyUXXtlcsFG"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Text-zu-Bild-Modelle\n","</font></p>"],"metadata":{"id":"QCw3bkugc20D"}},{"cell_type":"markdown","source":["Text-zu-Bild-Sprachmodelle markieren einen revolutionären Fortschritt in der Welt der generativen künstlichen Intelligenz. Sie zeigen ein tiefgehendes Verständnis für Inhalte, Kontexte und künstlerische Nuancen.\n","\n","Indem sie große Datensätze auswerten, die Bilder mit ihren jeweiligen Textbeschreibungen verknüpfen, lernen diese Modelle, komplexe Muster, Stile und Texturen zu erkennen und detailgetreu wiederzugeben. Diese Technologie erweitert nicht nur die Möglichkeiten künstlerischer Gestaltung, sondern findet auch praktische Anwendungen in Bereichen wie Design, Bildung und Unterhaltung. Aus einfachen Texteingaben entstehen auf diese Weise aussagekräftige visuelle Inhalte.\n","\n","**Beispiele:**\n","\n","[DALL-E](https://)   \n","[Stable-Diffsion](https://)\n","\n"],"metadata":{"id":"wBJg4p6lcyJ-"}},{"cell_type":"markdown","metadata":{"id":"Ol51wGB6cCZj"},"source":["# **3 <font color='orange'>|</font> Einführung OpenAI**\n","---"]},{"cell_type":"markdown","source":["OpenAI ist ein Forschungsunternehmen im Bereich der künstlichen Intelligenz, das darauf abzielt,  KI-Technologien zu entwickeln und zu fördern, die der gesamten Menschheit zugutekommen. Gegründet wurde es im Dezember 2015 von Elon Musk, Sam Altman und anderen, mit dem Ziel, positive menschliche Auswirkungen zu maximieren und sicherzustellen, dass KI-Entwicklungen breit verteilt und nicht von wenigen beherrscht werden. OpenAI ist bekannt für seine fortschrittlichen KI-Modelle, darunter GPT (Generative Pre-trained Transformer) und DALL-E, die in einer Vielzahl von Anwendungen eingesetzt werden, von Sprachverarbeitung bis hin zu Bildgenerierung."],"metadata":{"id":"VbU2BDXnn2gb"}},{"cell_type":"markdown","source":["In diesem Kurs müssen Sie sich für ein OpenAI-Konto anmelden und einen API-Key erhalten, eine eindeutige Kennung, mit der Sie auf die Programmierschnittstellen von OpenAI zugreifen können. Ein API-Key fungiert als Passcode und ermöglicht eine sichere Interaktion zwischen Ihren Softwareanwendungen und den Diensten von OpenAI."],"metadata":{"id":"5OvpGU8Hc5xS"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key erstellen\n","</font></p>"],"metadata":{"id":"XGl--eXBc-MS"}},{"cell_type":"markdown","source":["Sie können über die folgende URL auf das OpenAI-System zugreifen. Wenn Sie noch kein OpenAI-Konto haben, können Sie sich hier für eines registrieren.\n","\n","+ Anmelden/Registrieren: https://platform.openai.com/docs/overview\n","+ Sobald Sie angemeldet sind, sehen Sie sich die vertikale Optionsleiste links an.\n","+ Wählen Sie das Zahnrad mit der Aufschrift „Einstellungen“ und dann „Abrechnung“ aus.\n","+ Daraufhin wird Abbildung 1.ABRECHNUNG angezeigt."],"metadata":{"id":"WF0AYYs-TCw5"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key sichern\n","</font></p>"],"metadata":{"id":"4L_pvQEtolQJ"}},{"cell_type":"markdown","source":["Sichern Sie Ihren API-Key in Colab.\n","\n","**Schritte:**\n","\n","\n","\n","1. Linke Navgationsleiste \"Schlüsselsymbol\"\n","2. Neues Secret hinzufügen\n","3. Namen vergeben und API-Key als Wert hinterlegen"],"metadata":{"id":"kpr_OhQ1ozdp"}},{"cell_type":"markdown","source":["**Empfehlung:** Speichern Sie Ihren API-Key unter den Namen: `OPENAI_API_KEY`"],"metadata":{"id":"Gk_NmNNXGkNP"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key testen\n","</font></p>"],"metadata":{"id":"cXErDbSypmHT"}},{"cell_type":"code","source":["from openai import models\n","\n","try:\n","    models = models.list()  # Note the lowercase 'models'\n","    print(\"✅ OpenAI API-Key ist gültig!\")\n","    # for model in models.data:\n","    #     print(model) # This prints the entire model object.  You can access individual attributes like model.id\n","\n","except Exception as e:  # Catch other potential errors\n","    print(\"❌ OpenAI API-Key ungültig!\")\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"yd4PJ7GutmMi","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","OpenAI Konversationsformat\n","</font></p>"],"metadata":{"id":"ZzcX1hxbx0Jt"}},{"cell_type":"markdown","source":["OpenAI bietet ein Konversationsformat für die Nutzung seiner Sprachmodelle, insbesondere für die Interaktion mit Chatbot-artigen Anwendungen. Dieses Format wird typischerweise in der ChatCompletion-API verwendet, die speziell für dialogorientierte Aufgaben entwickelt wurde. Die API erleichtert die Strukturierung von Dialogen, indem sie die Verwendung von rollenbasierten Nachrichten unterstützt, um den Kontext und die Intentionen der Beteiligten klar zu definieren.\n","\n","Grundprinzipien des Konversationsformats von OpenAI:   \n","In der Chat-API von OpenAI besteht ein Dialog aus einer Serie von Nachrichten, die jeweils einer Rolle zugeordnet sind. Die Hauptrollen sind:\n","\n","+ **system**: Definiert den **Kontext** oder die Anweisungen für das Modell.\n","+ **user**: Enthält die **Benutzer**eingaben.\n","+ **assistant**: Die vom **Modell** generierten Antworten."],"metadata":{"id":"Lw_xg6j2xymU"}},{"cell_type":"code","source":["# API-Key wir von oben übernommen"],"metadata":{"id":"L6Rvne49wBdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI, chat\n","from IPython.display import Markdown\n","\n","client = OpenAI()\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"developer\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n","    {\"role\": \"user\", \"content\": \"Künstliche Intelligenz ist ...\"}\n","  ]\n",")\n","\n","Markdown(completion.choices[0].message.content)"],"metadata":{"id":"KHboUvTZrpnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4 <font color='orange'>|</font> Einführung Hugging Face**\n","---"],"metadata":{"id":"tG34OSP_SliL"}},{"cell_type":"markdown","source":["Hugging Face ist ein Unternehmen, das sich auf die Schaffung und Bereitstellung von Technologien im Bereich der künstlichen Intelligenz spezialisiert hat, insbesondere auf natürliche Sprachverarbeitung (NLP). Es wurde 2016 gegründet und ist vor allem für seine „Transformers“-Bibliothek bekannt, die eine breite Palette von vortrainierten Modellen wie BERT, GPT, T5 und anderen bietet, die für Aufgaben wie Textklassifikation, Übersetzung, Zusammenfassung und Frage-Antwort-Systeme verwendet werden können.\n","\n","Hugging Face betreibt auch eine Plattform, auf der die Community Modelle teilen und zusammenarbeiten kann. Diese Plattform ermöglicht es Forschern, Entwicklern und Unternehmen, Modelle zu finden, zu testen und einzusetzen. Darüber hinaus bietet Hugging Face Tools und Dienstleistungen für das Training, Hosting und die Verwaltung von KI-Modellen, einschließlich einer Modellhub-API, die den Zugriff auf tausende von Modellen ermöglicht.\n","\n","Das Unternehmen setzt stark auf Open-Source- und Gemeinschaftsgetriebene Ansätze, um die Entwicklung und Verbreitung von KI-Technologien zu demokratisieren und sicherzustellen, dass diese Technologien breit und ethisch angewendet werden.\n","\n","\n","Für den Kurs ist es wichtig zu wissen, dass Hugging Face\n","+  den Zugang zu modernsten KI-Modellen vereinfacht und\n","+ ständig neue Modelle bereitstellt und die Plattform sowohl für\n","+ Anfänger als auch für Fortgeschrittene geeignet ist."],"metadata":{"id":"H1upFIMoTJ0D"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key erstellen\n","</font></p>"],"metadata":{"id":"WgYO4rFGu8xR"}},{"cell_type":"markdown","source":["Ein Hugging Face API-Key ist ein eindeutiger Code, der es Ihnen ermöglicht, auf die Ressourcen und Dienste von Hugging Face zuzugreifen, wie z. B. vortrainierte Modelle und Datensätze. Um einen API-Key zu erstellen, müssen Sie sich auf der Hugging Face-Website anmelden und ein Konto erstellen. Sobald Sie angemeldet sind, können Sie Ihren API-Key in Ihren Kontoeinstellungen generieren. Dieser Schlüssel sollte sicher aufbewahrt und nicht öffentlich weitergegeben werden, da er Ihnen Zugriff auf sensible Daten und Ressourcen ermöglicht.\n"],"metadata":{"id":"CfNFmT5Wu_Po"}},{"cell_type":"markdown","source":["**Empfehlung:** Speichern Sie Ihren API-Key unter den Namen: `HF_TOKEN`"],"metadata":{"id":"9zTuv9cYG1VK"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key testen\n","</font></p>\n"],"metadata":{"id":"78f5UINgTM2L"}},{"cell_type":"code","source":["from huggingface_hub import HfApi\n","\n","def test_huggingface_token():\n","    \"\"\"Testet die Gültigkeit des Hugging Face API-Keys aus einer Umgebungsvariablen.\"\"\"\n","\n","    try:\n","        api = HfApi()\n","        api.whoami()\n","        print(\"✅ Hugging Face API-Key ist gültig!\")\n","        return True\n","    except Exception as e:\n","        print(\"❌ Hugging Face API-Key ungültig!\")\n","        print(f\"Fehlermeldung: {str(e)}\")\n","        return False\n","\n","# Verwendung\n","result = test_huggingface_token()"],"metadata":{"id":"PbwTn5qsxkLx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Einfaches Beispiel Hugging Face\n","</font></p>"],"metadata":{"id":"yzKMTM-XTsuz"}},{"cell_type":"code","source":["!uv pip install --system -q sacremoses"],"metadata":{"id":"TA2pO2GewBTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","from IPython.display import Markdown\n","\n","# Laden eines Modells für Übersetzung\n","translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n","\n","# Text zum Übersetzen\n","text_to_translate = \"Why is the sky blue?\"\n","\n","# Übersetzung durchführen\n","result = translator(text_to_translate)\n","\n","# Ergebnis anzeigen\n","Markdown(result[0]['translation_text'])"],"metadata":{"id":"J1Ojqr8oTxSP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiQSIwXXcOCH"},"source":["# **5 <font color='orange'>|</font> Einführung LangChain**\n","---"]},{"cell_type":"markdown","source":["LangChain ist ein Software-Framework, das darauf abzielt, die Entwicklung von Sprachanwendungen zu vereinfachen, indem es Werkzeuge zur Integration von Sprachmodellen mit externen Datenquellen und Diensten bietet. Es ist speziell darauf ausgerichtet, die Fähigkeiten von Large Language Models (LLMs) wie OpenAI's GPT-3 zu nutzen und diese Modelle effektiv mit anderen Systemen zu verknüpfen, um praktische und funktionale Anwendungen zu erstellen.\n","\n","Das Framework bietet eine Reihe von Funktionen, darunter:\n","- **Chain-of-Thought Prompting**: Dies hilft, die Antworten von Sprachmodellen zu verbessern, indem es den Denkprozess strukturiert, der in den Antworten enthalten ist.\n","- **Retrieval-Augmented Generation (RAG)**: Eine Methode, die es ermöglicht, externe Informationen während der Generierung von Antworten dynamisch abzurufen, um die Genauigkeit und Relevanz der Antworten zu verbessern.\n","- **Modulare Architektur**: LangChain ermöglicht es Entwicklern, verschiedene Komponenten wie Suchmaschinen, Datenbanken und andere Dienste einfach zu integrieren und zu kombinieren, um komplexe Anwendungen zu erstellen.\n","\n","Entwickelt von Charles Foster, zielt LangChain darauf ab, die Erstellung von KI-Anwendungen zu demokratisieren, indem es Entwicklern ermöglicht, leistungsstarke Sprachmodelle einfacher und effektiver in einer Vielzahl von Domänen einzusetzen. Das Framework unterstützt die Erstellung von Anwendungen, die über einfache Textgenerierung hinausgehen und tieferes Verständnis und Interaktionen ermöglichen, indem es die Vorteile von Large Language Models mit spezifischen, aufgabenorientierten Informationen verbindet.\n","\n"],"metadata":{"id":"Zj0NmHpydGoy"}},{"cell_type":"markdown","metadata":{"id":"Y9nvX9oA3a0Z"},"source":["<p><font color='black' size=\"5\">\n","Eine einzelne Frage stellen\n","</font></p>"]},{"cell_type":"markdown","source":["Um dem Modell eine einzelne, von vorherigen Dialogen unabhängige Frage zu stellen, kann eine Zeichenfolge als Eingabe verwendet werden, auf die das Modell direkt reagiert."],"metadata":{"id":"I7wXQlljdMx1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"34-95k0qg8ss"},"outputs":[],"source":["from langchain_openai import OpenAI, ChatOpenAI\n","from IPython.display import display, Markdown\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPERATURE = 0.0\n","\n","# Initialisieren des OpenAI LLM (Language Learning Model)\n","llm = ChatOpenAI(model=MODEL, temperature=TEMPERATURE)\n","\n","# Definieren der Frage\n","question = \"Was sind die fünf grössten Städte in Deutschland?\"\n","\n","# Verwenden von Langchain, um die OpenAI-API aufzurufen\n","response = llm.invoke(question)\n","\n","# Ausgabe der Antwort\n","display(Markdown(\"## ✨ Model response:\"))\n","display(Markdown(\"---\"))\n","display(Markdown(response.content))"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Überblick LangChain Konzepte\n","</font></p>"],"metadata":{"id":"VlARJEowAAIR"}},{"cell_type":"markdown","source":["Konzepte von LangChain sind grundlegende Bausteine und Prinzipien, die das Framework ausmachen und seine Funktionsweise ermöglichen. Hier sind einige der wichtigsten Konzepte:\n","\n","+ Chat-Modelle (**Chat models**): LLMs, die über eine Chat-API verfügbar sind und Sequenzen von Nachrichten verarbeiten1.\n","+ Nachrichten (**Messages**): Kommunikationseinheiten in Chat-Modellen für Ein- und Ausgabe1.\n","+ Chat-Verlauf (**Chat history**): Eine Sequenz von Nachrichten, die eine Konversation darstellt.\n","+ Tools (**Tools**): Funktionen mit definierten Schemata für Name, Beschreibung und Argumente.\n","+ Strukturierte Ausgabe (**Structured output**): Technik, um Chat-Modelle in strukturierten Formaten antworten zu lassen.\n","+ Retrieval Augmented Generation (**RAG**): Technik zur Verbesserung von Sprachmodellen durch Kombination mit externen Wissensbasen.\n","+ Prompt-Vorlagen (**Prompt template**s): Komponenten zur Erstellung strukturierter Prompts für LLMs.\n","+ Chains (**Chains**): Verknüpfungen mehrerer LLMs oder anderer Komponenten für komplexere Anwendungen.\n","+ Agenten (**Agents**): Nutzen Sprachmodelle, um Aktionssequenzen auszuwählen und mit externen Ressourcen zu interagieren.\n","+ Retriever (**Retriever**): Komponenten, die relevante Dokumente aus einer Wissensbasis abrufen."],"metadata":{"id":"g5B7bWJKBB-C"}},{"cell_type":"markdown","source":["# **A <font color='orange'>|</font> Aufgabe**\n","---"],"metadata":{"id":"y57B93v5AEOI"}},{"cell_type":"markdown","source":["Die Aufgabestellungen unten bieten Anregungen, Sie können aber auch gerne eine andere Herausforderung angehen."],"metadata":{"id":"mBNrTE85AiFG"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","OpenAI API-Nutzung\n","</font></p>"],"metadata":{"id":"qYrW164VAE6L"}},{"cell_type":"markdown","source":["\n","\n","Erstellen Sie ein einfaches Python-Skript, das die OpenAI API verwendet, um eine Konversation mit einem der OpenAI-Modelle zu führen. Implementieren Sie dabei:\n","\n","```python\n","from openai import OpenAI\n","import os\n","\n","def erstelle_konversation():\n","    # OpenAI Client initialisieren\n","    client = OpenAI()\n","    \n","    # Eine Konversation mit System-, User- und Assistant-Rollen erstellen\n","    completion = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"Sie sind ein Experte für maschinelles Lernen, der Konzepte einfach erklärt.\"},\n","            {\"role\": \"user\", \"content\": \"Bitte erklären Sie mir den Unterschied zwischen überwachtem und unüberwachtem Lernen.\"}\n","        ]\n","    )\n","    \n","    # Antwort ausgeben\n","    print(completion.choices[0].message.content)\n","\n","if __name__ == \"__main__\":\n","    erstelle_konversation()\n","```\n","\n","Erweitern Sie dieses Skript, indem Sie:\n","- Eine Funktion hinzufügen, die mehrere Nachrichten in einer Konversation verwaltet\n","- Verschiedene System-Prompts testen und die Ergebnisse vergleichen\n","- Die Antworten in einer Markdown-Datei speichern"],"metadata":{"id":"C86r9yIkASv9"}}]}