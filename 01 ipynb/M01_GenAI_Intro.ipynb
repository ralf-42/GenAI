{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pC9A-LaYhsta","GFfOERAQb0og","Ol51wGB6cCZj","tG34OSP_SliL","fiQSIwXXcOCH"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"MDvedNTt20Db"}},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Einf√ºhrung in Generative AI\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfdhPIzcEYRG","cellView":"form","collapsed":true},"outputs":[],"source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  Colab-Umfeld</font> </br></p>\n","# Installierte Python Version\n","import sys\n","print(f\"Python Version: \",sys.version)\n","# Installierte LangChain Bibliotheken\n","print()\n","print(\"Installierte LangChain Bibliotheken:\")\n","\n","!pip list | grep '^langchain'\n","# Unterdr√ºckt die \"DeprecationWarning\" von LangChain f√ºr die Memory-Funktionden\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langsmith.client\")"]},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='green'>  SetUp API-Keys (setup_api_keys)</font> </br></p>\n","\n","def setup_api_keys():\n","    \"\"\"Konfiguriert alle ben√∂tigten API-Keys aus Google Colab userdata\"\"\"\n","\n","    # Dictionary der ben√∂tigten API-Keys\n","    keys = {\n","        'OPENAI_API_KEY': 'OPENAI_API_KEY',\n","        'HF_TOKEN': 'HF_TOKEN',\n","        # Weitere Keys bei Bedarf\n","    }\n","\n","    # Keys in Umgebungsvariablen setzen\n","    for env_var, key_name in keys.items():\n","        environ[env_var] = userdata.get(key_name)\n","\n","    return {k: environ[k] for k in keys.keys()}\n","\n","# Verwendung\n","from google.colab import userdata\n","import os\n","from os import environ\n","\n","all_keys = setup_api_keys()\n","# Bei Bedarf einzelne Keys direkt zugreifen\n","# WEATHER_API_KEY = all_keys['WEATHER_API_KEY']"],"metadata":{"cellView":"form","id":"WD3Wwr6sESX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# 1 | Kurs√ºberblick\n","---"]},{"cell_type":"markdown","source":["In diesem Kurs lernen die Teilnehmer:innen, wie Generative K√ºnstliche Intelligenz (GenAI) praktisch angewendet wird. Der Schwerpunkt liegt auf Text-zu-Text-Modellen (z.‚ÄØB. GPT) und Text-zu-Bild-Modellen (z.‚ÄØB. DALL-E). Die Teilnehmer:innen erstellen und nutzen eigene Modelle.\n","\n","Generative KI ist ein Teilbereich der k√ºnstlichen Intelligenz, der darauf spezialisiert ist, neue Inhalte wie Texte, Bilder, Musik oder synthetische Daten zu erzeugen. Sie nutzt komplexe Algorithmen, um Muster, Stile und Strukturen aus umfangreichen Datens√§tzen zu erkennen und auf dieser Basis eigenst√§ndige, kreative Ausgaben zu generieren.\n","\n","Die Einsatzm√∂glichkeiten sind vielf√§ltig: von der Erzeugung realistischer Bilder, die in der Realit√§t nicht existieren, √ºber die Komposition von Musikst√ºcken bis hin zur Generierung menschen√§hnlicher Texte oder der Entwicklung neuer virtueller Welten. Ihre besondere St√§rke liegt in der F√§higkeit, bestehende Formen und Stile zu replizieren und kreativ zu kombinieren ‚Äì und damit die Grenzen der automatisierten Inhaltserstellung stetig zu erweitern.\n"],"metadata":{"id":"aVlQfdrVcYdm"}},{"cell_type":"markdown","metadata":{"id":"GFfOERAQb0og"},"source":["# 2 | √úberblick generative KI\n","---"]},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Text-zu-Text-Modelle\n","</font></p>"],"metadata":{"id":"E0UhGX1ieJQI"}},{"cell_type":"markdown","source":["Text-zu-Text-Sprachmodelle markieren einen bedeutenden Fortschritt im Bereich der generativen k√ºnstlichen Intelligenz und er√∂ffnen vielf√§ltige Einsatzm√∂glichkeiten ‚Äì von automatisierter Schreibhilfe bis hin zu hochentwickelten Konversationsagenten. Sie verarbeiten Eingabetexte und erzeugen darauf basierend Ausgabetexte, die Aufgaben wie √úbersetzungen, Zusammenfassungen oder die Erstellung kreativer Inhalte erf√ºllen.\n","Grundlage dieser Modelle sind Deep-Learning-Algorithmen, die auf umfangreichen Textkorpora trainiert werden. Dadurch k√∂nnen sie die Feinheiten menschlicher Sprache erfassen und nachbilden. Ihre F√§higkeit, Kontext zu verstehen und koh√§rente, aufgabenspezifische Texte zu generieren, macht sie zu vielseitigen Werkzeugen in professionellen wie kreativen Anwendungsfeldern.\n","\n","\n","**Beispiele:**\n","\n","[ChatGPT](https://chat.openai.com)   \n","[Perplexity](https://)\n","\n"],"metadata":{"id":"cZyUXXtlcsFG"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Text-zu-Bild-Modelle\n","</font></p>"],"metadata":{"id":"QCw3bkugc20D"}},{"cell_type":"markdown","source":["Text-zu-Bild-Modelle markieren einen bedeutenden Fortschritt in der Entwicklung generativer k√ºnstlicher Intelligenz. Sie erfassen Inhalte, Kontexte und k√ºnstlerische Feinheiten auf beeindruckende Weise.\n","\n","Basierend auf gro√üen Datens√§tzen, die Bilder mit entsprechenden Textbeschreibungen verkn√ºpfen, lernen diese Modelle, komplexe Strukturen, Stile und Texturen zu analysieren und detailgetreu zu reproduzieren. Neben neuen kreativen M√∂glichkeiten finden sie praktische Anwendung in Bereichen wie Design, Bildung und Unterhaltung, indem sie aus Texteingaben hochwertige visuelle Darstellungen erzeugen.\n","\n","\n","**Beispiele:**\n","\n","[DALL-E](https://)   \n","[Stable-Diffsion](https://)\n","\n"],"metadata":{"id":"wBJg4p6lcyJ-"}},{"cell_type":"markdown","metadata":{"id":"Ol51wGB6cCZj"},"source":["# 3 | Einf√ºhrung OpenAI\n","---"]},{"cell_type":"markdown","source":["OpenAI ist ein Forschungsunternehmen im Bereich der k√ºnstlichen Intelligenz, das darauf abzielt,  KI-Technologien zu entwickeln und zu f√∂rdern. Gegr√ºndet wurde es im Dezember 2015 von Elon Musk, Sam Altman und anderen, mit dem Ziel, positive menschliche Auswirkungen zu maximieren und sicherzustellen, dass KI-Entwicklungen breit verteilt und nicht von wenigen beherrscht werden. OpenAI ist bekannt f√ºr seine fortschrittlichen KI-Modelle, darunter GPT (Generative Pre-trained Transformer) und DALL-E, die in einer Vielzahl von Anwendungen eingesetzt werden, von Sprachverarbeitung bis hin zu Bildgenerierung."],"metadata":{"id":"VbU2BDXnn2gb"}},{"cell_type":"markdown","source":["Im Kurs wird vorausgesetzt, dass die Teilnehmer:innen ein OpenAI-Konto einrichten und einen eigenen API-Key erstellen, der als eindeutige Kennung den Zugriff auf die Programmierschnittstellen von OpenAI erm√∂gliche. Der API-Key fungiere wie ein Passcode und gew√§hrleiste eine sichere Kommunikation zwischen den eigenen Anwendungen und den Diensten von OpenAI."],"metadata":{"id":"5OvpGU8Hc5xS"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key erstellen\n","</font></p>"],"metadata":{"id":"XGl--eXBc-MS"}},{"cell_type":"markdown","source":["Man kann √ºber die folgende URL auf OpenAI zugreifen und sich registrieren.\n","\n","+ Anmelden/Registrieren: https://platform.openai.com/docs/overview\n","+ Nach Anmeldung sieht man die vertikale Optionsleiste links.\n","+ Auswahl des Zahnrads ‚öôÔ∏è `Settings`\n","+ Auswahl `API Keys` (linke Navigationsleiste).\n","+ Auswahl `Create new secret key`."],"metadata":{"id":"WF0AYYs-TCw5"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key sichern\n","</font></p>"],"metadata":{"id":"4L_pvQEtolQJ"}},{"cell_type":"markdown","source":["Sichern des API-Keys in Colab.\n","\n","**Schritte:**\n","\n","\n","\n","+ Im Jupyter-Notebook linke Navgationsleiste `Secrets` mit dem üóùÔ∏è-Symbol\n","+ Neues Secret hinzuf√ºgen\n","+ Namen vergeben und API-Key als Wert hinterlegen\n","+ Die Eintr√§ge sind **privat** und nur f√ºr den Account und f√ºr **ausgew√§hlten Notebooks** sichtbar."],"metadata":{"id":"kpr_OhQ1ozdp"}},{"cell_type":"markdown","source":["**Empfehlung:** Speichern des API-Keys unter den Namen: `OPENAI_API_KEY`"],"metadata":{"id":"Gk_NmNNXGkNP"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key testen\n","</font></p>"],"metadata":{"id":"cXErDbSypmHT"}},{"cell_type":"code","source":["from openai import models\n","\n","try:\n","    models = models.list()  # Note the lowercase 'models'\n","    print(\"‚úÖ OpenAI API-Key ist g√ºltig!\")\n","    # for model in models.data:\n","    #     print(model) # This prints the entire model object.  You can access individual attributes like model.id\n","\n","except Exception as e:  # Catch other potential errors\n","    print(\"‚ùå OpenAI API-Key ung√ºltig!\")\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"yd4PJ7GutmMi","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","OpenAI Konversationsformat\n","</font></p>"],"metadata":{"id":"ZzcX1hxbx0Jt"}},{"cell_type":"markdown","source":["OpenAI bietet ein Konversationsformat f√ºr die Nutzung seiner Sprachmodelle, insbesondere f√ºr die Interaktion mit Chatbot-artigen Anwendungen. Dieses Format wird typischerweise in der ChatCompletion-API verwendet, die speziell f√ºr dialogorientierte Aufgaben entwickelt wurde. Die API erleichtert die Strukturierung von Dialogen, indem sie die Verwendung von rollenbasierten Nachrichten unterst√ºtzt, um den Kontext und die Intentionen der Beteiligten klar zu definieren.\n","\n","Grundprinzipien des Konversationsformats von OpenAI:   \n","In der Chat-API von OpenAI besteht ein Dialog aus einer Serie von Nachrichten, die jeweils einer Rolle zugeordnet sind. Die Hauptrollen sind:\n","\n","+ **system**: Definiert den **Kontext** oder die Anweisungen f√ºr das Modell.\n","+ **user**: Enth√§lt die **Benutzer**eingaben.\n","+ **assistant**: Die vom **Modell** generierten Antworten."],"metadata":{"id":"Lw_xg6j2xymU"}},{"cell_type":"code","source":["from openai import OpenAI, chat\n","from IPython.display import display, Markdown\n","\n","client = OpenAI()\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"developer\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n","    {\"role\": \"user\", \"content\": \"Generative KI ist ...\"}\n","  ]\n",")\n","\n","display(Markdown('## ü§ñ KI:'))\n","display(Markdown(completion.choices[0].message.content))"],"metadata":{"id":"KHboUvTZrpnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 | Einf√ºhrung Hugging Face\n","---"],"metadata":{"id":"tG34OSP_SliL"}},{"cell_type":"markdown","source":["Hugging Face ist ein Unternehmen, das sich auf die Schaffung und Bereitstellung von Technologien im Bereich der k√ºnstlichen Intelligenz spezialisiert hat, insbesondere auf nat√ºrliche Sprachverarbeitung (NLP). Es wurde 2016 gegr√ºndet und ist vor allem f√ºr seine ‚ÄûTransformers‚Äú-Bibliothek bekannt, die eine breite Palette von vortrainierten Modellen wie BERT, GPT, T5 und anderen bietet, die f√ºr Aufgaben wie Textklassifikation, √úbersetzung, Zusammenfassung und Frage-Antwort-Systeme verwendet werden k√∂nnen.\n","\n","Hugging Face betreibt auch eine Plattform, auf der die Community Modelle teilen und zusammenarbeiten kann. Diese Plattform erm√∂glicht es Forschern, Entwicklern und Unternehmen, Modelle zu finden, zu testen und einzusetzen. Dar√ºber hinaus bietet Hugging Face Tools und Dienstleistungen f√ºr das Training, Hosting und die Verwaltung von KI-Modellen, einschlie√ülich einer Modellhub-API, die den Zugriff auf tausende von Modellen erm√∂glicht.\n","\n","Das Unternehmen setzt stark auf Open-Source- und Community-basierten Ans√§tze, um die Entwicklung und Verbreitung von KI-Technologien zu demokratisieren und sicherzustellen, dass diese Technologien breit und ethisch angewendet werden.\n","\n","\n","F√ºr den Kurs ist es wichtig zu wissen, dass Hugging Face\n","+ den Zugang zu modernsten KI-Modellen vereinfacht und\n","+ st√§ndig neue Modelle bereitstellt und die Plattform sowohl f√ºr\n","+ Anf√§nger als auch f√ºr Fortgeschrittene geeignet ist."],"metadata":{"id":"H1upFIMoTJ0D"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key erstellen\n","</font></p>"],"metadata":{"id":"WgYO4rFGu8xR"}},{"cell_type":"markdown","source":["Ein Hugging Face API-Key ist ein eindeutiger Code, der es Ihnen erm√∂glicht, auf die Ressourcen und Dienste von Hugging Face zuzugreifen, wie z. B. vortrainierte Modelle und Datens√§tze. Um einen API-Key zu erstellen, muss man sich auf der Hugging Face-Website anmelden und ein Konto erstellen. Sobald man angemeldet ist, kann man eine API-Key in den Kontoeinstellungen generieren. Dieser Schl√ºssel sollte sicher aufbewahrt und nicht √∂ffentlich weitergegeben werden, da er Ihnen Zugriff auf sensible Daten und Ressourcen erm√∂glicht.\n"],"metadata":{"id":"CfNFmT5Wu_Po"}},{"cell_type":"markdown","source":["**Empfehlung:** Speichern des eigenen API-Keys unter den Namen: `HF_TOKEN`"],"metadata":{"id":"9zTuv9cYG1VK"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API-Key testen\n","</font></p>\n"],"metadata":{"id":"78f5UINgTM2L"}},{"cell_type":"code","source":["from huggingface_hub import HfApi\n","\n","def test_huggingface_token():\n","    \"\"\"Testet die G√ºltigkeit des Hugging Face API-Keys aus einer Umgebungsvariablen.\"\"\"\n","\n","    try:\n","        api = HfApi()\n","        api.whoami()\n","        print(\"‚úÖ Hugging Face API-Key ist g√ºltig!\")\n","        return True\n","    except Exception as e:\n","        print(\"‚ùå Hugging Face API-Key ung√ºltig!\")\n","        print(f\"Fehlermeldung: {str(e)}\")\n","        return False\n","\n","# Verwendung\n","result = test_huggingface_token()"],"metadata":{"id":"PbwTn5qsxkLx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Einfaches Beispiel Hugging Face\n","</font></p>"],"metadata":{"id":"yzKMTM-XTsuz"}},{"cell_type":"markdown","source":["`uv` ist ein schnelles und modernes Installationsprogramm und kann f√ºr das klassische `pip` eingesetzt werden."],"metadata":{"id":"-qeF3nxLx-Mj"}},{"cell_type":"code","source":["!uv pip install --system --prerelease allow -q sacremoses"],"metadata":{"id":"TA2pO2GewBTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","from IPython.display import display, Markdown\n","\n","# Laden eines Modells f√ºr √úbersetzung\n","translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n","\n","# Text zum √úbersetzen\n","text_to_translate = \"Why is the sky blue?\"\n","\n","# √úbersetzung durchf√ºhren\n","result = translator(text_to_translate)\n","\n","# Ergebnis anzeigen\n","display(Markdown('## ü§ñ KI:'))\n","Markdown(result[0]['translation_text'])"],"metadata":{"id":"J1Ojqr8oTxSP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiQSIwXXcOCH"},"source":["# 5 | Einf√ºhrung LangChain\n","---"]},{"cell_type":"markdown","source":["LangChain ist ein Software-Framework, das darauf abzielt, die Entwicklung von Sprachanwendungen zu vereinfachen, indem es Werkzeuge zur Integration von Sprachmodellen mit externen Datenquellen und Diensten bietet. Es ist speziell darauf ausgerichtet, die F√§higkeiten von Large Language Models (LLMs) wie OpenAI's GPT-4x zu nutzen und diese Modelle effektiv mit anderen Systemen zu verkn√ºpfen, um praktische und funktionale Anwendungen zu erstellen.\n","\n","Das Framework bietet eine Reihe von Funktionen, darunter:\n","- **Chain-of-Thought Prompting**: Dies hilft, die Antworten von Sprachmodellen zu verbessern, indem es den Denkprozess strukturiert, der in den Antworten enthalten ist.\n","- **Retrieval-Augmented Generation (RAG)**: Eine Methode, die es erm√∂glicht, externe Informationen w√§hrend der Generierung von Antworten dynamisch abzurufen, um die Genauigkeit und Relevanz der Antworten zu verbessern.\n","- **Modulare Architektur**: LangChain erm√∂glicht es Entwicklern, verschiedene Komponenten wie Suchmaschinen, Datenbanken und andere Dienste einfach zu integrieren und zu kombinieren, um komplexe Anwendungen zu erstellen.\n","\n","Das Framework unterst√ºtzt die Erstellung von Anwendungen, die √ºber einfache Textgenerierung hinausgehen und tieferes Verst√§ndnis und Interaktionen erm√∂glichen, indem es die Vorteile von Large Language Models mit spezifischen, aufgabenorientierten Informationen verbindet.\n"],"metadata":{"id":"Zj0NmHpydGoy"}},{"cell_type":"markdown","metadata":{"id":"Y9nvX9oA3a0Z"},"source":["<p><font color='black' size=\"5\">\n","Eine einzelne Frage stellen\n","</font></p>"]},{"cell_type":"markdown","source":["Um dem Modell eine einzelne, von vorherigen Dialogen unabh√§ngige Frage zu stellen, kann eine Zeichenfolge als Eingabe verwendet werden, auf die das Modell direkt reagiert."],"metadata":{"id":"I7wXQlljdMx1"}},{"cell_type":"code","source":["!uv pip install --system --prerelease allow -q langchain_openai"],"metadata":{"id":"0KW418ARxnHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34-95k0qg8ss"},"outputs":[],"source":["from langchain_openai import OpenAI, ChatOpenAI\n","from IPython.display import display, Markdown\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPERATURE = 0.0\n","\n","# Initialisieren des OpenAI LLM (Language Learning Model)\n","llm = ChatOpenAI(model=MODEL, temperature=TEMPERATURE)\n","\n","# Definieren der Frage\n","question = \"Was sind die f√ºnf gr√∂ssten St√§dte in Deutschland?\"\n","\n","# Aufrzf des LLMs\n","response = llm.invoke(question)\n","\n","# Ausgabe der Antwort\n","display(Markdown(\"## ‚ú® Model response:\"))\n","display(Markdown(\"---\"))\n","display(Markdown(response.content))"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","√úberblick LangChain Konzepte\n","</font></p>"],"metadata":{"id":"VlARJEowAAIR"}},{"cell_type":"markdown","source":["Konzepte von LangChain sind grundlegende Bausteine und Prinzipien, die das Framework ausmachen und seine Funktionsweise erm√∂glichen. Hier sind einige der wichtigsten Konzepte:\n","\n","+ Chat-Modelle (**Chat models**): LLMs, die √ºber eine Chat-API verf√ºgbar sind und Sequenzen von Nachrichten verarbeiten1.\n","+ Nachrichten (**Messages**): Kommunikationseinheiten in Chat-Modellen f√ºr Ein- und Ausgabe1.\n","+ Chat-Verlauf (**Chat history**): Eine Sequenz von Nachrichten, die eine Konversation darstellt.\n","+ Tools (**Tools**): Funktionen mit definierten Schemata f√ºr Name, Beschreibung und Argumente.\n","+ Strukturierte Ausgabe (**Structured output**): Technik, um Chat-Modelle in strukturierten Formaten antworten zu lassen.\n","+ Retrieval Augmented Generation (**RAG**): Technik zur Verbesserung von Sprachmodellen durch Kombination mit externen Wissensbasen.\n","+ Prompt-Vorlagen (**Prompt template**s): Komponenten zur Erstellung strukturierter Prompts f√ºr LLMs.\n","+ Chains (**Chains**): Verkn√ºpfungen mehrerer LLMs oder anderer Komponenten f√ºr komplexere Anwendungen.\n","+ Agenten (**Agents**): Nutzen Sprachmodelle, um Aktionssequenzen auszuw√§hlen und mit externen Ressourcen zu interagieren.\n","+ Retriever (**Retriever**): Komponenten, die relevante Dokumente aus einer Wissensbasis abrufen."],"metadata":{"id":"g5B7bWJKBB-C"}}]}