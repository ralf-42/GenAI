{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pC9A-LaYhsta","GFfOERAQb0og","Ol51wGB6cCZj","tG34OSP_SliL","fiQSIwXXcOCH"],"authorship_tag":"ABX9TyMzukMHDkcbiykArn5qhOIe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"8\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"MDvedNTt20Db"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 01: Einführung in Generative AI\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"],"metadata":{"id":"9hdJze7yPOiT"}},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# **1 <font color='orange'>|</font> Kursüberblick**\n","---"]},{"cell_type":"markdown","source":["In diesem Kurs wird vermittelt, wie Generative Künstliche Intelligenz (GenAI) angewendet wird. Der Fokus liegt hauptsächlich auf Text-zu-Text-Modellen (wie ChatGPT) und Text-zu-Bild-Modellen (wie Stable Diffusion). Die Teilnehmer:innen des Kurses werden Modelle erstellen und ausführen.\n","\n","\n","Generative KI wird als eine Untergruppe der Technologien der künstlichen Intelligenz beschrieben, die in der Lage sind, neue Inhalte zu generieren, einschließlich Texte, Bilder, Musik und sogar synthetische Daten. Im Kern verwendet generative KI komplexe Algorithmen, um Muster, Stile oder Logik aus umfangreichen Datensätzen zu extrahieren. Dieses erworbene Verständnis wird dann genutzt, um Originalausgaben zu erstellen, die das gelernte Material nachahmen.\n","\n","Die Technologie findet vielfältige Anwendungsmöglichkeiten, beispielsweise bei der Erstellung realistisch aussehender Bilder, die real nicht existieren, beim Komponieren von Musik, beim Generieren menschenähnlicher Textantworten oder bei der Entwicklung neuer Videospielumgebungen. Die Stärke der generativen KI besteht darin, bestehende Formen und Stile zu replizieren und durch das Mischen von Elementen auf innovative Weise die Grenzen der Kreativität und der automatisierten Inhaltserstellung zu erweitern.\n","\n"],"metadata":{"id":"aVlQfdrVcYdm"}},{"cell_type":"markdown","metadata":{"id":"GFfOERAQb0og"},"source":["# **2 <font color='orange'>|</font> Überblick generative KI**\n","---"]},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Text-zu-Text-Modelle\n","</font></p>"],"metadata":{"id":"E0UhGX1ieJQI"}},{"cell_type":"markdown","source":["Text-zu-Text-Sprachmodelle stellen einen bahnbrechenden Fortschritt im Bereich der generativen künstlichen Intelligenz dar und bieten ein breites Anwendungsspektrum, das von automatisierter Schreibhilfe bis hin zu hochentwickelten Konversationsagenten reicht. Im Kern verarbeiten diese Modelle Eingabetext und erzeugen Ausgabetext, der der jeweiligen Aufgabe entspricht, sei es das Übersetzen zwischen Sprachen, das Zusammenfassen langer Dokumente oder das Generieren kreativer Inhalte. Diese Modelle basieren auf Deep-Learning-Algorithmen und werden anhand riesiger Textdatenkorpora trainiert, wodurch sie die Nuancen der menschlichen Sprache erfassen und nachbilden können. Ihre Fähigkeit, Kontext zu verstehen und kohärenten, kontextrelevanten Text zu generieren, macht sie zu vielseitigen Werkzeugen sowohl im professionellen als auch im kreativen Bereich.\n","\n","**Beispiele:**\n","\n","[ChatGPT](https://chat.openai.com)   \n","[Perplexity](https://)\n","\n"],"metadata":{"id":"cZyUXXtlcsFG"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Text-zu-Bild-Modelle\n","</font></p>"],"metadata":{"id":"QCw3bkugc20D"}},{"cell_type":"markdown","source":["Text-zu-Bild-Sprachmodelle markieren einen revolutionären Fortschritt in der Welt der generativen künstlichen Intelligenz. Sie zeigen ein tiefgehendes Verständnis für Inhalte, Kontexte und künstlerische Nuancen.\n","\n","Indem sie große Datensätze auswerten, die Bilder mit ihren jeweiligen Textbeschreibungen verknüpfen, lernen diese Modelle, komplexe Muster, Stile und Texturen zu erkennen und detailgetreu wiederzugeben. Diese Technologie erweitert nicht nur die Möglichkeiten künstlerischer Gestaltung, sondern findet auch praktische Anwendungen in Bereichen wie Design, Bildung und Unterhaltung. Aus einfachen Texteingaben entstehen auf diese Weise aussagekräftige visuelle Inhalte.\n","\n","**Beispiele:**\n","\n","[DALL-E](https://)   \n","[Stable-Diffsion](https://)\n","\n"],"metadata":{"id":"wBJg4p6lcyJ-"}},{"cell_type":"markdown","metadata":{"id":"Ol51wGB6cCZj"},"source":["# **3 <font color='orange'>|</font> Einführung OpenAI**\n","---"]},{"cell_type":"markdown","source":["OpenAI ist ein Forschungsunternehmen im Bereich der künstlichen Intelligenz, das darauf abzielt, sichere KI-Technologien zu entwickeln und zu fördern, die der gesamten Menschheit zugutekommen. Gegründet wurde es im Dezember 2015 von Elon Musk, Sam Altman und anderen, mit dem Ziel, positive menschliche Auswirkungen zu maximieren und sicherzustellen, dass KI-Entwicklungen breit verteilt und nicht von wenigen beherrscht werden. OpenAI ist bekannt für seine fortschrittlichen KI-Modelle, darunter GPT (Generative Pre-trained Transformer) und DALL-E, die in einer Vielzahl von Anwendungen eingesetzt werden, von Sprachverarbeitung bis hin zu Bildgenerierung."],"metadata":{"id":"VbU2BDXnn2gb"}},{"cell_type":"markdown","source":["In diesem Kurs müssen Sie sich für ein OpenAI-Konto anmelden und einen API-Schlüssel erhalten, eine eindeutige Kennung, mit der Sie auf die Programmierschnittstellen von OpenAI zugreifen können. Ein API-Schlüssel fungiert als Passcode und ermöglicht eine sichere Interaktion zwischen Ihren Softwareanwendungen und den Diensten von OpenAI."],"metadata":{"id":"5OvpGU8Hc5xS"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API Key erstellen\n","</font></p>"],"metadata":{"id":"XGl--eXBc-MS"}},{"cell_type":"markdown","source":["Sie können über die folgende URL auf das OpenAI-System zugreifen. Wenn Sie noch kein OpenAI-Konto haben, können Sie sich hier für eines registrieren.\n","\n","+ Anmelden/Registrieren: https://platform.openai.com/docs/overview\n","+ Sobald Sie angemeldet sind, sehen Sie sich die vertikale Optionsleiste links an.\n","+ Wählen Sie das Zahnrad mit der Aufschrift „Einstellungen“ und dann „Abrechnung“ aus.\n","+ Daraufhin wird Abbildung 1.ABRECHNUNG angezeigt."],"metadata":{"id":"WF0AYYs-TCw5"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API Key sichern\n","</font></p>"],"metadata":{"id":"4L_pvQEtolQJ"}},{"cell_type":"markdown","source":["Sichern Sie Ihren API-Schlüssel in Colab.\n","\n","**Schritte:**\n","\n","\n","\n","1. Linke Navgationsleiste \"Schlüsselsymbol\"\n","2. Neues Secret hinzufügen\n","3. Namen vergeben und API-Key als Wert hinterlegen"],"metadata":{"id":"kpr_OhQ1ozdp"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API Key testen\n","</font></p>"],"metadata":{"id":"cXErDbSypmHT"}},{"cell_type":"code","source":["# API-Key aus Secrets lesen und als Umgebungsvariable setzen\n","from os import environ\n","from google.colab import userdata\n","\n","environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"hFQfP_RppVho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import models\n","\n","try:\n","    models = models.list()  # Note the lowercase 'models'\n","    print(\"✅ OpenAI API-Key ist gültig!\")\n","    for model in models.data:\n","        print(model) # This prints the entire model object.  You can access individual attributes like model.id\n","\n","except Exception as e:  # Catch other potential errors\n","    print(\"❌ OpenAI API-Key ungültig!\")\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"yd4PJ7GutmMi","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","OpenAI Konversationsformat\n","</font></p>"],"metadata":{"id":"ZzcX1hxbx0Jt"}},{"cell_type":"markdown","source":["OpenAI bietet ein Konversationsformat für die Nutzung seiner Sprachmodelle, insbesondere für die Interaktion mit Chatbot-artigen Anwendungen. Dieses Format wird typischerweise in der ChatCompletion-API verwendet, die speziell für dialogorientierte Aufgaben entwickelt wurde. Die API erleichtert die Strukturierung von Dialogen, indem sie die Verwendung von rollenbasierten Nachrichten unterstützt, um den Kontext und die Intentionen der Beteiligten klar zu definieren.\n","\n","Grundprinzipien des Konversationsformats von OpenAI\n","In der Chat-API von OpenAI besteht ein Dialog aus einer Serie von Nachrichten, die jeweils einer Rolle zugeordnet sind. Die Hauptrollen sind:\n","\n","+ **system**: Definiert den Kontext oder die Anweisungen für das Modell.\n","+ **user**: Enthält die Benutzereingaben.\n","+ **assistant**: Die vom Modell generierten Antworten."],"metadata":{"id":"Lw_xg6j2xymU"}},{"cell_type":"code","source":["# API-Key wir von oben übernommen"],"metadata":{"id":"L6Rvne49wBdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI, chat\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Künstliche Intelligenz ist ...\"}\n","  ]\n",")\n","\n","print(completion.choices[0].message)"],"metadata":{"id":"KHboUvTZrpnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4 <font color='orange'>|</font> Einführung Hugging Face**\n","---"],"metadata":{"id":"tG34OSP_SliL"}},{"cell_type":"markdown","source":["Hugging Face ist ein Unternehmen, das sich auf die Schaffung und Bereitstellung von Technologien im Bereich der künstlichen Intelligenz spezialisiert hat, insbesondere auf natürliche Sprachverarbeitung (NLP). Es wurde 2016 gegründet und ist vor allem für seine „Transformers“-Bibliothek bekannt, die eine breite Palette von vortrainierten Modellen wie BERT, GPT, T5 und anderen bietet, die für Aufgaben wie Textklassifikation, Übersetzung, Zusammenfassung und Frage-Antwort-Systeme verwendet werden können.\n","\n","Hugging Face betreibt auch eine Plattform, auf der die Community Modelle teilen und zusammenarbeiten kann. Diese Plattform ermöglicht es Forschern, Entwicklern und Unternehmen, Modelle zu finden, zu testen und einzusetzen. Darüber hinaus bietet Hugging Face Tools und Dienstleistungen für das Training, Hosting und die Verwaltung von KI-Modellen, einschließlich einer Modellhub-API, die den Zugriff auf tausende von Modellen ermöglicht.\n","\n","Das Unternehmen setzt stark auf Open-Source- und Gemeinschaftsgetriebene Ansätze, um die Entwicklung und Verbreitung von KI-Technologien zu demokratisieren und sicherzustellen, dass diese Technologien breit und ethisch angewendet werden.\n","\n","\n","Für den Kurs ist es wichtig zu wissen, dass Hugging Face\n","+  den Zugang zu modernsten KI-Modellen vereinfacht und\n","+ ständig neue Modelle bereitstellt die Plattform sowohl\n","+ für Anfänger als auch für Fortgeschrittene geeignet ist."],"metadata":{"id":"H1upFIMoTJ0D"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API Key erstellen\n","</font></p>"],"metadata":{"id":"WgYO4rFGu8xR"}},{"cell_type":"markdown","source":["Ein Hugging Face API-Schlüssel ist ein eindeutiger Code, der es Ihnen ermöglicht, auf die Ressourcen und Dienste von Hugging Face zuzugreifen, wie z. B. vortrainierte Modelle und Datensätze. Um einen API-Schlüssel zu erstellen, müssen Sie sich auf der Hugging Face-Website anmelden und ein Konto erstellen. Sobald Sie angemeldet sind, können Sie Ihren API-Schlüssel in Ihren Kontoeinstellungen generieren. Dieser Schlüssel sollte sicher aufbewahrt und nicht öffentlich weitergegeben werden, da er Ihnen Zugriff auf sensible Daten und Ressourcen ermöglicht.\n"],"metadata":{"id":"CfNFmT5Wu_Po"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","API Key testen\n","</font></p>\n"],"metadata":{"id":"78f5UINgTM2L"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"],"metadata":{"id":"y1_4zmeoxKtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import HfApi\n","\n","def test_huggingface_token():\n","    \"\"\"Testet die Gültigkeit des Hugging Face API-Keys aus einer Umgebungsvariablen.\"\"\"\n","    hf_token = os.getenv(\"HF_TOKEN\")  # Liest den API-Key aus der Umgebungsvariable\n","\n","    try:\n","        api = HfApi(token=hf_token)\n","        api.whoami()\n","        print(\"✅ Hugging Face API-Key ist gültig!\")\n","        return True\n","    except Exception as e:\n","        print(\"❌ Hugging Face API-Key ungültig!\")\n","        print(f\"Fehlermeldung: {str(e)}\")\n","        return False\n","\n","# Verwendung\n","result = test_huggingface_token()"],"metadata":{"id":"PbwTn5qsxkLx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Einfaches Beispiel Hugging Face\n","</font></p>"],"metadata":{"id":"yzKMTM-XTsuz"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Laden eines Modells für Textgenerierung\n","generator = pipeline('text-generation', model='gpt2')\n","\n","# Text generieren\n","text = generator(\"Who is Albert Einstein?\")\n","print(text[0]['generated_text'])"],"metadata":{"id":"J1Ojqr8oTxSP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiQSIwXXcOCH"},"source":["# **5 <font color='orange'>|</font> Einführung LangChain**\n","---"]},{"cell_type":"markdown","source":["LangChain ist ein Software-Framework, das darauf abzielt, die Entwicklung von Sprachanwendungen zu vereinfachen, indem es Werkzeuge zur Integration von Sprachmodellen mit externen Datenquellen und Diensten bietet. Es ist speziell darauf ausgerichtet, die Fähigkeiten von Large Language Models (LLMs) wie OpenAI's GPT-3 zu nutzen und diese Modelle effektiv mit anderen Systemen zu verknüpfen, um praktische und funktionale Anwendungen zu erstellen.\n","\n","Das Framework bietet eine Reihe von Funktionen, darunter:\n","- **Chain-of-Thought Prompting**: Dies hilft, die Antworten von Sprachmodellen zu verbessern, indem es den Denkprozess strukturiert, der in den Antworten enthalten ist.\n","- **Retrieval-Augmented Generation (RAG)**: Eine Methode, die es ermöglicht, externe Informationen während der Generierung von Antworten dynamisch abzurufen, um die Genauigkeit und Relevanz der Antworten zu verbessern.\n","- **Modulare Architektur**: LangChain ermöglicht es Entwicklern, verschiedene Komponenten wie Suchmaschinen, Datenbanken und andere Dienste einfach zu integrieren und zu kombinieren, um komplexe Anwendungen zu erstellen.\n","\n","Entwickelt von Charles Foster, zielt LangChain darauf ab, die Erstellung von KI-Anwendungen zu demokratisieren, indem es Entwicklern ermöglicht, leistungsstarke Sprachmodelle einfacher und effektiver in einer Vielzahl von Domänen einzusetzen. Das Framework unterstützt die Erstellung von Anwendungen, die über einfache Textgenerierung hinausgehen und tieferes Verständnis und Interaktionen ermöglichen, indem es die Vorteile von Large Language Models mit spezifischen, aufgabenorientierten Informationen verbindet.\n","\n"],"metadata":{"id":"Zj0NmHpydGoy"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","LangChain Chat-Konversationsformat\n","</font></p>"],"metadata":{"id":"b6vDy5G0dJlu"}},{"cell_type":"markdown","metadata":{"id":"YmWHTAub0sTm"},"source":["Das Konversationsformat besteht aus Arrays von Chat-Einträgen der folgenden drei Typen:\n","\n","* **SystemMessage** - Diese Klasse bezeichnet die Systemaufforderung, die der KI Anweisungen zur Art der Konversation sowie Hinweise und Richtlinien gibt. Im Allgemeinen wird am Anfang des Arrays nur eine Systemnachricht angezeigt.\n","* **HumanMessage** – Diese Klasse bezeichnet die Chat-Nachrichten von außerhalb des LLM, normalerweise vom menschlichen Benutzer.\n","* **AIMessage** – Diese Klasse bezeichnet die Chat-Nachrichten vom LLM als Antworten auf die HumanMessage-Nachrichten.\n","\n","Hier sehen wir die Kette zum Stellen einer einfachen Frage."]},{"cell_type":"code","source":["!uv pip install --system -q langchain_openai"],"metadata":{"id":"L_RH5TC7yqOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# API-Key wir von oben übernommen"],"metadata":{"id":"CuTVi65Dv8_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2lC_JK3guaj"},"outputs":[],"source":["from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n","from langchain_core.prompts.chat import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    SystemMessagePromptTemplate,\n",")\n","from langchain_openai import ChatOpenAI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_sJoVYAtE6b"},"outputs":[],"source":["messages = [\n","    SystemMessage(\n","        content=\"You are a helpful assistant that concisely and accurately answers questions.\"\n","    ),\n","    HumanMessage(\n","        content=\"What is the capital of France?\"\n","    ),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xfb875JhtI6J"},"outputs":[],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.0,\n","  n= 1,\n","  max_tokens= 256)\n","\n","print(\"Model response:\")\n","output = llm.invoke(messages)\n","print(output.content)\n","print(\"-----------\")\n","print(output.response_metadata)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vJuMVHZ1jJ8"},"outputs":[],"source":["messages.append(output)\n","messages.append(HumanMessage(content=\"Are you sure, I think it was renamed for some reason?\"))\n","\n","for message in messages:\n","    print(message)"]},{"cell_type":"markdown","metadata":{"id":"A8Z7DZRH5TFr"},"source":["Wir können das Konversationsarray an das Modell übermitteln und seine neueste Antwort anzeigen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qFxkEmAz1w1"},"outputs":[],"source":["print(\"Model response:\")\n","output = llm.invoke(messages)\n","print(output.content)"]},{"cell_type":"markdown","metadata":{"id":"Y9nvX9oA3a0Z"},"source":["<p><font color='black' size=\"5\">\n","Eine einzelne Frage stellen\n","</font></p>"]},{"cell_type":"markdown","source":["\n","\n","Wenn Sie dem Modell eine einzelne Frage stellen möchten, die nicht Teil einer Konversationskette ist, können Sie dem Modell eine Zeichenfolge zur Antwort übergeben."],"metadata":{"id":"I7wXQlljdMx1"}},{"cell_type":"code","source":["from IPython.display import Markdown"],"metadata":{"id":"ZdHqbFI_12_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34-95k0qg8ss"},"outputs":[],"source":["# vollständig\n","from langchain_openai import OpenAI, ChatOpenAI\n","\n","MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM (Language Learning Model) mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(model=MODEL, temperature=0)\n","\n","# Definieren Sie die Frage\n","question = \"What are the five largest cities in the USA by population?\"\n","\n","# Verwenden Sie Langchain, um die OpenAI-API aufzurufen\n","# Die Methode und die Parameter können je nach Langchain-Version unterschiedlich sein.\n","response = llm.invoke(question)\n","\n","# Drucken Sie die Antwort\n","Markdown(response.content)"]},{"cell_type":"markdown","metadata":{"id":"_o2EkUkN3hEX"},"source":["\n","<p><font color='black' size=\"5\">\n","Eingabeaufforderungsvorlagen\n","</font></p>"]},{"cell_type":"markdown","source":["\n","\n","Mit LangChain können Sie Operationsketten erstellen, die normalerweise als Teil einer LLM-fähigen Anwendung ausgeführt werden. Eine dieser Operationen ist eine Eingabeaufforderungsvorlage, mit der Sie Text in eine zuvor erstellte Eingabeaufforderung einfügen können. In diesem Beispiel erstellen wir eine Eingabeaufforderungsvorlage, die das Modell auffordert, einen zufälligen Titel für einen Blogbeitrag zu erstellen.\n","\n","```\n","Return only the title of a blog post article title on the topic of {topic} in {language}\n","```\n","\n","Um dieses Ziel zu erreichen, verwenden wir ein **PromptTemplate**-Objekt."],"metadata":{"id":"gPvElGbrdOHq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-g3zOXBmulc"},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","\n","topic = \"pets for data scientists\"\n","language = \"english\"\n","\n","# Höhere Temperaturen für mehr Kreativität\n","llm = ChatOpenAI(model=MODEL, temperature=0.7)\n","\n","# Definieren der Eingabeaufforderungsvorlage\n","title_template = PromptTemplate(\n","    input_variables=['topic', 'language'],\n","    template='Return only the title of a blog post article title on the topic of {topic} in {language}'\n",")\n","\n","# Verkettung\n","title_chain = title_template | llm\n","\n","# Aufrufen der Kette mit Eingaben\n","response = title_chain.invoke({'topic': topic, 'language': language})\n","print(response.content)"]},{"cell_type":"markdown","metadata":{"id":"IOpAcj-byBPg"},"source":["\n","<p><font color='black' size=\"5\">\n","Erstellen einer einfache sequentielle Kette\n","</font></p>"]},{"cell_type":"markdown","source":["\n","\n","Wir werden nun LangChain verwenden, um mehrere LLM-Aufrufe mithilfe der Klasse **SimpleSequentialChain** zu einer längeren Kette zusammenzufassen. Wir werden zwei kleinere Ketten verwenden, um einen Titel und einen Textkörper für einen Blogbeitrag zu erstellen. Wir beginnen mit der Definition der beiden Eingabeaufforderungen, die wir zum Erstellen dieses Blogbeitrags verwenden werden. Beachten Sie auch, dass wir verlangen, dass das LLM [markdown](https://en.wikipedia.org/wiki/Markdown) verwendet, um den eigentlichen Blogbeitrag zu generieren.\n"],"metadata":{"id":"HFgf9flrdPwq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELS-9JD3Sao6"},"outputs":[],"source":["# Erstellen Sie die beiden Eingabeaufforderungsvorlagen\n","title_template = PromptTemplate( input_variables = ['topic'], template = 'Give me a blog post title on {topic} in German' )\n","article_template = PromptTemplate( input_variables = ['title'], template = 'Write a blog post for {title}, format in markdown.' )"]},{"cell_type":"markdown","metadata":{"id":"k3vy7jf3-_xl"},"source":["Wir erstellen die erste Kette, um den zufälligen Titel zu generieren. Hier können die Benutzer das Thema angeben. Wir verwenden eine höhere Temperatur, um die Kreativität des Titels zu steigern. Wir verwenden auch ein einfacheres Modell, um die Kosten für die relativ einfache Aufgabe der Titelauswahl zu minimieren."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KV8UJUDyP8M"},"outputs":[],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Erstellen Sie eine Kette, um einen Zufallsgenerator zu erzeugen.\n","llm = ChatOpenAI(model=MODEL, temperature=0.7)\n","title_chain = title_template | llm"]},{"cell_type":"markdown","metadata":{"id":"cO0ielMf_xRa"},"source":["Als nächstes verfassen wir den eigentlichen Blogbeitrag. Wir verwenden eine niedrigere Temperatur, um die Kreativität zu verringern und das LLM dazu zu bringen, sich an sachliche Informationen zu halten und Halluzinationen zu vermeiden. Wir verwenden auch ein komplexeres Modell, um einen besseren Artikel zu erstellen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7OCQCggyHlB"},"outputs":[],"source":["MODEL2 = 'gpt-4o'\n","\n","# Erstellen der Artikelkette\n","llm2 = ChatOpenAI(model=MODEL2, temperature=0.1)\n","article_chain = article_template | llm2"]},{"cell_type":"markdown","metadata":{"id":"6rftFvMyBa4-"},"source":["Nun kombinieren wir diese beiden Ketten zu einer. Die Eingabe für die erste Kette ist das ausgewählte Thema. Die erste Kette gibt dann den Titel an die zweite Kette aus, die wiederum den eigentlichen Artikel ausgibt."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ibHBt4eyKZt"},"outputs":[],"source":["# Erstellen einer vollständige Kette, um einen neuen Blogbeitrag zu erstellen\n","complete_chain = title_chain | article_chain"]},{"cell_type":"markdown","metadata":{"id":"V_7P-n_DBvpD"},"source":["Wir können nun den fertigen Artikel anzeigen. In diesem Fall haben wir einen Artikel zum Thema „Architecture“ angefordert und den Markdown des fertigen Artikels angezeigt."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwro_kfKXvml"},"outputs":[],"source":["article = complete_chain.invoke('Architecture')"]},{"cell_type":"markdown","metadata":{"id":"h1pN8CbXCE6F"},"source":["Die eigentliche Anzeige des Markdowns wird durch diesen Code übernommen:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt5uGJawuru_"},"outputs":[],"source":["Markdown(article.content)"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","LangChain Konzepte\n","</font></p>"],"metadata":{"id":"VlARJEowAAIR"}},{"cell_type":"markdown","source":["Konzepte von LangChain sind grundlegende Bausteine und Prinzipien, die das Framework ausmachen und seine Funktionsweise ermöglichen. Hier sind einige der wichtigsten Konzepte:\n","\n","+ Chat-Modelle (Chat models): LLMs, die über eine Chat-API verfügbar sind und Sequenzen von Nachrichten verarbeiten1.\n","+ Nachrichten (Messages): Kommunikationseinheiten in Chat-Modellen für Ein- und Ausgabe1.\n","+ Chat-Verlauf (Chat history): Eine Sequenz von Nachrichten, die eine Konversation darstellt.\n","+ Tools (Tools): Funktionen mit definierten Schemata für Name, Beschreibung und Argumente.\n","+ Strukturierte Ausgabe (Structured output): Technik, um Chat-Modelle in strukturierten Formaten antworten zu lassen.\n","+ Retrieval Augmented Generation (RAG): Technik zur Verbesserung von Sprachmodellen durch Kombination mit externen Wissensbasen.\n","+ Prompt-Vorlagen (Prompt templates): Komponenten zur Erstellung strukturierter Prompts für LLMs.\n","+ Chains (Chains): Verknüpfungen mehrerer LLMs oder anderer Komponenten für komplexere Anwendungen.\n","+ Agenten (Agents): Nutzen Sprachmodelle, um Aktionssequenzen auszuwählen und mit externen Ressourcen zu interagieren.\n","+ Retriever (Retriever): Komponenten, die relevante Dokumente aus einer Wissensbasis abrufen."],"metadata":{"id":"g5B7bWJKBB-C"}}]}