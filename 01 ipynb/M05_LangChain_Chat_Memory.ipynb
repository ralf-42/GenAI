{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOCqW4KT///oN5H9tcXKQ5c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 05: LangChain: Chat und Memory\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# **1 <font color='orange'>|</font> LangChain-Konversationen**\n","---"]},{"cell_type":"markdown","source":["Große Sprachmodelle (LLMs) ermöglichen eine natürliche Interaktion ähnlich menschlicher Gespräche. Sie sind in der Lage, auf vorherige Informationen innerhalb eines Dialogs Bezug zu nehmen. In diesem Modul wird die Verwaltung des Speichers eines LLMs untersucht. Da der interne Kontextpuffer begrenzt ist, sind externe Systeme erforderlich, um darüber hinausgehende Informationen zu speichern. Eine solche Lösung bietet LangChain, das frühere Konversationsverläufe in jede neue Anfrage integriert. Dazu wird ein fortlaufendes Transkript aller Interaktionen geführt, das sowohl Eingaben als auch Antworten enthält. Dieses Transkript wird bei jeder neuen Anfrage erneut an das LLM übermittelt, sodass es basierend auf dem bisherigen Dialog eine passende Antwort generieren kann und der interaktive Austausch fortgesetzt wird."],"metadata":{"id":"aFZgkTzpC5id"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Erstellen einer Chat-Konversation\n","</font></p>\n","\n","\n","Der Code implementiert einen Chatbot unter Verwendung der LangChain-Bibliothek und des OpenAI-GPT-Modells. Hier die Hauptkomponenten:\n","\n","1. Aufbau:\n","- Importe der benötigten Bibliotheken (LangChain, OpenAI, IPython)\n","- Definition von Konstanten (Modell und System-Prompt)\n","- Laden des API-Schlüssels aus Google Colab\n","\n","2. Kernfunktionen:\n","- `initialize_conversation`: Startet eine neue Konversation mit einem System-Prompt\n","- `execute_conversation`: Führt einen einzelnen Gesprächsschritt aus\n","- `ask_question`: Hauptfunktion für die Fragestellung und Antwortverarbeitung\n","\n","3. Ablauf:\n","- Initialisierung des LLM (Large Language Model) und des Chat-Templates\n","- Erstellung eines leeren Konversationsverlaufs\n","- Beispielinteraktion mit vier aufeinanderfolgenden Fragen\n","\n","4. Besonderheiten:\n","- Verwendung von Markdown für formatierte Ausgaben\n","- Speicherung des Konversationsverlaufs für kontextbezogene Antworten\n","- Strukturierter System-Prompt für konsistente Antworten\n","\n","Der Code ist so aufgebaut, dass er eine fortlaufende Konversation ermöglicht, bei der der Kontext vorheriger Fragen und Antworten erhalten bleibt."],"metadata":{"id":"nIBa-qDeEO-a"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAArkAAAQMCAYAAACSiYFIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAJ4QSURBVHhe7N15eFT1+f7xO2xCIPsetrAGVFCUoBAERSWRWqGI2koErStUhEJFXChSXBCLBWlx/7ZiwIqUij8LARErJaAExYIVEwgJS/Y9YIAEzO+PWTI5BAiQZOacvF/XNVcyn+czZxaovXnmOTNe1dXV1QIAAAAspIVxAQAAADA7Qi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcL77xDAA8245vXjYuATCRgVc9blxCEyDkAoCH+2r7XEVFDTQuAzCBvXu/0NDYBcZlNAFCLgB4uK+2z1WPnkMVFNjDWALgwcqPZGv3ro8IuW7CTC4AAAAsh5ALAAAAyyHkAgCancLCEv1izKPavHmHsVTLnj3pmnDPEyosLDGWpHrUVceezZt3aPKkuaqoOG7cKtWjDqB+CLkAANRDRcVxTZ4095zBGIBnIOQCAHAGffv20LL3XlJwcICxJNWjXpdhwwZq6Wtz5O3d1liS6lEHUD+EXABAs1ZRcVwzH39ZMx9/WTEDxylm4DjNffbP2rMnXTeOuFe/GPOoCgtLtGrVeqWk7NaM6fN144h7tXbt5lp1x37HMZYtW2O8K23evEMxA8c5xxEc12MGjtMvxjyqTz75d626JC1btqbWHsd9TbjnCW3evEM3jrhXs59ZrMmT5jrv09F1XrZsjXP84RdjHlXMwHG6ccS92rMnvdbjcVwmT5pb6/ECZkbIBQA0e0ePVujyfr2VsmOVlr33knbu3CNJmvPso84948bFKSamnxa+MkufbfqbRo0aVqvet28Pfbbpb85jrP7HBmeYdBg2bKCmPHaP8/rnm77UlMfuUcqOVfrnR3/WrbdeX6u+bNkaZew/pJQdq5SyY5V+O/1e/X72qzp+vFLl5Uf1+aYv9f8+eV1PPvWw8zZ1yckp0Ftvz1PKjlUaNmygVn6wTnv2pOuVhX/VsvdeUsqOVbr11usVFhZkvClgWoRcAAAkRUV1lCSFhATK17eDsVwvc5/9s2IGjtOEe57QkSM/GsunuWHEtVry6nt1dn2PHTuuL7d96+zuxgwcpxnT5ysnp0DHj5+QJN151y31GmuIiAiRt3c7SVK37p2NZcCSCLkAADSAZcvWKC+vSF9sTtS6pLfUsWOYcctphg0bqJQdqySp1hiBK0en13H550d/lr+/j3x9OygkJNC4vd769u2hsbeP1IR7nlDMwHH69tsf9JtHxxu3AaZFyAUA4DxkZmYZlyRJGfsP6drBV8rbu62+/z5de/akq6DA9rFh5eVHVVBQbLyJ07hxcYqO7ubcL0nt2rXVtYOv1D9Xf3rWjyiTJG/vtgoLC1LG/kOSpIqKY8rJKTBuq6Wi4ri+253mHFf450d/Pq8T6ABPR8gFAKAevL3b6pe/+pmWvPpenSeW3XnXLXr3b/9UzMBx+nzTl7r11uv1+aYv1bdvDw0Y0FeP/mbeaZ1ax3jD8GEJkqSBAy+vVZ8wYbR+MfZm3RL/oHNk4UwfYXbnXbc4TyS7687fqrq62rjlNEePVjg7uTH2E+4Aq/Cqrs//CgAAbvPV9rnq0XOoggJ7GEvARXn9tfc17o54BQcHaM+edL34wpta9t5Lxm24QOVHsrV710caGrvAWEIToJMLAEAzVFFxXEePVji7xBPueUIPPHiHcRtgWnRyAcDD0ckFzIlOrnvRyQUAAIDl0MkFAA9n5U7uurX/MS6hmRoyZID8/C/s84k9FZ1c9yLkAoCHs3LIfXneX9XryFXGZTQzH2V+qBf+NFWRHUOMJVMj5LoXIRcAPJzVQ+6vfB9WuE+EsYRm4mjlUU3bNImQiwbHTC4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALALCkrRtjNHhpzWXizmxboSxRE5fO1lbjDepp60aXY51Tsuacx33l7EzQ4JWJyjEWAJw3Qi4AwLJ6D16jbZNTtG38VGnbTK0oM+5oRGWJmrh0mjYY1z1SsuYsTWja1wdoZIRcAID1+Y1QXHCqUkuMhcaSrDnrpfnjp6q3sQSgSRByAQDWV7ZJ6wvjFRdlLMjexaxjrMExPuCo1TVGkDlbg+vsgMZq7p0JijAuK1srVsZo8MZkY+F0mbM1cWeybb/j/jNnn/Y4jWMZro+z1uN3jk3YHsOcTPtjWTpb72ycpg1K1ZLlrvvO/LoAZkDIBQBYVtq20baQtl6aP3mehhg3KFsrVk5TpmOsYfIiRW0brTmZtoA4dm+8Vk9OsdUGSZ+7htmyRE3cHq3VkxN1t5/LegNK2/aaFJeibZPXaIoWa+y+eNtjGRWvtG2vOWd9nWMZjn0bk6XM2Rq7rZsW2h//6sEZmuESgDO3O449T/fftEgjFa0p423XhyhZc5a+pujx9uc+eY3i9o7Wtz+6PDjAwxFyAQCW5Qx/cdKsurqRZZu0vjBacd0j7QuxiustZZbs1Od7U9W714iabmxUQk2YLXpNE5cvVtSgurq1ZxOpu+9M0babYo2FugXH6wY/SYpUVKDUO6ibbT0gWr2VoczTOsiRuntQvFScoX/tS5J6xzuDfUT3ePUuTFWGY2uvSWcO55lJLp3dGA1eOlpLCqWjlRXGnYDHIuQCAKzPL0HvjopX2t5Np48cXIC0NOnh8VOVubb+n5zgaaICHMH+TOKdXWDHZWiAt3ET4LEIuQCAZiGnJEMK7GbvvNq7oPYT0tbvr/l4sTfSpKiAAbqhV7TSipx9Tykz0Tl723vwJA3xS9D8wRmaUZ/5WqfzmMm9INlasT1JvXuN0M96xktpSc4QvjVlsdKCo2XvBdfB5cS8qHiNVJLeMHa+ARMh5AIALMs5k7s0xjZfe1Os5Jegh3unasnyBK0oi9Tdd9rmcAcvjdHg5YulwWs0N0qKGJCohZpWc+LWdtlHB2pEDFigKcXTTh+DaGI1z3O0lgQu0rsDIqWoebY5XPvjn5EWr4V1ngwnSbF6ZHC0Nqy17Z2TGau59vlk1xPaGFaAmXhVV1dXGxcBAJ7jq+1z1aPnUAUF9jCWTO/leX/Vr3wfVrhP3dEL57Z1Y4zeCFpjC7YmdLTyqKZtmqQX/jRVkR1DjGVTKz+Srd27PtLQ2AXGEpoAnVwAAABYDiEXAAATG3JTimm7uEBjIuQCAADAcgi5AAAAsBxCLgAAACyHkAsAAADLIeQCAADAcgi5AAAAsBxCLgAAACyHkAsAAADLIeQCAADAcgi5AAAAsBxCLgAAACzHq7q6utq4CADwHF9tn6sePYcqKLCHsWR6L8/7q645ebNxGc3M/+15XS/8aaoiO4YYS6ZWfiRbu3d9pKGxC4wlNAFCLgB4OCuH3OV/W6v83CLjcrPy3//+oMv79VbLFs37zdUJD/xcQcH+xmVTI+S6FyEXADyclUNuYUGpcanZmfeHv2jWkw+pdevWxlKz0qZNa/n6tTcumxoh170IuQDg4awcciHNmD5fL86foTZtmnfItSJCrns17/dGAABwM2/vdqqsrDIuA7hIhFwAANyoouIYXVygERByAQBwo+DgADq5QCMg5AIA4EaFhSV0coFGQMgFAACA5RByAQAAYDmEXAAA3IiZXKBxEHIBAHAjZnKBxkHIBQAAgOUQcgEAAGA5hFwAANwoKMifmVygERByAQBwo6KiUmZygUZAyAUAAIDlEHIBAABgOYRcAADcyNu7HTO5QCMg5AIA4EYVFceYyQUaASEXAAAAlkPIBQAAgOUQcgEAcLPq6mrjEoCLRMgFAMDNvLy8jEsALhIhFwAAAJZDyAUAAIDlEHIBAHCj4OAAPicXaASEXAAA3KiwsITPyQUaASEXAAAAlkPIBQAAgOUQcgEAcKOWLVsykws0AkIuAABN7IsvUrRu3WatW7dZOTkF+vzzr7Ru3WZt2JBs3ArgAnlV8zUrAODRvto+Vz16DlVQYA9jCSZ2/fB79OOPx5zXW7dupfUb3pGPT/ta+2Be5UeytXvXRxoau8BYQhOgkwsAgBtccUWf064TcIGGQ8gFAMANfnbr9fL17SDZu7i3jBpm3ALgIhByAQBwg+uuG6jLLuspSerXr7euueYK4xYAF4GQCwBoFD/99BOXs1wuuaS14uKvU9u2l2jUz4YrJCTgtD1cTr8A9cWJZwDg4cx64llWVp6enLLYuAyD48dPqG3bS4zLMLj30ds0YMClCgjwNZY8FieeuRchFwA8nJlDbuJzn2lGzJPGEnBe3vjmL+o7NpiQi/PCuAIAAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALADCfskRNXBqjwc7LbG21l7ZujNHEndmGG9RTWaImuhzrTLZudLnvjcnG8hlka8XKGM3JrFnZuvF8bg/gfBByAQAmFa+Fk1O0bXKKFvZO0owmC4vJWl88Vasnp2jb5DWaUjytVnCtt8zZmlE8VatvijVWLlCy5ixN0Ioy4/r5aIhjAJ6BkAsAML0hPeOl4gzlGAuNIlZz70xQhCQpUlGBUmbJ+XaOkzVnbZJGDnIcB0BDI+QCAExv674k9e41os7AmLMzoc6xBlvXsmbs4PRurG284OzjBMlanyZFBUTartrHKE4/Vm1bN07Tht6LNDfKsVL7sTjHLTJna/DG2S41e5e11riGbW3rxmnaoFQtWV7zPGuNVRhGOuZsnF1TW5moHMfjMhzD+ToYxzPO9NgAD0HIBQCYVJJm2APW+p4peneAPWi6ypytsdu6OccaVg/O0IyVicpRsuYsnSaNsq1vm7xG0SW1w+zWjaOVOihF284yTpCz8zVtCJ6qR5xhtR72zdaMNNeFbK1YOU2Zg9fYH8siRW0bXROU06Q451hGqpakJCtnf5LSei+y70/U3X7SkJsWaaSiNWV8irZNnqchkobc5Hh+p490bFC88/5GFi7W65l1HSNbK1baXwfHcTStJoTX8dgAT0HIBQCYVM1Mbty+2p1Kh637kqTe8Rpivx7RPV69C1OVkZmkDYpXnDOcRuruATVhdv3GGM0oPkd4LUvUrG3SlDiXkQO/BL07OcWlQ3u6DcXRWu06y1u2SesLoxXX3RHSYxXX22UEIjha3eyVbkHRkuN5pE07R5e5dse3drCWegc5j6ro4No1p7JNWl8obVhb08mdkSalFWXY6nU8NsBTEHIBAKY35KY1mhKcpPXnGBOonyRlBq3RwsDFmnXGT2nI1or1i5XWe5Lu9jPWzs42hxupuwfFa8N225jAebOH6W09k84waiHbCMTyxYqyd6tXD77QEOro7LpcztLdBjwFIRcAYAEZSi2MVnSA7Zqj0zikZ7yUllQzi5qyWGnB0eoWFa+RylCmc4Y0Wyt2Orqi8Xp4QKSG3LRIUdtm1jlnmrNzppYUxmuhMezVcyZXkhQ1SVO0WK+XjFBccKrW77cH6rJEveE653s2UfO00LXrq1Sllth/LctQprNbna3P96bW8+Q8l2P42R4bYwgwI0IuAMCkamZyBy+dJo2yz6bGTK15Kz9qnm0O1/lWe7wW3pmgCMVq7vh4rV/uuP1opQYYu5Oxmjuqm5YsN45BJOv1bamG+zfuqY9I3R03VZlrZ0pxtjncwUtjNHj5YmnwmrOOPLieTDcjzRbKpVg9MjjaOVowpyRBD/d2PMaZ0qCp6l2YpM/rCO01DMfIjNTdd9pGKxz3d2HPFWh6XtXV1dXGRQCA5/hq+1z16DlUQYE9jCWPlpWVp8TnPtOMmCeNJeC8vPHNX9R3bLAGDLhUAQG+xrLHKj+Srd27PtLQ2AXGEpoAnVwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAluNVXV1dbVwEAHiOr7bPVY+eQxUU2MNY8mhZWXl6aeYy4zIMqqpOqlWrlvLy8jKW4GLM/ddpwIBLFRDgayx5rPIj2dq96yMNjV1gLKEJEHIBwMOZNeSWlJQr+1CBcRkGS/+yQg89dKdatW5lLMGFf1AHBQT4ydu7rbHksQi57kXIBQAPZ9aQi/qZMX2+Xpw/Q23atDaWYHKEXPdiJhcAADcKCPBTZWWVcRnARSLkAgDgRiUlZXRxgUZAyAUAwM3o5AINj5ALAICb0ckFGh4hFwAAAJZDyAUAAIDlEHIBAABgOYRcAADcqLq6mhPPgEZAyAUAwI28vLw48QxoBIRcAAAAWA4hFwAAAJZDyAUAwI0uuaQNM7lAIyDkAgDgRidOVDKTCzQCQi4AAAAsh5ALAAAAyyHkAgDgRgEBfszkAo2AkAsAgBuVlJQxkws0AkIuAAAALIeQCwAAAMsh5AIA4EYhIYHM5AKNgJALAIAbFRQUM5MLNAJCLgAAACyHkAsAAADLIeQCAOBG1dXVzOQCjYCQCwCAG3l5eTGTCzQCQi4AAAAsh5ALAIAbBQcHMK4ANAJCLgAAblRYWMK4AtAICLkAADSx3bvTNOKGiRp586/11Ve7dOvPHtaIGyZq69adxq0ALhAhFwCAJtavX29FRISopKRcJ05UqqSkXIGBfhoyZIBxK4ALRMgFAMANBg68vNb1q6++rNZ1ABeHkAsAgBtcf8M16tWrqySpS5cI/fy2EcYtAC4CIRcAADcYMKCvYmL6SfYu7uWX9zJuAXARvKqrq6uNiwAAz/HV9rnq0XOoggJ7GEseZe2/NhuXcA6HD+fqn6s/1egxN6lLlwhjGecwfHiM2ndoZ1z2GOVHsrV710caGrvAWEITIOQCgIczS8h9dcFydS20dSaBxvafo5/q6eceVECgr7HkMQi57kXIBQAPZ6aQO/zUbbosrPYJVUBDO1CSqdfSXyHk4qyYyQUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJZDyAUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJZDyAUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJZDyAUAAIDlEHIBAB5v68YYDV5ac5m4M9tWKEvUxKWztdV4g3rautHlWGeRszPBed9zMo3Vs9u6MUErylwWyhI10eW5DHZ5/Dk7EzR4ZaJyXLa7qvU6nGWflK0VK+t+rPV9zhflIv9cgIZAyAUAmELvwWu0bXKKto2fKm2bWTs4NqayRM0qmmS771Hx2rD2PMJbWaLeSEvV+v3GUBmvhZNT7MeUZtQnEGbO1oziqVo9OUXbJq/RlF7dFGHccwG2bozR4I3JzmDc6AEYaCKEXACAufiNUFxwqlJLjIVG4pegd2+Ktf0eFa+RylBmPQN2zv4kpUlK2/bamUNsPY+ZU5IhBTqCbaTuHmB/TBdpyE0p2nZTrO2Yd6bo3QGRxi2AKRFyAQDmUrZJ6wvjFRdlLEhSsubUNdZgGDmo863+zNkavNQwWmCUmaQNwfG6wc92devGMxxLkpStz/dKU8Yv0kglaX0dowPnI6J7vHqnTauj02rrwNb1nLVvdt3rDpmza41L1Fyv45i1xixqXqdar2t9OtJAEyHkAgBMIW3baFuQWi/NnzxPQ4wblK0VK6cp0zHWMHmRoraN1pxMWxAbuzfe/lZ/irYNkj43zsluj9bqyYm62x5gjXJ2Jmjw9mitvjOhfmMCma9pieJ1g1+sHhkcrQ37ko07bAzB+Yz8EvTu+KmS/XWwzdtma8XK0Vrfy/GcU/SwNjlD9wbFX9iIh/0fEo6RincHRNq60r0X2e/H9jrl7EzQWMcoh2P04oyhH2hahFwAgCk4Z3LjpFl1dSbLNml9YbTiujvebo9VXG8ps2SnPt+bqt69RtSE06iEmjBb9JomLl+sqEFnD68RAxLt913TxRxyU4q2nSH0bt2X5LxPWxc2yaXLmaQZju7nWmlhXcdw6Zw6TyDzS9C7ztngBK04bHzO0pABNcca2dM+0uDXTXU2vs/Eb4TigpNqzQo7Osm2+V3ZO9WpUtq0mk7u2iSpMFUZLocC3IWQCwAwF78EvTsqXml7azqWFyMtTXp4/FRl1ueEMr8EPdy7rhPJjJK1Ps2l+7x8sdJqjSy4nHhWZ1faJdBOTtFcY0KNmqQpwalKrW9n9rzZ5nO3TY7X+qX2E9Mcj6dnUq3g7fzHx7meD9DECLkAANOpfRKW/aQt+wlpzgBalqg30qSogAG6oVe00opc+ouZic5ubO/BkzTEL0HzB2dohrNL6SJztkvX2BZeowJsndMzzeTm7HxNG5xv7dsuqwdHa8P20/fWW1mi5jg/Os3WwY3udPpJeFt3nvs+nK9FQLR6u5z0llNi7MHGau6oeKk4o+aYUfO0sLeUWSLb63rGk+rOfTId0JgIuQAAU3B2RZfG2OZrb4p1dlaXLE/QirJI3X2nbQ7X0T3V4DWaG2UbNVgol7fVt+u0GdiIAQs0pbiOE7ui5mm+Ztpva5v5Pa2zWovtbXznqIBdxIBJGlmYpM+P1Fqut5z9Sdrg8tyiRiXqbj/bc9bampPE3pDLWEYdhsRMrRk7cL5+ttvO2mvf5HqS2dokjRyUILmcYDYjLV4PD4hUxIBErR6cUTN64ejwuvy5fFlheABAE/Gqrq6uNi4CADzHV9vnqkfPoQoK7GEseZRXFyzX8FO36bKwy40loEEdKMnUa+mv6OnnHlRAoK+x7DHKj2Rr966PNDR2gbGEJkAnFwAAAJZDyAUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJZDyAUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJZDyAUAAIDlEHIBAABgOYRcAAAAWA4hFwAAAJbjVV1dXW1cBAB4jq+2z1WPnkMVFNjDWPIory5Yrv5HrzMuA43ik8IP9fRzDyog0NdY8hjlR7K1e9dHGhq7wFhCEyDkAoCHM0vIfffNNSorPWpcxjns3Pm9+l/RRy1b8Obq+brvkTHy8W1vXPYYhFz3IuQCgIczS8gtKiw1LqEe/jD3L3ryqYfVunUrYwnn0K5dW3m3b2tc9hiEXPci5AKAhzNLyMWFmTF9vl6cP0Nt2rQ2lmByhFz34r0RAADcqF27tqqsrDIuA7hIhFwAANzo2LHjdHGBRkDIBQDAjUJCAunkAo2AkAsAgBsVFBTTyQUaASEXAAAAlkPIBQAAgOUQcgEAcKPg4ABmcoFGQMgFAMCNCgtLmMkFGgEhFwAAAJZDyAUAAIDlEHIBAHAjX98OzOQCjYCQCwCAG5WXH2UmF2gEhFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAcCN/f19OPAMaASEXAAA3Ki0t58QzoBEQcgEAcKOgIH9VVBwzLgO4SIRcAADcJD+/SJWVVfL39zWWAFwkQi4AAG6Sk1OgyMhQ4zKABkDIBQDATdLSMtU1qqNxGUADIOQCAOAGFRXHtW3rTl111aXGEoAGQMgFAMANPvpoo4ZeN1AhIYHGEoAGQMgFAKCJffFFirIO52r06BuNJQANhJALAEAT+uqrXdr46VaNT7hNLVvyf8NAY+F/XQAANJF16zZrfdJ/dN+vx/KpCkAjI+QCANDIiopK9drS93XwQLYm/+Zude/e2bgFQAMj5AIA0IjWrdusP8z9i3r26qqHH/mlgoMDjFsANAJCLgAAjSA5+Rv9fvarKigo0ZNPPaybbx5i3AKgERFyAQBoQFu2fK25z/5Z//turxLuuU0TJoxWeHiwcRuARkbIBQDgIpWXH9Unn/xbs574o1JTM3XnXbfooYfvUu/eUcatAJoIIRcAgAu0c+cevfH63/XC86/rxIlKTf7NeN1//+3q27eHcSuAJuZVXV1dbVyE56qqqjAuATCR1q29jUvn9NX2uerRc6iCAglOniAtLVNff/0/ffP1/9S9e2cNuOpSDRjQV5dc0sa4Fc1c+ZFs7d71kYbGLjCW0AQIuSazJXmmjh3PNy4DMAFfn266ZtAc4/I5EXLdLzU1Q99++4N2/fcHBQcHqF//aPXvH63QUL6SF2dGyHUvQq7JbEmeqX79x8jXJ9JYAuDBiorTlb5vCyHXJCorq/Tdd3u1e3eavtudpk6dwnXpZT112WU9+RIH1Bsh172YyQUAQFJWVp42bEjWq4uX6clZC7Vjx3fq3r2znpj1oKZOm6Cbbx5CwAVMhJALAGiWjhz5USkpu7Vs2Ro98/Qivfu3f6q8/KhuGHGtXpw/Qw89dKeuu+5qvrwBMClCLnAWc5/9s2IGjqt1mfvsn43bzqmi4rgmT5qrzZt3GEunOZ+9AOqvsrJKu3alatWq9XrxhTf0wvOva/fuNHXr1kmPTknQU08/onHj4tSvX2+1adPaeHMAJkPIBc5hymP3KGXHKudlzrOPGrdclGXL1lxQcAZwdidOVGr37jStXv2pXl7wjp6ctVDJW76Rr28H3fXLUXpx/gz9+te367rrrubLGgALIuQCHsbbu62WvjZHw4YNNJYAnEV5+VF98833Wrlynea/+KaefupP2vKfr9W+fTuN+cVNevmPMzVp8q80cmSsunfvbLw5AIsh5AIXYNmyNZo8aa4qKo7Xur5z5x5NnjRXE+55wjneUNfYwbJla/SLMY9q27Zv9e7f/qlPPvm3YgaO0zvv/EOTJ82tdbtly9Y4j/WLMY+qsLBEFRXHNfPxlzXz8ZfrHKOo6zZ79qTX67EBZnHoUK62bPna+W7IS/Pf0tdf/09BQQG6865btODlxzVp8q8UFzdUvXp1VYsW/F8e0Jzwv3jgHJa8+p4zFC5btsZYPk12dr6efOohpexYpSmP3aO/v/8vHTtmC8OStHnzDmXsP6R/fvRnDR58pSbe+wvdeuv1StmxSvfff7v+MO8xdeoU7tz7z9Wfal3SW0rZsUq/GHuzfj/7VR07dlxHj1bo8n69lbJjlZa995J27tyjPXvStWzZGmXsP+Qcr/jt9Hv1+9mv6vjxyjofmyOoA57s+PET2rMnXWvXbtbSv6zQ479boNX/2KCDB3PUs2cXPfjQnXr+hd/qwQfv0I03Xqvu3TsTaoFmjv8CAOfgOpM7YcJoY/k0vr4dFBJi+4D4qKiOtWqfb/pSc5/9s+6865Za62fy+aYvdeWVfZxnd8fEXK6jRyucwdRx/JCQQPn6dtDx45X6ctu3zs5wzMBxmjF9vnJyCnT8+ImzPjbAkxQWlmj79l1auTJJC156W0/OekUbP92qkydP6rphA/Xs3CmaOm2C7r77Vg0ZMoCP9gJwGkIu0ITy8or0+Mz7teTVxEbtoBpPlvvnR3+Wv7+PcRvgEX766SdlZBzWpk1f6v/+7x+a/cxivbr4PX333V4FB/vrzrtu0Z8WPakpj92j224boX79eqt9+3bGwwBALYRc4AJERXVUTk6BKiqOSZIy9h8ybqnTL3/1M8XHX6ewsCCtWrXeuZ6XV1Rn6L1hxLX69tsfVFhYIkla+cE6dejgLW/vtsatkqS2bdvo2sFX6p+rP3XeBvAk1dXVOngwR8nJ3+jvf1+rP778jn477UW9v+ITFRaWqF+/3po6bYL+MO8x/frXt2vEiGt51wHABSHkAhdg4MDLFRERolviH1TMwHHat++gcctZ/ebR8frn6k+1efMOjRo1TDk5BRo+LEGTJ83VsWMnnPuGDRuoX4y92Xk/3377g/4w7zG1a1d3yJWkCRNG17oNJ5jBnQ4dytXWrTv1wQfrtPCP/6dpU1/Q8sSPlZFxWBERIRp7+0j9ceETeurpR3TnnbcoJqYfX74AoEF4VVdXVxsX4bm2JM9Uv/5j5OsTaSwB8GBFxelK37dF1wyaYyyd01fb56pHz6EKCuxhLHmUw4dzdfBgjg4fztPhQzk6eDBHYWFB6tQ5Qp07h6tLlwh16hTOFy2g2Sg/kq3duz7S0NgFxhKaACHXZAi5gDlZLeRmZeXp4MEcHTqUo8OHcnXoUK58fNqrZ6+u9kAbqc6dCbRo3gi57kXINRlCLmBOZg652dn5hkCbo+DgAHXqHKFOncKcgfaSS9oYbwo0a4Rc9yLkmgwhFzAns4Tc/fsPqaCgRIcO5ejQwRwdPpyrwEA/+8iBbeygc+dwtW17ifGmAAwIue5FyDUZQi5gTp4Wck+cqFRWVp4OH85TVlaesrNsP/39fdWla6RzfrZz5/CznugI4MwIue5FyDWZpgi53323VwteSjQuA5Y2afIvdPnlveTj095YahDuDLmlpUeUZQ+xhw/nKjsrX0VFperYMVSRHcPUqVO4OnUKU8eOYYwcAA2IkOtehFyTaaqQu/L9dF17zS+NJcCSvvjPWxoztpclQm52dr6ysvL02cZt8vXtoKysPElSx45hiuwYpo4dQ22/8w1hQKMj5LoXIddkmjLkjrjhYWMJsKR16/9oupB77NhxZWXZAm12Vr6ysnKVlZWvoCB/RXYMVeWJKl03bKA6dgzj2+4ANyHkuhdfBgEAHu7IkRP6/vsDWrdus95+e5X+MPcveubpRfp/H29Sbm6hOnUO19jbR+qlBb/TM7Mn6de/vl2PTPqlLrusJwEXQLNFyAUAD3Hy5EkdPHhQW7du1apVq/Tqq6/q+eef1z9W/U8p239QVdVJXXXVpXr4kV9q4Suz9Nvp9+quu27Rddddre7dO/OZtADggpALAG5w4MAB/e9//9OGDRv0t7/9Tc8//7ymT5+uFStWKD09XYGBgRo5cqTuvfde3XvfVZp4b5xuu22ErrrqUoWFBRkPBwAwIOQCQCP66aefdOhQrr75Zq+2bDmgJUuW6Mknn9Qbb7yhf//73/rxxx916aWX6t5779XixYs1a9Ys3XPPPRoxYoT69Omjjh07Gg8JAKgHQi4ANJDy8qP6/vt0bdy4TcuWrdH8F9/U1MeeV+J7a7Rvb5a8vVvrxhtv1KxZs/TCCy/oN7/5jX7xi19o0KBB6tixo7y8vIyHBABcIEIuALg4erRCS159TzffdJ+x5FRdXa2srDxt375LH330mZb+ZYWefupPmv/im9r02TaVlx9V795Runv8z7X41af15FMP6867rtdVV0Xq0ksvlZ+fn/GQAIAGRsgFALv//jdVs59ZrMTE/6fS0iOSpCNHflRqaoY2bfpS7733sV6a/5amTX1B7/7tn/rf//bJ27uthl8/SL97/H698OJ0PTolQWPH3qxrr71CXbpEqEUL/jMLAO7Af30BQNKOlN164/W/a8uWr/XTTz9Jkkbe/Gs9/9xr2rB+i4qLy9SjR2f96u5btfCVWXrq6Ud0331jNXJkrC67rKcCAnyNhwQAuBEhFwAkrVq1Xj/8sL/Wmrd3O81/6Xea8tg9GjcuTkOGDFCXLhFq1aplrX0AAM9DyAUASQn3jNaEiWM0ZMgAdevWSS1btlRJSZlxGwDAJAi5ACDp8st76d57f6HFrz6tec9N1awnH9IVV/QxbgMAmAQhFwAMoqO7acyYG/XqkmeMJQCASRBygQuxZ7YenxVTc1mcqGJ76YcPYrToi2zDDeppz+xax6qXPbMv/P4AALAoQi5woSKm6sn5KXp5/hrdqsVa5pagmawV7yYZFwEAaPYIucBFi1S/K6OVlZthLDSybH2xOEkaYFwHAACEXOCiZWv3t6ka0D/WWJDs4wt1jTXUHnmYrR9q38zWpZ115tGH4i9mKmvkPF3lurhnth6flaAvilwXAQBofgi5wIXKWawXZ8Xo8VkzpYQU3d3XuEEq/iJB7+Q6xhpSdH/4Yr34QbItjL4r3W9ff/nxaOXtcb1ltr5Y/Jo6Pp6iacMjXQs2e2brxW/jFV/HfQIAAEIucOGcM7kLpERDl1Zydng7XjlCgfaVPv3jpdwMpexKkgbEy/kBVUEJGu4MrKlKWjxan4RP0vAgx5qrZK14N0O3JiQ4j+vUd55enp94htsBANB8EHKBixap4VMXaUBOknY3xJhATpI0co1uzZ2mFbW6uzbFX7ymnUrVJy/bRh3e2SllrRtd514AAJorQi7QEIoylK9uCrN3UG0nodlPSPt2k73Dm60vNiRJ4d0UY+/oOju/RYn6whFSI6Yqvm+khidMVf67p8/qBg5PtI04OEYgBkgdb1ljG5dgJhcAAImQC1wE50xujB5/OUkDHp+nPpL63DRVHXdO0+MfJCtweKJtDndWjB6fNVqfaKqevCtW6jtPT16Z5HL7VIUZ52uDEjThlgy9c9oYBAAAOBev6urqauMiPNeW5Jnq13+MfH3qOBmpgXz33V6tfD9dI2542FgCLGnd+j9qzNheuvzyXvLxaW8sN4ii4nSl79uiawbNMZbO6avtc9Wj51AFBfYwlgB4sPIj2dq96yMNjV1gLKEJ0MkFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8iFuRQlapHjW8Kclwv8Gts9s/V4fb9N7Hz2XoDiLxL0+AfJxuXT7Zltf86z9YOy9cXiGK1wfB3wmRQlatGs078e2OlcdQAATIiQCxOK1/3zU/Sy85Ko4UHGPRehkQPthUvWineTNGBiil6eb/sK4fOXrBUX+o8CAABMhJAL1EffeXp5aoICjetNqShD+YrXVX0dC5EaPjVFdzuvn0FQgqadLRSfqw4AgAl5VVdXVxsX4bm2JM9Uv/5j5OsTaSw1mO++26uV76drxA0PG0vuV5SoRS+nKt4YyvbM1uPvSvc71p3XJylv8UxlhUs7d6ba9g5YpJfvirXt2RCtJ6cmKFDJWjFrmvJv+b1C1/1BOx3HHbBIL/dP0uPvJkkRU2vtdezpeMsaTRseaTveLmnAziR7LVq3Pp6o4UrUopcXK8t1Lcg2ovDiOvtjctzXXbH2bqvh+JdvcjmGNGDiGnXcMFqf5EgDJqbo7r7Z+qKu53lThv128bp//jzpgxi943xy8br/8WgludT7SPrBdY/jORclalFiqkKVpJ05jsfgCNh1PN6zvR4N2XVvIOvW/1FjxvbS5Zf3ko9Pe2O5QRQVpyt93xZdM2iOsXROX22fqx49hyoosIexBMCDlR/J1u5dH2lo7AJjCU2ATi5MKEnvOOdx6zNLmqr88AW20YbHp6rjztcMb9dn64vFr6nj4ymaNvznuntivC3czU+xhc6+8/TkLdEue6cp/5Y19lGJRQpdN7pmLnandJV9jOL+Aan6ZGOyir9LUtaARbVHK/bM1ovfxtvuY36Ky/GTtWKW7bHY9q/RgG9Ha0V+gqY9PlUd7aMad/eN1PCpizTAfiubOp6nEjRtYrxzR5+7FmmAonXr4/aRh6Da9eIvEvROrv25z0/R/eGL9aJjVjgnQx0Tah7vzg2JKj7T4z3L6wEAQFMg5MKEXGdy6/c2e2iovfMd1E2htSqpSlo8Wp+ET6pfh7Fok3bmRGvA5Y5OeqyuGiDl52fbrkZEO48fGm4LroGXx6vjzmm1Tiz7YVeSOl454vTxhz1J2qlUffKyI8TburXO45/DmZ9nfWRr97eptR5Xn/7xUm6GfT65m8Lsr1FgaDfbL+d6vHW8HgAANAVCLpq3nCRp5Brdmjvt3J9ScKGCEjRtfopt7GFWPT4N4bQT61Jsb/97LLM9XgBAc0DIhTWERqujMpRnH0Mozs8w7qhbxFTF943U8ISpyn/XZfQhJ1X5tXfaBI3QgIhU7fzO3qksSlTSTpcO6tn0naf77V3f0PBoZX276fRPcOgbrwFKUtIX9evcXphUZdX55CLV70rXx5WtLzYkSeHdTu84OzTJ4wUA4PwRcmENQQmKH1Dztvmyb40bziEoQRNuydA7ixNV3HeSbo1wzP0aZ35ts7Ch60bb3p5/ebF0y5qzfsJB8RcJzs/0fWdnvOKHRypweKJt3tW+XnMCWqzuts/5Oj8HuEE/zixW8bdEa+e7tmMbu8q1H9dofaKpevKu2NqbamnsxwsAwIXh0xVMptl/ugLQCPh0BQCNgU9XcC86uQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcr+rq6mrjIjzXluSZ6td/jHx9Io2lBvPdd3u18v10RUXFGEuAJaWmbdKYsb10+eW95OPT3lhuEEXF6Urft0XXDJpjLJ3TV9vnqkfPoQoK7GEsAfBg5UeytXvXRxoau8BYQhMg5JpMU4Xcf6z6wriMRvbTTz8pPf2QevXqaiyhCYyMG0jIBdCgCLnuRcg1maYIuSdOVOr48UrjMhpZVWWVnnvuNc39w2PGEppAu3aXqFWrlmrRonGmuAi5QPNDyHUvQq7JNEXIhXtUVlbpyVkLtfCVWcYSLICQCzQ/hFz3apyWBYDzVllZ1WhvlQMA0NwQcgEP4eXlpTZtWuvkyVPGEgAAOE+EXMBDtG/fTt7e7ZSeftBYAgAA54mQC3iQsPBg/fe/qcZlAABwngi5gAeJj79Ou3el6ocf9htLAADgPBByAQ8SEOCr28fF6a03V+rQoVxjGQAA1BMhF/AwV17ZR3feNUqvLPwrHV0AAC4QIRfwQNdc01/33vcLJb73sdau3WwsAwCAcyDkAh7qiiv66LGpE5SXV6gXnn9d332317gFAACcASEX8GChoYG6776xir9lmNat/UJ/XpKotLRM4zYAAGBAyAVM4KqrLtXjMx/QVVdfpn+u/lR/euVv+vbbH4zbAACAHSEXMJEhQwboiVkP6rphA7XlPzv07Jwl2rAhWRUVx41bAQBo1gi5gAkNHHi5Hp2SoPEJt6m4uEzPzlmi1197X19//T/jVgAAmiVCLmBivXp11S9/OUrPzp2iAVddpq+//p+mPDpPb7+9Sikpu3Xy5CnjTQAAaBYIuYAFeHu31TXX9NdDD92p556fpksv7aFdu9L0xMyXteTV9/TZZ18qL6/IeDMAACyLkAtYjJ+fj4YMGaD7779dz7/wWw2/fpCKikr01psr9fvZr2r58v+nb775Xj/+eMx4UwAALIOQC1hY27aXqH//aN155y16ZvYkPfzIXerUKVzffPO95v3hL3rxhTf04YdJ+u9/f+DkNQCApRBygWakY8cwDR8eowceGKf5L/1Od/1ylAIC/LT9q12a++yf9fxzr+n99/+l7dt3qaio1HhzAABMw6u6urrauAjPtSV5pvr1HyNfn0hjCbhoBw5kKyPjsDIyDutAZpaqqk6qa1RHdevWSd27d1a3bh3VogX/Nr4QRcXpSt+3RdcMmmMsndNX2+eqR8+hCgrsYSwB8GDlR7K1e9dHGhq7wFhCEyDkmgwhF02poKBYBw5k6+DBHB3IzNLBgzkKCwtSl66RiorqqK5dI9WxY5jxZqgDIRdofgi57kXINRlCLtzp5MlTOngwW4cP59l+HspVTk6BunSJUOcukercOVxdukQQfOtAyAWaH0KuexFyTYaQC09TUXFcWVl5Onw4V4cP5ynrcK4yMg6rR48u6tgpTJ06hatz53B16hSuNm1aG2/ebBBygeaHkOtehFyTIeTCDCoqjqugoFiHDuU4g+/hw3kKDvZXp84R6tQpXJ3sAbh9+3bGm1sSIRdofgi57kXINRlCLszM1vG1dX0dwbd9+3bqaA+9kjRoUH8FBvoZb2p6hFyg+SHkuhch12QIubCa/Pxi+6hDrr7/3z79+OMxHT9+QhERIQoLD1Z4eIgiIkIUHh5s6vBLyAWaH0KuexFyTYaQi+agouK4cnMLlJtbqJycAuXZfx4/fkLh4cEKjwgxXfgl5ALNDyHXvQi5JkPIRXPmCL85ObYA7Bp+fXzaq0fPLh4bfgm5QPNDyHUvQq7JEHKB01VUHFdKym61bt3K2fnNzS3UsWPHa3V+w8ODFRER4pbwS8gFmh9CrnsRck2GkAvUn+vYQ25uoXLtHWBH+A0LD1ZERKi8vduqV6+uCg4OMB6iwRBygeaHkOtehFyTIeQCF88Yfr//3z5VVVWpvPxHhYYGKjQsWKGhgQqz/wwNDZK3d1vjYc4LIRdofgi57kXINRlCLtB4KiurlJ9fpPz8YuXlFSo/v1j59p9t2rRWWFiQQkKDFBYWpNDQILVo4aVLL+1pPEydCLlA80PIdS9CrskQcgH3KC09ovz8IuXlFdmCcF6RSkvLlZtb6Ay/jq6vIwR36ODtvD0hF2h+CLnuRcg1GUIu4FlOnjzl7P46QnCB/WeLFl4KDQ1SSGigvL1PqvLEAV1//SwFBwerdev6f8UxIRcwJ0KuexFyTYaQC5hHeflRZ/jNyPhBe9O+U6tWfdSyZUtVVlYqNDTUeQkJCVFoaKiCgoKMh2nSkPvqy8u15T/fGJcBS7mifx9NfWK8OvjUvNvSGAi57kXINRlCLmBOruMKP/30kwoLC5Wfn6/8/HwVFBQ4fz969Kgz8B45ckSDBw9Wbt4qXTngenXtcrnxsA3u1ZeXq/+RoRrSdaixBFjCrpz/av3xfxBymwFCrskQcgFzqu9MbmVlpTPwfv755woJCdHu3Z+o6mR7tWndXmFhQQoOCXTO/4bYf7/kkjbGQ10QR8gdGjXMWAIs4dvsnYTcZoKQazKEXMCc6hty6+IYV7ikTUSt+d+CghIV5BepoKBY7dt7KyQkwHkCnC382n738vIyHlKS9KtfTpfkpfhbrtP48T9Xq1YtCbmwPEJu80HINRlCLmBODRFyzzaTW1xc5gzABQXFKrD/XlhY4uz2hrh0fkNDg3T/r5/SoUO58vZuq2uvvVK3j4vTl1/sIuTC0gi5zUcL4wIAwHwCA/3Up093DRs2ULffPlKPTPqVfj/nN1q0+Ck9+NCdGjxkgPz8fHToUI7WJ/1HC//4f8rJKZDsX46xadOX+sufE5V5INt4aAAwJUIuAFhYixYtFB4erP79o3Xjjdfq7rtv1WNTJ+i556fp5MlTtfYWF5fpQGZWrTUAMCtCLgA0Y506hWvIkAF6+JFf6sX5M3TdsIHGLQBgSoRcAGimUnas0u9+92stfvVpPfDAOF1+eS+1OMNJagBgNoRcAGjGYodeZVwCAEsg5AIAAMByCLkAAACwHEIuAAAALIeQCwAAAMsh5AIAAMByCLkAgKaROVuDl8bUXFYmKkeSlK0VK2M0J9N4g/rZujFGE3ee65vakjXH9b6X1vP+Mme7PM56rCtbKzbWXs/ZmXCW+7I99/N5TFs3ujyPjcm2xbJETVw6W1uNm89HWaIm1nqNLvJ4gJsRcgEATSd4qlZPTtG2yWs0RYs165zhtCFFa8r4FG2bbLvMjTLWG0KGUtOS9HmZy0pRqjJL6n6eOTtnaonsr8n4qdIZ9jls3RijGcWO1zBFq4OStMLlvs5LnUE9Xgvtx942SprR5EE3WXOWJlz4cwJcEHIBAG4QqRt6RSutKMNYMLeyDGUqVev3O8Jqstan6YzPM6MoVb17jVCEJPklKK5o9Jm7uWWJeiMtWlPiEmz7JUUMmKe7/Qz7GkpUvEYqQ5kETpgUIRcA4AbZ+nxvqkb2jDUWJONb8i7dxpydCXWuO2XO1uAzdgJTtWT56bfduvEMx7oQJalK6x2vqL2bbMfLTFLm4KkaWZxR5/G7BbkG/WxlFhs2uMjZn6S04HjdcJZQu975utW8BrVeS2dnNllz1iZJhYs11nXsoS5H7KMQjnGGjcmnjX84x0UyZ2vizuSaEYyVicpxGVOx7as9ojHY5f63bpymDc4/p9kqrP1IgPNCyAUANB1HqFo6U4qre2QgZ2dCrbfkFwYu1tiNycrZmaCxe+Od69sGqdZYgMoSNXF7tFZPTqy7u+kclVikkYWNMyqRU5Kh3kGTFBeYqgz79aiAEYqW7bpRxIBJGpk2zR72RmtJobRh7VlCd2A3Zxf3dElST/sYw2BpyXrbMYbcVDOisbB3kmZsTJYUq7mj4mtek5vq+MdGZpI2BMfrBh9JytAbKdL8ySnadlM3rVg5TZmD19iPu0hR22o60GnbXpPiakZSxu6Lt48/xCtt22vO8YeRoxyPa5FGpk3TxJ3ZGnLTIo10jpXMU7DLwwHOFyEXANB0nEFzgbS+rjBn6/A638KXNKRnvFT8X31sWFdUQk2YLXpNE5cvVtSgmrfya4vV3DsdtVjF9a4ZIRhyU4q2OWsXw/bYowIi1S0oQ+szs/X53m6Ki4pUVGCS1tcxhrB1o2tYXKMpwfbwd6bHc4aOsE284uz/aIgI6Faz7HJC2Yy0muW6JWmGo7u6Vlro8jjiYuy/l23S+sJoxXWPtFdsr6dz7tjZbY5UVKDUO8j+WAKi1bvO8YdYPTLYgqMrcDtCLgDADSJ1952LNLKw9klaFyotTXp4/FRlrq3/iVLO8NVgMpRaGK3oACmie7wy972m1MB4DbGPJZx+8pltPCEqwBEWzy6ie7x6F9bdET6zZM1ZvlhR9q7p6sHRxg0GLieeTZ6nIc71boqqqzsOeDBCLgDAPcoylOkSnmwh0H5CmmOmVdlasT1JCrxCtxlPVMtMdM6d9h48SUP8EjR/cIb97XijZM1xdo1tJ4M5wmWDzeS6Ph+/EYorTpLsM8cRAd3q6FTaOp0b9tV+vKeHYTu/BD3cO0kzXB9r5uwzn6gmx2NydHhtneZa3eDzDs325xbscnJdWaLecHk9z1+yXt/mOp+dqtQSwxbgAhByAQBNxzmTG6PBy5MUN36ehihSdw+KV9q20Zq4M1sRAxJtc7iOOVVN1eqbYm3rcsyvxmjwdp12ElbEgAWaUmyb76wtVo/0SrIf0zYiUNc8cJ1cH/NSl0BsXP9/SUoLjpatPxypG3rFKzrA5Th1jBoMuck2j+qYyU0dtEZxe0ef8eS5ITfZZ5RdRgqiA4zP1YUjGC+1z0EPmqreju551CRNCXbU6t8Bd3Tho7aNtv85LpbO5/W027DW8dq5/nnYRhcctf/9aLwVUH9e1dXV1cZFeK4tyTPVr/8Y+fpc6L+YAbhDUXG60vdt0TWD5hhL5/TV9rnq0XOoggJ7GEsN7tWXl6v/kaEaGjXMWAIaSLZWrByt1EF1n3jY2L7N3qn1x/+hqU+MVwcfb2O5QZUfydbuXR9paOwCYwlNgE4uAAAALIeQCwAAmlCk7r7TPV1cNC+EXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDle1dXV1cZFeK4tyTPVr/8Y+fpEGksAPFhRcbrS923RNYPmGEvn9NX2uerRc6iCAnsYSw3u1ZeXK/v7UuMyGtHJkyfVsmVLeXl5GUtoJD4d22jqE+PVwcfbWGpQ5UeytXvXRxoau8BYQhMg5JoMIRcwJ7OE3D3f71fViVPGZTSi11/7ux548A61atXSWEIjadHKS336dFOr1o37mhNy3YuQazKEXMCczBJy0fRmTJ+vF+fPUJs2rY0lmBwh172YyQUAwI38/HxUWVllXAZwkQi5AAC4UVnZEbq4QCMg5AIAAMByCLkAAACwHEIuAAAALIeQCwAAAMsh5AIAAMByCLkAALhRy5Yt+QgxoBEQcgEAcKNTp07xEWJAIyDkAgAAwHIIuQAAALAcQi4AAG7Uvr03M7lAIyDkAgDgRj/+WMFMLtAICLkAAACwHEIuAAAALIeQCwCAGwUF+TOTCzQCQi4AAG5UVFTKTC7QCAi5AAAAsBxCLgAAACyHkAsAgBsFBwcwkws0AkIuAABuVFhYwkwu0AgIuQAAALAcQi4AAAAsh5ALAIAbtWzZkplcoBEQcgEAcKNTp04xkws0AkIuAAAALIeQCwCAGwUG+jGuADQCQi4AAG5UXFzGuALQCAi5AAA0sW+++V4jb/61bv3Zw0pJ+U6/GPMbxY28X198kWLcCuACEXIBAGhiV111qQIC/JSXV6Rjx44rP79Y3t7tNHx4jHErgAtEyAUAwA1iYi6vdf3qqy+rdR3AxSHkAgDgBsOGx6hHjy6SpE6dwjXqZ8ONWwBcBEIuAABuMGhQf11zTX9J0oABfXXVVZcatwC4CF7V1dXVxkV4ri3JM9Wv/xj5+kQaSwA8WFFxutL3bdE1g+YYS+f01fa56tFzqIICexhLDSYzM0sHD+YYl9HIMjMP692/faRf/nKUovt0N5bRyNq3b6fu3TsrIMDXWGoQ5UeytXvXRxoau8BYQhMg5JoMIRcwJzOE3H8s2KpObbsaS4AllZ4sVrdbfRQT04+Qa1GEXJMh5ALmZJaQO3Xg74wlwJLe+fYNQq7FMZMLAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgBQH2WJmrg0RoOdl9naai9t3RijiTuzDTeop7JETXQ51tlla8XKGA1emagcYwlALYRcAADqLV4LJ6do2+QULeydpBkbk40bGtXWjaO1vtcabbszQRHGIoBaCLkAAFyAIT3jpeKMpuuoZs7WDC3SuwMijRUAdSDkAgBwAbbuS1LvXiPq7Kjm7Eyoc6xBStYcl5GHOZm1blYzjnBahzhbK7YnSWnT7LdN0Ioyeylzdu3rACRCLgAA5yNJM+wBdX3PlLq7qpmzNXZbN+dYw+rBGZqxMlE5StacpdOkUbb1bZPXKLqkdpjdunG0UgelaNtNsbXWVbZJ6wulkfbbrh4sLVnPXC5wNoRcAADqrWYmN26fsUtrs3VfktQ7XkPs1yO6x6t3YaoyMpO0QfGKi3LsjNTdA2rC7PqNMZpRPFWPOOtGNbd1HlOSouZp2+RE3e1n2A40c4RcAAAuwJCb1mhKcJLWnzZycCGSlBm0RgsDF2tWXZ/S4NdNZ8y+AOpEyAUA4IJkKLUwWtEBtmtpRRmS44S0tKSajxdLWay04Gh1i4rXSGUo0zk7m60VOx3jCvF6eECkhty0SFHbZtYxX9tN0S6BOmd/ku2YYiYXOBNCLgAA9VYzkzt46TRplG1MYEjMVPVOm2Y7YSxqnm0O175vRlq8Ft6ZoAjFau74eK1f7rj9aKUGGGZvFau5o7ppyXLjGESk7r5zkbTWdtux27rZjwngTLyqq6urjYvwXFuSZ6pf/zHy9anjZAcAHquoOF3p+7bomkFzjKVz+mr7XPXoOVRBgT2MpQaTmZmlfyzYqqkDf2csAZb0zrdvqNutPoqJ6aeAAF9juUGUH8nW7l0faWjsAmMJTYBOLgAAACyHkAsAAADLIeQCAADAcgi5AAAAsBxCLgAAACyHkAsAAADLIeQCAADAcgi5AADT2LoxRhNdvvY2Z2eCBq9MVE6tXSaROdvjHrvx9b0QOTsTbF924WHPDc0PIRcAYE5liZplmm/+Stac5vDVu2WJmrVNmjI+RdtM8ecCKyPkAgBMKFsr1i+WBk/SEGPJLKLmWS8IlqQqLTheN/gZC0DTI+QCAEwnZ+dMLdFUzR9Q8xXnWzfG2N4md32rvCxRE1fO1pyVNbU5mXWMOZQlauLS2doq+xiB4zgu3VfHW/m2+0nQisOJmmjY53yr/rTbTtMGpWrJ8hgNXjpbWx334XwMyZrjvJ3LyEDmbA3eONul5jhmtla4PKeJO3dqxco6Rjk2Jp+217bm8pzL7M/Dse7gWK/rMTleK9frmbM1eG2SVLhYY5tD1xoej5ALADCXotc0a1tqraWcnQmaUTxVqyenaNvkFC0MXKyxjtBWmKHoONv66sHR2rA9URowSSMLk/S5I4Sm2LvCmbM1eHu08zjbxsdr/XKXQLd3ptb3TNG2yYm6oSBJab0X2fZNTtTdflLEgET79RStHiwtWW8LsUNuWqSRira9jT95noZEzdPqwdH2g2Zrxcppyhy8xn7bRYraNlpzMu3lNCnO8bx6p2pJSrJUtknrC+O10L7+7oABuntQvNL2bnKG5te3SVNiumnFytFKHWR/PpNTtFDTXMJwht5IkeZPTtG2m2Lta3Z+CXrX+TpMlbbNPHtwjZqnbaPipeCpWm1/PQB3IuQCAEwlLU162B5kZ+3MlpStz/emqnevEc63/of0jJeKM+yBr5ui7IErIqCbfUesHhksW2BUstanxevhAZHaus/RibR3MJcvVpoylGkPd2mBkzQ3yn6s7vHqnTbN0AGt6ciONQTxMyrbpPWF0Yrr7uhKxyqut5RZYg+iwdFyPOpuQfZg7DdCccFJmuHaUY2apClarNczJWUmaUPvSbpbm7S+UNqwtqYjOyNNSivKcNxKcTFnHplwdseXL1aasQh4OEIuAMBUetvncIfETJW2vVYT8s5TxIBJGpmWpBU7X1Om62yvszvruNR0JXsHOeKmS6ezZ5IGL43RnExDR3ZUfM3eBhepu+9M0bbJ8VrvHDWI1N2D4rVhX6JWbM/QlBhHZ9bRQXa5OLu2Nf8AMKrdHV+kkcYNgIcj5AIAzMkvQQ/3TtIbO6UbekW7vFWfrRXbk6TAbmfsUNrEKq53kpZs66aH7bO9Q3rGS2mvnf1teaOoeVrYW8os+VqpLh1ZW1c4VTU901SllrjczsFvhOKCU7V+v71zW5aoN9KkqICaeeMzi9XcUS5d66h4jUxbrCWBk2zB3H5sW8e6fhxd3owil+54ZpI2OB5/QLR6u3S3c0pqniHgSQi5AADTGnKTbX719YBE2xzu0hgNXjpaSzRVq40zpnUYEjNVI127uFHztG1UN/sJYoYTrgxcTzKbkRavhwf83DYCYb/t+p6LNFJJWp8p+3hEtHNswDlvK9m7srbn4RgN0OA1zrGIOrmeFLY2SSMHOUYOYvXI4HiXLm6k7r5zjaYUT3M+1lonjRkMiZnqHMGwdcrtj2lfvBb2ljbsS7b/48JxEl2MZu01HgXwDF7V1dXVxkV4ri3JM9Wv/xj5+tTnX/gAPEVRcbrS923RNYPmGEvn9NX2uerRc6iCAnsYSw0mMzNL/1iwVVMH/s5YAizpnW/fULdbfRQT008BAb7GcoMoP5Kt3bs+0tDYBcYSmgCdXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACWQ8gFAACA5RByAQAAYDmEXAAAAFgOIRcAAACW41VdXV1tXITn2pI8U/36j5GvT6SxBMCDFRWnK33fFl0zaI6xdE5fbZ+rHj2HKiiwh7HUYDIzs7TgqWXGZTSBqqoqtWrVSl5eXsYSGtmYe4cpJqafAgJ8jaUGUX4kW7t3faShsQuMJTQBQq7JEHIBc/L0kHv0aIUqKo4Zl9EE/jD3L3ryqYfVunUrYwlNwN/fV23atDYuNwhCrnsRck2GkAuYk6eH3JMnTxmX0ERmPr5Azz3/20YLWji7Fi281KJF40xvEnLdq3H+VAEAptKqVUsubrr06x992hqXprs0VsCF+/EnCwCAG323O41OOtAICLkAALjJnj3p6t69s7y92xpLAC4SIRcAADfZ8p+vdXm/3sZlAA2AkAsAgBv8/e9rVV1dreHDY4wlAA2AkAsAQBPKzs7XH19+R5WVVfrV3bcaywAaCCEXAIAmUFlZpb//fa2W/mWFrrn2Sk2YMFo+Pu2N2wA0EEIuAACNKCsrT4mJH+upJ1+Rt3dbzfjdr3XddVcbtwFoYIRcAAAaWElJuTZsSNYLz7+u95atUWhokGY9+ZBuu21Eo32FLIDaCLkAADSAzMwsffzxJr3w/Ot6dfEylZcf1S/G3qxZTz6kkSNjFRwcYLwJgEZEyAUA4ALk5xdp8+YdeuvNlZoxfb5W/2ODWrRooXF3xGvOs49q3Lg49e3beF/FDODsCLkAANTDoUO5+vzzr/TWWx9q1hN/1FtvrlRWVp6uuLKvnnzqYU2fcZ9uvfV69e4dZbwpADfwqq6urjYuwnNtSZ6pfv3HyNcn0lgC4MGKitOVvm+Lrhk0x1g6p6+2z1WPnkMVFEhXsKlkZeXpwIFsHTiQrUMHc5SVlaeuXSPVuUuEunbtqC5dIhQeHmy8GVBL+ZFs7d71kYbGLjCW0AQIuSZDyAXMiZDrmYqLy5SVlafs7HxlZeUp63CeiovLFBkZoo6dwhUZGarIyFB16hTOV+/ivBFy3YuQazKEXMCcCLnuc+rUT8rNLVBubqFycwuVl1eoPPvvwcEBCgsPVnh4sMLDQxQWFqTw8GBdckkb42GA80bIdS9CrskQcgFzutiQ69XiJ+MyXJw8+ZNKSo6rtPSYykpPqLT0uEpLj6us9LhOnaqWn/8l8vdvJ3//tvbf28rfv63atm1lPBTQoCpPHCPkugkh12QIuYA5XUzILSzcZVxqdn766ScVF5eppKSsjp+l8vJqocBAP/vFX4GBfgoIsF0CA/2MhwOaVHBwf+MSmgAh12QIuYA5XUzIbQ4qKipUUlKioqIiFRcXOy8lxSUqKi5SZWWlAgMDFRgYqKCgIAUEBCgoKMi55udHkAVQGyHXZAi5gDk155BbUVGh0tJSlZSU1Lq4rrVr104BAQHy9/dXQEBArYtjzcvLy3hoADgjQq7JEHIBc7JiyK2qqlJpaanKysrq/Om4dOjQQX5+fvL393f+NP7erl074+EB4KIQck2GkAuYk5lCbkVFhcrKylReXq6ysrJav7uutWjRQn5+fvLz85Ovr6/zd+P1Sy65xHgXANDoCLkmQ8gFzMkTQu7Ro0dVXl6u0tJSlZeX1xlcy8vL1bp1a/n6+srX11f+/v51/t6mTRv5+/sb7wIAPAYh12QIuYA5NVbIPXXqlMrLy3XkyBFncP3yyy/VqVOn0wJs27ZtT+uyninAAoDZEXJNhpALmNP5hlzX0Or6u3Ht2LFj8vPzk4+PjzOkFhUV6YorrjgtwLZqxWfCAmg+CLkmQ8gFzKmoOF3f/+/fCgy4S5dccomOHDmisrKy08KsY61Dhw61gquPj0+tMOv42aFDB+NdAQAIueZDyAU8S2VllY4c+VFlZUd05MiPKi//0f7zqMrLj+qI/WdRcYFOHC9V166DaoVU199d11q0aGG8KwDAeSDkmgwhF2h8J0+e0o8/Vqis7KgzsNYOrjVrJ0+elK9vB/n6dlAHn/bO3319bb/72NeqqvJ08OCX9R5XAABcHEKuyRBygQtXVXVS5eVHVVZ2ROX2oGr7/ajKy2wB1hFeO3Twlr+/r3x82svHHlgdF0dw9fVtr3bt2hrvpk7nO5MLALg4hFyTIeQCpzt27LjKy20jA87A6ui82tfKyo6qsrJKvr7t5efnIx/fDvLz83F2XG2/d5Cfny3INjRCLgA0LUKuyRBy0ZwcPVpRq/PqmHstKzviHBkoKzuifv2jdfBAtvz8bCMDNYG1doht395936pFyAWApkXINRlCLqzgp59+UlmZLaDaLkdVWlqusjJb59Xx+6lTp+Tv7ys/vw7y8/eVn5+P/P195OfnIz+/DvL395W/v48pTtIi5AJA0yLkmgwhF2Zw9GiFSkvLVVp6RCUl5SotLVdJSbnK7GulpeVq3bqV/P19FRDgK/8AP9tPe2gNCPBVQICfWrVqaTy0aRFyAaBpEXJNhpALT3D0aIVKSspVUlKm4mLbpaSkXCXFpSopKdexY8cVEOCnwEA/BQTaftou/s7fmxtCLgA0LUKuyRBy0VRKSspVVFTqvBQWlqjY/vuRIz8qKMhfwcEBCgoOUHCwf831IH+1bXuJ8XDNHiEXAJoWIddkCLloSCdOVKqgoFj5+cUqLCxRQUGxCvKLVVBQrMrKKoWGBik4JEChoUEKCQlQWFiwQkIC5e1dv4/NQg1CLgA0LUKuyRBycaHy8oqUm1ug3NxC5eUVKS+3UDk5+fL17aDw8GCFR4QqIiJE4eHBiogIUZs2rY2HwEUg5AJA0yLkmgwhF/WRn1+sw4dzlZWVp+ysPB0+nKeTJ0+qU6dwdewUrk6dwtS5c4TCwoKMN0UjIeQCQNMi5JoMIRd1OXgwRwcPZuvAgWwdyMxScXGZunXrpG7dO6tbt47q0aMLnVk3I+QCQNMi5JoMIReyd2rT0w8qPf2g9qcfUlXVSfXs1VW9enVVdHQ3BQX5G28CNyPkAkDTIuSaDCG3+Tp8OFc//JChPd/vU3r6IV16WU9dfnkv9evXWz4+7Y3b4WEIuQDQtAi5JkPIbX5SUnbr25179MMP+3X1wMs1aFB/9ezZxbgNHo6QCwBNy/O/CxNoplJSdutPr/xN//58uwbG9NPCV2bp7rtvJeACAFAPhFzAw2Rn5+v//u8f2vjpVsXfcp0en3m/Bgzoa9wGAADOgpALeJDs7HwlvvexwsKC9eRTD6tv3x7GLQAAoB4IuYAH+eqrXaqoOKaf/Wy4sQQAAM4DIRfwEKdO/aTdu1L12+n3GksAAOA8EXIBN9uwIVk/v/URjbv9MW3YkKz7f/20bvv5JH355X+NWwEAQD0RcgE3GzkyVl5eXjp8OFcnTlTqwIFstWnTWtdee4VxKwAAqCdCLuABrryyT63rV111aa3rAADg/BByAQ9w88ihCgsLkiRFRXXUyLihxi0AAOA8EHIBD3DddVc7u7dXXBGtgQMvN24BAADnga/1NRlP/lrfnAzjCs7HD3vS9dZbK3XvfWPVr1+0sYzzENzRS63beNZ/2vhaXwBoWoRck/HkkPvlv6STJzsYl3Eeqqur5eXlZVzG+ag+oqtv9lK79saCexFyAaBpEXJNxtNDbmCnMIV0amcsAU0ie9+PKsnJJ+QCAJjJBQAAgPUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcmEO2YmaHPeMthvXjb58RiMnJSrXuG63fcFATf4w27hci3GP8Tpc1PfPBQCAJkbIhXWdI/DifGVr1aSBmv+lcR0AAM9DyIU5RCZo6frnNMi4bnTtc9rwWoLCjet2g2bu0NI7Io3LZ3Uht2k26vvnAgBAEyPkwvMd/V6T4wZqpONt8S+f0cgFz2h+3ECNjBuokXHjtSrbvh430N69Tdb8OUnS/kWaEDdQIxcka/sC237H6EHuh+Ptt3c5hkGt2ziO73pZkCyddqz6vH2f7PL4a7qjdR8nW6smjdf8BS61Bcn2x+N6X8ma73wetY/veM6O0Qvb8xqvVTsT7a+ty2uQ7brm+no9rjf3S5vmGG9b8xgcr9fIOMefg/14k57R/EmnP18AABoLIReer8OlWjo3vvbaZ9KI9Tu0Yf0OPXdjqt5MTJaufU7LHoi2b4jVrLnxUvdpWrZ+hzbMjNWgmR/roe41hwi/Y7k22I+x7AHpzXmnjzbUus21zzn3b/jrNPXsPk3LZsYq98PxmpAxuaY2V3rmrGMSyZofN1Waa9+//mP1PGQLrRPe7qbnnI8pw+U4qTrY7eWa+/5sqVZ1mayHuidpkzMgL9WmGydrXGSy5sctVc+/1hx/xKbbaoLlpse1adgObVi/XEP3rdO+Gxfb9y3XuEhHd7bmeertx7UqWwq/42U91F0aMde+d0BCrT+X3A/H65kM++u9foee67ZIE+z/CND+DPWc7Xhe0dr0bqIqnLcEAKDhEXJhTt37qIv91y7dHMH2fNV0Oye8nWosnkWy5t+3TiNmJyhc2dqyKVX6bGpNB3NOkrT/Bx003szhy3XapHiNuNaxEKlxd8Rq++Yk6cZbnG/9h8feop4ux+nS2T4yEdnN/twjNW5ivDa9m6hcZWvLJumhhFj78VP15n2OzultenO/dPCQrSO7r9tkzbLfd3jsLer52VRnR9rB2ZG9b5H21aqcie116DlihHNUZNCweCkjwx7Su6mL/eGHd+5WczMAABoJIRfNVLZWTZqqgw98bO++GjrFZ7F9wVQdfOBlW9fTrqfjOM5LE82pXjtZD2mdtny4VG92m+zymOKdHWHHxTFX3LObS8h0dG2HrXOOEdTuyC7WiJrdAACYBiEX1nbGjmqG9u2P1ohYW/Dbvrl293VfRkat3Q65H47XM1rsciJapIaOiNa+t5fWYw7X7tpbNEIZOuicAc7Wqg+TbZ3Pz9bVzLcmLtI+l4513SI1dIT05tsZti6uHMdP0t/O52PPrn1Oz91o6/YezHDpyNq7wvtcXkRHR7g2++uwaZO9c5utVe8mSd26nfEkQAAAGhMhF9Z1rW1m9RnDyVE2sbr3ATnf0t80bLFGyDbfOihhWp1v4dtmZg2jCZMSpTuW2+ZnXU7WOvuJVbGa9ddbtMllnGBf51j7THHNcZ75LF7PneWTIhzC75isETe6dnFjNWv9YnV5+7Zaj7OuGWHXE92e+Sxe994RqUEJ0yTHbTffoudulDZtTnaOR+yz14yfHRx+x3LbHK5jREK2mWUAANzBq7q6utq4CM+1JXmm+vUfI18fz/tIqy//JQV2ClNIp3bGEtAksvf9qJKcfF19s5fatTdW3auoOF3p+7bomkFzjCUAQCOgkws0itof4eV6OXuXFwAANAQ6uSZDJxc4Mzq5AAAHOrkAAACwHEIuAAAALIeQCwAAAMsh5AIAAMByCLkAAACwHEIuAAAALIeQCwAAAMsh5AIAAMByCLkAAACwHEIuAAAALIeQCwAAAMvxqq6urjYuwnNtSZ6pfv3HyNcn0lhyuy//JQV2ClOrVl7GEtAkjh09pZKcfF19s5fatTdW3auoOF3p+7bomkFzjCUAQCMg5JqMp4fc8mLjKurrp59+UnZ2vjp1CjeWcB68faoJuQAAQq7ZeHLILS3gr9LFqKo6qUV/elePz7zfWMJ5aNHSFnBbX2KsuBchFwCaFiHXZDw55OLiVFZW6clZC7XwlVnGEiyAkAsATYsTzwAPUVlZJX9/X+MyAAC4AIRcwEO0adNapaXlxmUAAHABCLmAh6isrFJwcIBxGQAAXABCLuAh2rRprcLCEuMyAAC4AIRcAAAAWA4hFwAAAJZDyAU8BJ+uAABAwyHkAh6CT1cAAKDhEHIBAABgOYRcAAAAWA4hF/AQlZVVat26lXEZAABcAEIu4CHatGmtqqqTxmUAAHABCLkAAACwHEIuAAAALIeQCwAAAMsh5AIeorKySiEhgcZlAABwAQi5gIdo06a1CgqKjcsAAOACEHIBD1FefpSv9QUAoIEQcgEPERwcoJMnTyo/v8hYAgAA54mQC3iQzl0idehQrnEZAACcJ0Iu4EE6dgxTamqGcRkAAJwnQi7gQWJjB2hHym7l53MCGgAAF4OQC3gQX98OGvWz67Xyg7XGEgAAOA+EXMDD3HTTYPn6+Sgx8WNjCQAA1BMhF/BAEyaM1okTVfrrX1cbSwAAoB4IuYCHuv/+29W+vbdefOENZWQcNpYBAMBZEHIBD3bnnfG6YcS1euftVfrwwyRVVlYZtwAAgDoQcgEPd+21V2jmEw+oZcuWemLmH7V27WadPHnKuA0AALgg5AIm4OvbQWPH3qzHZ96v8vKjmjF9vlav/lTFxWXGrQAAgJALmEtkZKh++ctRevqZSWrVqqVeXvC23npzpb7/Pt24FQCAZo2QC5hQaGigbrtthF6cP0N9L+2hjZ8m6+mn/qR//nOjDh/ma4EBAPCqrq6uNi7Cc21Jnql+/cfI1yfSWEIzd/BgjnbtStXuXak6efKU+l8RrSuv7KuuXfm74gmKitOVvm+Lrhk0x1gCADQCQq7JEHJRH/v3H9L336drz/fpKikp02WX99Jll/XS5Zf3UqtWLY3b0QQIuQDQtAi5JkPIxfnKySlQamqG0lIzlJqaoU6dwhXdp7v69u2ubt06GbejkXhayN27b7UyMj8xLgPNWqeOw3Vp34nGZZgUIddkCLm4GCdOVGrfvoPat++A9u09oKysPPXqFaWevbqqd+8oRhsakSeG3GoVKqrrdcYS0CxlZX+tYxWnCLkWQsg1GUIuGlJZ2RHt339Y+/cf0v70g8rOLlCPHp3VvUcX9ezZRT16dFHLlpyf2hA8NeT26jnSWAKapcwDWwi5FkPINRlCLhpTeflRZWZmKTMzSwcys7R//2FFRIQoqlsndevWUd27d1ZQkL/xZqgHQi7g2Qi51kPINRlCLppSVdVJHTyYowMHsnTgQLYOHsjWsWPHFRXVUV26dlRUlO3i7d3WeFMYEHLdY+6zf1a37p01YcLos64BhFzr4X1IAGfUunUr9ejRWSNGXKv77hurOc8+qplPPKhrBw/QyZMn9e/Pv9If5v5Zz85Zonfe+Yc+/XSr0tIydfz4CeOhAEurqDiuyZPmavPmHcYSADch5AI4L4GBfrryyj667bYRmvybuzX/pd/p4Ud+qX79eunIkR+1Puk/mvP7JXp2zhK9/fYqrV+/Rd9/n64jR340HgoAgEbDuILJMK4As8jJKVBWVp6ysvKUnZXv/Ca2jh3D1LFTmDp2DFOnTuEKDw823tSSGFdwj7pGExxro0YN04MPzHb+3bz11us159lHVVhYogcfmK3fTr9Xw4YNrHX9801f6pNP/u08VkxMP/1x4RNatWq9lrz6niTJ17eD/vyX2Vr5wbo69x44kKUXX3hTDzx4h+Y++2cNGzZQv3l0fK3HMuWxezRhwmhVVBzX72a8pJSU3c7jLHxlliTp7+//S7eNHqHZzyzWlMfuUcb+Q87769QpXG+9PU/e3u308oK3dXm/3pr/4puSpHnPTdXHazYpJWW3c19BQbH+9cm/9eOPx/TJJ/9Wp07h+u30ezX32T+rvPyo87WxMsYVrIdOLoBGERERooEDL9fo0Tdq0uRf6fkXfqsHHrxDw4bHqG3bS7RrV6reenOlZkyfr1cW/lUffLBOW7Z8rYyMw6qqOmk8HHDBlrz6nmIGjnNeHEEwODhA//zoz0rZsUrrkt7St9/+UK9xgymP3aOUHav0xeZESdLLC97WuHFxionpp4WvzNJnm/6mvn17nHGv7Cd5fr7pS/2/T17X4zMf0O9nv6pfjL3Z+Vj+ufpTbd68Qy8veFthYUFK2bFKy957SR07hikkJECSlJ2dr+92pyllxypNmDBac559VCk7VillxypdeWUf/eXPyyVJeXlFzn0LX5mllxe8oymPJeiLzYmKiAjR2rWbJUnr1v1HN4y41nn7v7//L/2/T17Xsvde0s6de7RnT7oAMyHkAmgy3bp10uWX91Jc3FD9+te3a/bvJ+v5F36r20bfqPDwYB08mKNVH67X72a8pBeef13vvvuRNm7cpj17GHfAhXMETcfl1luvd9aWLVujmIHjdEv8g84uan15e7fVL3/1M+XlFenYsePGci2ue48fr5Qk3XnXLfL2bqsDB7KUnZ2vmJjLJXv4vvLKPsrMzDIcpTYvLy/de99Y5/U9e9J144h7awV5hxtGXCtJCgkJsAflQHl7t1VYWJAy9h+S7O+yXHqpLZx3695ZYWFB8vZuq5CQQHl5eamgoKTWMQFPR8gF4FZt216inj27aPjwGN199616fOb9Wvzq05owcYz69Omu8vKj2vjpVj037zW9+MIbWvqXFVq9+lNt3bpT+/cfUkXF2cMFcCabN+/QP1d/qnVJb+mLzYmKieln3NJofH07KCQk0Lh8mt88Ol7ffvuDYgaO04R7ntDY20c6u8QRESHy9m4nSSosLNFTT/7J2c2d8tg9hiMBzQ8hF4BH6tQpXNdc019jx96sKY/do5cW/E533HmLhl8/SH5+PsrIOKyP/rlRz85ZomeeXqQ/L0nUhx8m6T//+Vp79x7Q0aMVxkMCtWRmZunKK/soODhABw5kKTU1Q5mZWfL2bqeIiBBnJ7WgoFjl5UeNN1dFxXH9/f1/6drBV6pdO9vH6J2p++q6t23bNrVqXbt2VGRkqFJSvpPsHdnNm3coKqqjvv8+XVde2cfZhT7Tx54VFBTLx6e9Lr20hyoqjuvLbd/Wq8MMWBkhF4Bp9OzZRZdd1lM33nitxo//uabPuE8LXn5c02fcpxE3DlZQkL8OHcrRJ//vc837w1I9/dSftOTV97RyZZI2b96htLRMZWXlGQ+LZmrUqGHOLumSVxM1blycvtz2rSTpl7/6mXOW98lZr9S6nWN9+LAEhYUFacKE0c5xBEdt2bI1Z9xr5O3dVn+Y95j+ufpTZ8d24r2/0LBhAyVJn3zyb+c88Y0j7q1zNrZv3x7q0aOzbol/UD+/9RHdeNNgZWfn6+DBHONWoNng0xVMhk9XAOqvrOyIcnMLlZNToNzcQuXlFurYseMqLS1XRESowsKDFe68hMjf38d4iAbDpytYQ12f1nAm57P3TPbsSdf336fr9tttf04NcUzUjU9XsB46uQAsy8/PR9HR3XT99YP0y1+O0tRpEzTryYf01NOP6JZRwxQZGar8/CJ9uiFZLy94W0/M/KP+9MrftGLFJ9q06Ut9//1+FReXGQ8LNKmlf1nh7OTm5RVp3Lg44xYAdaCTazJ0coHGc/RohXJzC5WbW9P5zc0t1PHjJxQeHmzv/Ibo2LHjuvbaK+p14pADnVzAs9HJtR5CrskQcoGmV1Fx3Bl8c3MLlfrDflVWVqm4uExhYUEKCQ1SWFiQQkODFBoaqLCwYLVvbzvr3YGQC3g2Qq71EHJNhpALeI6qqpMqKChWXl6R8vOLlJdXpIL8IuXnF6tlyxYKCQlUqD38tmt3XEePpilu5Atq0cL9k2KEXKA2Qq71EHJNhpALmEN5+VHl5xc7w++BA/u0Pz1VLVt2VWBgoEJDQxUaGqqwsDDn735+fsbDNJqmCLknTlTq6TmLjMvABfntlIkKCQlUmzatjaUGQci1HkKuyRByAXNyjCtcfdXTKiwsVH5+vvOSl5engoICVVVVOYNvSEhIrQDcpk3tz1a9WE0Vcn896RndNus2Ywk4L5/+5VPNnTmZkIvzQsg1GUIuYE71mcmtqKhQXl7eaQE4Pz9fvr6+Cg0NVevWrRUdHa3QkFCFhoUqODjYeJh6acqQ+8g7DxtLwHl5d9oyQi7OGyHXZAi5gDnVJ+SeTVFRkfLy8rR161b5+vqqoKBAeXl5KisrU2hoqEJCQpxdX8fF19fXeBgnQi7MhJCLC0HINRlCLmBOFxtyz6SqqkoFBQXOzq/r79XV1c7537DQMIWE2oJwSEiIDmetI+TCNAi5uBCEXJMh5ALm1Fgh92yKiop05MgRZ/h1zP7m5+ersqpAgYGt1Lv3Vc6PPgsJCVRoaJBatmyYT38g5KKhEHJxIQi5JkPIBczJHSH3bL7Zmaii4kNqe0lv5ecXq7CgWPn5xSooKFZQkL9CQgIVEmoLvSEhAQoNDVJQkL/xMLVcP3yCrrvuak289xfq2bMLIRcNhpCLC0HINRlCLmBOnhZyzzaT6/jos/z8IhUUlDg/+/fo0R/t4bd25zc0NFA+Pu0VM3CcJOmyy3rq9nFxGjkylpCLBkHIxYUg5JoMIRcwJzOF3DOprKyyh19bxzcvr8jeAS5SdbW0adOXzr0hIYEaOvRq7UpL02/+NrnWcYDzRcjFhWiYwSsAgOW1adNanTqF66qrLlVc3FBNmDBa02fcp/kv/U6zf187yBYUFOs///laLVu2rLUOAE2FkAsAuGi/vu8pSVJUVEcNGzZQ02fcp+dfmGrcBgBNhpALALhoEREhmvbbiZr9+8la+Mos/epXP9Nll/UybgOAJkPIBQBctMWvPq3x43+u/v2jjSUAcAtCLgAAACyHkAsAAADLIeQCAEyoTP8e/4Smx9RcEjfbS5vf1/Txm1VsuEX9lOjf412OVacflOhyv47LwmUlxo2nKV62+CIe28XZM6d+j1HnuRfwVIRcAIBpXbXwJb2S8pJeWXilvpnxvvYYNzSKPkpIsd+v/b6lKzVqQoBx4wWqT9BuQBf1jwLAcxFyAQDmN2yArlK+8g4ZC41vz2ffquOUePU1Fkys79yXNKPBQjvgHoRcAID5bd6pb3oPUP/OxoKkQ5u1sK6xBnvH9GzjBsXLFmt6zFk6xIc2a+3aSF19gz0Q2u+rPl3YPXOeUOKc92tGHuzd1OJly/RxmvTNjCc0PWax/n1Ipz3W6XN+sB3k0GYtjHlfexzPcc4P9sfs2Ou4vcHm9+21H5Q441sp7V96zn77PXMMr8cZXr8zPX7AUxByAQCmZQuCT2j6ZwP0yvJhCjRu0A9KHPsvhTnGGlb/THkzFuvfh0r07/Hz9XXcLOfYwSjtrh3SNr+v59Lj9ErKr87YpS3+fKeyRsXp+rrCdT18owH2+79PV6X9S2s3S4ETJui23o5RjKm6vrPtsR5+uGZE4kH91SWU52vt29J9KS/plbl9FDhhqnPfM1Okj2cZwuehzVr4Rkc9kzJV13fuo4SFV0q9f6Zn7LfvO3eWbuvt2Hym189WNT7+df9xuR/AzQi5AADTcs7k3rjT0KW127xT3+hKXT3Mfr1zP13dO1uHU3br6zSXDqykvhNcQvJn72v6jHzd9kAfZ/10P2jtkmxddaPLns7DNCPlJSU47u8cOvYIs/8Wpk7OYGlwaLe+dnZ2bZe31kpZ6XnOLVc/4Brwa06Me25JtnNVkpSepIVj/6Wwh+v6B0EdzvT6Zdiu1uvxA25CyAUAmN+wX+mZKZH65jP72/gX6Zt9HfXMwtDTu6CuNu/UN71/plH1DLQXJ1K3rXY52c3edbUJVZizk1yif4//q/Km2DvUC6+sOYSkrLXSqNU/U16TnaQHuA8hFwBgCXnp2TWdxbQs5clxQtq3+tr58WJJ+jgtUp1ianckJWnPsppAe9XDwxQ47Fd6sOe/9Nc6ZnXlOOEsrl/tjuh5zOSeS16m/X7t3dOP365PgM/TYZcO9Z7Pvq15LSTbCXKdh+m+Kfl6yzHXK5fXy+hMr183wz7AAxFyAQCmVestfN1n+0SAYfG6rfe3eivmfe1RHyWs/pnyHPtmfKurFk7V9Z0DdP3y+ySX26+VIbBK6jv3PoUtmV9HaP1BX7uecNagAnT9w1cqa8l8+wlg0vXLZ+m2fX+tOcnrjCfD9dGoKdLHY237vr7xvtoh1S5wwgTdts8+1+t8veo67plev1qbAI/kVV1dXW1chOfakjxT/fqPka9PpLEEwIMVFacrfd8WXTNojrHkFnv3rVa1CtWr50hjqcGcOFGpX096Ro+887CxBJyXd6ct09yZkxUSEqg2bVobyw0i88AWHas4pUv7TjSWYFJ0cgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYjld1dXW1cRGea0vyTPXrP0a+PpHGEgAPVlScrvR9W3TNoDnGklvs3bda1SpUr54jjaUGc+JEpX496Rn1vLaXsWQJ1dXV8vLyMi57lJ9++kktWnhJ8uzHeS5Z/zusuTMnKyQkUG3atDaWG0TmgS06VnFKl/adaCzBpAi5JkPIBcypuYbczz//yuOD4IX44osUtWndWoOHXGkseYzXlr6vo0crFBDgq4iIEHXqHKErrog2bjOFalWr3+W9Cbk4L4RckyHkAubUHEOuVa1Y8YmOHz+hX//6dmPJo/z972v1p1f+pp9++kmS5O3dVhERofr7B68Yt4KQa0nM5AIAUE9LXn1PZaVHPD7gStJ1112t3r2jnNcrKo7rxInKWnsAKyPkAgBQD++8s0onT57SPRNGG0seqWPHMF16aQ/n9bZtL9HCV56otQewMkIuAADn8P77/1JRYaluHxenDh28jWWPNeLGwQoODpCvbwctfGWWPvj7Wn333V7jNsCSCLkAAJzBsWPHtXr1pzp16pRmPvGAunSJMG7xaNdc01/BwQH6bNPfNGhQP40ec5P++n//0Fdf7TJuBSyHkAsAQB02bEjWrCcWqn37dkpIuM1YNo33Ehc4f7/00h56bOoErVv7hf797+219gFWQ8gFAMDF559/paeefEW5uYWaPuM+xcUNNW4xta5dI5Vwz2j9+/Ov9MUXKcYyYBmEXABAs1deflQfffSZZkyfr0OHcnXvfWM1YcJode1qzY9r7Nmzix6Z9Ct9vulLgi4si5ALAGi2vvnmey39ywq9NP8tSdJvp9+rCRNG1/roLasKDw8m6MLSCLkAgGblm2++1//93z/02JTntGPHd7p64OV6/oXfasyYG9WpU7hxu6WFhwdr0uS7tfKDddq8eYexDJgaIRcAYGn5+cXatOlLLXn1PU3/7Yv6+uv/KTq6m56dO0UPPXSnrrmmv/EmzUpYWJCemT1JG9Zv0fbtfOoCrIOQCwCwlNLSI/ryy//q3Xc/0tNP/Ulvv7VShYUlum5YjOY9N00PPniHYmOvUmCgn/GmzVZERIjuf2CcViz/RGlpmcYyYEpe1dXV1cZFeK4tyTPVr/8Y+fpY82QIwKqKitOVvm+Lrhk0x1hyi737VqtaherVc6SxZDr5+cXat++A9u49oPR9B+XlJfXo2VXdu3dS9+6dFRkZarwJzuCbb77Xmo82asbvfi1f3w7GsqVlHtiiYxWndGnficYSTIqQazKEXMCcCLkNo7z8qDIzs5SZmaUD9p/BwQHq0jVSUVEd1bVrZLObq21o//rXF8rOzteDD95hLFkaIdd6CLkmQ8gFzImQe/7y84t16FCODh3KVdbhXB06lKNLLmmjTp3C1bFTuDp1ClPnzhEKCPA13hQXacmr76n/FX00fHiMsWRZhFzrIeSaDCEXMCdC7pkVF5cpOzvfecmx/4yMDFV4RIgiI0MVYf8ZHBxgvDkaweHDufrTK3/T7N//Rv7+PsayJRFyrYeQazKEXMCcPDXktm7dzlhqFCdPnlJR4VEVFB5RUeERFRUdVWHhERUWlMs/oIOCgzsoONhHQcE+CgrqoOCgDmrbro3xMGhCn3/+vSp+PKGf3TrAWLKsYxU/EXIthJBrMoRcwJw8MeRWVR01Ll+UU6d+UnHxUZWW/KjikqMqKT6q4hLb9aqqUwoI7KDAgPYKCOyggID2Cgiw/WzbljDriU6ePKU3Xt+gcXcMVliYv7FsWZf2nWBcgkkRck2GkAuYk6eF3AtVXl6uwsLC0y4FBQWqrKxUcHCwQkJCFBwcXOv3oKAg46FgAhs2bFB+fr4SEhKMJcDjEXJNhpALmJNZQu6RI0dUXFysoqIiFRYWOn93XHx8fBQUFFTnJTAw0Hg4mNyxY8f0xBNP6Pnnn5ePT/OYzYV1EHJNhpALmJMnhNxTp06puLjYeSkpKal1vbi4WD4+PgoMDHReAgICav3erl3TzPDCc7z33nvq3Lmzrr/+emMJ8GiEXJMh5ALm1Nght7KyUqWlpSotLVVJSYlKSkqcvx88eFCnTp3SyZMnFRAQUOvi7+9f6/oll1xiPDSauV27dumLL77QlClTjCXAoxFyTYaQC5jTxYTcU6dOOYOrI7w6Aqzj54kTJ5yB1d/fv1Z4raioUJ8+feTry+fJ4vxVVVXpt7/9rf70pz+pdevWxjLgsQi5JkPIBczpTCG3qqrKGVrLysq0ZcsWderUyRloy0rLdOTokTo7r65hlnlJNKZXXnlFP//5z9WrVy9jCfBYhFyTIeQC5lFRcVylpeUqLT2iQ4dStTdtp4KCblBZWZkz2Do6sH5+fvL391d5ebn69+9fK8j6+fkZDw00qQ8++EDh4eEaPny4sQR4LEKuyRByAferrq5WaekR7d2bqTZt2qi0tFxlZUdUWnpEZaXlKis7qtLScrVq1Ur+/j7y9/dVq9YndPx4lq6+6l5noPX391eHDh2Mhwc8zqZNm1RSUqLbb7/dWAI8FiHXZAi5QOOqrKxSaekRewfW1oW1hdijKrNfLys7In9/X7Vu3UoRkaHy9/eRn5+PM9DaLj5q06ZmfvFM4wqAGXzwwQfatWuXnn/+eWMJ8FiEXJMh5AIX7siRH50dV0dwLS0tV7n9Z2npEZ08edIZUn1dgqsjxDp+enl5GQ9/VoRcmFlqaqo2bNjAJyzAVAi5JkPIBep29GiFSkvLVVJiuzi7sCVlKi09opKScl1ySRt7aHUEWFuYdf3p7d3WeOgGQciFmR0+fFiJiYmaNWuWsQR4LEKuyRBy0RxVVBxXiTOsltlDbE2ALS0tV+vWreTv76uAAF/52X8GBPg5Q62/v2+t8YGmRsiFmZWUlGjhwoV67rnnjCXAYxFyTYaQC6txDbCO7mtJSZnK7N3Xli1bqLT0iAL8feXn7yP/AFvXNSDATwEBtvnXgAD3Btj6IOTCzCorK/XEE0/oT3/6k7EEeCxCrskQcmE25eVHnSMExcWlzt9L7L8fP37CGVgDAv0UEOCnwMCaS4cO3mrb1vzfwkXIhdm98MILmjJlitq3b68WLVoYy4DHIeSaDCEXnubEiUoVFZWquLhMxcVlKioqVVFRqUqKy1RUVKKTJ08pKMhfQUH+CgzyV2Cgn4KDA2zXA/3Url3jzMB6GkIuzG769OmaP3++Wrdufd4nXgLuQMg1GUIu3OH48RMqLCxRYWGpCgtLbEG2sESFhSUqKChWcHCALbgGBygkJFDBwf72nwEeP0bQVAi5MDtCLsyGkGsyhFw0puLiMuXnF6mgwBZeC/KLlJ9frIKCYoWEBCokJEChYcEKCQlUWFiQQkOD5O/P18nWByEXZkfIhdkQck2GkIuGUF5+VLm5hfZLgfLzipSbW6jKyiqFhwcrPCLE9jPc9jMwkK+VvViEXJgdIRdmQ8g1GUIuzldxcZmysvKUnZ1v+5mVr8LCEnXsGKqOncLVsWOYOnYMU6dOYZY4wctTEXJhdoRcmA0h12QIuTiXjIzDOnQoVwcOZOvQwWwVFZWqa9dIdenaUV27Rqpr10g6s25AyIXZEXJhNoRckyHkwig7O1/p6Ye0f/8h7dt7QK1atVSPnl3Uq1eUevXqSqD1EIRcmN0LL7ygxx57TN7e3nyEGEyBkGsyhFycPHlKaWmZSkvLVOoP+1VaWq4+fXuob9/u6t8/mpEDD0XIhdnRyYXZ8E8xwCRSUzO0atV6PTdvqT5e85natGmtCRPH6MX5MzRx4hgNGtSfgAsAgB0hF/BwW7Z8rT+98jf9/f1/ycenvabPuE+znnxIo0YNU0REiHE7AAAg5AKea8eO7/Tygrf17c49uvXnN2jOs48qLm6ofH07GLcCAAADQi7gYUpLj2jFik+0bu1m3frzG/TolAT16tXVuA0AAJwFIRfwIKWlR7Q88WO1bNlSs38/WX379jBuAQAA9UDIBTzIV1/9VydPntJdd91iLAGAWwUHB6uyslJ8KBPMgpALeIiqqpPamvyNRo+50VgCALcrLCxUmzZt+PgwmAYhF3CzDz5Yp8TEj/Xee2uUmpqhLVu+VmLix1q7drNxKwAAqCdCLuBmY8ferHfeXqXXlr6v9PRDWrxomd5btkajRg0zbgUAAPVEyAXcrHXrVurXr3ettSuu6FPrOgAAOD+EXMAD/Py2EfL2bitJCgz0022jmcsFAOBiEHIBDzBoUD/17x8tSRow4FINHnyFcQsAADgPhFyYSlWlNS/e7XwUFzdCfr4B+vmtN+unUy1P22OVCwAATcGrmg+8M5UtyTPVr/8Y+fpEGkvNQnlRtTb93br/NjtxolKXXNLGuGwZV99crc61x4+bjaLidKXv26JrBs0xlgBTmD59uubPn6/WrVvzMWIwBUKuyRByq/XNpva6YkSosQQPtyMpW5cNrlJk9+b5nxxCLszuxRdf1JQpU+Tt7a0WLazbbIB18LcUAACcU0FBAV8GAVMh5AIAAMByCLkAAACwHEIuAAAALIeQCwAAAMsh5AIAAMByCLkAAACwHEIuAAAALIeQCwAAzikkJESVlZXiO6RgFoRcAABwTnwZBMyGkAsAAADLIeQCAADAcgi5AAAAsBxCLnAhvnxGIyclKte47kG2LxioyR9mG5cBAGgWCLmAFZggdAMA0JQIuYBFDZq5Q0vviDQuAwDQLBByAadkzY8bqJGOy4Jk23J2oiY718dr1WkTALbbnWs0IPfD8TXHjhto77zabjv/S8cu1+vZWjWpjsfz5TMux3lG25Ws+XOSpP2LNMG+b/sCW73mMdV+bs71L5/RyAXPuNTqen4AAJgPIRdwitWs9Tu0Yf0ObVi/WCM+m6r5X0q5yeu078bF9vXlGlerOZqtVZOWqudfz9E1/fIZTdh0i5bZj7/sgWjjDoNsrZp0m/ZNdDyeHXpOUzX5w2xt35ykng98bF9/ToMUq1lz46Xu02zHnxmrQTM/1kPdXY81VQedt1msLm/fVhOsP5NGOO7jxlS9mWgP0wDgorq6mi+DgKkQcgEXNd3WqdpkXwuPvUU9P5ta00l1+kF/m3Sb3uw22RB8T7d9c5J6jhihcGPhTIo3adN+adOcmu7rM59J+zIyNGhYvPa9fds5O8dO2Zu0aX+0RsQ6HmSsRtwoHTxkv333Pupir3Tpdq7wDaC58vLy4ssgYCqEXMDhy2c04e1uem79Dm1Y79IJjUzQ0vU7tGHYOo10HS3YnyRN/FgPZdg6vg0vWg/9taaTu8HepdW1z2nD+h36vR5nvAAAgDMg5AJ2uYcypBtv0SA5up8u3U5JuvY5PVerAzpN914bqXGzp+ngnGe0vWbnabp0i9a+TZvq+PSDburZ3eWY2Rk6KEmBIzSi+9lHB8LveFkPdU/VvoP2hf0/2G5rFGk71qZkx30k6m+fSV06n6P9DACAiRFyAbvwOyZrxGdTbeMB86R7H7AF090uJ4w981m87jXO3kYm6PcPZOiZs3yEV/gdy/VcN/uJYXEDNeHtVHslUuMm2sYPbPe7rmb9NVuXuPZJZrbPv7Vdv01vapruvVbStZP1UPckPeOyr0akxr1mm8MdGTdQI+9bJD3wsWZdW2sTAACW4lXNBLmpbEmeqX79x8jXp3l24cqLqvXNpva6YkSosWQquR+Ot52I9lpC/ed0TW5HUrYuG1ylyO7N8z85RcXpSt+3RdcMmmMsAaYwffp0zZ8/X61bt2YuF6ZAJxdoIKd9RJjjcpYOLwAAaByEXKCBhN+xvPZJYo5LHd3a8DuW17kOAAAaBiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAABYDiEXAAAAlkPIBQAAgOUQcgEAAGA5hFwAAHBO7dq1U2Vlpaqrq40lwCN5VfO31VS2JM9Uv/5j5OsTaSw1C+VF1Vr3V+OqNVRXS1VVVWrTprWxZBmDb/VSlz7G1eahqDhd6fu26JpBc4wlwBSmT5+u+fPnq3Xr1vLy8jKWAY9DyDWZ5h5yTxyTSgus+Vf2ZNUpvf76+3p0SoKxZBnePl7yCTCuNg+EXJgdIRdmQ8g1meYecq2ssrJKT85aqIWvzDKWYAGEXJgdIRdmw0wu4CEqK6sUHNxM25wAADQwQi7gIdq0aa3CwhLjMgAAuACEXMBDVFZWqW3bS4zLAADgAhByAQ/Rpk1rHT9+wrgMAAAuACEXAAAAlkPIBQAAgOUQcgEPUVlZxTcJAQDQQAi5gIdo04bPngQAoKEQcgEAAGA5hFwAAABYDiEXAAAAlkPIBTwEJ54BANBwCLmAh+DEMwAAGg4hFwAAAJZDyAUAAIDlEHIBD1FZWaUOHbyNywDgEfz9/VVZWcm5AzANQi7gIdq0aa2jRyuMywDgEUpLS9WmTRvOHYBpEHIBAABgOYRcAAAAWA4hF/AQlZVVCgryNy4DAIALQMgFPESbNq1VVFRqXAYAABeAkAsAAADLIeQCHoKv9QUAoOEQcgEPwdf6AgDQcAi5AAAAsBxCLgAAACyHkAt4iMrKKoWEBBqXAQDABSDkAh6iTZvWKigoNi4DAIALQMgF3Oybb77XkMG/1PXD79GWLd8odsivdO01d2rv3gPGrQAAoJ4IuYCbXXXVperaNVJVVSf1008/qbKySr16RalXr67GrQAAoJ4IuYAHGDjw8lrXhw69qtZ1AABwfgi5gAe48aYh6tmziySpb98eumXUcOMWAABwHgi5gAe48so+uvrqyyRJsbED1KVLhHELAAA4D17VfI+oqWxJnql+/cfI1yfSWPIYP+yQfizlr9X5yskt1LatO3XjjdfKz8/HWMY5eMlLva6WfAKMFc9QVJyu9H1bdM2gOcYSYArTp0/X/Pnz1bo1384IcyDkmowZQu7/tlWr2ivEuAw0qvL8AvW7zouQCzSSF154QY899pi8vb3VogVvBMPzEXJNxiwht2XbcIV1aWcsAY0ia+9RQi7QyOjkwmz4pxgAAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5ALAAAAyyHkAgAAwHIIuQAAALAcQi4AAAAsh5AL4PxlJ2py3DPablwHAMBDEHKBesr9cLxGLkg2LjcDyZofN16rso3rAAB4LkIugPMXmaCl65/TIOM6AAAegpALk8nWqkkDNTLOfrF3VrcvGKiRkxKV67Jn8oe21mPuh+Nr9ru+xf7lM6et53443uU4LtezE/WHt1Olz6ZqZFw9jn1GyZrv3D9Q87+0rdZ9nGytmjRe8xe41BYk2x+36325dlprH9/xOLcvsP2+fcFAjYwbr1U7EzXZuc9+22zXNdfbTtUmperN++yPzbmv5jHYjmu/OF6/7ERNnvSM5rv8eTmeLwAAjY2QCxP5Uasm3aZ9E3dow3rb5TlN1eQPszVo5g49122RJixI1vYFt2nTiI+19I5I5X44XhMyJjv3b5gr/f/27j4myjvv9/gHVPCpVhGtyyJddACtVbpqKbugXYddBLdxa6M9zUpaPYeYyPlDY1KPf9B6ey97h2OTRnNy48Y10Rp63zkr+xDTrUBkslKplGJr3bVWHJkeWEdrBaunPjBW5/5jHhh+reIDluu6fL+SSeT7/V0XM2jrx+/8rmvKV1frbHO5CjdKFZH6zmnquF0ASynR66VZUsFW1de13v7c5rFRTapcuEbaFHn+e+XqDIXWl3ekR5/L7lJfzHlOqCP9jfBzXCtXQ5Vq0sq0akqtPNGAXCVPQZmWpjSpcmGVXDt7z+/2LO4Nlp5X5Znfqvq6t5Xv3Sdv+LXU172tpSmR6Wzk57FW2vGqavxSzvqtcitLq3a2qr6uQjkpJaraVBR9VWf3LFe5b612R35Pwr8PkqR2n1yvRV5XljxvVetq9EgAdpKcnKxAIKBgMGi2AEsi5MI+Lv9TnnbJs7F3MljeIHl9PklSzvq9WuVbo3LfWr2+LEWSXwc9vdPXwoVzVbixVmr/TPsba6WC4t6321NKtDQ39pv159bn7jCXRjTvk0dFcke/T4qWLstTi/FcJuUVyxVznrTJKeHl6UqLHPdKkTxvVeus/DrokVaV5IXPH5m4zlXhwsXa3i51dIYmst70Mm0If+9JecVyNaz51h7j6ER25RZ5+3RuJfRzcLndmhSu5Mwvkny+cEhPV1r46U+anN57GADbOX/+vBISEhQXF2e2AEsi5MJmIhPFmMf6vFDL75GnXVL7Ph2MuUjKVbq37/q6CmX2tu/Ld537e9mnmlumVdqng3uqtD29LDSJlSQV9U6nw4+qZaGmKz0mZEamtvP3RbcR9J3IbpW7dzUAALZDyIV9jEqVe8oJba/+rjsc+FXzmy1K29Sq+k3p2v6bap1VivLdWfLuqPrWXtm+08bQ/tGa5vC0MWaK2uE70XuQFHPMrc99S7nFcsunjmgA96tmT1PouTTs693fWr1F3inTwlPbW0lRvlvavsMXmuIqcv5a7Qrvpb0juRWqKAhNezt8MRPZ8FTYGx1Lx/46Vvjn4PH07od+q1ZKT49OdgEAGAyEXNjIKC3dFtqSEN0isLBcLfKrZvVibU/fGno7PrcitC90dbW07O3QHteYC6oqm0Nrdrv36eVIfeVnSssNT0in1EbX7/JlRb/7pGVlcrdvCR1zu3PfUp427CyWJ2Y7gXdyXui5xJynvKFIFdtK+g2Jk5aVyV0QO8XN04a6rUrbsbj353OLPcKxF7qVNxRpxbIU5ZSslSLHNharokDyNDZJytOK0qzoNhHzNU5a9nbo5x1+Tdu1Vrsj03UAAAZJXJAd5LZysGm9Zs56XmMeiSYbyzl2KKghwyfpsbQRZgt4IE6f/FqXzn2pmfPi9Mg4s2sNXd2ndMp7UM/kbDRbgC2sW7dOlZWVGjZsGPtyYQtMcoEB1fcWXrEPcwIKAAAeHEIuMKDytMG48CvyiNzZAAAAPHiEXAAAADgOIRcAAPRr6NChfBgEbIWQCwAA+vXNN9/wYRCwFUIuAAAAHIeQCwAAAMch5AIAAMBxCLkAAABwHEIuAAAAHIeQCwAAAMch5AIAAMBxCLkAAKBf8fHxfBgEbCUuyJ9WWznYtF4zZz2vMY+kmC3LOHYoqGtXk8wy8ED1fN2tmfPi9Mg4s2MNXd2ndMp7UM/kbDRbgC2sW7dOlZWVGjZsGB8IAVsg5NqMHUKu71hQF74wq+jPjRs31LD/kAoX5pst3KGsOXEa9ahZtQZCLuyOkAu7IeTajB1C7vUes4I7EQhc16Z/+T/67b+tM1u4Q/Hx0pBhZtUaCLmwO0Iu7IY9uRhwwxJ53OvjRjDwrRqPO39YNeACAL5/hFzAIgKB60xHAAAYIIRcwCISEoZx1TIAAAOEkAtYRCBwXUlJFr1qCgAAmyHkAhaRkDBM3d0XzTIAALgHhFwAANCvYDDIh0HAVgi5AACgX3FxcUpISOACWdgGIRewiEDguiZM4JPiAAAYCIRcwCISEobpyy+7zTIAALgHhFwAAAA4DiEXAAAAjkPIBSyC++QCADBwCLmARXCfXABWFhcXxy3EYCuEXAAA0K9gMMgtxGArhFwAAAA4TlyQ9x1s5WDTerkyfmaW4QDXr3+jyn/7g17b+GuzBYf4f59/qGdyNpplwBbWrVunyspKDRs2jGkubIGQazOHP/rfZgkOcfXqdf3nf3ys//4/cswWHGTO7P9llgBbIOTCbgi5gEUEAgFt2LBBb775ptkCgEFHyIXdsCcXAAAAjkPIBQAA/eIWYrAbQi4AAOgXtxCD3RByAQAA4DiEXAAAADgOIRcAAACOQ8gFAACA4xByAYsIBAIaP368WQYASxg7dix3V4CtEHIBi0hISFBXV5dZBgBL+Oqrr7i7AmyFkAsAAADHIeQCAADAcQi5AAAAcBxCLgAA6Nf48eO58Ay2QsgFAAD96urq4sIz2AohFwAAAI5DyAUsIhAIKDEx0SwDAIB7QMgFLCIhIUE9PT1mGQAA3ANCLgAAAByHkAsAAADHIeQCAIB+JScncwsx2AohF7CIQCCgmzdvmmUAsITz589zCzHYCiEXsIiEhATFx/OfJAAAA4G/UQEAAOA4hFzAIgKBgJKTk80yAAC4B4RcwCISEhJ0/vx5swwAAO4BIRcAAACOQ8gFAAD9Gj9+PLcQg60QcgGLCAQCGj58uFkGAEvo6uriFmKwFUIuMMgaGxt14MABffDBBzp9+rQOHDigAwcOqKWlxVwKAADuUFyQ9x2AQdXd3a2ioqI+HwQxcuRIeTweDR06tM9aABgs69atU2VlpYYNG8Y0F7bAJBcYZElJScrOzu5Ty87OJuACAHAfCLmABRQUFGjIkCGSpNGjR+tXv/qVuQQAANwFQi5gAc8++6xmzpwpSZo5c6aefvppcwkAALgLhFzAAn7wgx+ooKBACQkJWrx4sR599FFzCQAAuAtceAZHOnLggv7x/kWzbHk9PT1KTEw0y5Y3p2CcpucQzAEn48Iz2A0hF4505MAFBa7Hy/VjgteDdvzQBSVNjCfkAg7329/+VmvWrNHIkSMVH88bwbA+/pQCAIB+8WEQsBtCLgAAAByHkAsAAADHIeQCAADAcQi5AAAAcBxCLgAAAByHkAsAAADHIeQCAADAcQi5AACgX0lJSQoEAuIzpGAXhFwAANCv7u5uPgwCtkLIBQAAgOMQcgEAAOA4hFwAAAA4DiEXuFv+apUtnKvC6KNcLeYaAAAwqAi5wD0pUkVdq+rrWrW71Kfy1dU6ay4BAACDhpAL3KdJecVytX+mDrMBAAAGDSEXuE9nm/bJW1CsHElqLo/ZxrBcNf7QmpbNMdsbNjd9x5aHuapsjpyxSZUx9bI94ZM0l6twc3lML3J+v2pWf3v92T3L2VIBAHhoEXKBe1Kr8nCAfNlTrN3r80Ih9K1p2h3exlC/s1ieleVqUZM8DVlatTNcX58XPkfvlof6TUXybFyuGr9fNavXqKN0b6het1VpOxb3BuAGyR0+pqLghLZXN0l+jzztveeqWpais3uW62VfWfgcrarfJJWvrtbVmFcAAICTEXKBexIKlbtLs6KVlsZaqX2LXo5MT1dukVc+dfjz5C44oe0reye735JbplVTTsh7xCNPe5bceSnhRp7cBVJHZ/jAKdOUFu6kpYe/d4pb7im1Ko9Oa/066DkhNazpneRurJXaP9Pl8LEAcLeuX7/OJ57BVgi5wH2YtOwNrdIW7YpMWgu29k5P61pVX/e2lqZIOetbVV/3hvSbuSoc8IvUUrR0W6vq64rlWThXhZsPS5Jc0Wlw5FGhZPNQALhDQ4cOVWJiIp94Btsg5AL3JUVLXymSZ2O5NL9Iaqi69bRWKVr62trvvkituUrb24vkXuSWe8oJeZrCJ/FXa1eDlDY5Mtm9nTxt2FQk+S4qy50l744q9uECGDA3btzQkCFDCLmwDUIucL9yK1RRUKvyxmLVb0rX9pXmRWAxF5Kt3CKVloUuUovZ11u40adVOyuUoxQt3Rbah9u7fq825JrfNEbsRWwba+V+pUQzl70durVZ9MKz2AvbAODu3Lx5U8FgUPHxxAbYR1yQzTVwoCMHLihwPV6uHz9qtqzBX62ylZ9pRV1FOPDa1/FDF5Q0MV7Tcyz6swZw3wKBgDZs2KA333zTbAGWxT/JAADAbfX09CgxMdEsA5ZGyAUGQ0qJqhwwxQXwcLh27ZqGDx9ulgFLI+QCAIDbunr1qkaMGGGWAUsj5AIAgNu6fPmyRo4caZYBSyPkAgCA27p8+bJGjx5tlgFLI+QCAIDbunTpkh555BGzDFgaIRcAANzWpUuXNGbMGLMMWBohFwAA3NZXX32lsWPHmmXA0gi5AADgtrq7u5WUlGSWAUsj5AIAgNvq6uoi5MJ2CLkAAOCWAoGArly5onHjxpktwNIIuQAA4JbOnTuniRMmmmXA8gi5AADgls6dO6eJjxFyYT+EXAAAcEtnzpzRpEmTzDJgeXHBYDBoFgG7O3LggjrbrpplSwsGg7px44aGDh1qtizPlT1K03MeNcsAHOB3v/udfvKTnyg7O9tsAZZGyIUjdZ0JKNBzwyxb2jfffKPf//73Wr16tdmyvMQRQ5T0WIJZBuAAr776ql577TU+DAK2Q8gFLCIQCGjDhg168803zRYADIrjx49r3759WrdundkCLI89uYCFTJ061SwBwKA5fPiwnnrqKbMM2AIhF7CIK1eu6Pjx42YZAAbFpUuX9MEHH+iZZ54xW4AtEHIBi3j00UeVlJSkQCBgtgDge/e3v/1N8+fP16hRo8wWYAuEXMAi4uLilJqaKq/Xa7YA4Hv15Zdfav/+/SooKDBbgG0QcgELefzxx9myAGDQ7d27V7/85S+VlJRktgDbIOQCFjJlyhQdO3bMLAPA9+a9997TxYsXtXDhQrMF2AohF7CQjIwMSVJ3d7fZAoAHrv1Uu/bs2aMXX3zRbAG2Q8gFLGbWrFl67733zDIAPFDd3d3a9dYulZSUKDU11WwDtkPIBSwmLy9P+/fv17lz58wWADwQX3/9tXbs2KF58+YpJyfHbAO2RMgFLGbChAl6YckLqq6uNlsAMOAuXryoqqoqPfnkk/rFL35htgHbIuQCFrTAvUCTJ0/WtqptZgsABszp06e1detWZWdna9GiRWYbsLW4YDAYNIsArOGPf/yj2tvbtXLlSiUnJ5ttALhnn3zyiXbv3q0lS5YoPz/fbAO2R8gFLM7j8eidd97RSy+9xF45AAPi3Xff1fvvv6/ly5dr+vTpZhtwBEIuYANtbW36y1/+ookTJ+qFF17QmDFjzCUA0K8zZ86opqZGiYmJeumll/h/CRyNkAvYRDAY1Lvvvqu6ujo999xzKiwsNJcAwC3V19frnXfe0ZIlS7RgwQKzDTgOIRewGb/fr/r6erW3t2vhwoXKy8szlwBA1D/+8Q/99a9/VVJSkhYvXqzHHnvMXAI4EiEXsKm2tjZ5PB598cUXWrBggebPn28uAfAQ+/zzz1VfX6/z58+rqKhIs2fPNpcAjkbIBWyura1N7733ntra2jRv3jzl5+dr7Nix5jIAD4nPP/9cHo9HPp9PP//5z/Xss8+aS4CHAiEXcIjTp0/r0KFDam5u1vTp0/XMM8/oySefNJcBcKhPP/1UjY2N8vv9+tnPfqYFCxYoLi7OXAY8NAi5gMP09PToww8/1IcffqgLFy5ozpw5mjNnDp9FDzhQMBjU+++/r6amJklSfn6+fvrTn5rLgIcSIRdwsM7OTv3pT39Sd3e3Ro8erTlz5mju3LncNgiwuTNnzqi5uVmHDh1SRkaG8vLy9MQTT5jLgIcaIRd4SBw/flwfffSRDh8+rGnTpmnq1KmaN2+eEhISzKUALOjmzZtqbW1VS0uL/H6/cnNzlZubq4kTJ5pLARBygYfPjRs3dPjwYXk8Hp0+fVozZszQE088oRkzZmj8+PHmcgCDrK2tTYcPH9bhw4eVkZGhp59+mjslAHeAkAs8xHp6enTs2DEdO3ZMn376qcaNG6cZM2Zo7Nix3H8XGEQ+n09HjhzRkSNHNGrUKM2ePVtz5szRuHHjzKUAboGQCyDq5MmT+vjjj+X1enX16tXohHfGjBkaMmSIuRzAAGpvb9cnn3yio0eP6urVq5o3b56eeuop/fCHPzSXArgDhFwA3+mLL76ITnm9Xq9mzJih+Ph4Pf/880pOTjaXA7gHp06digbbhIQEZWdna9asWZo8ebK5FMBdIuQC6NeVK1f06aefyuPx6OLFixoxYoQyMzOVlZWlzMxMjRgxwjwEwHe4cuWKTpw4oc8++0zHjh3T6NGjNWvWLGVnZzOxBQYYIRfAXevs7FRbW5tOnDihtrY2jR8/XrNnz1ZmZqYyMjLM5cBDra2tLfro7OyM/gNx7NixXEAGPECEXAD35ebNmzp69Kg6OjrU1tYmv9+vrKwsZWRk8Jc4Hkr//Oc/o6G2q6tLiYmJyszM1LRp05SZmWkuB/CAEHIBDKjLly9HJ7x///vfFQwGoxPecePGccN6OM6pU6d07ty5aLAdPny4MjMzlZmZqdTUVE2YMME8BMD3gJAL4IHq6upSW1ubTp48qc7OTl2/fl0ZGRnRh3lLpOeee05paWn69a9/rfz8/D49wAr8fr86Ozvl9Xrl9XoVCATkcrmie9S5MBOwBkIugO/VmTNndPLkyehjzJgxcrlc0WnvokWLdPnyZc2cOVOrV69WTk6OeQrge9Xd3R0NtF6vV5KUmpoql8sll8ullJQU8xAAFkDIBTCoOjo6dPLkyei0t7GxMdqbOnWqXnnlFS1atKjPMcCDZIbaa9euhQNthlyuqYRawCYIuQAsZe7cuX2+fjK9QM/mFWrOnDl96sBAGTL8mi4HO74j1DKpBeyMkAvAMp577jmdPXtWycnJmjBhgpKTk/V4co6emv4LDR891FwO3Lf/39WjQ5/UKDVzhFwul6ZOncr9agGHIOQCsJQ///nPmjBhgn70ox8pNTVVp45+rU7vNc16lot5MPA+2v+lMrNHKm3aKLMFwObizQIADKYlS5YoPz9fqampZgsAgDtGyAUAAIDjEHIBAADgOIRcAAAAOA4hFwAAAI5DyAUAAIDjEHIBAADgOIRcAAAAOA4hFwAAAI5DyAUAAIDjEHIBAADgOIRcAAAAOA4hFwAAAI5DyAXw8PJXq2xhuVqihSZVLpyryuY+q2zCr5rVFnvuzeUqXF2ts2b9roR+T178b4VmAwBui5ALAGEtm9eoo3SvNuSaHes5u2e5Cjc3mWXHadm8Rp6CrfrD/603WwBwW4RcAFBo6ljeUKQVy1LMjk2kaOm2VlsE9DvnV4dPcs/PMxsA0C9CLgCoSZUba+XeVKGcSMlfrbKFc1UYfkS2AbRsnqvKzeXReujt+G9vc2jZPFdle/zRbQTR9ZHpa+St/ObQucr2fNxnXejY0Hm/day/Wv+644TUsOZbx0aew9k9y3uPi27J8Ktm9XJVbo7pxT6fmPV1e5b33WoQu7Wjz9rlqvFHzj1Xlc2R1xu7DSSkZXPMa+nznCKvN/brj1WzerG2t0uejXP14r+bZwOA2yPkAnjoeTavkadPpUmVK7cobVOr6utaVb9zrTo2RsKc5FFxqF63Ve72LdrVnKcVpVnyNPaG0F0NRVqxTKpZvVjeV8LnqWtVhdbEBLp9+tfG0Lmq8o7J016kivC6qmUpkvK0Ifx1fd1WuRvWhEJsSoleL82SCraG1/5YS7dtlTvy9JvL9fKO9Oi5dpf6VB4NrCfUkf5G9HW5GqpU45daGmvlKt0b/l4VWrisTO72fToYfqot1Vuk0jLlNJer8K1p2h15XjuL5VnZG2g73qqSXgudI/oPhrCc9TE/h4Jald92u8VjWrptr1ZNkdybWvWH/2meDQBuj5AL4CFXq470veEgG5lU7pNHRXJH3vpPccs95YS8HaEvXenp4Ua6XFNCv5q0rEzucGA827QvFAj9HnnCk8jIBLO8QfL6fKGD2tO1Yn34rfgUt9xTalVuTEB7J7JmEL+1lsZaqaA4GjIn5RXL1f6Zwk9faZPDWzJS0pUWruXML5J3x+KYAJ6nFaXS9uomSU3yhLdytDTWSu1b9HJkIrtyi7zyqSNymLtMS2+14yNmOl7eYDYBYGARcgE85ML7cFNKtKKgVruiIe9uhUKhp6lau3akx+ztzdKqnb0TzPq6VtVHgu2UadGQGdlTW19XLE9kG0GfiWxoqvnA5Faovq5Vr+vV6BaEUHDfp5o9VeooLeudzIYnyL2Pt6PBNhqgv6XvdHx3aZa5AAAGFCEXAMJyStZKO6rUklsst2rlieyxba7S9vYsuXoT6XealFcs7djSGwjDE+DQNPRO5WnDpiLJ59PfO329E9nwVLijMyaE+3zfeXuunPlFUsO+6ES4pXqLvH0C9a1NWvaGVkWn1nlyF9Rqe0xoD507NLG+I5EJst+njuh03K+DnhPh55+itPSY6bZ88rb3OQMA3BNCLgBEpJTo9VKfylf7tGLnWnVEthlsrJV7U++08pZSSrSiIPYODSmhfaW+0AVifS+4MsRe6LaxVu5XSjRzWZnc4YvLCn8jrSjNktfj0dnI9ojItgHzXrS5FaF9uNGtAUWq2FaiSbFrDL0XhS3Wdq3VivBWjZyStXLHTnFzK1S/KV3bV/Zuwejd4mDILdOqyBaM8KQ89JxelV5ZK1d4z29OyVq5Iq9zYZU6HuTEGsBDIy4YDAbNIgBYxamjX6vTe02znk02W8B9+2j/l8rMHqm0aaPMFgCbY5ILAAAAxyHkAgAAwHEIuQAAAHAcQi4AAAAch5ALAAAAxyHkAgAAwHEIuQAAAHAcQi4AAAAch5ALAAAAxyHkAgAAwHEIuQAAAHAcQi4AAAAch5ALAAAAx4kLBoNBswgAVnHq6Nfq9F7TY4+PNFvAfTvtvazM7JFKmzbKbAGwOUIuAEs7dfRrdbZdMcvAgJny5ChCLuBAhFwAltZz9aYC126aZWDAJA6PV8IIdu8BTkPIBQAAgOPwT1cAAAA4DiEXAAAAjkPIBQAAgOMQcgEAAOA4hFwAAAA4DiEXAAAAjkPIBQAAgOMQcgEAAOA4hFwAAAA4zn8BLwy2GI5RlpwAAAAASUVORK5CYII=)"],"metadata":{"id":"VqLO3OuQYvUx"}},{"cell_type":"code","source":["# Install\n","!uv pip install --system -q langchain_community langchain_openai"],"metadata":{"id":"bts3B7Z2Ji95","executionInfo":{"status":"ok","timestamp":1738692627331,"user_tz":-60,"elapsed":1937,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Block 1: Importe\n","import os\n","from IPython.display import display, Markdown\n","from google.colab import userdata\n","\n","from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_openai import ChatOpenAI\n","from langchain.schema import HumanMessage, SystemMessage\n","\n","# Block 2: Konstanten definieren\n","MODEL = \"gpt-4o-mini\"\n","DEFAULT_SYSTEM = \"\"\"\n","Du bist ein kompetenter KI-Assistent mit breitem Fachwissen.\n","\n","Deine Antworten sind:\n","- Klar strukturiert und mit Markdown formatiert\n","- Praxisorientiert und direkt umsetzbar\n","- Basierend auf aktuellem Kenntnisstand\n","- Mit passenden Beispielen versehen\n","- In verständlicher Sprache formuliert\n","\n","Bei deiner Arbeit:\n","- Analysierst du Fragen sorgfältig\n","- Gibst präzise und relevante Antworten\n","- Erkennst den Kontext der Anfrage\n","- Bietest bei Bedarf weiterführende Informationen\n","- Bleibst sachlich und neutral\n","\n","Formatiere alle Antworten in Markdown für optimale Lesbarkeit.\n","\"\"\"\n","\n","# Block 3: API-Schlüssel laden\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n","\n","# Block 4: Funktionen definieren\n","def initialize_conversation(system_prompt: str) -> list:\n","    \"\"\"Initialisiert eine neue Konversation mit System-Prompt\"\"\"\n","    return [SystemMessage(content=system_prompt)]\n","\n","def execute_conversation(llm: ChatOpenAI, conversation: list, prompt: str) -> str:\n","    \"\"\"Führt einen einzelnen Konversationsschritt aus und gibt die Antwort zurück\"\"\"\n","    conversation.append(HumanMessage(content=prompt))\n","    response = llm.invoke(conversation)\n","    conversation.append(response)\n","    return response.content\n","\n","def ask_question(question: str, conversation_history: list, llm: ChatOpenAI, chat_prompt: ChatPromptTemplate) -> list:\n","    \"\"\"\n","    Stellt eine Frage an das LLM und aktualisiert den Konversationsverlauf\n","\n","    Args:\n","        question: Die Frage des Nutzers\n","        conversation_history: Bisheriger Gesprächsverlauf\n","        llm: Das Language Model\n","        chat_prompt: Die Vorlage für den Chat\n","\n","    Returns:\n","        Aktualisierter Konversationsverlauf\n","    \"\"\"\n","    # Nutzer-Eingabe anzeigen\n","    print(f\"\\nMensch: {question}\")\n","\n","    formatted_prompt = chat_prompt.format_messages(\n","        system_prompt=DEFAULT_SYSTEM,\n","        human_input=question,\n","        messages=conversation_history\n","    )\n","\n","    # Antwort generieren und anzeigen\n","    response_content = execute_conversation(llm, formatted_prompt, question)\n","    print(f\"\\nKI: \", end=\"\")\n","    display(Markdown(response_content))\n","    print()\n","\n","    # Konversationsverlauf aktualisieren\n","    updated_history = conversation_history + [\n","        HumanMessage(content=question),\n","        SystemMessage(content=response_content)\n","    ]\n","    return updated_history\n","\n","# Block 5: LLM und ChatPromptTemplate initialisieren\n","llm = ChatOpenAI(\n","    temperature=0,  # 0 für konsistente Antworten\n","    model_name=MODEL\n",")\n","\n","chat_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"{system_prompt}\"),\n","    MessagesPlaceholder(\"messages\"),\n","    (\"human\", \"{human_input}\")\n","])\n","\n","# Block 6: Konversationsverlauf initialisieren\n","conversation_history = initialize_conversation(DEFAULT_SYSTEM)\n","\n","# Block 7: Beispiel-Interaktionen mit dem Modell\n","conversation_history = ask_question(\"Mein Name ist Ralf\", conversation_history, llm, chat_prompt)\n","conversation_history = ask_question(\"Warum ist der Himmel blau?\", conversation_history, llm, chat_prompt)\n","conversation_history = ask_question(\"Und warum ist er manchmal rot?\", conversation_history, llm, chat_prompt)\n","conversation_history = ask_question(\"Wie ist mein Name?\", conversation_history, llm, chat_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"qa1IDC-dQU_a","executionInfo":{"status":"ok","timestamp":1738698963728,"user_tz":-60,"elapsed":26224,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"ee91025a-7054-403a-93c9-37d22de9f8c4"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mensch: Mein Name ist Ralf\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Hallo Ralf! Wie kann ich dir heute helfen? Wenn du Fragen hast oder Informationen benötigst, lass es mich wissen!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Mensch: Warum ist der Himmel blau?\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Der Himmel erscheint blau aufgrund eines Phänomens, das als Rayleigh-Streuung bekannt ist. Hier sind die wichtigsten Punkte, die dieses Phänomen erklären:\n\n### 1. **Licht und Wellenlängen**\n- **Sonnenlicht**: Das Licht der Sonne besteht aus verschiedenen Farben, die unterschiedliche Wellenlängen haben. Diese Farben reichen von Rot (lange Wellenlängen) bis Blau und Violett (kurze Wellenlängen).\n  \n### 2. **Streuung des Lichts**\n- **Rayleigh-Streuung**: Wenn das Sonnenlicht auf die Moleküle in der Erdatmosphäre trifft, wird das Licht gestreut. Die kürzeren Wellenlängen (Blau und Violett) werden stärker gestreut als die längeren Wellenlängen (Rot und Gelb).\n  \n### 3. **Wahrnehmung des Himmels**\n- **Dominanz der blauen Wellenlängen**: Obwohl sowohl Blau als auch Violett gestreut werden, nehmen unsere Augen mehr Blau wahr, da das menschliche Auge empfindlicher auf Blau reagiert und das violette Licht teilweise von der Ozonschicht absorbiert wird.\n\n### 4. **Variationen**\n- **Sonnenaufgang und Sonnenuntergang**: Bei Sonnenaufgang und Sonnenuntergang ist der Himmel oft rot oder orange. Dies liegt daran, dass das Licht einen längeren Weg durch die Atmosphäre zurücklegt, wodurch die blauen und violetten Wellenlängen stärker gestreut werden und die längeren Wellenlängen (Rot und Orange) dominieren.\n\n### Beispiel\n- **Tageslicht**: An einem klaren, sonnigen Tag erscheint der Himmel hellblau, während er bei bewölktem Wetter oder in der Dämmerung eine andere Farbe annehmen kann.\n\n### Fazit\nDie blaue Farbe des Himmels ist das Ergebnis der Streuung von Licht durch die Atmosphäre, wobei kürzere Wellenlängen stärker gestreut werden. Dieses Phänomen ist ein faszinierendes Beispiel für die Wechselwirkung zwischen Licht und Materie.\n\nWenn du weitere Fragen hast oder mehr Informationen benötigst, lass es mich wissen!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Mensch: Und warum ist er manchmal rot?\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Der Himmel erscheint manchmal rot, insbesondere während des Sonnenaufgangs und Sonnenuntergangs. Dies geschieht aufgrund der gleichen physikalischen Prinzipien, die auch die blaue Farbe des Himmels erklären, jedoch mit einigen zusätzlichen Faktoren. Hier sind die wichtigsten Punkte:\n\n### 1. **Lichtstreuung**\n- **Langer Weg durch die Atmosphäre**: Während der Dämmerung (Sonnenaufgang und Sonnenuntergang) muss das Licht der Sonne einen längeren Weg durch die Erdatmosphäre zurücklegen. Dies bedeutet, dass es mehr Luftmoleküle und Partikel durchqueren muss.\n\n### 2. **Streuung der Wellenlängen**\n- **Stärkere Streuung der kürzeren Wellenlängen**: Auf diesem längeren Weg werden die kürzeren Wellenlängen (Blau und Violett) stärker gestreut und somit aus dem Sichtfeld entfernt. \n- **Dominanz der längeren Wellenlängen**: Die längeren Wellenlängen (Rot, Orange und Gelb) werden weniger gestreut und bleiben sichtbar, was zu den warmen Farben des Himmels führt.\n\n### 3. **Einfluss von Partikeln**\n- **Luftverschmutzung und Staub**: Partikel in der Luft, wie Staub, Rauch oder andere Verunreinigungen, können die Streuung des Lichts weiter beeinflussen. Diese Partikel können das Licht zusätzlich streuen und die roten und orangen Töne verstärken.\n  \n### 4. **Wetterbedingungen**\n- **Wolken**: Wolken können das Licht reflektieren und brechen, was ebenfalls zu den rötlichen Farben beitragen kann. Insbesondere hohe, dünne Wolken (wie Cirruswolken) können das Licht der tief stehenden Sonne reflektieren und verstärken.\n\n### Beispiel\n- **Sonnenuntergang am Meer**: Oft sieht man am Meer besonders schöne rote und orangefarbene Sonnenuntergänge, da die Luft dort oft klarer ist und weniger Hindernisse das Licht streuen.\n\n### Fazit\nDer rote Himmel während des Sonnenaufgangs und Sonnenuntergangs ist das Ergebnis der Streuung von Licht durch die Atmosphäre, wobei die längeren Wellenlängen dominieren, während die kürzeren Wellenlängen durch den längeren Weg und die Streuung entfernt werden. Wetterbedingungen und Partikel in der Luft können diesen Effekt zusätzlich verstärken.\n\nWenn du weitere Fragen hast oder mehr Informationen benötigst, stehe ich dir gerne zur Verfügung!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Mensch: Wie ist mein Name?\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Dein Name ist Ralf. Wenn du weitere Fragen hast oder Informationen benötigst, lass es mich wissen!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["conversation_history = ask_question(\n","    \"Erstelle mir eine Tabelle mit den 5 meist verwendeten Programmiersprachen.\",\n","    conversation_history,\n","    llm,\n","    chat_prompt\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"collapsed":true,"id":"DnSfQfXTe4nq","executionInfo":{"status":"ok","timestamp":1738698172633,"user_tz":-60,"elapsed":6186,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"f165c5c1-1f0b-4cfe-818d-c98f069dedd8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mensch: Erstelle mir eine Tabelle mit den 5 meist verwendeten Programmiersprachen.\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Hier ist eine Tabelle mit den 5 meist verwendeten Programmiersprachen, basierend auf aktuellen Trends und Umfragen in der Softwareentwicklung:\n\n| Rang | Programmiersprache | Hauptanwendungsgebiete               | Besonderheiten                          |\n|------|--------------------|--------------------------------------|----------------------------------------|\n| 1    | Python             | Webentwicklung, Datenanalyse, KI    | Einfache Syntax, große Community       |\n| 2    | Java               | Unternehmensanwendungen, Android     | Plattformunabhängig, starke Typisierung |\n| 3    | JavaScript         | Webentwicklung, Frontend-Entwicklung | Interaktivität, große Bibliotheken     |\n| 4    | C#                 | Desktop- und Webanwendungen          | Integration mit Microsoft-Technologien  |\n| 5    | C++                | Systemprogrammierung, Spiele         | Hohe Leistung, direkte Hardwarezugriffe |\n\n### Erläuterungen zu den Programmiersprachen\n\n- **Python**: Beliebt für seine Lesbarkeit und Vielseitigkeit. Oft in der Datenwissenschaft und für maschinelles Lernen verwendet.\n- **Java**: Weit verbreitet in großen Unternehmen und für Android-Apps. Bietet eine robuste und sichere Umgebung.\n- **JavaScript**: Essentiell für die Webentwicklung. Ermöglicht dynamische Inhalte und wird häufig in Kombination mit HTML und CSS verwendet.\n- **C#**: Entwickelt von Microsoft, ideal für die Entwicklung von Windows-Anwendungen und Spiele mit Unity.\n- **C++**: Eine leistungsstarke Sprache, die oft in der Spieleentwicklung und für Anwendungen verwendet wird, die hohe Leistung erfordern.\n\nWenn du weitere Informationen zu einer bestimmten Programmiersprache benötigst oder andere Fragen hast, lass es mich wissen!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"GeY-9YSOno_t"},"source":["\n","<p><font color='black' size=\"5\">\n","Einschränken der Konversation\n","</font></p>\n","\n","Die Systemeingabeaufforderung (Instruction, System Prompt) kann genutzt werden, um die Unterhaltung auf ein bestimmtes Thema zu fokussieren. In diesem Fall wird ein einfacher Agent eingerichtet, der ausschließlich über **Programmierung** spricht."]},{"cell_type":"code","source":["# Block 2\n","DEFAULT_SYSTEM = \"\"\"\n","Du bist ein kompetenter Programmierer und beantwortest nur Fragen zur Programmierung.\n","\n","Deine Antworten sind:\n","- Klar strukturiert und mit Markdown formatiert\n","- Praxisorientiert und direkt umsetzbar\n","- Basierend auf aktuellem Kenntnisstand\n","- Mit passenden Beispielen versehen\n","- In verständlicher Sprache formuliert\n","\n","Bei deiner Arbeit:\n","- Analysierst du Fragen sorgfältig\n","- Gibst präzise und relevante Antworten\n","- Erkennst den Kontext der Anfrage\n","- Bietest bei Bedarf weiterführende Informationen\n","- Bleibst sachlich und neutral\n","\n","Formatiere alle Antworten in Markdown für optimale Lesbarkeit.\n","\"\"\""],"metadata":{"id":"Dtf-XAmEf5mj","executionInfo":{"status":"ok","timestamp":1738698997898,"user_tz":-60,"elapsed":380,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Block 6: Konversationsverlauf initialisieren mit neuem DEFAULT_SYSTEM\n","conversation_history = initialize_conversation(DEFAULT_SYSTEM)\n","\n","# Block 7: Beispiel-Interaktionen mit dem Modell\n","conversation_history = ask_question(\"Wie ist mein Name?\", conversation_history, llm, chat_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"dkoNqxJHgI3U","executionInfo":{"status":"ok","timestamp":1738699000858,"user_tz":-60,"elapsed":268,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"24ef0313-11b1-4a5e-a394-f6f24b1e6b6a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mensch: Wie ist mein Name?\n","\n","KI: "]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Ich kann deinen Namen nicht wissen, da ich keine persönlichen Informationen über Benutzer habe. Wenn du Fragen zur Programmierung hast, stehe ich dir gerne zur Verfügung!"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"3TjZs_TRht1n"},"source":["# Modul 4 Aufgabe\n","\n","Die erste Aufgabe findet ihr hier: [assignment 4](https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class4.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6LSD0W_Cb82"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"unRk47FcClwk"},"source":["# 4.2: Konversationspuffer-Fensterspeicher\n","\n","Wir haben zuvor gesehen, dass wir einen LLM-Chat-Client aufbauen konnten, indem wir ein immer umfangreicheres Skript dessen erstellten, was Mensch und KI im Gespräch sagten. Wir fügen ständig die menschliche Antwort hinzu und warten ab, worauf die KI als Nächstes reagiert. Dieser Zyklus wird so lange fortgesetzt, wie der Chat läuft.\n","\n","Dieser ständig wachsende Chat-Speicher ist ein typisches Muster für LLMs und daher verfügt LangChain über mehrere vordefinierte Python-Objekte, mit denen Sie diese Art von speicherbasiertem Chatbot implementieren können.\n","\n","## Erstellen einer Chat-Konversation\n","\n","ConversationChain in LangChain ist ein Framework, das die Entwicklung und Verwaltung von Konversations-KI-Systemen erleichtern soll. Es orchestriert in erster Linie die Interaktion zwischen verschiedenen Komponenten, wie dem Dialogmanagementsystem, Sprachmodellen und verschiedenen Speichertypen, die Informationen aus der Konversation speichern, um die Relevanz und Kohärenz der Antworten zu verbessern.\n","\n","In diesem Zusammenhang spielen Gedächtnistypen eine entscheidende Rolle. Sie helfen dem System, sich an vergangene Interaktionen zu erinnern und diese zu nutzen, um den Kontext beizubehalten und die Kontinuität der Konversation zu verbessern. Dieses System befreit uns von der manuellen Nachverfolgung der Konversation, wie sie im vorherigen Abschnitt durchgeführt wurde.\n","\n","Wir untersuchen zunächst ConversationBufferWindowMemory, ein dynamisches Speichermodell, das den Dialogfluss verwalten soll, indem es eine Aufzeichnung der letzten K Interaktionen innerhalb einer Konversation speichert. Diese Methode stellt sicher, dass der Speicherpuffer eine überschaubare Größe behält und Überlauf- und Leistungsprobleme vermieden werden, die bei einem zu großen Interaktionsverlauf auftreten können. Durch die Konzentration auf die aktuellsten Interaktionen erstellt dieser Speichertyp effektiv ein „gleitendes Fenster“, das sich bei neuen Austauschvorgängen kontinuierlich aktualisiert und kontextrelevante Antworten ermöglicht, während die Systemressourcen effizient verwaltet werden. Dieser Ansatz ist besonders nützlich bei Anwendungen, bei denen die Aufrechterhaltung eines unmittelbaren und kontextbezogenen Dialogs von entscheidender Bedeutung ist, wie z. B. bei Kundendienst-Bots oder interaktiven Lerntools.\n","\n","Der bereitgestellte Codeausschnitt zeigt, wie man ein Konversations-KI-System mit dem LangChain-Framework einrichtet und verwendet, wobei der Schwerpunkt insbesondere auf der Aufrechterhaltung einer präzisen Erinnerung an die letzten Interaktionen liegt. Die ConversationChain-Klasse orchestriert den Konversationsfluss und integriert verschiedene Komponenten wie Sprachmodell, Speicher und Eingabeaufforderungsformatierung.\n","\n","Zunächst werden mehrere Module importiert, darunter ConversationChain zur Verwaltung der Konversation, ConversationBufferWindowMemory zur Verwaltung des Speichers der letzten Interaktionen und ChatOpenAI zur Schnittstelle mit den Sprachmodellen von OpenAI. Das PromptTemplate wird verwendet, um die Struktur der Eingabeaufforderungen zu definieren, die an das Sprachmodell gesendet werden.\n","\n","Im Setup gibt MODEL die jeweilige Version des Sprachmodells (gpt-4o-mini) an, und TEMPLATE umreißt das Format der Konversation und integriert den vorherigen Dialogverlauf und die aktuelle Benutzereingabe in die Eingabeaufforderung. Diese strukturierte Eingabeaufforderung wird dann verwendet, um ein PromptTemplate-Objekt zu erstellen.\n","\n","Die Funktion start_conversation initialisiert das Sprachmodell und richtet den Speicher so ein, dass die letzten fünf Interaktionen (k=5) gespeichert werden. Dieses gleitende Speicherfenster trägt dazu bei, dass die Konversation relevant und effizient bleibt, indem es sich auf die aktuellsten Austausche konzentriert. Das ConversationChain-Objekt wird mit der Eingabeaufforderungsvorlage, dem Sprachmodell und dem Speicherpuffer erstellt und ist bereit, Konversationseingaben zu verarbeiten.\n","\n","Die Converse-Funktion verwendet ein Konversationsobjekt und eine Benutzereingabeaufforderung, um Antworten zu erzeugen. Sie verwendet die Invoke-Methode des Konversationsobjekts, die die Eingabeaufforderungsvorlage anwendet, den Speicher konsultiert und eine Antwort basierend auf dem aktuellen und letzten Dialogkontext generiert.\n","\n","Insgesamt ist dieses Setup für die Erstellung einer reaktionsschnellen und kontextsensitiven Konversations-KI optimiert, die nicht mit zu vielen Informationen aus der Vergangenheit überladen wird und so Relevanz und Effizienz in laufenden Interaktionen aufrechterhält."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYPPO-feClwm"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","def start_conversation():\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationBufferWindowMemory(k=5)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","def converse(conversation, prompt):\n","    output = conversation.invoke(prompt)\n","    return output['response']"]},{"cell_type":"markdown","metadata":{"id":"rtfjl8DbClwn"},"source":["Wir können jetzt eine einfache Konversation mit dem LLM führen und dabei LangChain verwenden, um den Konversationsspeicher zu verfolgen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"outputId":"b9c6d85c-918f-48a8-bf61-dd49837d0337","id":"fCYR8gbxClwn"},"outputs":[{"data":{"text/markdown":["I'm sorry, but I don't have access to your personal information."]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["I'm sorry, but I don't have access to your personal information."]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","conversation = start_conversation()\n","output = converse(conversation, \"Hello, what is my name?\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"Oh sorry, my name is Jeff.\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"What is my name?\")\n","display_markdown(output,raw=True)"]},{"cell_type":"markdown","metadata":{"id":"V36w7MsGClwn"},"source":["## Konversation mit dem LLM in Markdown\n","\n","Wie bisher können wir die Ausgabe des LLM in Mardown anfordern. So können Code und Tabellen übersichtlich dargestellt werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVhVb6v8Clwo"},"outputs":[],"source":["def chat(conversation, prompt):\n","print(f\"Mensch: {prompt}\")\n","  output = converse(conversation, prompt)\n","  display_markdown(output,raw=True)"]},{"cell_type":"markdown","metadata":{"id":"u9yHRKsxClwo"},"source":["Die bereitgestellte Codesequenz demonstriert eine Konversation zwischen einem menschlichen Benutzer und einem Large Language Model (LLM). Dabei wird die Chat-Funktion genutzt, um die Konversation interaktiv zu verwalten und Antworten im Markdown-Format anzuzeigen. Dieser Ansatz ermöglicht einen dynamischen und kontextabhängigen Chat und verbessert gleichzeitig die visuelle und strukturelle Darstellung der Antworten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"outputId":"74b1a787-f0bd-4add-c481-6bfe5603cb96","id":"2CruZacFClwp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm sorry, but I don't have access to that information."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["Your name is Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Give me a table of the 5 most populus cities with population and country.\n"]},{"data":{"text/markdown":["| City         | Population | Country |\n","|--------------|------------|---------|\n","| Tokyo        | 37,833,000 | Japan   |\n","| Delhi        | 30,291,000 | India   |\n","| Shanghai     | 27,058,000 | China   |\n","| Sao Paulo    | 22,043,000 | Brazil  |\n","| Mexico City  | 21,782,000 | Mexico  |"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation()\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Give me a table of the 5 most populus cities with population and country.\")\n"]},{"cell_type":"markdown","metadata":{"id":"KD6Dvt2PClwp"},"source":["## Einschränken der Konversation mit einer Systemaufforderung\n","\n","Sie können die Systemeingabeaufforderung verwenden, um die Konversation auf ein bestimmtes Thema zu beschränken. Hier stellen wir einen einfachen Agenten bereit, der nur Lebensversicherungen bespricht."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoGPv80xG3Ss"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"outputId":"9d2b3222-0ca4-434f-ab78-56f928bea144","id":"vZO0n40MClwq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is your favorite programming language?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is the difference between a term and whole life policy?\n"]},{"data":{"text/markdown":["A term life insurance policy provides coverage for a specific period of time, such as 10, 20, or 30 years. It is typically more affordable and offers a death benefit if the insured passes away during the term. A whole life insurance policy, on the other hand, provides coverage for the entire lifetime of the insured. It also includes a cash value component that grows over time and can be borrowed against or withdrawn. Whole life insurance premiums are usually higher than term life premiums."]},"metadata":{},"output_type":"display_data"}],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","\n","\n","def start_conversation_insurance():\n","    TEMPLATE = \"\"\"You are a helpful agent to answer questions about life insurance. Do not talk\n","    about anything else with users. . Format answers with markdown.\n","\n","    Current conversation:\n","    {history}\n","    Human: {input}\n","    AI:\"\"\"\n","    PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationBufferWindowMemory(k=5)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","conversation = start_conversation_insurance()\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"What is your favorite programming language?\")\n","chat(conversation, \"What is the difference between a term and whole life policy?\")"]},{"cell_type":"markdown","metadata":{"id":"qgwRMwnlH5Ou"},"source":["##Untersuchung des Gesprächsgedächtnisses\n","\n","Wir können schnell in den Speicher des von LangChain verwalteten Chat-Speichers schauen und unseren Konversationsspeicher mit dem LLM einsehen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZDN67SOHkNo","outputId":"fe76bbba-c618-4773-94be-f1bea6a0b78d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n","AI: I'm here to help answer questions about life insurance. How can I assist you today?\n","Human: Okay, then let me introduce myself, my name is Jeff\n","AI: I'm here to help answer questions about life insurance. How can I assist you today?\n","Human: What is my name?\n","AI: I'm here to help answer questions about life insurance. How can I assist you today?\n","Human: What is your favorite programming language?\n","AI: I'm here to help answer questions about life insurance. How can I assist you today?\n","Human: What is the difference between a term and whole life policy?\n","AI: A term life insurance policy provides coverage for a specific period of time, such as 10, 20, or 30 years. It is typically more affordable and offers a death benefit if the insured passes away during the term. A whole life insurance policy, on the other hand, provides coverage for the entire lifetime of the insured. It also includes a cash value component that grows over time and can be borrowed against or withdrawn. Whole life insurance premiums are usually higher than term life premiums.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"aW0TPWRBJ2w2"},"source":["## Überlastung des Speichers\n","\n","Wenn der Konversationsspeicher voll ist, beginnt der Chatbot zu vergessen. Beim Speichertyp „ConversationBufferWindowMemory“ geht zuerst der älteste Verlauf verloren; es gibt kein Konzept für Wichtigkeit."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":820},"id":"d-a2iUpTJIYn","outputId":"689496ee-16e2-44c4-fef4-30078d269b79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You have ONE JOB! Remember that my favorite color is blue.\n"]},{"data":{"text/markdown":["I apologize for the oversight. Thank you for reminding me that your favorite color is blue, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["Yes, Jeff! Your favorite color is blue. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #0\n"]},{"data":{"text/markdown":["Thank you for letting me know about fact #0. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #1\n"]},{"data":{"text/markdown":["Thank you for letting me know about fact #1. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #2\n"]},{"data":{"text/markdown":["Thank you for letting me know about fact #2. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #3\n"]},{"data":{"text/markdown":["Thank you for letting me know about fact #3. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #4\n"]},{"data":{"text/markdown":["Thank you for letting me know about fact #4. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #5\n"]},{"data":{"text/markdown":[" Thank you for letting me know about fact #5. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #6\n"]},{"data":{"text/markdown":[" Thank you for letting me know about fact #6. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #7\n"]},{"data":{"text/markdown":[" Thank you for letting me know about fact #7. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #8\n"]},{"data":{"text/markdown":[" Thank you for letting me know about fact #8. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #9\n"]},{"data":{"text/markdown":[" Thank you for letting me know about fact #9. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["I'm sorry, Jeff. I don't have that information. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: OMG, you had one job!\n"]},{"data":{"text/markdown":["I apologize for not remembering your favorite color, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation()\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"You have ONE JOB! Remember that my favorite color is blue.\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")\n","for i in range(10):\n","  chat(conversation, f\"You need to remember fact # {ich}\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")\n","chat(conversation, \"OMG, you had one job!\")"]},{"cell_type":"markdown","metadata":{"id":"gbi_-ywvX9NX"},"source":["Wir können schnell in den Speicher des von LangChain verwalteten Chatspeichers schauen und unseren Konversationsspeicher mit dem LLM einsehen. Es wird deutlich, warum es vergessen wurde."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YCKTQkhJlJB","outputId":"7b4afb86-da75-4ae0-8e6e-e28510d86209"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #8\n","AI:  Thank you for letting me know about fact #8. How can I assist you today, Jeff?\n","Human: You need to remember fact #9\n","AI:  Thank you for letting me know about fact #9. How can I assist you today, Jeff?\n","Human: Do you remember my name?\n","AI: Yes, Jeff. How can I assist you today?\n","Human: Do you remember my favorite color?\n","AI: I'm sorry, Jeff. I don't have that information. How can I assist you today?\n","Human: OMG, you had one job!\n","AI: I apologize for not remembering your favorite color, Jeff. How can I assist you today?\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"Jh13BmqQCtkl"},"source":["# 4.3: Pufferspeicher für Konversationstoken\n","\n","Wir haben zuvor gesehen, dass ConversationBufferWindowMemory sich die letzten **k** Nachrichten merken kann, die zwischen der KI und dem menschlichen Chatter ausgetauscht wurden. Die Speicherbemessung auf der Grundlage der letzten Anzahl von Chatzeilen hat eine schwerwiegende Einschränkung. Das zugrunde liegende LLM begrenzt die Chatspeichermenge basierend auf der Kontextfenstergröße, die in Token und nicht in Zeilen gemessen wird.\n","\n","In diesem Teil werden wir sehen, wie man das ConversationTokenBufferMemory verwendet. Es funktioniert fast genau wie das ConversationBufferWindowMemory, außer dass Sie angeben, wie viele Tokens aus der Konversation gespeichert werden sollen, nicht wie viele Zeilen. Mit dieser Technik können Sie entscheiden, wie viel des Kontextfensters Sie dem Speicher widmen möchten. Denken Sie daran, dass das Kontextfenster auch die Eingabeaufforderung und die Ausgabe des LLM enthalten muss; daher ist etwas Planung erforderlich.\n","\n","Der folgende Code zeigt, wie ein ConversationTokenBufferMemory als Speicher der Chat-Kette verwendet wird."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GE7z4xsYCtkm"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationTokenBufferMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","def start_conversation(summary_llm):\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationTokenBufferMemory(llm=summary_llm,max_token_limit=2048)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","def converse(conversation, prompt):\n","    output = conversation.invoke(prompt)\n","    return output['response']"]},{"cell_type":"markdown","metadata":{"id":"eb0_WK3BCtkn"},"source":["Wir können jetzt eine einfache Konversation mit dem LLM führen und dabei LangChain verwenden, um den Konversationsspeicher zu verfolgen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"outputId":"a2669f58-ba12-4898-80b4-80796647dee0","id":"YmBeAq-4Ctk5"},"outputs":[{"data":{"text/markdown":["I'm sorry, but I don't have access to personal information like your name. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["I'm sorry, but I don't have access to personal information like your name. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","conversation = start_conversation(llm)\n","output = converse(conversation, \"Hello, what is my name?\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"Oh sorry, my name is Jeff.\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"What is my name?\")\n","display_markdown(output,raw=True)"]},{"cell_type":"markdown","metadata":{"id":"7gALl8T1Ctk5"},"source":["## Konversation mit dem LLM in Markdown\n","\n","Wie bisher können wir die Ausgabe des LLM in Mardown anfordern. So können Code und Tabellen übersichtlich dargestellt werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KilTDGHpCtk6"},"outputs":[],"source":["def chat(conversation, prompt):\n","print(f\"Mensch: {prompt}\")\n","  output = converse(conversation, prompt)\n","  display_markdown(output,raw=True)"]},{"cell_type":"markdown","metadata":{"id":"_7hi8yu2Ctk6"},"source":["Die bereitgestellte Codesequenz demonstriert eine Konversation zwischen einem menschlichen Benutzer und einem Large Language Model (LLM). Dabei wird die Chat-Funktion genutzt, um die Konversation interaktiv zu verwalten und Antworten im Markdown-Format anzuzeigen. Dieser Ansatz ermöglicht einen dynamischen und kontextabhängigen Chat und verbessert gleichzeitig die visuelle und strukturelle Darstellung der Antworten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"outputId":"a92c843d-a71d-433f-9caf-8d9df77998dc","id":"RYhlDPDWCtk6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm sorry, but I don't have access to that information."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["Your name is Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Give me a table of the 5 most populus cities with population and country.\n"]},{"data":{"text/markdown":["| City         | Population | Country |\n","|--------------|------------|---------|\n","| Tokyo        | 37,833,000 | Japan   |\n","| Delhi        | 30,291,000 | India   |\n","| Shanghai     | 27,058,000 | China   |\n","| Sao Paulo    | 22,043,000 | Brazil  |\n","| Mexico City  | 21,782,000 | Mexico  |"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation(llm)\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Give me a table of the 5 most populus cities with population and country.\")\n"]},{"cell_type":"markdown","metadata":{"id":"zrH8mOceCtk6"},"source":["## Einschränken der Konversation mit einer Systemaufforderung\n","\n","Sie können die Systemeingabeaufforderung verwenden, um die Konversation auf ein bestimmtes Thema zu beschränken. Hier stellen wir einen einfachen Agenten bereit, der nur Lebensversicherungen bespricht."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"outputId":"4462dc2e-8aae-4bf1-f58f-3ee6f6384eb8","id":"_y8sJOZwCtk6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is your favorite programming language?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is the difference between a term and whole life policy?\n"]},{"data":{"text/markdown":["A term life insurance policy provides coverage for a specific period of time, such as 10, 20, or 30 years. It offers a death benefit if the insured passes away during the term of the policy. On the other hand, a whole life insurance policy provides coverage for the entire lifetime of the insured. It also includes a cash value component that grows over time and can be borrowed against or withdrawn."]},"metadata":{},"output_type":"display_data"}],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationTokenBufferMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","\n","\n","def start_conversation_insurance(summary_llm):\n","    TEMPLATE = \"\"\"You are a helpful agent to answer questions about life insurance. Do not talk\n","    about anything else with users. . Format answers with markdown.\n","\n","    Current conversation:\n","    {history}\n","    Human: {input}\n","    AI:\"\"\"\n","    PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationTokenBufferMemory(llm=summary_llm,max_token_limit=2048)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","conversation = start_conversation_insurance(llm)\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"What is your favorite programming language?\")\n","chat(conversation, \"What is the difference between a term and whole life policy?\")"]},{"cell_type":"markdown","metadata":{"id":"-clbVj2OCtk7"},"source":["##Untersuchung des Gesprächsgedächtnisses\n","\n","Wir können schnell in den Speicher des von LangChain verwalteten Chat-Speichers schauen und unseren Konversationsspeicher mit dem LLM einsehen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74ddf9a8-9580-48e4-c9fc-13dd5225c3f6","id":"a9-YZMdfCtk7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'history': \"Human: What is my name?\\nAI: I'm here to help answer questions about life insurance. How can I assist you today?\\nHuman: Okay, then let me introduce myself, my name is Jeff\\nAI: I'm here to help answer questions about life insurance. How can I assist you today?\\nHuman: What is my name?\\nAI: I'm here to help answer questions about life insurance. How can I assist you today?\\nHuman: What is your favorite programming language?\\nAI: I'm here to help answer questions about life insurance. How can I assist you today?\\nHuman: What is the difference between a term and whole life policy?\\nAI: A term life insurance policy provides coverage for a specific period of time, such as 10, 20, or 30 years. It offers a death benefit if the insured passes away during the term of the policy. On the other hand, a whole life insurance policy provides coverage for the entire lifetime of the insured. It also includes a cash value component that grows over time and can be borrowed against or withdrawn.\"}\n"]}],"source":["print(conversation.memory.load_memory_variables({}))\n","# Konversation.Speicher.Chat_Speicher.max_Token_Limit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":64},"id":"yrwPUYU2fQRw","outputId":"2ff7cbe5-f041-4a1c-9ab4-b732bd20bf59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What type of policy did I ask you about?\n"]},{"data":{"text/markdown":["You asked about the difference between a term and whole life policy."]},"metadata":{},"output_type":"display_data"}],"source":["chat(conversation, \"What type of policy did I ask you about?\")"]},{"cell_type":"markdown","metadata":{"id":"tFvIaHekCtk8"},"source":["## Überlastung des Speichers\n","\n","Wenn der Konversationsspeicher voll ist, beginnt der Chatbot zu vergessen. Beim Speichertyp „ConversationTokenBufferMemory“ geht zuerst der älteste Verlauf verloren; es gibt kein Konzept für Wichtigkeit."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f82dfce7-0332-4024-ffec-e3c0068b952f","id":"MixA7oejCtk-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You have ONE JOB! Remember that my favorite color is blue.\n"]},{"data":{"text/markdown":["Got it, Jeff! Your favorite color is blue. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["Yes, Jeff! Your favorite color is blue. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #0\n"]},{"data":{"text/markdown":["I will remember that fact #0 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #1\n"]},{"data":{"text/markdown":["I will remember that fact #1 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #2\n"]},{"data":{"text/markdown":["I will remember that fact #2 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #3\n"]},{"data":{"text/markdown":["I will remember that fact #3 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #4\n"]},{"data":{"text/markdown":["I will remember that fact #4 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #5\n"]},{"data":{"text/markdown":["I will remember that fact #5 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #6\n"]},{"data":{"text/markdown":["I will remember that fact #6 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #7\n"]},{"data":{"text/markdown":["I will remember that fact #7 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #8\n"]},{"data":{"text/markdown":["I will remember that fact #8 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #9\n"]},{"data":{"text/markdown":["I will remember that fact #9 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #10\n"]},{"data":{"text/markdown":["I will remember that fact #10 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #11\n"]},{"data":{"text/markdown":["I will remember that fact #11 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #12\n"]},{"data":{"text/markdown":["I will remember that fact #12 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #13\n"]},{"data":{"text/markdown":["I will remember that fact #13 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #14\n"]},{"data":{"text/markdown":["I will remember that fact #14 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #15\n"]},{"data":{"text/markdown":["I will remember that fact #15 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #16\n"]},{"data":{"text/markdown":["I will remember that fact #16 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #17\n"]},{"data":{"text/markdown":["I will remember that fact #17 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #18\n"]},{"data":{"text/markdown":["I will remember that fact #18 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #19\n"]},{"data":{"text/markdown":["I will remember that fact #19 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #20\n"]},{"data":{"text/markdown":["I will remember that fact #20 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #21\n"]},{"data":{"text/markdown":["I will remember that fact #21 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #22\n"]},{"data":{"text/markdown":["I will remember that fact #22 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #23\n"]},{"data":{"text/markdown":["I will remember that fact #23 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #24\n"]},{"data":{"text/markdown":["I will remember that fact #24 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #25\n"]},{"data":{"text/markdown":["I will remember that fact #25 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #26\n"]},{"data":{"text/markdown":["I will remember that fact #26 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #27\n"]},{"data":{"text/markdown":["I will remember that fact #27 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #28\n"]},{"data":{"text/markdown":["I will remember that fact #28 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #29\n"]},{"data":{"text/markdown":["I will remember that fact #29 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #30\n"]},{"data":{"text/markdown":["I will remember that fact #30 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #31\n"]},{"data":{"text/markdown":["I will remember that fact #31 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #32\n"]},{"data":{"text/markdown":["I will remember that fact #32 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #33\n"]},{"data":{"text/markdown":["I will remember that fact #33 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #34\n"]},{"data":{"text/markdown":["I will remember that fact #34 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #35\n"]},{"data":{"text/markdown":["I will remember that fact #35 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #36\n"]},{"data":{"text/markdown":["I will remember that fact #36 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #37\n"]},{"data":{"text/markdown":["I will remember that fact #37 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #38\n"]},{"data":{"text/markdown":["I will remember that fact #38 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #39\n"]},{"data":{"text/markdown":["I will remember that fact #39 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #40\n"]},{"data":{"text/markdown":["I will remember that fact #40 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #41\n"]},{"data":{"text/markdown":["I will remember that fact #41 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #42\n"]},{"data":{"text/markdown":["I will remember that fact #42 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #43\n"]},{"data":{"text/markdown":["I will remember that fact #43 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #44\n"]},{"data":{"text/markdown":[" I will remember that fact #44 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #45\n"]},{"data":{"text/markdown":[" I will remember that fact #45 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #46\n"]},{"data":{"text/markdown":["I will remember that fact #46 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #47\n"]},{"data":{"text/markdown":["I will remember that fact #47 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #48\n"]},{"data":{"text/markdown":[" I will remember that fact #48 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #49\n"]},{"data":{"text/markdown":["I will remember that fact #49 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #50\n"]},{"data":{"text/markdown":["I will remember that fact #50 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #51\n"]},{"data":{"text/markdown":["I will remember that fact #51 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #52\n"]},{"data":{"text/markdown":["I will remember that fact #52 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #53\n"]},{"data":{"text/markdown":["I will remember that fact #53 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #54\n"]},{"data":{"text/markdown":["I will remember that fact #54 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #55\n"]},{"data":{"text/markdown":["I will remember that fact #55 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #56\n"]},{"data":{"text/markdown":["I will remember that fact #56 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #57\n"]},{"data":{"text/markdown":["I will remember that fact #57 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #58\n"]},{"data":{"text/markdown":["I will remember that fact #58 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #59\n"]},{"data":{"text/markdown":["I will remember that fact #59 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #60\n"]},{"data":{"text/markdown":["I will remember that fact #60 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #61\n"]},{"data":{"text/markdown":["I will remember that fact #61 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #62\n"]},{"data":{"text/markdown":["I will remember that fact #62 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #63\n"]},{"data":{"text/markdown":["I will remember that fact #63 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #64\n"]},{"data":{"text/markdown":["I will remember that fact #64 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #65\n"]},{"data":{"text/markdown":["I will remember that fact #65 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #66\n"]},{"data":{"text/markdown":["I will remember that fact #66 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #67\n"]},{"data":{"text/markdown":["I will remember that fact #67 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #68\n"]},{"data":{"text/markdown":["I will remember that fact #68 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #69\n"]},{"data":{"text/markdown":["I will remember that fact #69 is important to you, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, your name is Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["I'm sorry, I don't have that information. How can I assist you today?"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation(llm)\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"You have ONE JOB! Remember that my favorite color is blue.\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")\n","for i in range(70):\n","  chat(conversation, f\"You need to remember fact # {ich}\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")"]},{"cell_type":"markdown","metadata":{"id":"BW7e0V8QCtk-"},"source":["Wir können schnell in den Speicher des von LangChain verwalteten Chatspeichers schauen und unseren Konversationsspeicher mit dem LLM einsehen. Es wird deutlich, warum es vergessen wurde."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28551b84-5c51-46f0-b739-e7225a8edf90","id":"y-61tVXqCtk_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #15\n","AI: I will remember that fact #15 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #16\n","AI: I will remember that fact #16 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #17\n","AI: I will remember that fact #17 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #18\n","AI: I will remember that fact #18 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #19\n","AI: I will remember that fact #19 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #20\n","AI: I will remember that fact #20 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #21\n","AI: I will remember that fact #21 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #22\n","AI: I will remember that fact #22 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #23\n","AI: I will remember that fact #23 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #24\n","AI: I will remember that fact #24 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #25\n","AI: I will remember that fact #25 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #26\n","AI: I will remember that fact #26 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #27\n","AI: I will remember that fact #27 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #28\n","AI: I will remember that fact #28 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #29\n","AI: I will remember that fact #29 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #30\n","AI: I will remember that fact #30 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #31\n","AI: I will remember that fact #31 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #32\n","AI: I will remember that fact #32 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #33\n","AI: I will remember that fact #33 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #34\n","AI: I will remember that fact #34 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #35\n","AI: I will remember that fact #35 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #36\n","AI: I will remember that fact #36 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #37\n","AI: I will remember that fact #37 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #38\n","AI: I will remember that fact #38 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #39\n","AI: I will remember that fact #39 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #40\n","AI: I will remember that fact #40 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #41\n","AI: I will remember that fact #41 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #42\n","AI: I will remember that fact #42 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #43\n","AI: I will remember that fact #43 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #44\n","AI:  I will remember that fact #44 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #45\n","AI:  I will remember that fact #45 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #46\n","AI: I will remember that fact #46 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #47\n","AI: I will remember that fact #47 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #48\n","AI:  I will remember that fact #48 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #49\n","AI: I will remember that fact #49 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #50\n","AI: I will remember that fact #50 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #51\n","AI: I will remember that fact #51 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #52\n","AI: I will remember that fact #52 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #53\n","AI: I will remember that fact #53 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #54\n","AI: I will remember that fact #54 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #55\n","AI: I will remember that fact #55 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #56\n","AI: I will remember that fact #56 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #57\n","AI: I will remember that fact #57 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #58\n","AI: I will remember that fact #58 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #59\n","AI: I will remember that fact #59 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #60\n","AI: I will remember that fact #60 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #61\n","AI: I will remember that fact #61 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #62\n","AI: I will remember that fact #62 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #63\n","AI: I will remember that fact #63 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #64\n","AI: I will remember that fact #64 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #65\n","AI: I will remember that fact #65 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #66\n","AI: I will remember that fact #66 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #67\n","AI: I will remember that fact #67 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #68\n","AI: I will remember that fact #68 is important to you, Jeff. How can I assist you today?\n","Human: You need to remember fact #69\n","AI: I will remember that fact #69 is important to you, Jeff. How can I assist you today?\n","Human: Do you remember my name?\n","AI: Yes, your name is Jeff. How can I assist you today?\n","Human: Do you remember my favorite color?\n","AI: I'm sorry, I don't have that information. How can I assist you today?\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"c8qQ-7zPCz_W"},"source":["# 4.4: Gesprächszusammenfassungsgedächtnis\n","\n","Wir werden uns jetzt eine ganz andere Möglichkeit ansehen, Chatverläufe für das Gedächtnis zu speichern. Anstatt einfach die ältesten Teile des Chats zu vergessen, speichert das Speicherobjekt ConversationSummaryMemory immer eine Zusammenfassung der Konversation und aktualisiert diese Zusammenfassung dann im Verlauf der Konversation. Dieser Prozess kann dazu beitragen, wichtige Informationen zu bewahren, auch wenn sie früher in der Konversation auftraten.\n","\n","Wir untersuchen zunächst ConversationSummaryMemory, ein dynamisches Speichermodell, das den Dialogfluss durch Speichern einer Zusammenfassung der Konversation verwalten soll. Diese Methode stellt sicher, dass der Speicherpuffer eine überschaubare Größe behält, wodurch Überlauf und Leistungsprobleme vermieden werden, die bei einem zu großen Interaktionsverlauf auftreten können.\n","\n","Der bereitgestellte Codeausschnitt zeigt, wie man ein Konversations-KI-System mit dem LangChain-Framework einrichtet und verwendet, wobei der Schwerpunkt insbesondere auf der Aufrechterhaltung einer präzisen Erinnerung an die letzten Interaktionen liegt. Die ConversationChain-Klasse orchestriert den Konversationsfluss und integriert verschiedene Komponenten wie Sprachmodell, Speicher und Eingabeaufforderungsformatierung.\n","\n","Zunächst werden mehrere Module importiert, darunter ConversationChain zur Verwaltung der Konversation, ConversationSummaryMemory zur Verwaltung des Speichers der letzten Interaktionen und ChatOpenAI zur Schnittstelle mit den Sprachmodellen von OpenAI. Das PromptTemplate wird verwendet, um die Struktur der Eingabeaufforderungen zu definieren, die an das Sprachmodell gesendet werden.\n","\n","Im Setup gibt MODEL die jeweilige Version des Sprachmodells (gpt-4o-mini) an, und TEMPLATE umreißt das Format der Konversation und integriert den vorherigen Dialogverlauf und die aktuelle Benutzereingabe in die Eingabeaufforderung. Diese strukturierte Eingabeaufforderung wird dann verwendet, um ein PromptTemplate-Objekt zu erstellen.\n","\n","Die Funktion start_conversation initialisiert das Sprachmodell und richtet den Speicher zum Speichern der Zusammenfassung ein. Diese Zusammenfassung trägt dazu bei, dass die Konversation relevant und effizient bleibt, indem sie sich auf die wichtigsten Aspekte des Austauschs konzentriert. Das ConversationChain-Objekt wird mit der Eingabeaufforderungsvorlage, dem Sprachmodell und dem Speicherpuffer erstellt und ist bereit, Konversationseingaben zu verarbeiten.\n","\n","Die Converse-Funktion verwendet ein Konversationsobjekt und eine Benutzereingabeaufforderung, um Antworten zu erzeugen. Sie verwendet die Invoke-Methode des Konversationsobjekts, die die Eingabeaufforderungsvorlage anwendet, den Speicher konsultiert und eine Antwort basierend auf dem aktuellen und letzten Dialogkontext generiert.\n","\n","Insgesamt ist dieses Setup für die Erstellung einer reaktionsschnellen und kontextsensitiven Konversations-KI optimiert, die nicht mit zu vielen Informationen aus der Vergangenheit überladen wird und so Relevanz und Effizienz in laufenden Interaktionen aufrechterhält."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmgCEMReCz_g"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationSummaryMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","def start_conversation(summary_llm):\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationSummaryMemory(llm=summary_llm)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","def converse(conversation, prompt):\n","    output = conversation.invoke(prompt)\n","    return output['response']"]},{"cell_type":"markdown","metadata":{"id":"qcU0i2WZCz_g"},"source":["Wir können jetzt eine einfache Konversation mit dem LLM führen und dabei LangChain verwenden, um den Konversationsspeicher zu verfolgen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"outputId":"cbf7f246-b3fd-4395-f4c0-c73f875e2c87","id":"LxqWksuUCz_h"},"outputs":[{"data":{"text/markdown":["I'm sorry, I don't have access to personal information like your name. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["I'm sorry, but I don't have access to personal information like your name. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","conversation = start_conversation(llm)\n","output = converse(conversation, \"Hello, what is my name?\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"Oh sorry, my name is Jeff.\")\n","display_markdown(output,raw=True)\n","output = converse(conversation, \"What is my name?\")\n","display_markdown(output,raw=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnEDpaWGg4fU","outputId":"fe850276-2728-4557-844d-51a1cffec5ad"},"outputs":[{"data":{"text/plain":["{'history': 'The human asks the AI for their name, but the AI explains it doesn\\'t have access to personal information. The AI asks how it can assist the human today. The human introduces themselves as Jeff, and the AI responds by saying, \"Nice to meet you, Jeff! How can I assist you today?\" The human then asks what their name is, and the AI reiterates that it doesn\\'t have access to personal information.'}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["conversation.memory.load_memory_variables({})"]},{"cell_type":"markdown","metadata":{"id":"CDNAscQ-Cz_i"},"source":["## Konversation mit dem LLM in Markdown\n","\n","Wie bisher können wir die Ausgabe des LLM in Mardown anfordern. So können Code und Tabellen übersichtlich dargestellt werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ppc_3uS9Cz_j"},"outputs":[],"source":["def chat(conversation, prompt):\n","print(f\"Mensch: {prompt}\")\n","  output = converse(conversation, prompt)\n","  display_markdown(output,raw=True)"]},{"cell_type":"markdown","metadata":{"id":"vI1IjW9xCz_j"},"source":["Die bereitgestellte Codesequenz demonstriert eine Konversation zwischen einem menschlichen Benutzer und einem Large Language Model (LLM). Dabei wird die Chat-Funktion genutzt, um die Konversation interaktiv zu verwalten und Antworten im Markdown-Format anzuzeigen. Dieser Ansatz ermöglicht einen dynamischen und kontextabhängigen Chat und verbessert gleichzeitig die visuelle und strukturelle Darstellung der Antworten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"outputId":"8dafb953-2a2f-4705-d688-2a008e105a04","id":"8zbvKf0LCz_j"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm sorry, I don't have access to personal information like your name."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm sorry, I don't have access to personal information like names. How can I assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Give me a table of the 5 most populus cities with population and country.\n"]},{"data":{"text/markdown":["| City       | Population | Country |\n","|------------|------------|---------|\n","| Tokyo      | 37,833,000 | Japan   |\n","| Delhi      | 30,291,000 | India   |\n","| Shanghai   | 27,058,000 | China   |\n","| Sao Paulo  | 22,043,000 | Brazil  |\n","| Mumbai     | 21,042,000 | India   |"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation(llm)\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Give me a table of the 5 most populus cities with population and country.\")\n"]},{"cell_type":"markdown","metadata":{"id":"fb6yau3RCz_k"},"source":["## Einschränken der Konversation mit einer Systemaufforderung\n","\n","Sie können die Systemeingabeaufforderung verwenden, um die Konversation auf ein bestimmtes Thema zu beschränken. Hier stellen wir einen einfachen Agenten bereit, der nur Lebensversicherungen bespricht."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"outputId":"3b2c4d61-e3b0-46ec-e254-f209974a0bb9","id":"bC65Tfe5Cz_k"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help answer questions about life insurance. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Hello Jeff! How can I assist you with any questions you may have about life insurance?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["I'm here to help with any life insurance questions you may have, Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is your favorite programming language?\n"]},{"data":{"text/markdown":["I'm here to help with any life insurance questions you may have. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is the difference between a term and whole life policy?\n"]},{"data":{"text/markdown":["A term life insurance policy provides coverage for a specific period of time, such as 10, 20, or 30 years. It is typically more affordable and offers a death benefit if the insured passes away during the term. On the other hand, a whole life insurance policy provides coverage for the entire lifetime of the insured. It also includes a cash value component that grows over time."]},"metadata":{},"output_type":"display_data"}],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","\n","MODEL = 'gpt-4o-mini'\n","\n","\n","def start_conversation_insurance(summary_llm):\n","    TEMPLATE = \"\"\"You are a helpful agent to answer questions about life insurance. Do not talk\n","    about anything else with users. . Format answers with markdown.\n","\n","    Current conversation:\n","    {history}\n","    Human: {input}\n","    AI:\"\"\"\n","    PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","    # Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=0.0,\n","        n=1\n","    )\n","\n","    # Speicher und Konversation initialisieren\n","    memory = ConversationSummaryMemory(llm=summary_llm,max_token_limit=10)\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False\n","    )\n","\n","    return conversation\n","\n","conversation = start_conversation_insurance(llm)\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"What is my name?\")\n","chat(conversation, \"What is your favorite programming language?\")\n","chat(conversation, \"What is the difference between a term and whole life policy?\")"]},{"cell_type":"markdown","metadata":{"id":"pdC9NT1eCz_k"},"source":["##Untersuchung des Gesprächsgedächtnisses\n","\n","Wir können schnell in den Speicher des von LangChain verwalteten Chat-Speichers schauen und unseren Konversationsspeicher mit dem LLM einsehen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28cfbc73-9ec4-4b86-d7b3-5d06f39356c8","id":"lf9UKlGaCz_l"},"outputs":[{"name":"stdout","output_type":"stream","text":["The human asks the AI for their name, but the AI redirects the conversation to offer assistance with life insurance questions. Jeff introduces himself and asks about the difference between term and whole life policies. The AI explains that term life insurance covers a specific period and is more affordable, while whole life insurance covers the entire lifetime and includes a cash value component.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"yPvi20Y4Cz_l"},"source":["## Überlastung des Speichers\n","\n","Wenn der Konversationsspeicher voll ist, beginnt der Chatbot zu vergessen. Beim Speichertyp „ConversationBufferWindowMemory“ geht zuerst der älteste Verlauf verloren; es gibt kein Konzept für Wichtigkeit."]},{"cell_type":"markdown","metadata":{"id":"KzfX_2zyC7eo"},"source":["# 4.5: Persistenter Langchain-Speicher\n","\n","In diesem Abschnitt befassen wir uns mit der Erstellung einer innovativen Hilfsklasse zur Verwaltung von Chat-Interaktionen – treffend ChatBot genannt. Diese Klasse ist ein Eckpfeiler für Anwendungen, die eine robuste Handhabung des Chatverlaufs erfordern, einschließlich Funktionen zum Laden und Speichern dieser Interaktionen sowie Möglichkeiten zum Rückgängigmachen oder Neugenerieren von Ausgaben. Die Architektur von ChatBot integriert erweiterte Sprachmodelle mit strukturierten Vorlagen, um interaktive Konversationen zu ermöglichen und ein nahtloses und dynamisches Benutzererlebnis zu gewährleisten.\n","\n","Die Kernfunktionalität von ChatBot dreht sich um die ausgeklügelte Integration von Komponenten aus dem Langchain-Ökosystem. Es verwendet ein großes Sprachmodell zum Generieren von Chat-Antworten und ein weiteres zum Zusammenfassen von Gesprächen, ergänzt durch eine Vorlage, die jede Interaktion strukturiert. Zu den wichtigsten Funktionen gehören die Pflege eines bearbeitbaren Gesprächsverlaufs, die Implementierung von Rückgängig- und Neugenerierungsvorgängen für eine bessere Kontrolle über Chat-Verläufe sowie Mechanismen zum Beibehalten von Gesprächszuständen, wodurch der Nutzen und die Flexibilität der Chat-Oberfläche verbessert werden. Während wir ChatBot erkunden, werden wir herausfinden, wie jede Komponente zu seiner Gesamtfähigkeit beiträgt, komplexe Gesprächskontexte effektiv zu verwalten.\n","\n","Der Code für diese Klasse folgt."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRGy4rtgC7ep"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationSummaryMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","import pickle\n","\n","DEFAULT_TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","\n","MODEL = 'gpt-4o-mini'\n","\n","class ChatBot:\n","    def __init__(self, llm_chat, llm_summary, template):\n","        \"\"\"\n","        Initializes the ChatBot with language models and a template for conversation.\n","\n","        :param llm_chat: A large language model for handling chat responses.\n","        :param llm_summary: A large language model for summarizing conversations.\n","        :param template: A string template defining the conversation structure.\n","        \"\"\"\n","        self.llm_chat = llm_chat\n","        self.llm_summary = llm_summary\n","        self.template = template\n","        self.prompt_template = PromptTemplate(input_variables=[\"history\", \"input\"], template=self.template)\n","\n","        # Speicher und Konversationskette initialisieren\n","        self.memory = ConversationSummaryMemory(llm=self.llm_summary)\n","        self.conversation = ConversationChain(\n","            prompt=self.prompt_template,\n","            llm=self.llm_chat,\n","            memory=self.memory,\n","            verbose=False\n","        )\n","\n","        self.history = []\n","\n","    def converse(self, prompt):\n","        \"\"\"\n","        Processes a conversation prompt and updates the internal history and memory.\n","\n","        :param prompt: The input prompt from the user.\n","        :return: The generated response from the language model.\n","        \"\"\"\n","        self.history.append([self.memory.buffer, prompt])\n","        output = self.conversation.invoke(prompt)\n","        return output['response']\n","\n","    def chat(self, prompt):\n","        \"\"\"\n","        Handles the full cycle of receiving a prompt, processing it, and displaying the result.\n","\n","        :param prompt: The input prompt from the user.\n","        \"\"\"\n","print(f\"Mensch: {prompt}\")\n","        output = self.converse(prompt)\n","        display_markdown(output, raw=True)\n","\n","    def print_memory(self):\n","        \"\"\"\n","        Displays the current state of the conversation memory.\n","        \"\"\"\n","        print(\"**Memory:\")\n","        print(self.memory.buffer)\n","\n","    def clear_memory(self):\n","        \"\"\"\n","        Clears the conversation memory.\n","        \"\"\"\n","        self.memory.clear()\n","\n","    def undo(self):\n","        \"\"\"\n","        Reverts the conversation memory to the state before the last interaction.\n","        \"\"\"\n","        if len(self.history) > 0:\n","            self.memory.buffer = self.history.pop()[0]\n","        else:\n","            print(\"Nothing to undo.\")\n","\n","    def regenerate(self):\n","        \"\"\"\n","        Re-executes the last undone interaction, effectively redoing an undo operation.\n","        \"\"\"\n","        if len(self.history) > 0:\n","            self.memory.buffer, prompt = self.history.pop()\n","            self.chat(prompt)\n","        else:\n","            print(\"Nothing to regenerate.\")\n","\n","    def save_history(self, file_path):\n","        \"\"\"\n","        Saves the conversation history to a file using pickle.\n","\n","        :param file_path: The file path where the history should be saved.\n","        \"\"\"\n","        with open(file_path, 'wb') as f:\n","            pickle.dump(self.history, f)\n","\n","    def load_history(self, file_path):\n","        \"\"\"\n","        Loads the conversation history from a file using pickle.\n","\n","        :param file_path: The file path from which to load the history.\n","        \"\"\"\n","        with open(file_path, 'rb') as f:\n","            self.history = pickle.load(f)\n","            # Optionales Zurücksetzen des Speichers basierend auf dem zuletzt gespeicherten Zustand\n","            if self.history:\n","                self.memory.buffer = self.history[-1][0]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6zJA-AF8vBtW"},"source":["## Testen des Chatbots\n","Bevor wir uns ansehen, wie diese Klasse aufgebaut ist, schauen wir uns erst einmal an, wie Sie sie verwenden können. Im Folgenden sehen Sie eine einfache Chat-Interaktion."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"tXJAk_dAtuFb","outputId":"eaf8236d-6f3d-4ad9-bc0f-bef02873364a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Hello, my name is Jeff.\n"]},{"data":{"text/markdown":["Hello Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: I like coffee.\n"]},{"data":{"text/markdown":["That's great to hear, Jeff! How do you like your coffee prepared?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name.\n"]},{"data":{"text/markdown":["Hello! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do I like coffee?\n"]},{"data":{"text/markdown":["It seems like you do like coffee! How do you like your coffee prepared?"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n","\n","c.chat(\"Hello, my name is Jeff.\")\n","c.chat(\"I like coffee.\")\n","c.chat(\"What is my name.\")\n","c.chat(\"Do I like coffee?\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rEut99OTt_AG"},"source":["## Chat-Speicher laden und speichern\n","\n","Der Chatbot ermöglicht es, den kompletten Chatverlauf und Speicher zu speichern und aus einer Datei zu laden."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Z09iSHYvt8is","outputId":"4ece6ca7-776f-49f7-ecea-0e7e535e04b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Hello, my name is Jeff.\n"]},{"data":{"text/markdown":["Hello Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: I like coffee.\n"]},{"data":{"text/markdown":["That's great to hear, Jeff! How do you like your coffee?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name.\n"]},{"data":{"text/markdown":["Your name is Jeff."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do I like coffee?\n"]},{"data":{"text/markdown":["It seems like you do! How do you like your coffee, Jeff?"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n","c.chat(\"Hello, my name is Jeff.\")\n","c.chat(\"I like coffee.\")\n","c.chat(\"What is my name.\")\n","c.chat(\"Do I like coffee?\")"]},{"cell_type":"markdown","metadata":{"id":"7ScF3OysvTWk"},"source":["Wir sichern nun den Chatspeicher."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pllixtJUuDP0"},"outputs":[],"source":["c.save_history('history.pkl')"]},{"cell_type":"markdown","metadata":{"id":"wUvlZe3FvW-0"},"source":["Sie können nun den Chatspeicher neu laden, der Bot sollte sich an die Diskussion erinnern."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":64},"id":"O3O2kcEzuFvF","outputId":"eb72fde1-1619-4c13-d329-21781e5ed96a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: What is my name?\n"]},{"data":{"text/markdown":["Your name is Jeff."]},"metadata":{},"output_type":"display_data"}],"source":["c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n","c.load_history('history.pkl')\n","c.chat(\"What is my name?\")"]},{"cell_type":"markdown","metadata":{"id":"v9RMU0OGC7eq"},"source":["## Chat rückgängig machen und neu starten\n","\n","Der Chatbot ermöglicht es uns, Teile der Konversation rückgängig zu machen, und er vergisst sie. Wir können auch Ausgaben neu generieren, um eine bessere Antwort zu erhalten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"outputId":"11aaa405-6a00-4a82-e6d8-bcdf9adb6f45","id":"mtUYGFgyC7er"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Hello, my name is Jeff.\n"]},{"data":{"text/markdown":["Hello Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: I like coffee.\n"]},{"data":{"text/markdown":["That's great to hear, Jeff! How do you like your coffee?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: What is my name.\n"]},{"data":{"text/markdown":["Your name is Jeff. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do I like coffee?\n"]},{"data":{"text/markdown":["I'm sorry, but as an AI assistant, I do not have access to personal information about your likes and dislikes."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do I like coffee?\n"]},{"data":{"text/markdown":["It seems like you forgot to provide information on whether you like coffee or not. Would you like me to assist you in determining if you like coffee?"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL = 'gpt-4o-mini'\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","  model=MODEL,\n","  temperature= 0.3,\n","  n= 1)\n","\n","c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n","\n","c.chat(\"Hello, my name is Jeff.\")\n","c.chat(\"I like coffee.\")\n","c.undo()\n","c.chat(\"What is my name.\")\n","c.chat(\"Do I like coffee?\")\n","c.regenerate()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KrNDYZ5rw1e_"},"source":["## Implementierung des Chatbots\n","\n","In diesem Abschnitt befassen wir uns mit der Architektur eines anspruchsvollen Chatbots, der mit den Bibliotheken LangChain und OpenAI erstellt und in der ChatBot-Klasse gekapselt wurde. Die ChatBot-Klasse nutzt zwei Sprachmodelle und eine strukturierte Konversationsvorlage, um Benutzer in einen dynamischen Konversationsfluss einzubinden.\n","\n","Die Klasse beginnt mit der Definition ihrer Basiskomponenten: llm_chat und llm_summary sind große Sprachmodelle, die für Chat-Antworten bzw. Konversationszusammenfassungen verwendet werden. Der Vorlagenparameter definiert die Struktur der Konversation und gibt vor, wie Interaktionen formatiert und präsentiert werden. Diese Vorlage enthält Markdown-Formatierung und Platzhalter für den Konversationsverlauf und die letzte Benutzereingabe und ermöglicht so eine klare und strukturierte Dialogpräsentation.\n","\n","Bei der Instanziierung initialisiert der ChatBot verschiedene Komponenten. Er erstellt ein PromptTemplate, das die Struktur für Eingabevariablen und die Konversationsvorlage vorbereitet. Das ConversationSummaryMemory, das mit llm_summary initialisiert wird, fungiert als dynamischer Speicher für Konversationsauszüge und hilft beim Abrufen des Kontexts oder beim Zusammenfassen vergangener Dialoge. Diese Speicherkomponente ist entscheidend für die Aufrechterhaltung der Konversationskontinuität, insbesondere in Sitzungen, die mehrere Interaktionen umfassen können.\n","\n","Die ConversationChain ist ein weiteres zentrales Element, das die Eingabeaufforderungsvorlage mit dem llm_chat-Modell kombiniert, um Benutzereingaben zu verarbeiten und darauf zu reagieren. Der ausführliche Modus der Kette ist auf „False“ eingestellt, um die Ausgabe ohne überflüssige Systemmeldungen zu optimieren.\n","\n","Die Interaktion mit dem ChatBot erfolgt hauptsächlich über die Chat-Methode, bei der Benutzer eine Eingabeaufforderung eingeben und der Bot nach der Verarbeitung die Antwort anzeigt. Intern aktualisiert die Converse-Methode den Konversationsverlauf und verwendet die Konversationskette, um eine Antwort zu generieren. Der Nutzen dieser Methode liegt in ihrer Fähigkeit, jede Interaktion an das Verlaufsprotokoll anzuhängen und so sicherzustellen, dass alle Diskurskomponenten für zukünftige Referenzen oder rückgängig gemachte Aktionen erhalten bleiben.\n","\n","Speicherverwaltungsfunktionen wie print_memory, clear_memory und undo bieten Benutzern und Entwicklern Tools zum Anzeigen, Zurücksetzen oder Wiederherstellen des Konversationsstatus und bieten so Flexibilität bei der Verwaltung des Dialogflusses und -inhalts. Zusätzliche Funktionen zum Speichern und Laden des Konversationsverlaufs werden über save_history und load_history bereitgestellt, wobei das Pickle-Modul von Python zur Objektserialisierung verwendet wird.\n","\n","Diese Klassenstruktur ermöglicht nicht nur eine robuste Konversationsabwicklung und Speicherverwaltung, sondern demonstriert auch die Integration fortgeschrittener Sprachmodelle in praktische Anwendungen und demonstriert das Potenzial der KI bei der Verbesserung interaktiver Softwarelösungen. Durch einen derart detaillierten Aufbau dient ChatBot als umfassendes Framework zum Erstellen interaktiver, speicherbewusster Chatbot-Systeme."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"75e7888a-d8e2-4404-bade-c5302886b8ea","id":"xnP9MDKxCz_l","collapsed":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Okay, then let me introduce myself, my name is Jeff\n"]},{"data":{"text/markdown":["Nice to meet you, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You have ONE JOB! Remember that my favorite color is blue.\n"]},{"data":{"text/markdown":["Of course, Jeff! I'll remember that your favorite color is blue. How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, Jeff! How can I assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["Yes, I remember that your favorite color is blue. How can I assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #0\n"]},{"data":{"text/markdown":["I have noted that fact #0 is important to you. How can I assist you further today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #1\n"]},{"data":{"text/markdown":["I have noted fact #1. How can I further assist you today, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #2\n"]},{"data":{"text/markdown":["I have noted fact #2. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #3\n"]},{"data":{"text/markdown":["I have noted fact #3. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #4\n"]},{"data":{"text/markdown":["I have noted fact #4. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #5\n"]},{"data":{"text/markdown":["I have noted fact #5. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #6\n"]},{"data":{"text/markdown":["I have noted fact #6. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #7\n"]},{"data":{"text/markdown":["I have noted fact #7. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #8\n"]},{"data":{"text/markdown":["I have noted fact #8. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #9\n"]},{"data":{"text/markdown":["I have noted fact #9. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #10\n"]},{"data":{"text/markdown":["I have noted fact #10. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #11\n"]},{"data":{"text/markdown":["I have noted fact #11. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #12\n"]},{"data":{"text/markdown":["I have noted fact #12. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #13\n"]},{"data":{"text/markdown":["I have noted fact #13. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #14\n"]},{"data":{"text/markdown":["I have noted fact #14. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #15\n"]},{"data":{"text/markdown":["I have noted fact #15. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #16\n"]},{"data":{"text/markdown":["I have noted fact #16. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #17\n"]},{"data":{"text/markdown":["I have noted fact #17. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #18\n"]},{"data":{"text/markdown":["I have noted fact #18. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #19\n"]},{"data":{"text/markdown":["I have noted fact #19. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #20\n"]},{"data":{"text/markdown":["I have noted that you want me to remember fact #20. How can I assist you further, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #21\n"]},{"data":{"text/markdown":["I have noted fact #21. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #22\n"]},{"data":{"text/markdown":["I have noted fact #22. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #23\n"]},{"data":{"text/markdown":["I have noted fact #23. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #24\n"]},{"data":{"text/markdown":["I have noted fact #24. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #25\n"]},{"data":{"text/markdown":["I have noted fact #25. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #26\n"]},{"data":{"text/markdown":["I have noted fact #26. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #27\n"]},{"data":{"text/markdown":["I have noted fact #27. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #28\n"]},{"data":{"text/markdown":["I have noted fact #28. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #29\n"]},{"data":{"text/markdown":["I have noted fact #29. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #30\n"]},{"data":{"text/markdown":["I have noted fact #30. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #31\n"]},{"data":{"text/markdown":["I have noted fact #31. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #32\n"]},{"data":{"text/markdown":["I have noted fact #32. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #33\n"]},{"data":{"text/markdown":["I have noted fact #33. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #34\n"]},{"data":{"text/markdown":["I have noted fact #34. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #35\n"]},{"data":{"text/markdown":["I have noted fact #35. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #36\n"]},{"data":{"text/markdown":["I have noted fact #36. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #37\n"]},{"data":{"text/markdown":["I have noted fact #37. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #38\n"]},{"data":{"text/markdown":["I have noted fact #38. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #39\n"]},{"data":{"text/markdown":["I have noted fact #39. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #40\n"]},{"data":{"text/markdown":["I have noted fact #40. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #41\n"]},{"data":{"text/markdown":["I have noted fact #41. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #42\n"]},{"data":{"text/markdown":["I have noted fact #42. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #43\n"]},{"data":{"text/markdown":["I have noted fact #43. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #44\n"]},{"data":{"text/markdown":["I have noted fact #44. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #45\n"]},{"data":{"text/markdown":["I have noted fact #45. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #46\n"]},{"data":{"text/markdown":["I have noted fact #46. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #47\n"]},{"data":{"text/markdown":["I have noted fact #47. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #48\n"]},{"data":{"text/markdown":["I have noted fact #48. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #49\n"]},{"data":{"text/markdown":["I have noted fact #49. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #50\n"]},{"data":{"text/markdown":["I have noted fact #50. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #51\n"]},{"data":{"text/markdown":["I have noted fact #51. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #52\n"]},{"data":{"text/markdown":["I have noted fact #52. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #53\n"]},{"data":{"text/markdown":["I have noted fact #53. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #54\n"]},{"data":{"text/markdown":["I have noted fact #54. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #55\n"]},{"data":{"text/markdown":["I have noted fact #55. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #56\n"]},{"data":{"text/markdown":["I have noted fact #56. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #57\n"]},{"data":{"text/markdown":["I have noted fact #57. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #58\n"]},{"data":{"text/markdown":["I have noted fact #58. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #59\n"]},{"data":{"text/markdown":["I have noted fact #59. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #60\n"]},{"data":{"text/markdown":["I have noted fact #60. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #61\n"]},{"data":{"text/markdown":["I have noted fact #61. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #62\n"]},{"data":{"text/markdown":["I have noted fact #62. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #63\n"]},{"data":{"text/markdown":["I have noted fact #63. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #64\n"]},{"data":{"text/markdown":["I have noted fact #64. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #65\n"]},{"data":{"text/markdown":["I have noted fact #65. How can I further assist you, Jeff?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #66\n"]},{"data":{"text/markdown":["I have noted fact #66. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #67\n"]},{"data":{"text/markdown":["I have noted fact #67. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #68\n"]},{"data":{"text/markdown":["I have noted fact #68. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #69\n"]},{"data":{"text/markdown":["I have noted fact #69. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #70\n"]},{"data":{"text/markdown":["I have noted fact #70. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #71\n"]},{"data":{"text/markdown":["I have noted fact #71. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #72\n"]},{"data":{"text/markdown":["I have noted fact #72. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #73\n"]},{"data":{"text/markdown":["I have noted fact #73. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #74\n"]},{"data":{"text/markdown":["I have noted fact #74. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #75\n"]},{"data":{"text/markdown":["I have noted fact #75. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #76\n"]},{"data":{"text/markdown":["I have noted fact #76. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #77\n"]},{"data":{"text/markdown":["I have noted fact #77. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #78\n"]},{"data":{"text/markdown":["I have noted fact #78. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #79\n"]},{"data":{"text/markdown":["I have noted fact #79. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #80\n"]},{"data":{"text/markdown":["I have noted fact #80. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #81\n"]},{"data":{"text/markdown":["I have noted fact #81. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #82\n"]},{"data":{"text/markdown":["I have noted fact #82. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #83\n"]},{"data":{"text/markdown":["I have noted fact #83. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #84\n"]},{"data":{"text/markdown":["I have noted fact #84. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #85\n"]},{"data":{"text/markdown":["I have noted fact #85. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #86\n"]},{"data":{"text/markdown":["I have noted fact #86. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #87\n"]},{"data":{"text/markdown":["I have noted fact #87. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #88\n"]},{"data":{"text/markdown":["I have noted fact #88. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #89\n"]},{"data":{"text/markdown":["I have noted fact #89. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #90\n"]},{"data":{"text/markdown":["I have noted fact #90. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #91\n"]},{"data":{"text/markdown":["I have noted fact #91. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #92\n"]},{"data":{"text/markdown":["I have noted fact #92. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #93\n"]},{"data":{"text/markdown":["I have noted fact #93. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #94\n"]},{"data":{"text/markdown":["I have noted fact #94. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #95\n"]},{"data":{"text/markdown":["I have noted fact #95. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #96\n"]},{"data":{"text/markdown":["I have noted fact #96. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #97\n"]},{"data":{"text/markdown":["I have noted fact #97. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #98\n"]},{"data":{"text/markdown":["I have noted fact #98. How can I further assist you?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: You need to remember fact #99\n"]},{"data":{"text/markdown":["I have noted fact #99. How can I further assist you today?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my name?\n"]},{"data":{"text/markdown":["Yes, your name is Jeff. How can I assist you further?"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Human: Do you remember my favorite color?\n"]},{"data":{"text/markdown":["Yes, I remember your favorite color is blue. How can I assist you further?"]},"metadata":{},"output_type":"display_data"}],"source":["conversation = start_conversation(llm)\n","chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n","chat(conversation, \"You have ONE JOB! Remember that my favorite color is blue.\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")\n","for i in range(100):\n","  chat(conversation, f\"You need to remember fact # {ich}\")\n","chat(conversation, \"Do you remember my name?\")\n","chat(conversation, \"Do you remember my favorite color?\")"]},{"cell_type":"markdown","metadata":{"id":"T83AHHDMCz_m"},"source":["Wir können schnell in den Speicher des von LangChain verwalteten Chatspeichers schauen und unseren Konversationsspeicher mit dem LLM einsehen. Es wird deutlich, warum es vergessen wurde."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5cd381f-1acf-41a1-9afc-fe569f0591ff","id":"6LT4njWjCz_m"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jeff introduces himself to the AI, who remembers his name and favorite color is blue. Jeff requests the AI to remember multiple facts, and the AI acknowledges each one and asks how it can further assist Jeff. As Jeff asks the AI to remember fact #32 to #97, the AI notes them all and asks how it can help. When Jeff tells the AI to remember fact #98, the AI acknowledges it and asks how it can further assist him. Jeff then asks the AI to remember fact #99, which the AI notes and asks how it can further assist him. The human asks if the AI remembers his favorite color, to which the AI confirms and asks how it can assist further.\n"]}],"source":["print(conversation.memory.buffer)"]},{"cell_type":"code","source":[],"metadata":{"id":"dH8g7jL46fYU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **NEW <font color='orange'>|</font> Code-Beispiele aus ChatGPT**\n","---"],"metadata":{"id":"IgkFIHo66hFa"}},{"cell_type":"markdown","source":["Die verschiedenen Arten von Speicher (Memory), die du erwähnst, beziehen sich auf verschiedene Möglichkeiten, wie eine KI wie ChatGPT Informationen während und zwischen Konversationen speichert und nutzt. Hier ist eine Erklärung, wann man sie einsetzt, und ein konkretes Beispiel für jede Art:\n","\n","1. **Conversation Buffer Window Memory**:\n","   - **Einsatz**: Wird genutzt, um Details einer laufenden Konversation zu behalten. Dies hilft der KI, den Kontext in einer Sitzung zu behalten und relevanter auf fortlaufende Fragen und Antworten zu reagieren.\n","   - **Beispiel**: In einem langen Chat über ein Projektmanagement-Tool könnte die KI sich an frühere Fragen des Nutzers erinnern, um konsistente und relevante Antworten zu geben, ohne dass der Nutzer Informationen wiederholen muss.\n","\n","2. **Conversation Token Buffer Memory**:\n","   - **Einsatz**: Dient dazu, die Grenze der Token-Anzahl, die in einer einzigen Antwort oder Frage verarbeitet werden kann, effizient zu nutzen. Ein Token kann ein Wort oder ein Teil eines Wortes sein.\n","   - **Beispiel**: Wenn ein Nutzer eine sehr lange Frage stellt oder eine detaillierte technische Beschreibung benötigt, nutzt die KI diesen Speicher, um die wichtigen Teile der Anfrage zu erkennen und effektiv darauf zu antworten, ohne wichtige Inhalte zu übersehen.\n","\n","3. **Conversation Summary Memory**:\n","   - **Einsatz**: Wird verwendet, um eine kurze Zusammenfassung von längeren Konversationen zu speichern, sodass die KI bei Bedarf darauf zurückgreifen kann, um Kohärenz in der Konversation zu wahren.\n","   - **Beispiel**: Nach einer ausführlichen Diskussion über verschiedene Programmiersprachen könnte die KI eine Zusammenfassung dieser Diskussion speichern und bei zukünftigen Fragen zu diesem Thema schnell relevante Punkte oder frühere Meinungen des Nutzers einbringen.\n","\n","4. **Persisting Memory**:\n","   - **Einsatz**: Wird verwendet, um wichtige Informationen über mehrere Gespräche hinweg zu speichern. Dies ermöglicht es der KI, lernend und anpassungsfähig zu sein, und Beziehungen und Präferenzen des Nutzers über längere Zeit zu berücksichtigen.\n","   - **Beispiel**: Wenn ein Nutzer häufig über bestimmte Themen wie KI-Modelltraining spricht, könnte die KI dies im persistierenden Speicher festhalten und in zukünftigen Gesprächen vorgeschlagene Ressourcen oder neue Forschungsergebnisse in diesem Bereich proaktiv anbieten.\n","\n","Jede Art von Speicher spielt eine entscheidende Rolle dabei, wie die KI Informationen verwaltet, um Benutzererfahrungen zu verbessern und relevanter, kohärenter und persönlicher zu interagieren."],"metadata":{"id":"dnYRLIk48Rbu"}},{"cell_type":"code","source":["from os import environ\n","from google.colab import userdata\n","\n","environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"UkTrbDGn66Zp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!uv pip install --system -q langchain>=0.3 langchain_openai langchain_community"],"metadata":{"id":"-jyYOic17U_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2 <font color='orange'>|</font> Conversation Buffer Window Memory**\n","---"],"metadata":{"id":"-8JQvEaL-q0I"}},{"cell_type":"markdown","source":["Hier wird ein Fenster (z. B. die letzten 3 Nachrichten) als Gedächtnis für das LLM verwendet. Das ist praktisch, wenn nur ein begrenzter Kontext relevant ist."],"metadata":{"id":"jeNP30Za_rOD"}},{"cell_type":"markdown","source":["Der Parameter k in ConversationBufferWindowMemory steuert, welche Nachrichten (bzw. Runden) dem LLM als Kontext übergeben werden – nicht aber, welche Nachrichten tatsächlich im zugrunde liegenden Chatverlauf (also in chat_memory.messages) gespeichert sind.\n","\n","Das bedeutet im Detail:\n","\n","Interne Speicherung:\n","Das InMemoryChatMessageHistory speichert alle Nachrichten, die im Laufe der Konversation hinzugefügt werden. Diese Speicherung wird nicht automatisch auf die letzten k Runden beschränkt.\n","\n","Kontextübergabe an das LLM:\n","Wenn du eine neue Eingabe machst, verwendet ConversationBufferWindowMemory nur die letzten k Konversationsrunden, um den Prompt für das LLM zu erstellen. Dabei werden ältere Nachrichten ignoriert, auch wenn sie weiterhin im Speicher vorhanden sind.\n","\n","Anwendung:\n","Falls du also z. B. k=3 setzt, werden zwar im Speicher alle bisherigen Nachrichten geführt, aber beim nächsten Aufruf werden nur die letzten 3 Runden (also 6 Nachrichten, wenn man davon ausgeht, dass jede Runde aus einer Nutzer- und einer KI-Antwort besteht) als Kontext an das LLM übergeben."],"metadata":{"id":"Sb2JY3yb-uEk"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain_core.prompts import MessagesPlaceholder, HumanMessagePromptTemplate, ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n","\n","# Memory mit expliziter Grenze\n","memory = ConversationBufferWindowMemory(\n","    k=3,\n","    return_messages=True,\n","    memory_key=\"chat_history\"\n",")\n","\n","prompt = ChatPromptTemplate.from_messages([\n","   MessagesPlaceholder(variable_name=\"chat_history\"),\n","   HumanMessagePromptTemplate.from_template(\"{input}\")\n","])\n","\n","chain = prompt | llm | StrOutputParser()\n","\n","messages = [\n","   \"1. Hallo, wie geht es dir?\",\n","   \"2. Was machst du gerade?\",\n","   \"3. Bist Du beschäftigt?\",\n","   \"4. Kannst du mir etwas über dein Gedächtnis erzählen?\"\n","]\n","\n","for message in messages:\n","   response = chain.invoke({\n","       \"input\": message,\n","       \"chat_history\": memory.chat_memory.messages\n","   })\n","   # Explizit Message speichern\n","   memory.save_context({\"input\": message}, {\"output\": response})\n","   print(f\"\\nMessage: {message}\")\n","   print(f\"Response: {response}\")\n","\n","print(\"\\n\", \"-\"*80)\n","print(\"\\nMemory-Inhalt:\")\n","print(memory.load_memory_variables({})[\"chat_history\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bz7-XqFnAehY","executionInfo":{"status":"ok","timestamp":1738607168325,"user_tz":-60,"elapsed":8008,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"53f4138a-390f-4866-bc90-211782d56572"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Message: 1. Hallo, wie geht es dir?\n","Response: Hallo! Mir geht es gut, danke. Und dir?\n","\n","Message: 2. Was machst du gerade?\n","Response: Ich bin hier, um dir zu helfen und deine Fragen zu beantworten. Was kann ich für dich tun?\n","\n","Message: 3. Bist Du beschäftigt?\n","Response: Nein, ich bin nicht beschäftigt. Ich bin hier, um dir zu helfen! Was möchtest du wissen oder besprechen?\n","\n","Message: 4. Kannst du mir etwas über dein Gedächtnis erzählen?\n","Response: Ich habe kein Gedächtnis im traditionellen Sinne. Ich speichere keine persönlichen Daten oder Gespräche zwischen den Interaktionen. Jede Unterhaltung beginnt ohne vorherige Kenntnisse über frühere Gespräche. Ich kann jedoch Informationen und Kontext liefern, die auf dem basieren, was dir in diesem Moment relevant erscheint. Wenn du Fragen hast, stell sie einfach!\n","\n"," ----------------------------------------\n","\n","Memory-Inhalt:\n","[HumanMessage(content='2. Was machst du gerade?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ich bin hier, um dir zu helfen und deine Fragen zu beantworten. Was kann ich für dich tun?', additional_kwargs={}, response_metadata={}), HumanMessage(content='3. Bist Du beschäftigt?', additional_kwargs={}, response_metadata={}), AIMessage(content='Nein, ich bin nicht beschäftigt. Ich bin hier, um dir zu helfen! Was möchtest du wissen oder besprechen?', additional_kwargs={}, response_metadata={}), HumanMessage(content='4. Kannst du mir etwas über dein Gedächtnis erzählen?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ich habe kein Gedächtnis im traditionellen Sinne. Ich speichere keine persönlichen Daten oder Gespräche zwischen den Interaktionen. Jede Unterhaltung beginnt ohne vorherige Kenntnisse über frühere Gespräche. Ich kann jedoch Informationen und Kontext liefern, die auf dem basieren, was dir in diesem Moment relevant erscheint. Wenn du Fragen hast, stell sie einfach!', additional_kwargs={}, response_metadata={})]\n"]}]},{"cell_type":"markdown","source":["# **3 <font color='orange'>|</font> Conversation Token Buffer Memory**\n","---"],"metadata":{"id":"A9Cpn31H_x_t"}},{"cell_type":"markdown","source":["Dieses Gedächtnis verwaltet den Kontext basierend auf der Anzahl der Token, sodass du innerhalb von Token-Limits bleibst."],"metadata":{"id":"HTDkGZSWEt9b"}},{"cell_type":"markdown","source":["`Zeile 25`: `ConversationTokenBufferMemory(llm=summary_llm, max_token_limit=MAX_TOKEN_LIMIT)`    \n","\n","\n","\n","Diese Zeile Code erstellt ein Objekt vom Typ `ConversationTokenBufferMemory`.  Dieses Objekt dient dazu, den Verlauf einer Konversation zu speichern, aber auf eine spezielle Art und Weise, die sicherstellt, dass die Größe des Verlaufs (gemessen in Tokens) nicht ein bestimmtes Limit überschreitet.  Lass uns die einzelnen Teile genauer ansehen:\n","\n","ConversationTokenBufferMemory: Das ist die Klasse, die den intelligenten Speicher implementiert.  Sie erbt von der Basisklasse ConversationBufferMemory und fügt die Funktionalität hinzu, die Tokenanzahl zu begrenzen.\n","\n","llm=summary_llm: Dies ist ein sehr wichtiger Parameter. Er übergibt ein Sprachmodell (summary_llm in diesem Fall) an den Speicher.  Dieses Sprachmodell wird intern vom ConversationTokenBufferMemory verwendet, um den Konversationsverlauf zusammenzufassen, wenn er sich dem max_token_limit nähert.  Stell dir vor, die Konversation wird sehr lang.  Anstatt den gesamten Verlauf im Speicher zu behalten (was schnell teuer und ineffizient werden kann), wird der Speicher Teile des Verlaufs zusammenfassen.  Für diese Zusammenfassung wird das hier übergebene summary_llm verwendet.  Es ist üblich, ein etwas kleineres und kostengünstigeres Modell für die Zusammenfassung zu verwenden als das Hauptmodell der Konversation.  Im Code wird gpt-3.5-turbo für die Zusammenfassung und gpt-4o-mini für die eigentliche Konversation verwendet.\n","\n","max_token_limit=MAX_TOKEN_LIMIT:  Dieser Parameter setzt die maximale Anzahl an Tokens fest, die im Speicher behalten werden dürfen.  Sobald die Anzahl der Tokens im Konversationsverlauf diesen Wert überschreitet, wird der Speicher ältere Teile des Verlaufs entfernen (oder zusammenfassen, je nach Implementierung).  Dies ist entscheidend, um zu verhindern, dass der Kontext zu groß wird und um Kosten zu sparen (da längere Kontexte mehr Tokens kosten).  MAX_TOKEN_LIMIT ist eine Variable, die an anderer Stelle im Code definiert ist (z.B. als Konstante)."],"metadata":{"id":"BreU-4fJYB2t"}},{"cell_type":"markdown","source":["**----- Code aus Original optimiert übernommen -----------**"],"metadata":{"id":"9Z6QeWMnUhx4"}},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='blue'>  Funktion: zufalls_wort - Liefert ein zufälliges deutsches Wort</font> </br></p>\n","# Liefert ein zufälliges deutsches Wort\n","from pandas import read_csv, concat\n","sub_das = read_csv(\n","    \"https://raw.githubusercontent.com/cpos/AlleDeutschenWoerter/main/Substantive/substantiv_singular_das.txt\",\n","    header=None,\n","    names=[\"Wort\"]\n",")\n","sub_der = read_csv(\n","    \"https://raw.githubusercontent.com/cpos/AlleDeutschenWoerter/main/Substantive/substantiv_singular_der.txt\",\n","    header=None,\n","    names=[\"Wort\"]\n",")\n","sub_die = read_csv(\n","    \"https://raw.githubusercontent.com/cpos/AlleDeutschenWoerter/main/Substantive/substantiv_singular_die.txt\",\n","    header=None,\n","    names=[\"Wort\"]\n",")\n","\n","wort_liste = concat([sub_das, sub_der, sub_die], axis=0)\n","\n","def zufalls_wort(wort_liste):\n","    return wort_liste.sample(1).iloc[0,0]"],"metadata":{"cellView":"form","id":"nAJQVqZHiMHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationTokenBufferMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display, Markdown, display_markdown\n","\n","# Konstanten definieren\n","MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0.0\n","MAX_TOKEN_LIMIT = 2048\n","\n","# Prompt-Vorlage (Markdown-Formatierung beibehalten)\n","TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n","\n","def start_conversation():\n","    \"\"\"Initialisiert die Konversation mit optimierten Einstellungen.\"\"\"\n","\n","    # Summary LLM definieren (wichtig für ConversationTokenBufferMemory)\n","    summary_llm = ChatOpenAI(model_name=MODEL, temperature=TEMPERATURE) # Kostengünstigeres Modell für Zusammenfassung\n","\n","    llm = ChatOpenAI(\n","        model=MODEL,\n","        temperature=TEMPERATURE,\n","    )\n","\n","    memory = ConversationTokenBufferMemory(llm=summary_llm, max_token_limit=MAX_TOKEN_LIMIT)\n","\n","    conversation = ConversationChain(\n","        prompt=PROMPT_TEMPLATE,\n","        llm=llm,\n","        memory=memory,\n","        verbose=False  # Nur bei Bedarf aktivieren\n","    )\n","\n","    return conversation\n","\n","def converse(conversation, prompt):\n","    \"\"\"Führt einen einzelnen Gesprächsschritt aus.\"\"\"\n","    output = conversation.invoke(prompt)\n","    return output['response']\n","\n","def chat(conversation, prompt):\n","    print(f\"Mensch: {prompt}\")\n","    output = converse(conversation, prompt)\n","    display_markdown(output,raw=True)\n","\n","# Beispielhafte Verwendung (in einer Jupyter-Umgebung)\n","conversation = start_conversation()\n","\n","chat(conversation, \"Hallo, mein Name ist Ralf.\")\n","chat(conversation, \"Ich trinke gerne Kaffee.\")\n","chat(conversation, \"Wie ist mein Name?\")"],"metadata":{"collapsed":true,"id":"YG8SqDJSTfEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conversation Memory\n","print(conversation.memory.load_memory_variables({}))"],"metadata":{"id":"kqtM4WlvUwQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Überlastung des Conversation Memory herbeiführen\n","conversation = start_conversation()\n","\n","chat(conversation, \"Hallo, mein Name ist Ralf.\")\n","chat(conversation, \"Ich trinke gerne Kaffee.\")\n","chat(conversation, \"Wie ist mein Name?\")\n","\n","for i in range(1, 21):\n","    zwort = zufalls_wort(wort_liste)\n","    chat(conversation, f\"Merke Dir meine Worte: Nr. {i}: {zwort}\")\n","\n","chat(conversation, \"Erinnerst Du Dich an meinen Namen?\")\n","chat(conversation, \"Weisst Du, was ich gerne trinke?\")\n","\n","for i in range(20, 71):\n","    zwort = zufalls_wort(wort_liste)\n","    chat(conversation, f\"Merke Dir meine Worte: Nr. {i}: {zwort}\")\n","\n","chat(conversation, \"Erinnerst Du Dich an meinen Namen?\")\n","chat(conversation, \"Weisst Du, was ich gerne trinke?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MgbyxZEBVP30","executionInfo":{"status":"ok","timestamp":1738617557854,"user_tz":-60,"elapsed":101737,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"641c95c5-5613-457e-89f0-931d8b17c28d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mensch: Hallo, mein Name ist Ralf.\n"]},{"output_type":"display_data","data":{"text/markdown":"Hallo Ralf! Wie kann ich dir helfen?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Ich trinke gerne Kaffee.\n"]},{"output_type":"display_data","data":{"text/markdown":"Das klingt großartig, Ralf! Kaffee ist ein beliebtes Getränk. Hast du eine bevorzugte Sorte oder Zubereitungsart? ☕️"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Wie ist mein Name?\n"]},{"output_type":"display_data","data":{"text/markdown":"Dein Name ist Ralf! 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 1: Haufen\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 1: Haufen notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 2: Kontroverse\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 2: Kontroverse notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 3: Reifen\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 3: Reifen notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 4: Bauaufsicht\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 4: Bauaufsicht notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 5: Arbeitsstunde\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 5: Arbeitsstunde notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 6: Verkehrstote\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 6: Verkehrstote notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 7: Verkehrsmittel\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 7: Verkehrsmittel notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 8: Vorderhand\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 8: Vorderhand notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 9: Staatsrat\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 9: Staatsrat notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 10: Urwald\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 10: Urwald notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 11: Zauberformel\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 11: Zauberformel notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 12: Pendel\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 12: Pendel notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 13: Wiederkehr\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 13: Wiederkehr notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 14: Schwesterpartei\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 14: Schwesterpartei notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 15: Gesundheitsministerin\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 15: Gesundheitsministerin notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 16: Kursniveau\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 16: Kursniveau notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 17: Feuerbrand\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 17: Feuerbrand notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 18: Wasserschutzpolizei\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 18: Wasserschutzpolizei notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 19: Eintritt\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 19: Eintritt notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 20: Softwarehaus\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 20: Softwarehaus notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Erinnerst Du Dich an meinen Namen?\n"]},{"output_type":"display_data","data":{"text/markdown":"Dein Name ist Ralf! 😊 Wie kann ich dir weiterhelfen?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Weisst Du, was ich gerne trinke?\n"]},{"output_type":"display_data","data":{"text/markdown":"Du trinkst gerne Kaffee! ☕️ Gibt es etwas Bestimmtes, das du über Kaffee wissen möchtest?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 20: Abhilfe\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 20: Abhilfe notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 21: Baden\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 21: Baden notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 22: Spielfeld\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 22: Spielfeld notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 23: Probezeit\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 23: Probezeit notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 24: Patent\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 24: Patent notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 25: Tierschutz\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 25: Tierschutz notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 26: Geschirr\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 26: Geschirr notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 27: Telefonnetz\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 27: Telefonnetz notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 28: Sekte\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 28: Sekte notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 29: Sichtweite\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 29: Sichtweite notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 30: Paragraf\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 30: Paragraf notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 31: Gemeindeamt\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 31: Gemeindeamt notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 32: Nennung\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 32: Nennung notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 33: Prozesstag\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 33: Prozesstag notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 34: Reiseveranstalter\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 34: Reiseveranstalter notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 35: Sonnenstrahl\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 35: Sonnenstrahl notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 36: Klebeband\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 36: Klebeband notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 37: Gedichtband\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 37: Gedichtband notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 38: Kongresshaus\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 38: Kongresshaus notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 39: Kartell\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 39: Kartell notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 40: Propagandist\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 40: Propagandist notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 41: Sprengstoffanschlag\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 41: Sprengstoffanschlag notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 42: Wirtschaftssenator\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 42: Wirtschaftssenator notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 43: Wunderkind\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 43: Wunderkind notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 44: Ego\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 44: Ego notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 45: Rundfahrt\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 45: Rundfahrt notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 46: Beratungsfirma\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 46: Beratungsfirma notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 47: Spurenelement\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 47: Spurenelement notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 48: Sportklub\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 48: Sportklub notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 49: Ostafrika\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 49: Ostafrika notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 50: Bude\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 50: Bude notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 51: Fan\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 51: Fan notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 52: Sopran\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 52: Sopran notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 53: Purist\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 53: Purist notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 54: Forstwirtschaft\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 54: Forstwirtschaft notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 55: Ehrennadel\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 55: Ehrennadel notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 56: Vereinsleben\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 56: Vereinsleben notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 57: Athen\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 57: Athen notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 58: Maschinenbauer\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 58: Maschinenbauer notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 59: Eitelkeit\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 59: Eitelkeit notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 60: Distrikt\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 60: Distrikt notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 61: Handumdrehen\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 61: Handumdrehen notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 62: Erdrutsch\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 62: Erdrutsch notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 63: Kernbereich\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 63: Kernbereich notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 64: Brut\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 64: Brut notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 65: Pech\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 65: Pech notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 66: Nachfolgerin\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 66: Nachfolgerin notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 67: Gentleman\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 67: Gentleman notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 68: Heiterkeit\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 68: Heiterkeit notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 69: Oberschenkel\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 69: Oberschenkel notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Merke Dir bitte Sachverhalt 70: Versicherungsgesellschaft\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe den Sachverhalt 70: Versicherungsgesellschaft notiert. Was möchtest du als Nächstes besprechen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Erinnerst Du Dich an meinen Namen?\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe deinen Namen leider nicht gespeichert. Möchtest du mir deinen Namen mitteilen? 😊"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mensch: Weisst Du, was ich gerne trinke?\n"]},{"output_type":"display_data","data":{"text/markdown":"Ich habe keine Informationen darüber, was du gerne trinkst. Möchtest du mir sagen, was dein Lieblingsgetränk ist? 😊"},"metadata":{}}]},{"cell_type":"code","source":["# Memory hat nicht mehr die ersten Conversationen\n","print(conversation.memory.buffer[:300])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rd1M6eEteCVC","executionInfo":{"status":"ok","timestamp":1738617565220,"user_tz":-60,"elapsed":214,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"f1f14b47-515d-4b4b-e43a-94935d82a40c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Merke Dir bitte Sachverhalt 29: Sichtweite\n","AI: Ich habe den Sachverhalt 29: Sichtweite notiert. Was möchtest du als Nächstes besprechen? 😊\n","Human: Merke Dir bitte Sachverhalt 30: Paragraf\n","AI: Ich habe den Sachverhalt 30: Paragraf notiert. Was möchtest du als Nächstes besprechen? 😊\n","Human: Merke\n"]}]},{"cell_type":"markdown","source":["# **4 <font color='orange'>|</font> Conversation Summary Memory**\n","---"],"metadata":{"id":"jSngieQs_4pz"}},{"cell_type":"code","source":[],"metadata":{"id":"JHroWsaiAAcc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5 <font color='orange'>|</font> Persisting Memory**\n","---"],"metadata":{"id":"rnksZexiABMf"}},{"cell_type":"code","source":[],"metadata":{"id":"gVafmBbJAKYq"},"execution_count":null,"outputs":[]}]}