{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOslsT2ipCgP4v8Gah5WqR8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 13: Fine-Tuning und Optimierung\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"markdown","source":["# 1 | √úbersicht\n","---"],"metadata":{"id":"oYvUY6gMBKO1"}},{"cell_type":"markdown","metadata":{"id":"v2MPPX0c1pHi"},"source":["# Teil 11.1: Feinabstimmung verstehen\n","\n","OpenAI bietet Feinabstimmungsfunktionen, mit denen Benutzer Modelle wie GPT-4 f√ºr bestimmte Anwendungsf√§lle anpassen k√∂nnen, indem sie sie mit dom√§nenspezifischen Daten trainieren. Bei der Feinabstimmung wird ein kuratierter Datensatz bereitgestellt, um die Gewichte des Modells anzupassen, was die Leistung bei speziellen Aufgaben wie der Beantwortung von Fragen, der Erstellung genauerer Vorhersagen oder der Einhaltung von Markenrichtlinien verbessert. Der Feinabstimmungsprozess von OpenAI unterst√ºtzt eine schnelle Anpassung, sodass sich das Modell besser an die Erwartungen der Benutzer anpassen und spezifische Anweisungen effektiver verarbeiten kann. Dieser Ansatz ist besonders n√ºtzlich f√ºr Branchen wie Finanzen, Gesundheitswesen oder Kundendienst, in denen Fachwissen und Pr√§zision von entscheidender Bedeutung sind.\n","\n","Die vollst√§ndige Dokumentation von OpenAI zur Feinabstimmung finden Sie hier:\n","\n","* [OpenAI Finetuning Guide](https://platform.openai.com/docs/guides/fine-tuning)\n","\n","\n","Feinabstimmung ist eine leistungsstarke Technik, mit der Sie vorab trainierte Modelle optimieren, sie an bestimmte Aufgaben anpassen und eine h√∂here Leistung als mit Standardeingaben erzielen k√∂nnen. W√§hrend Modelle, die √ºber APIs wie die von OpenAI verf√ºgbar sind, anhand riesiger Datens√§tze vorab trainiert werden, verbessert die Feinabstimmung ihre F√§higkeiten, was mehrere wichtige Vorteile mit sich bringt:\n","\n","* H√∂here Qualit√§t der Ergebnisse als durch einfache Eingabeaufforderungen\n","* M√∂glichkeit, an mehr Beispielen zu trainieren, als in eine einzelne Eingabeaufforderung passen\n","* Token-Einsparungen durch k√ºrzere, effizientere Eingabeaufforderungen\n","* Geringere Latenz bei Anfragen, da das Modell spezialisierter wird\n","\n","Typische Anwendungsf√§lle f√ºr die Feinabstimmung sind:\n","\n","* **Stil und Ton** ‚Äì Wenn Sie den Gesamtton √§ndern m√∂chten, mit dem das LLM antwortet.\n","* **Strukturierte Ausgabe** ‚Äì Wenn Sie erzwingen m√∂chten, dass die Ausgabe immer JSON, XML oder eine andere Struktur ist.\n","* **Tool Calling** ‚Äì Wenn Sie dem LLM erm√∂glichen m√∂chten, Tools auf eine bestimmte Art und Weise zu verwenden.\n","* **Funktionsaufruf** ‚Äì Wenn Sie dem LLM erm√∂glichen m√∂chten, Funktionen auf eine bestimmte Art und Weise aufzurufen.\n","\n","### Was ist Feinabstimmung?\n","Die Textgenerierungsmodelle von OpenAI sind anhand eines breiten Datenkorpus vortrainiert, sodass sie eine breite Palette von Aufgaben bew√§ltigen k√∂nnen. Bei der sofortigen Verwendung m√ºssen Benutzer das Modell jedoch h√§ufig mit sorgf√§ltig entworfenen Eingabeaufforderungen und Beispielen steuern. Diese als ‚ÄûFew-Shot-Learning‚Äú bekannte Technik kann effektiv sein, ist jedoch durch die Anzahl der Beispiele begrenzt, die in einer Eingabeaufforderung bereitgestellt werden k√∂nnen.\n","\n","Durch die Feinabstimmung wird dies noch weiter vorangetrieben, da das Modell anhand einer viel gr√∂√üeren Anzahl von Beispielen trainiert werden kann. Dieser Prozess aktualisiert die internen Gewichte des Modells, um die spezifischen Aufgaben oder Dom√§nen, auf die Sie sich konzentrieren, besser zu bew√§ltigen und letztendlich genauere und zuverl√§ssigere Ergebnisse zu erzielen. Nach der Feinabstimmung ben√∂tigt das Modell weniger Beispiele, um auf hohem Niveau zu funktionieren, was sowohl die Eingabeaufforderungsl√§nge als auch die Kosten reduziert und gleichzeitig die Reaktionszeiten verbessert.\n","\n","### Der Feinabstimmungsprozess\n","Die Feinabstimmung umfasst normalerweise die folgenden Schritte:\n","\n","* Trainingsdaten vorbereiten und hochladen\n","Ihre Trainingsdaten sollten einen umfassenden Satz von Beispielen enthalten, die die Aufgabe oder den Bereich repr√§sentieren, den Sie verbessern m√∂chten.\n","\n","* Trainieren Sie ein neues, fein abgestimmtes Modell\n","Das Modell wird mithilfe Ihres benutzerdefinierten Datensatzes neu trainiert und seine Parameter werden so angepasst, dass sie besser Ihren Anforderungen entsprechen.\n","\n","* Ergebnisse auswerten und iterieren\n","Nach dem Training m√ºssen Sie die Leistung des Modells bewerten. Bei Bedarf k√∂nnen Sie Ihre Daten verfeinern oder die Konfiguration des Modells anpassen und es f√ºr weitere Verbesserungen erneut trainieren.\n","\n","### Implementieren und verwenden Sie Ihr optimiertes Modell\n","Wenn Sie mit der Leistung des Modells zufrieden sind, k√∂nnen Sie es f√ºr den Einsatz in der Produktion bereitstellen und so schnellere und kosteneffizientere Antworten liefern, die auf Ihre spezifischen Aufgaben zugeschnitten sind.\n","\n","Durch Feinabstimmung k√∂nnen effizientere und spezialisiertere Modelle erstellt werden, sodass Sie Zeit und Ressourcen sparen und gleichzeitig bessere Ergebnisse erzielen. Weitere Informationen zur Kostenstruktur und den Preisen f√ºr feinabgestimmte Modelle finden Sie auf unserer Preisseite.\n","\n","### Datenformate\n","\n","\n","Das Format f√ºr das LLM-Training ist ein Konversationsstil, der zum Trainieren eines dialogbasierten Modells, wie beispielsweise eines Chatbots, verwendet wird. Dieses Format organisiert den Austausch in einer Folge von ‚ÄûNachrichten‚Äú, wobei jeder Nachricht eine bestimmte ‚ÄûRolle‚Äú (entweder ‚ÄûSystem‚Äú, ‚ÄûBenutzer‚Äú oder ‚ÄûAssistent‚Äú) und ein ‚ÄûInhalt‚Äú zugewiesen wird, der den vom Benutzer bereitgestellten oder vom Assistenten generierten Text erfasst. Es erm√∂glicht dem Modell, durch √úberpr√ºfung einer Reihe von Interaktionen zu lernen, wie es im Kontext reagieren soll. Die ‚ÄûSystem‚Äú-Nachricht gibt normalerweise den Ton oder die Anweisungen f√ºr den Assistenten vor (z. B. Sarkasmus), w√§hrend nachfolgende Nachrichten ein Gespr√§ch zwischen dem Benutzer und dem Assistenten simulieren und dem Modell helfen, zu verstehen, wie kontextuell angemessene und stilistisch konsistente Antworten formuliert werden k√∂nnen.\n","\n","```\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n","```\n","\n","\n","### Feinabstimmungskosten verstehen\n","\n","\n","Die Feinabstimmung eines gro√üen Sprachmodells (LLM) kann kostspielig sein, nicht nur im Hinblick auf den anf√§nglichen Trainingsprozess, sondern auch aufgrund der laufenden Kosten f√ºr die Bereitstellung und Abfrage des Modells. Das Training eines LLM erfordert erhebliche Rechenressourcen, insbesondere wenn mit gro√üen Datens√§tzen gearbeitet wird, um die Parameter des Modells anzupassen, was zu hohen Kosten f√ºr Cloud-Dienste oder Spezialhardware f√ºhren kann. Dar√ºber hinaus ist das Hosten des Modells f√ºr den Produktionseinsatz nach der Feinabstimmung mit der Wartung einer teuren Infrastruktur zur Verarbeitung von Echtzeitabfragen verbunden, die je nach Nutzung skaliert werden kann und f√ºr eine kosteneffiziente Bereitstellung optimiert werden muss. Die kombinierten Trainings- und Betriebskosten k√∂nnen sich schnell summieren, was die Feinabstimmung zu einem ressourcenintensiven Prozess macht.\n","\n","Die Kosten f√ºr die Trainings- und Inferenzphasen haben sich im Laufe der Zeit ge√§ndert und entwickeln sich weiter. Die aktuellen Preise finden Sie hier:\n","\n","* [OpenAI Pricing](https://openai.com/api/pricing/)"]},{"cell_type":"markdown","metadata":{"id":"DFDCiJxmJTYY"},"source":["# Teil 11.2: Feinabstimmung √ºber das Dashboard\n","\n","Wir beginnen mit der Feinabstimmung unserer Modelle mithilfe der OpenAI-Website. Im n√§chsten Teil lernen wir, wie man die API verwendet. Zun√§chst verwenden wir die folgenden beiden Dateien zur Feinabstimmung. Die erste enth√§lt die Trainingsdaten; die zweite verwenden wir zur Validierung unseres Trainings.\n","\n","* [sarcastic.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl)\n","* [sarcastic_val.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl)\n","\n","Wir beginnen mit der Erstellung einiger fein abgestimmter Modelle. Sie m√ºssen die beiden Trainingsdateien in den Trainingsdialog hochladen, um alle Trainingsparameter einzugeben.\n","\n","![Finetune 1](https://data.heatonresearch.com/images/wustl/app_genai/finetune_1.jpg)\n","\n","Anschlie√üend werden Ihre Dateien vor Beginn des Trainings validiert.\n","\n","![Finetune 2](https://data.heatonresearch.com/images/wustl/app_genai/tinetune_2.jpg)\n","\n","Sobald das Training abgeschlossen ist, sehen Sie Ihr fertiges Modell. Es ist wichtig zu verstehen, dass Sie bei OpenAI vorab trainierte Modelle nicht l√∂schen k√∂nnen. Allerdings fallen auch keine Kosten f√ºr das Hochladen hochgeladener Modelle an. OpenAI berechnet Ihnen nur die Trainings- und Inferenzzeit.\n","\n","![Finetune 3](https://data.heatonresearch.com/images/wustl/app_genai/finetune_3.jpg)\n","\n","Schlie√ülich k√∂nnen wir das feinabgestimmte Modell testen.\n","\n","![Finetune 4](https://data.heatonresearch.com/images/wustl/app_genai/finetune_4.jpg)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVBafD-nJPKF"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jtIfC2KWJaNT"},"source":["# Teil 11.3: Feinabstimmung aus dem Code\n","\n","Genau wie im letzten Teil werden wir die folgenden Trainingsdaten verwenden.\n","\n","* [sarcastic.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl)\n","* [sarcastic_val.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OawqUP3Jr85z"},"outputs":[],"source":["from openai import OpenAI\n","\n","!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl\n","!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl\n","\n","client = OpenAI()\n","\n","obj = client.files.create(\n","  file=open(\"sarcastic.jsonl\", \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TZeEIbtyXxw"},"outputs":[],"source":["obj.id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQEFmRLzHCQH"},"outputs":[],"source":["status"]},{"cell_type":"markdown","metadata":{"id":"slJEgf6XiFDw"},"source":["### Ausf√ºhren und √úberwachen der Feinabstimmung"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSgK0cLbfDZA"},"outputs":[],"source":["import time\n","from openai import OpenAI\n","\n","# Beginnen Sie mit der Feinabstimmung\n","train = client.fine_tuning.jobs.create(\n","    training_file=obj.id,\n","    model=\"gpt-4o-mini-2024-07-18\"\n",")\n","\n","done = False\n","\n","# Initialisieren Sie einen Satz zum Speichern verarbeiteter Ereignis-IDs\n","processed_event_ids = set()\n","\n","while not done:\n","    # Den neuesten Status des Feinabstimmungsauftrags abrufen\n","    status = client.fine_tuning.jobs.retrieve(train.id)\n","print(f\"Auftragsstatus: {status.status}\")\n","\n","    # Alle mit der Feinabstimmung zusammenh√§ngenden Ereignisse abrufen\n","    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=train.id)\n","\n","    # Neue, noch nicht verarbeitete Ereignisse erfassen\n","    new_events = []\n","    for event in events:\n","        if event.id not in processed_event_ids:\n","            new_events.append(event)\n","            processed_event_ids.add(event.id)\n","\n","    # Sortieren Sie die neuen Ereignisse in chronologischer Reihenfolge\n","    new_events.sort(key=lambda e: e.created_at)\n","\n","    # Neue Ereignisse der Reihe nach anzeigen\n","    for event in new_events:\n","print(f\"{event.created_at}: {event.message}\")\n","\n","    if status.status == \"succeeded\":\n","        done = True\n","        print(\"Done!\")\n","    elif status.status == \"failed\":\n","        done = True\n","        print(\"Failed!\")\n","    else:\n","        print(\"Waiting for updates...\")\n","        time.sleep(20)  # 20 Sekunden schlafen\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRVAzHzYjT8T"},"outputs":[],"source":["model_id = status.fine_tuned_model\n","print(f\"ID des trainierten Modells: {model_id}\")"]},{"cell_type":"markdown","metadata":{"id":"xqdT0CyTiq2x"},"source":["### Testen Sie das fein abgestimmte Modell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5Eeuf3JiT6O"},"outputs":[],"source":["from openai import OpenAI\n","client = OpenAI()\n","\n","completion = client.chat.completions.create(\n","  model=model_id,\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n","    {\"role\": \"user\", \"content\": \"What is the capital of the USA?\"}\n","  ]\n",")\n","print(completion.choices[0].message)"]},{"cell_type":"markdown","metadata":{"id":"ukvYwN20ilos"},"source":["### Alte Modelle l√∂schen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPTpmdYbiOxp"},"outputs":[],"source":["# Client.Modelle.L√∂schen(\"ft:gpt-4o-mini-2024-07-18:pers√∂nlich:sarkastisch:A9yCtR0b\")"]},{"cell_type":"markdown","metadata":{"id":"BXVxFuRLJgyD"},"source":["# Teil 11.4: Auswerten Ihres Modells\n","\n","## Wie werden gro√üe Sprachmodelle ausgewertet?\n","\n","Bevor Sie Strategien zur Verbesserung Ihres fein abgestimmten Sprachmodells implementieren, m√ºssen Sie unbedingt verstehen, wie OpenAI diese Modelle w√§hrend des Feinabstimmungsprozesses bewertet. Dieses Verst√§ndnis erm√∂glicht es Ihnen, die von der API bereitgestellten Metriken effektiv zu interpretieren und fundierte Entscheidungen zur Verbesserung der Leistung Ihres Modells zu treffen.\n","\n","### Trainingsmetriken verstehen\n","Die wichtigsten Kennzahlen, die zur Bewertung eines Modells w√§hrend der Feinabstimmung verwendet werden, sind der Trainingsverlust und der Validierungsverlust. Diese Kennzahlen werden mithilfe der Kreuzentropieverlustfunktion berechnet, einer Standardmethode zum Messen der Differenz zwischen den vorhergesagten Wahrscheinlichkeiten und der tats√§chlichen Verteilung der Zieldaten bei Klassifizierungsaufgaben.\n","\n","### Kreuzentropieverlust\n","Der Kreuzentropieverlust quantifiziert die Leistung eines Klassifizierungsmodells, dessen Ausgabe ein Wahrscheinlichkeitswert zwischen 0 und 1 ist. Im Kontext von Sprachmodellen misst er, wie gut das Modell das n√§chste Wort in einer Sequenz vorhersagt.\n","\n","Der Kreuzentropieverlust:\n","\n","\n","$L = -\\sum_{i=1}^{N} y_i \\log(p_i)$\n","\n","Wo:\n","\n","* $ùëÅ$ ist die Anzahl der m√∂glichen Klassen (in Sprachmodellen die Vokabulargr√∂√üe).\n","* $y_i$ ist die wahre Verteilung (1 f√ºr das richtige Wort und 0 f√ºr andere).\n","* $p_i$ ist die vorhergesagte Wahrscheinlichkeit f√ºr die Klasse\n","\n","F√ºr einen Datensatz ergibt der durchschnittliche Kreuzentropieverlust √ºber alle Vorhersagen hinweg den Trainingsverlust bzw. Validierungsverlust.\n","\n","### Trainingsverlust\n","Der Trainingsverlust stellt den durchschnittlichen Kreuzentropieverlust dar, der √ºber den Trainingsdatensatz berechnet wird. Er spiegelt wider, wie gut das Modell die Trainingsdaten lernt. Ein √ºber Epochen hinweg abnehmender Trainingsverlust zeigt an, dass das Modell Muster innerhalb der Trainingsdaten effektiv erfasst.\n","\n","### Validierungsverlust\n","Der Validierungsverlust wird auf √§hnliche Weise berechnet, jedoch √ºber einen separaten Validierungsdatensatz, der vom Modell w√§hrend des Trainings nicht gesehen wurde. Er dient als Indikator f√ºr die F√§higkeit des Modells, auf neue, unbekannte Daten zu verallgemeinern. Ein geringer Validierungsverlust deutet darauf hin, dass das Modell erlernte Muster effektiv auf unbekannte Eingaben anwenden kann und nicht nur die Trainingsdaten auswendig lernt.\n","\n","### Interpretation von Verlustkurven\n","Das Aufzeigen der Trainings- und Validierungsverluste im Vergleich zu den Epochen kann dabei helfen, die Leistung des Modells zu visualisieren:\n","\n","* **Konvergenz:** Wenn beide Verluste abnehmen und sich schlie√ülich stabilisieren, lernt das Modell wahrscheinlich effektiv.\n","* **√úberanpassung:** Wenn der Trainingsverlust weiter abnimmt, w√§hrend der Validierungsverlust zunimmt, ist dies m√∂glicherweise auf eine √úberanpassung des Modells zur√ºckzuf√ºhren, d. h. das Modell merkt sich die Trainingsdaten, ohne gut zu verallgemeinern.\n","Durch die Analyse dieser Trends k√∂nnen Sie entscheiden, ob Sie Trainingsparameter anpassen, Ihren Datensatz √§ndern oder Techniken wie fr√ºhzeitiges Stoppen implementieren m√ºssen.\n","\n","### Ratlosigkeit als Bewertungsma√ü\n","Perplexit√§t ist eine weitere aus dem Kreuzentropieverlust abgeleitete Metrik, die h√§ufig in der Sprachmodellierung verwendet wird, um zu bewerten, wie gut ein Wahrscheinlichkeitsmodell eine Stichprobe vorhersagt.\n","\n","$P=e^L$\n","\n","Wobei $L$ der Kreuzentropieverlust ist. Niedrigere Perplexit√§tswerte weisen auf eine bessere Vorhersageleistung hin, da das Modell durch die Daten weniger ‚Äûperplex‚Äú ist.\n","\n","### Verwenden des Validierungsdatensatzes\n","F√ºr eine unvoreingenommene Bewertung ist die Einbeziehung eines Validierungsdatensatzes von entscheidender Bedeutung:\n","\n","* **Separate Daten:** Der Validierungsdatensatz sollte sich von den Trainingsdaten unterscheiden, um eine genaue Bewertung der Generalisierungsf√§higkeiten des Modells zu erm√∂glichen.\n","* **Verlustberechnung:** Der Validierungsverlust wird mithilfe des Kreuzentropieverlusts √ºber den Validierungsdatensatz nach jeder Epoche berechnet.\n","Durch den Vergleich von Trainings- und Validierungsverlusten k√∂nnen Sie Probleme wie √úberanpassung erkennen und Ihre Trainingsstrategie entsprechend anpassen.\n","\n","Zugriff auf detaillierte Trainingsmetriken\n","Die API von OpenAI bietet detaillierte Protokolle und Metriken w√§hrend des Feinabstimmungsprozesses:\n","\n","\n","## Wie k√∂nnen Sie die Ergebnisse beim Finetuning eines gro√üen Sprachmodells verbessern?\n","\n","Durch die Feinabstimmung gro√üer Sprachmodelle, wie sie beispielsweise von OpenAI bereitgestellt werden, k√∂nnen Entwickler diese leistungsstarken Tools an bestimmte Aufgaben und Dom√§nen anpassen. Um optimale Ergebnisse zu erzielen, ist mehr erforderlich als nur die Durchf√ºhrung des Feinabstimmungsprozesses. Es ist ein strategischer Ansatz f√ºr die Datenaufbereitung, Parameteranpassung und iterative Verbesserung erforderlich. In diesem Kapitel werden verschiedene Methoden untersucht, um die Ergebnisse der Feinabstimmung eines OpenAI-Sprachmodells mithilfe der API zu verbessern.\n","\n","### Hochwertige Trainingsdaten\n","Der Grundstein f√ºr eine effektive Feinabstimmung ist die Qualit√§t der Trainingsdaten.\n","\n","* **Relevanz:** Stellen Sie sicher, dass Ihr Datensatz eng mit den Aufgaben oder Themen √ºbereinstimmt, die das Modell behandeln soll. Wenn Sie beispielsweise ein Modell f√ºr medizinische Diagnosen entwickeln, schlie√üen Sie medizinische Fallstudien und Terminologien ein.\n","\n","* **Klarheit und Konsistenz:** Verwenden Sie eine klare, pr√§zise Sprache, um Mehrdeutigkeiten zu vermeiden. Behalten Sie im gesamten Datensatz einen konsistenten Stil, Ton und eine konsistente Formatierung bei, damit das Modell die gew√ºnschten Muster effektiv lernen kann.\n","\n","### Ausreichende Datenmenge\n","Zwar steht die Qualit√§t an erster Stelle, doch die Leistung des Modells wird auch von der Datenmenge beeinflusst.\n","\n","* **Umfassende Beispiele:** Ein gr√∂√üerer Datensatz stellt dem Modell mehr Muster zum Lernen zur Verf√ºgung und verbessert so seine F√§higkeit zur Generalisierung auf neue Eingaben.\n","\n","* **Ausgewogener Datensatz:** F√ºgen Sie eine vielf√§ltige Palette von Beispielen ein, um unterschiedliche Szenarien abzudecken, vermeiden Sie jedoch unn√∂tige Wiederholungen, die zu einer √úberanpassung f√ºhren k√∂nnten.\n","\n","### Optimieren der Datenformatierung\n","Richtig strukturierte Daten leiten das Modell w√§hrend des Trainings.\n","\n","* **JSONL-Format verwenden:** OpenAI empfiehlt das JSON Lines-Format (JSONL), wobei jede Zeile ein JSON-Objekt ist, das die Schl√ºssel ‚ÄûPrompt‚Äú und ‚ÄûCompletion‚Äú enth√§lt.\n","\n","Strukturierte Eingabeaufforderungen und Vervollst√§ndigungen: Definieren Sie die Eingabe (Eingabeaufforderung) und die erwartete Ausgabe (Vervollst√§ndigung) klar. Beispiel:\n","\n","```\n","{\n","  \"messages\": [\n","    {\"role\": \"system\", \"content\": \"You are a language translation assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Translate to French: Hello, how are you?\"},\n","    {\"role\": \"assistant\", \"content\": \"Bonjour, comment √ßa va?\"}\n","  ]\n","}\n","```\n","\n","F√ºgen Sie bei Bedarf Metadaten ein: In die Eingabeaufforderungen k√∂nnen zus√§tzliche Informationen wie Beschriftungen oder Kontextkennungen eingebettet werden, um dem Modell mehr Kontext zu verleihen.\n","\n","### Anweisungen zum Erstellen von Anweisungen\n","Durch die Anleitung des Modells mithilfe gut konzipierter Eingabeaufforderungen k√∂nnen seine Reaktionen verbessert werden.\n","\n","* **Explizite Anweisungen:** Beginnen Sie Aufforderungen mit klaren Anweisungen oder Fragen. Beispiel: ‚ÄûErkl√§ren Sie die Bedeutung der Photosynthese bei Pflanzen.‚Äú\n","\n","* **Konsistentes Eingabeaufforderungsformat:** Behalten Sie eine einheitliche Struktur in den Eingabeaufforderungen bei, damit das Modell die gew√ºnschten Antwortmuster erkennen und reproduzieren kann.\n","\n","### Anpassen der Trainingsparameter\n","Feinabstimmungsparameter beeinflussen den Lernprozess des Modells erheblich.\n","\n","* **Epochen:** Experimentieren Sie mit der Anzahl der Epochen ‚Äì der H√§ufigkeit, mit der das Modell den gesamten Trainingsdatensatz durchl√§uft. Zu wenige Epochen k√∂nnen zu Unteranpassung f√ºhren, w√§hrend zu viele zu √úberanpassung f√ºhren k√∂nnen.\n","\n","* **Batchgr√∂√üe:** Passen Sie die Batchgr√∂√üe an, also die Anzahl der Trainingsbeispiele, die in einer Iteration verwendet werden. Eine gr√∂√üere Batchgr√∂√üe kann das Training beschleunigen, erfordert aber m√∂glicherweise mehr Rechenressourcen.\n","\n","* **Lernrate:** Die Lernrate steuert, wie stark das Modell seine Gewichte bei jedem Update anpasst. Eine geeignete Lernrate gew√§hrleistet eine stabile Konvergenz.\n","\n","### Datenerweiterungstechniken\n","Durch die Erweiterung Ihres Datensatzes mittels Augmentation k√∂nnen Sie die Robustheit des Modells verbessern.\n","\n","* **Paraphrasieren:** Formulieren Sie S√§tze um, um dem Modell unterschiedliche Eingaben mit derselben Bedeutung bereitzustellen.\n","\n","* **Synonyme und Antonyme:** Ersetzen Sie W√∂rter durch Synonyme, um den Wortschatz vielf√§ltiger zu gestalten.\n","\n","* **Rauscheneinf√ºhrung:** F√ºhren Sie absichtlich kleinere Fehler oder Variationen ein, um dem Modell zu helfen, mit unvollst√§ndigen Eingaben umzugehen.\n","\n","### Regelm√§√üige Evaluierung und Iteration\n","Eine laufende Bewertung erm√∂glicht eine kontinuierliche Verbesserung.\n","\n","* **Validierungssatz:** Reservieren Sie einen Teil Ihrer Daten als Validierungssatz, um die Leistung des Modells objektiv zu bewerten.\n","\n","* **Leistungskennzahlen:** √úberwachen Sie Kennzahlen wie Genauigkeit, Verlust und Verwirrung, um Verbesserungen zu messen.\n","\n","* **Iterative Verfeinerung:** Verwenden Sie Erkenntnisse aus Auswertungen, um Ihre Trainingsdaten zu verfeinern und Parameter in nachfolgenden Trainingsrunden anzupassen.\n","\n","## Erweiterte API-Funktionen nutzen\n","Die API von OpenAI bietet Optionen zum Feinabstimmen der Modellausgaben w√§hrend der Inferenz.\n","\n","* **Temperatureinstellung:** Steuert die Zuf√§lligkeit der Ausgabe. Niedrigere Werte machen die Antworten deterministischer, w√§hrend h√∂here Werte die Kreativit√§t steigern.\n","\n","* **Top-p (Nucleus Sampling):** Passt den kumulativen Wahrscheinlichkeitsschwellenwert f√ºr die Token-Auswahl an und gleicht den Kompromiss zwischen Diversit√§t und Fokus aus.\n","\n","* **Max. Token:** Begrenzt die L√§nge der generierten Ausgabe, um √ºberm√§√üig lange Antworten zu vermeiden.\n","\n","### Fr√ºhzeitiges Stoppen implementieren\n","Verhindern Sie √úberanpassung, indem Sie das Training am optimalen Punkt beenden.\n","\n","* **Verlusttrends √ºberwachen:** Beobachten Sie den Trainings- und Validierungsverlust. Wenn der Validierungsverlust zunimmt, w√§hrend der Trainingsverlust abnimmt, liegt m√∂glicherweise eine √úberanpassung vor.\n","\n","* **Geduldsstufen festlegen:** Definieren Sie eine Anzahl von Epochen ohne Verbesserung, nach denen das Training beendet wird.\n","\n","Mehrere Feinabstimmungsrunden\n","Durch sequentielle Feinabstimmung kann die Modellleistung schrittweise verbessert werden.\n","\n","* **Umfassende Erstschulung:** Beginnen Sie mit einem allgemeinen Datensatz, um dem Modell die grundlegenden Muster beizubringen.\n","\n","* **Gezielte Verfeinerung:** Verwenden Sie in den nachfolgenden Runden spezifischere Daten, um die Leistung des Modells bei bestimmten Aufgaben zu verbessern.\n","\n","### Einbeziehung negativer Beispiele\n","Dem Modell beizubringen, was es nicht tun soll, kann genauso wichtig sein, wie ihm beizubringen, was es tun soll.\n","\n","* **Falsche Beispiele:** F√ºgen Sie Eingabeaufforderungen, die zu falschen Vervollst√§ndigungen f√ºhren, und Korrekturen ein.\n","\n","* **Strafmechanismen:** Obwohl nicht direkt unterst√ºtzt, kann die Strukturierung der Daten zur Verhinderung bestimmter Ausgaben das Modell von unerw√ºnschten Reaktionen abhalten.\n","\n","### Sicherstellung der Datensatzvielfalt\n","Ein vielf√§ltiger Datensatz hilft dem Modell, eine gro√üe Bandbreite an Eingaben zu verarbeiten.\n","\n","* **Abwechslungsreiche Themen:** Integrieren Sie Inhalte aus verschiedenen Themenbereichen.\n","\n","* **Stilistische Variation:** Verwenden Sie Beispiele mit unterschiedlichen Schreibstilen, Tonf√§llen und Formaten.\n","\n","### √úberwachung der Trainingsmetriken\n","Behalten Sie den Lernprozess des Modells im Auge.\n","\n","* **Verlustkurven:** Das Aufzeigen von Trainings- und Validierungsverlusten √ºber Epochen kann Lernmuster aufdecken.\n","\n","* **Genauigkeitsmetriken:** Verfolgen Sie gegebenenfalls, wie oft das Modell korrekte Antworten liefert.\n","\n","### Effektives Prompt-Engineering\n","Das Entwerfen von Eingabeaufforderungen, die die gew√ºnschte Reaktion hervorrufen, ist eine Kunst.\n","\n","* **Platzhalter verwenden:** Verwenden Sie Variablen in Eingabeaufforderungen, um Muster zu verallgemeinern. Beispiel: ‚ÄûBerechnen Sie die Summe von {Zahl1} und {Zahl2}.‚Äú\n","\n","* **Direktive Sprache:** Beginnen Sie Eingabeaufforderungen mit Verben wie ‚ÄûErkl√§ren‚Äú, ‚ÄûBeschreiben‚Äú oder ‚ÄûZusammenfassen‚Äú, um das Modell zu leiten.\n","\n","### Einbeziehung von Benutzerfeedback\n","Der Einsatz in der Praxis liefert wertvolle Erkenntnisse.\n","\n","* **Feedback sammeln:** Sammeln Sie Antworten von Benutzern, um St√§rken und Schw√§chen zu identifizieren.\n","\n","* **Trainingsdaten aktualisieren:** Nutzen Sie dieses Feedback, um Ihren Datensatz anzupassen, neue Beispiele hinzuzuf√ºgen oder vorhandene zu korrigieren.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJmFqyPTJdZT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"i-qb-mcqmp8U"},"source":["# Teil 11.5 Feinabstimmung mit Dreambooth\n","\n","Generative Modelle werden h√§ufig feinabgestimmt. In diesem Abschnitt werden wir ein generatives Modell feinabstimmen, um ein zus√§tzliches Objekt einzuschlie√üen, das dem Modell bekannt ist. Eine Anwendung besteht darin, Ihr eigenes Gesicht in das Modell einzuf√ºgen, wodurch Sie als Cartoon oder auf verschiedene Arten gerendert werden k√∂nnen. Abbildung 7.JEFF zeigt mich selbst als Star Trek-Figur.\n","\n","**Abbildung 11.JEFF: Jeff als Star Trek-Charakter**\n","\n","![Jeff Star Trek](https://data.heatonresearch.com/images/wustl/class/jeff-startrek.jpg)\n","\n","Der erste Schritt besteht darin, Ihre Daten zu sammeln. Sie sollten zwischen 10 und 20 verschiedene Bilder Ihres Motivs aus unterschiedlichen Winkeln haben.\n","\n","**Abbildung 11.JEFFS: Mehrere Bilder von Jeff aus verschiedenen Winkeln**\n","\n","![Jeff Star Trek](https://data.heatonresearch.com/images/wustl/class/jeffs.jpg)\n","\n","Um ein Modell zu optimieren, sollten Sie das folgende CoLab-Notizbuch verwenden. Dadurch kann Dream Booth von CoLab aus ausgef√ºhrt werden. Dream Booth ist ein Programm, das h√§ufig zum Optimieren stabiler Diffusionsmodelle verwendet wird.\n","\n","* [Finetuning with Dreambooth](https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb)\n","\n","Es gibt auch kommerzielle Dienste, die Zeit zum Erstellen stabiler Diffusionsmodelle verkaufen. Dies kann im Vergleich zur Anschaffung und Konfiguration eigener Hardware sehr wirtschaftlich sein.\n","\n","* [Diffusion Hub](https://diffusionhub.firstpromoter.com/)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0Q7yGz-JkXs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggj4JLWwJIXS"},"outputs":[],"source":[]}]}