{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOslsT2ipCgP4v8Gah5WqR8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 13: Fine-Tuning und Optimierung\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"markdown","source":["# 1 | Übersicht\n","---"],"metadata":{"id":"oYvUY6gMBKO1"}},{"cell_type":"markdown","metadata":{"id":"v2MPPX0c1pHi"},"source":["# Teil 11.1: Feinabstimmung verstehen\n","\n","OpenAI bietet Feinabstimmungsfunktionen, mit denen Benutzer Modelle wie GPT-4 für bestimmte Anwendungsfälle anpassen können, indem sie sie mit domänenspezifischen Daten trainieren. Bei der Feinabstimmung wird ein kuratierter Datensatz bereitgestellt, um die Gewichte des Modells anzupassen, was die Leistung bei speziellen Aufgaben wie der Beantwortung von Fragen, der Erstellung genauerer Vorhersagen oder der Einhaltung von Markenrichtlinien verbessert. Der Feinabstimmungsprozess von OpenAI unterstützt eine schnelle Anpassung, sodass sich das Modell besser an die Erwartungen der Benutzer anpassen und spezifische Anweisungen effektiver verarbeiten kann. Dieser Ansatz ist besonders nützlich für Branchen wie Finanzen, Gesundheitswesen oder Kundendienst, in denen Fachwissen und Präzision von entscheidender Bedeutung sind.\n","\n","Die vollständige Dokumentation von OpenAI zur Feinabstimmung finden Sie hier:\n","\n","* [OpenAI Finetuning Guide](https://platform.openai.com/docs/guides/fine-tuning)\n","\n","\n","Feinabstimmung ist eine leistungsstarke Technik, mit der Sie vorab trainierte Modelle optimieren, sie an bestimmte Aufgaben anpassen und eine höhere Leistung als mit Standardeingaben erzielen können. Während Modelle, die über APIs wie die von OpenAI verfügbar sind, anhand riesiger Datensätze vorab trainiert werden, verbessert die Feinabstimmung ihre Fähigkeiten, was mehrere wichtige Vorteile mit sich bringt:\n","\n","* Höhere Qualität der Ergebnisse als durch einfache Eingabeaufforderungen\n","* Möglichkeit, an mehr Beispielen zu trainieren, als in eine einzelne Eingabeaufforderung passen\n","* Token-Einsparungen durch kürzere, effizientere Eingabeaufforderungen\n","* Geringere Latenz bei Anfragen, da das Modell spezialisierter wird\n","\n","Typische Anwendungsfälle für die Feinabstimmung sind:\n","\n","* **Stil und Ton** – Wenn Sie den Gesamtton ändern möchten, mit dem das LLM antwortet.\n","* **Strukturierte Ausgabe** – Wenn Sie erzwingen möchten, dass die Ausgabe immer JSON, XML oder eine andere Struktur ist.\n","* **Tool Calling** – Wenn Sie dem LLM ermöglichen möchten, Tools auf eine bestimmte Art und Weise zu verwenden.\n","* **Funktionsaufruf** – Wenn Sie dem LLM ermöglichen möchten, Funktionen auf eine bestimmte Art und Weise aufzurufen.\n","\n","### Was ist Feinabstimmung?\n","Die Textgenerierungsmodelle von OpenAI sind anhand eines breiten Datenkorpus vortrainiert, sodass sie eine breite Palette von Aufgaben bewältigen können. Bei der sofortigen Verwendung müssen Benutzer das Modell jedoch häufig mit sorgfältig entworfenen Eingabeaufforderungen und Beispielen steuern. Diese als „Few-Shot-Learning“ bekannte Technik kann effektiv sein, ist jedoch durch die Anzahl der Beispiele begrenzt, die in einer Eingabeaufforderung bereitgestellt werden können.\n","\n","Durch die Feinabstimmung wird dies noch weiter vorangetrieben, da das Modell anhand einer viel größeren Anzahl von Beispielen trainiert werden kann. Dieser Prozess aktualisiert die internen Gewichte des Modells, um die spezifischen Aufgaben oder Domänen, auf die Sie sich konzentrieren, besser zu bewältigen und letztendlich genauere und zuverlässigere Ergebnisse zu erzielen. Nach der Feinabstimmung benötigt das Modell weniger Beispiele, um auf hohem Niveau zu funktionieren, was sowohl die Eingabeaufforderungslänge als auch die Kosten reduziert und gleichzeitig die Reaktionszeiten verbessert.\n","\n","### Der Feinabstimmungsprozess\n","Die Feinabstimmung umfasst normalerweise die folgenden Schritte:\n","\n","* Trainingsdaten vorbereiten und hochladen\n","Ihre Trainingsdaten sollten einen umfassenden Satz von Beispielen enthalten, die die Aufgabe oder den Bereich repräsentieren, den Sie verbessern möchten.\n","\n","* Trainieren Sie ein neues, fein abgestimmtes Modell\n","Das Modell wird mithilfe Ihres benutzerdefinierten Datensatzes neu trainiert und seine Parameter werden so angepasst, dass sie besser Ihren Anforderungen entsprechen.\n","\n","* Ergebnisse auswerten und iterieren\n","Nach dem Training müssen Sie die Leistung des Modells bewerten. Bei Bedarf können Sie Ihre Daten verfeinern oder die Konfiguration des Modells anpassen und es für weitere Verbesserungen erneut trainieren.\n","\n","### Implementieren und verwenden Sie Ihr optimiertes Modell\n","Wenn Sie mit der Leistung des Modells zufrieden sind, können Sie es für den Einsatz in der Produktion bereitstellen und so schnellere und kosteneffizientere Antworten liefern, die auf Ihre spezifischen Aufgaben zugeschnitten sind.\n","\n","Durch Feinabstimmung können effizientere und spezialisiertere Modelle erstellt werden, sodass Sie Zeit und Ressourcen sparen und gleichzeitig bessere Ergebnisse erzielen. Weitere Informationen zur Kostenstruktur und den Preisen für feinabgestimmte Modelle finden Sie auf unserer Preisseite.\n","\n","### Datenformate\n","\n","\n","Das Format für das LLM-Training ist ein Konversationsstil, der zum Trainieren eines dialogbasierten Modells, wie beispielsweise eines Chatbots, verwendet wird. Dieses Format organisiert den Austausch in einer Folge von „Nachrichten“, wobei jeder Nachricht eine bestimmte „Rolle“ (entweder „System“, „Benutzer“ oder „Assistent“) und ein „Inhalt“ zugewiesen wird, der den vom Benutzer bereitgestellten oder vom Assistenten generierten Text erfasst. Es ermöglicht dem Modell, durch Überprüfung einer Reihe von Interaktionen zu lernen, wie es im Kontext reagieren soll. Die „System“-Nachricht gibt normalerweise den Ton oder die Anweisungen für den Assistenten vor (z. B. Sarkasmus), während nachfolgende Nachrichten ein Gespräch zwischen dem Benutzer und dem Assistenten simulieren und dem Modell helfen, zu verstehen, wie kontextuell angemessene und stilistisch konsistente Antworten formuliert werden können.\n","\n","```\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n","{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n","```\n","\n","\n","### Feinabstimmungskosten verstehen\n","\n","\n","Die Feinabstimmung eines großen Sprachmodells (LLM) kann kostspielig sein, nicht nur im Hinblick auf den anfänglichen Trainingsprozess, sondern auch aufgrund der laufenden Kosten für die Bereitstellung und Abfrage des Modells. Das Training eines LLM erfordert erhebliche Rechenressourcen, insbesondere wenn mit großen Datensätzen gearbeitet wird, um die Parameter des Modells anzupassen, was zu hohen Kosten für Cloud-Dienste oder Spezialhardware führen kann. Darüber hinaus ist das Hosten des Modells für den Produktionseinsatz nach der Feinabstimmung mit der Wartung einer teuren Infrastruktur zur Verarbeitung von Echtzeitabfragen verbunden, die je nach Nutzung skaliert werden kann und für eine kosteneffiziente Bereitstellung optimiert werden muss. Die kombinierten Trainings- und Betriebskosten können sich schnell summieren, was die Feinabstimmung zu einem ressourcenintensiven Prozess macht.\n","\n","Die Kosten für die Trainings- und Inferenzphasen haben sich im Laufe der Zeit geändert und entwickeln sich weiter. Die aktuellen Preise finden Sie hier:\n","\n","* [OpenAI Pricing](https://openai.com/api/pricing/)"]},{"cell_type":"markdown","metadata":{"id":"DFDCiJxmJTYY"},"source":["# Teil 11.2: Feinabstimmung über das Dashboard\n","\n","Wir beginnen mit der Feinabstimmung unserer Modelle mithilfe der OpenAI-Website. Im nächsten Teil lernen wir, wie man die API verwendet. Zunächst verwenden wir die folgenden beiden Dateien zur Feinabstimmung. Die erste enthält die Trainingsdaten; die zweite verwenden wir zur Validierung unseres Trainings.\n","\n","* [sarcastic.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl)\n","* [sarcastic_val.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl)\n","\n","Wir beginnen mit der Erstellung einiger fein abgestimmter Modelle. Sie müssen die beiden Trainingsdateien in den Trainingsdialog hochladen, um alle Trainingsparameter einzugeben.\n","\n","![Finetune 1](https://data.heatonresearch.com/images/wustl/app_genai/finetune_1.jpg)\n","\n","Anschließend werden Ihre Dateien vor Beginn des Trainings validiert.\n","\n","![Finetune 2](https://data.heatonresearch.com/images/wustl/app_genai/tinetune_2.jpg)\n","\n","Sobald das Training abgeschlossen ist, sehen Sie Ihr fertiges Modell. Es ist wichtig zu verstehen, dass Sie bei OpenAI vorab trainierte Modelle nicht löschen können. Allerdings fallen auch keine Kosten für das Hochladen hochgeladener Modelle an. OpenAI berechnet Ihnen nur die Trainings- und Inferenzzeit.\n","\n","![Finetune 3](https://data.heatonresearch.com/images/wustl/app_genai/finetune_3.jpg)\n","\n","Schließlich können wir das feinabgestimmte Modell testen.\n","\n","![Finetune 4](https://data.heatonresearch.com/images/wustl/app_genai/finetune_4.jpg)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVBafD-nJPKF"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jtIfC2KWJaNT"},"source":["# Teil 11.3: Feinabstimmung aus dem Code\n","\n","Genau wie im letzten Teil werden wir die folgenden Trainingsdaten verwenden.\n","\n","* [sarcastic.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl)\n","* [sarcastic_val.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OawqUP3Jr85z"},"outputs":[],"source":["from openai import OpenAI\n","\n","!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl\n","!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl\n","\n","client = OpenAI()\n","\n","obj = client.files.create(\n","  file=open(\"sarcastic.jsonl\", \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TZeEIbtyXxw"},"outputs":[],"source":["obj.id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQEFmRLzHCQH"},"outputs":[],"source":["status"]},{"cell_type":"markdown","metadata":{"id":"slJEgf6XiFDw"},"source":["### Ausführen und Überwachen der Feinabstimmung"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSgK0cLbfDZA"},"outputs":[],"source":["import time\n","from openai import OpenAI\n","\n","# Beginnen Sie mit der Feinabstimmung\n","train = client.fine_tuning.jobs.create(\n","    training_file=obj.id,\n","    model=\"gpt-4o-mini-2024-07-18\"\n",")\n","\n","done = False\n","\n","# Initialisieren Sie einen Satz zum Speichern verarbeiteter Ereignis-IDs\n","processed_event_ids = set()\n","\n","while not done:\n","    # Den neuesten Status des Feinabstimmungsauftrags abrufen\n","    status = client.fine_tuning.jobs.retrieve(train.id)\n","print(f\"Auftragsstatus: {status.status}\")\n","\n","    # Alle mit der Feinabstimmung zusammenhängenden Ereignisse abrufen\n","    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=train.id)\n","\n","    # Neue, noch nicht verarbeitete Ereignisse erfassen\n","    new_events = []\n","    for event in events:\n","        if event.id not in processed_event_ids:\n","            new_events.append(event)\n","            processed_event_ids.add(event.id)\n","\n","    # Sortieren Sie die neuen Ereignisse in chronologischer Reihenfolge\n","    new_events.sort(key=lambda e: e.created_at)\n","\n","    # Neue Ereignisse der Reihe nach anzeigen\n","    for event in new_events:\n","print(f\"{event.created_at}: {event.message}\")\n","\n","    if status.status == \"succeeded\":\n","        done = True\n","        print(\"Done!\")\n","    elif status.status == \"failed\":\n","        done = True\n","        print(\"Failed!\")\n","    else:\n","        print(\"Waiting for updates...\")\n","        time.sleep(20)  # 20 Sekunden schlafen\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRVAzHzYjT8T"},"outputs":[],"source":["model_id = status.fine_tuned_model\n","print(f\"ID des trainierten Modells: {model_id}\")"]},{"cell_type":"markdown","metadata":{"id":"xqdT0CyTiq2x"},"source":["### Testen Sie das fein abgestimmte Modell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5Eeuf3JiT6O"},"outputs":[],"source":["from openai import OpenAI\n","client = OpenAI()\n","\n","completion = client.chat.completions.create(\n","  model=model_id,\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n","    {\"role\": \"user\", \"content\": \"What is the capital of the USA?\"}\n","  ]\n",")\n","print(completion.choices[0].message)"]},{"cell_type":"markdown","metadata":{"id":"ukvYwN20ilos"},"source":["### Alte Modelle löschen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPTpmdYbiOxp"},"outputs":[],"source":["# Client.Modelle.Löschen(\"ft:gpt-4o-mini-2024-07-18:persönlich:sarkastisch:A9yCtR0b\")"]},{"cell_type":"markdown","metadata":{"id":"BXVxFuRLJgyD"},"source":["# Teil 11.4: Auswerten Ihres Modells\n","\n","## Wie werden große Sprachmodelle ausgewertet?\n","\n","Bevor Sie Strategien zur Verbesserung Ihres fein abgestimmten Sprachmodells implementieren, müssen Sie unbedingt verstehen, wie OpenAI diese Modelle während des Feinabstimmungsprozesses bewertet. Dieses Verständnis ermöglicht es Ihnen, die von der API bereitgestellten Metriken effektiv zu interpretieren und fundierte Entscheidungen zur Verbesserung der Leistung Ihres Modells zu treffen.\n","\n","### Trainingsmetriken verstehen\n","Die wichtigsten Kennzahlen, die zur Bewertung eines Modells während der Feinabstimmung verwendet werden, sind der Trainingsverlust und der Validierungsverlust. Diese Kennzahlen werden mithilfe der Kreuzentropieverlustfunktion berechnet, einer Standardmethode zum Messen der Differenz zwischen den vorhergesagten Wahrscheinlichkeiten und der tatsächlichen Verteilung der Zieldaten bei Klassifizierungsaufgaben.\n","\n","### Kreuzentropieverlust\n","Der Kreuzentropieverlust quantifiziert die Leistung eines Klassifizierungsmodells, dessen Ausgabe ein Wahrscheinlichkeitswert zwischen 0 und 1 ist. Im Kontext von Sprachmodellen misst er, wie gut das Modell das nächste Wort in einer Sequenz vorhersagt.\n","\n","Der Kreuzentropieverlust:\n","\n","\n","$L = -\\sum_{i=1}^{N} y_i \\log(p_i)$\n","\n","Wo:\n","\n","* $𝑁$ ist die Anzahl der möglichen Klassen (in Sprachmodellen die Vokabulargröße).\n","* $y_i$ ist die wahre Verteilung (1 für das richtige Wort und 0 für andere).\n","* $p_i$ ist die vorhergesagte Wahrscheinlichkeit für die Klasse\n","\n","Für einen Datensatz ergibt der durchschnittliche Kreuzentropieverlust über alle Vorhersagen hinweg den Trainingsverlust bzw. Validierungsverlust.\n","\n","### Trainingsverlust\n","Der Trainingsverlust stellt den durchschnittlichen Kreuzentropieverlust dar, der über den Trainingsdatensatz berechnet wird. Er spiegelt wider, wie gut das Modell die Trainingsdaten lernt. Ein über Epochen hinweg abnehmender Trainingsverlust zeigt an, dass das Modell Muster innerhalb der Trainingsdaten effektiv erfasst.\n","\n","### Validierungsverlust\n","Der Validierungsverlust wird auf ähnliche Weise berechnet, jedoch über einen separaten Validierungsdatensatz, der vom Modell während des Trainings nicht gesehen wurde. Er dient als Indikator für die Fähigkeit des Modells, auf neue, unbekannte Daten zu verallgemeinern. Ein geringer Validierungsverlust deutet darauf hin, dass das Modell erlernte Muster effektiv auf unbekannte Eingaben anwenden kann und nicht nur die Trainingsdaten auswendig lernt.\n","\n","### Interpretation von Verlustkurven\n","Das Aufzeigen der Trainings- und Validierungsverluste im Vergleich zu den Epochen kann dabei helfen, die Leistung des Modells zu visualisieren:\n","\n","* **Konvergenz:** Wenn beide Verluste abnehmen und sich schließlich stabilisieren, lernt das Modell wahrscheinlich effektiv.\n","* **Überanpassung:** Wenn der Trainingsverlust weiter abnimmt, während der Validierungsverlust zunimmt, ist dies möglicherweise auf eine Überanpassung des Modells zurückzuführen, d. h. das Modell merkt sich die Trainingsdaten, ohne gut zu verallgemeinern.\n","Durch die Analyse dieser Trends können Sie entscheiden, ob Sie Trainingsparameter anpassen, Ihren Datensatz ändern oder Techniken wie frühzeitiges Stoppen implementieren müssen.\n","\n","### Ratlosigkeit als Bewertungsmaß\n","Perplexität ist eine weitere aus dem Kreuzentropieverlust abgeleitete Metrik, die häufig in der Sprachmodellierung verwendet wird, um zu bewerten, wie gut ein Wahrscheinlichkeitsmodell eine Stichprobe vorhersagt.\n","\n","$P=e^L$\n","\n","Wobei $L$ der Kreuzentropieverlust ist. Niedrigere Perplexitätswerte weisen auf eine bessere Vorhersageleistung hin, da das Modell durch die Daten weniger „perplex“ ist.\n","\n","### Verwenden des Validierungsdatensatzes\n","Für eine unvoreingenommene Bewertung ist die Einbeziehung eines Validierungsdatensatzes von entscheidender Bedeutung:\n","\n","* **Separate Daten:** Der Validierungsdatensatz sollte sich von den Trainingsdaten unterscheiden, um eine genaue Bewertung der Generalisierungsfähigkeiten des Modells zu ermöglichen.\n","* **Verlustberechnung:** Der Validierungsverlust wird mithilfe des Kreuzentropieverlusts über den Validierungsdatensatz nach jeder Epoche berechnet.\n","Durch den Vergleich von Trainings- und Validierungsverlusten können Sie Probleme wie Überanpassung erkennen und Ihre Trainingsstrategie entsprechend anpassen.\n","\n","Zugriff auf detaillierte Trainingsmetriken\n","Die API von OpenAI bietet detaillierte Protokolle und Metriken während des Feinabstimmungsprozesses:\n","\n","\n","## Wie können Sie die Ergebnisse beim Finetuning eines großen Sprachmodells verbessern?\n","\n","Durch die Feinabstimmung großer Sprachmodelle, wie sie beispielsweise von OpenAI bereitgestellt werden, können Entwickler diese leistungsstarken Tools an bestimmte Aufgaben und Domänen anpassen. Um optimale Ergebnisse zu erzielen, ist mehr erforderlich als nur die Durchführung des Feinabstimmungsprozesses. Es ist ein strategischer Ansatz für die Datenaufbereitung, Parameteranpassung und iterative Verbesserung erforderlich. In diesem Kapitel werden verschiedene Methoden untersucht, um die Ergebnisse der Feinabstimmung eines OpenAI-Sprachmodells mithilfe der API zu verbessern.\n","\n","### Hochwertige Trainingsdaten\n","Der Grundstein für eine effektive Feinabstimmung ist die Qualität der Trainingsdaten.\n","\n","* **Relevanz:** Stellen Sie sicher, dass Ihr Datensatz eng mit den Aufgaben oder Themen übereinstimmt, die das Modell behandeln soll. Wenn Sie beispielsweise ein Modell für medizinische Diagnosen entwickeln, schließen Sie medizinische Fallstudien und Terminologien ein.\n","\n","* **Klarheit und Konsistenz:** Verwenden Sie eine klare, präzise Sprache, um Mehrdeutigkeiten zu vermeiden. Behalten Sie im gesamten Datensatz einen konsistenten Stil, Ton und eine konsistente Formatierung bei, damit das Modell die gewünschten Muster effektiv lernen kann.\n","\n","### Ausreichende Datenmenge\n","Zwar steht die Qualität an erster Stelle, doch die Leistung des Modells wird auch von der Datenmenge beeinflusst.\n","\n","* **Umfassende Beispiele:** Ein größerer Datensatz stellt dem Modell mehr Muster zum Lernen zur Verfügung und verbessert so seine Fähigkeit zur Generalisierung auf neue Eingaben.\n","\n","* **Ausgewogener Datensatz:** Fügen Sie eine vielfältige Palette von Beispielen ein, um unterschiedliche Szenarien abzudecken, vermeiden Sie jedoch unnötige Wiederholungen, die zu einer Überanpassung führen könnten.\n","\n","### Optimieren der Datenformatierung\n","Richtig strukturierte Daten leiten das Modell während des Trainings.\n","\n","* **JSONL-Format verwenden:** OpenAI empfiehlt das JSON Lines-Format (JSONL), wobei jede Zeile ein JSON-Objekt ist, das die Schlüssel „Prompt“ und „Completion“ enthält.\n","\n","Strukturierte Eingabeaufforderungen und Vervollständigungen: Definieren Sie die Eingabe (Eingabeaufforderung) und die erwartete Ausgabe (Vervollständigung) klar. Beispiel:\n","\n","```\n","{\n","  \"messages\": [\n","    {\"role\": \"system\", \"content\": \"You are a language translation assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Translate to French: Hello, how are you?\"},\n","    {\"role\": \"assistant\", \"content\": \"Bonjour, comment ça va?\"}\n","  ]\n","}\n","```\n","\n","Fügen Sie bei Bedarf Metadaten ein: In die Eingabeaufforderungen können zusätzliche Informationen wie Beschriftungen oder Kontextkennungen eingebettet werden, um dem Modell mehr Kontext zu verleihen.\n","\n","### Anweisungen zum Erstellen von Anweisungen\n","Durch die Anleitung des Modells mithilfe gut konzipierter Eingabeaufforderungen können seine Reaktionen verbessert werden.\n","\n","* **Explizite Anweisungen:** Beginnen Sie Aufforderungen mit klaren Anweisungen oder Fragen. Beispiel: „Erklären Sie die Bedeutung der Photosynthese bei Pflanzen.“\n","\n","* **Konsistentes Eingabeaufforderungsformat:** Behalten Sie eine einheitliche Struktur in den Eingabeaufforderungen bei, damit das Modell die gewünschten Antwortmuster erkennen und reproduzieren kann.\n","\n","### Anpassen der Trainingsparameter\n","Feinabstimmungsparameter beeinflussen den Lernprozess des Modells erheblich.\n","\n","* **Epochen:** Experimentieren Sie mit der Anzahl der Epochen – der Häufigkeit, mit der das Modell den gesamten Trainingsdatensatz durchläuft. Zu wenige Epochen können zu Unteranpassung führen, während zu viele zu Überanpassung führen können.\n","\n","* **Batchgröße:** Passen Sie die Batchgröße an, also die Anzahl der Trainingsbeispiele, die in einer Iteration verwendet werden. Eine größere Batchgröße kann das Training beschleunigen, erfordert aber möglicherweise mehr Rechenressourcen.\n","\n","* **Lernrate:** Die Lernrate steuert, wie stark das Modell seine Gewichte bei jedem Update anpasst. Eine geeignete Lernrate gewährleistet eine stabile Konvergenz.\n","\n","### Datenerweiterungstechniken\n","Durch die Erweiterung Ihres Datensatzes mittels Augmentation können Sie die Robustheit des Modells verbessern.\n","\n","* **Paraphrasieren:** Formulieren Sie Sätze um, um dem Modell unterschiedliche Eingaben mit derselben Bedeutung bereitzustellen.\n","\n","* **Synonyme und Antonyme:** Ersetzen Sie Wörter durch Synonyme, um den Wortschatz vielfältiger zu gestalten.\n","\n","* **Rauscheneinführung:** Führen Sie absichtlich kleinere Fehler oder Variationen ein, um dem Modell zu helfen, mit unvollständigen Eingaben umzugehen.\n","\n","### Regelmäßige Evaluierung und Iteration\n","Eine laufende Bewertung ermöglicht eine kontinuierliche Verbesserung.\n","\n","* **Validierungssatz:** Reservieren Sie einen Teil Ihrer Daten als Validierungssatz, um die Leistung des Modells objektiv zu bewerten.\n","\n","* **Leistungskennzahlen:** Überwachen Sie Kennzahlen wie Genauigkeit, Verlust und Verwirrung, um Verbesserungen zu messen.\n","\n","* **Iterative Verfeinerung:** Verwenden Sie Erkenntnisse aus Auswertungen, um Ihre Trainingsdaten zu verfeinern und Parameter in nachfolgenden Trainingsrunden anzupassen.\n","\n","## Erweiterte API-Funktionen nutzen\n","Die API von OpenAI bietet Optionen zum Feinabstimmen der Modellausgaben während der Inferenz.\n","\n","* **Temperatureinstellung:** Steuert die Zufälligkeit der Ausgabe. Niedrigere Werte machen die Antworten deterministischer, während höhere Werte die Kreativität steigern.\n","\n","* **Top-p (Nucleus Sampling):** Passt den kumulativen Wahrscheinlichkeitsschwellenwert für die Token-Auswahl an und gleicht den Kompromiss zwischen Diversität und Fokus aus.\n","\n","* **Max. Token:** Begrenzt die Länge der generierten Ausgabe, um übermäßig lange Antworten zu vermeiden.\n","\n","### Frühzeitiges Stoppen implementieren\n","Verhindern Sie Überanpassung, indem Sie das Training am optimalen Punkt beenden.\n","\n","* **Verlusttrends überwachen:** Beobachten Sie den Trainings- und Validierungsverlust. Wenn der Validierungsverlust zunimmt, während der Trainingsverlust abnimmt, liegt möglicherweise eine Überanpassung vor.\n","\n","* **Geduldsstufen festlegen:** Definieren Sie eine Anzahl von Epochen ohne Verbesserung, nach denen das Training beendet wird.\n","\n","Mehrere Feinabstimmungsrunden\n","Durch sequentielle Feinabstimmung kann die Modellleistung schrittweise verbessert werden.\n","\n","* **Umfassende Erstschulung:** Beginnen Sie mit einem allgemeinen Datensatz, um dem Modell die grundlegenden Muster beizubringen.\n","\n","* **Gezielte Verfeinerung:** Verwenden Sie in den nachfolgenden Runden spezifischere Daten, um die Leistung des Modells bei bestimmten Aufgaben zu verbessern.\n","\n","### Einbeziehung negativer Beispiele\n","Dem Modell beizubringen, was es nicht tun soll, kann genauso wichtig sein, wie ihm beizubringen, was es tun soll.\n","\n","* **Falsche Beispiele:** Fügen Sie Eingabeaufforderungen, die zu falschen Vervollständigungen führen, und Korrekturen ein.\n","\n","* **Strafmechanismen:** Obwohl nicht direkt unterstützt, kann die Strukturierung der Daten zur Verhinderung bestimmter Ausgaben das Modell von unerwünschten Reaktionen abhalten.\n","\n","### Sicherstellung der Datensatzvielfalt\n","Ein vielfältiger Datensatz hilft dem Modell, eine große Bandbreite an Eingaben zu verarbeiten.\n","\n","* **Abwechslungsreiche Themen:** Integrieren Sie Inhalte aus verschiedenen Themenbereichen.\n","\n","* **Stilistische Variation:** Verwenden Sie Beispiele mit unterschiedlichen Schreibstilen, Tonfällen und Formaten.\n","\n","### Überwachung der Trainingsmetriken\n","Behalten Sie den Lernprozess des Modells im Auge.\n","\n","* **Verlustkurven:** Das Aufzeigen von Trainings- und Validierungsverlusten über Epochen kann Lernmuster aufdecken.\n","\n","* **Genauigkeitsmetriken:** Verfolgen Sie gegebenenfalls, wie oft das Modell korrekte Antworten liefert.\n","\n","### Effektives Prompt-Engineering\n","Das Entwerfen von Eingabeaufforderungen, die die gewünschte Reaktion hervorrufen, ist eine Kunst.\n","\n","* **Platzhalter verwenden:** Verwenden Sie Variablen in Eingabeaufforderungen, um Muster zu verallgemeinern. Beispiel: „Berechnen Sie die Summe von {Zahl1} und {Zahl2}.“\n","\n","* **Direktive Sprache:** Beginnen Sie Eingabeaufforderungen mit Verben wie „Erklären“, „Beschreiben“ oder „Zusammenfassen“, um das Modell zu leiten.\n","\n","### Einbeziehung von Benutzerfeedback\n","Der Einsatz in der Praxis liefert wertvolle Erkenntnisse.\n","\n","* **Feedback sammeln:** Sammeln Sie Antworten von Benutzern, um Stärken und Schwächen zu identifizieren.\n","\n","* **Trainingsdaten aktualisieren:** Nutzen Sie dieses Feedback, um Ihren Datensatz anzupassen, neue Beispiele hinzuzufügen oder vorhandene zu korrigieren.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJmFqyPTJdZT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"i-qb-mcqmp8U"},"source":["# Teil 11.5 Feinabstimmung mit Dreambooth\n","\n","Generative Modelle werden häufig feinabgestimmt. In diesem Abschnitt werden wir ein generatives Modell feinabstimmen, um ein zusätzliches Objekt einzuschließen, das dem Modell bekannt ist. Eine Anwendung besteht darin, Ihr eigenes Gesicht in das Modell einzufügen, wodurch Sie als Cartoon oder auf verschiedene Arten gerendert werden können. Abbildung 7.JEFF zeigt mich selbst als Star Trek-Figur.\n","\n","**Abbildung 11.JEFF: Jeff als Star Trek-Charakter**\n","\n","![Jeff Star Trek](https://data.heatonresearch.com/images/wustl/class/jeff-startrek.jpg)\n","\n","Der erste Schritt besteht darin, Ihre Daten zu sammeln. Sie sollten zwischen 10 und 20 verschiedene Bilder Ihres Motivs aus unterschiedlichen Winkeln haben.\n","\n","**Abbildung 11.JEFFS: Mehrere Bilder von Jeff aus verschiedenen Winkeln**\n","\n","![Jeff Star Trek](https://data.heatonresearch.com/images/wustl/class/jeffs.jpg)\n","\n","Um ein Modell zu optimieren, sollten Sie das folgende CoLab-Notizbuch verwenden. Dadurch kann Dream Booth von CoLab aus ausgeführt werden. Dream Booth ist ein Programm, das häufig zum Optimieren stabiler Diffusionsmodelle verwendet wird.\n","\n","* [Finetuning with Dreambooth](https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb)\n","\n","Es gibt auch kommerzielle Dienste, die Zeit zum Erstellen stabiler Diffusionsmodelle verkaufen. Dies kann im Vergleich zur Anschaffung und Konfiguration eigener Hardware sehr wirtschaftlich sein.\n","\n","* [Diffusion Hub](https://diffusionhub.firstpromoter.com/)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0Q7yGz-JkXs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggj4JLWwJIXS"},"outputs":[],"source":[]}]}