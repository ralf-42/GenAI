{"cells":[{"cell_type":"markdown","id":"a1b6ca37","metadata":{"id":"a1b6ca37"},"source":["<p><font size=\"6\" color='grey'> <b>\n","Generative KI\n","</b></font> </br></p>\n","\n","<p><font size=\"5\" color='grey'> <b>\n","LangChain Einfacher Chatbot\n","</b></font> </br></p>\n","\n","---"]},{"cell_type":"markdown","source":["## Aufgabenbeschreibung des Programms:\n","\n","Dieses Programm implementiert einen einfachen Chatbot mit Hilfe von LangChain und OpenAI's GPT-3.5-turbo Modell.\n","\n","**Funktionalit√§t:**\n","\n","* Der Chatbot kann menschen√§hnlichen Text in einer Konversation generieren.\n","* Er verwendet die  `ChatOpenAI` Klasse von LangChain, um mit dem GPT-Modell zu interagieren.\n","* Die Chat-Historie wird im LangChain-Format gespeichert und f√ºr die Generierung jeder neuen Antwort verwendet.\n","* Das Programm nutzt Gradio, um eine einfache und interaktive Chat-Oberfl√§che bereitzustellen.\n","\n","**Einschr√§nkungen:**\n","\n","* Dieser Chatbot hat kein \"Ged√§chtnis\" √ºber die aktuelle Sitzung hinaus.\n","* Es werden keine externen Datenquellen oder Wissensdatenbanken verwendet.\n","* Es gibt kein Prompt-Engineering oder spezielle Anpassungen f√ºr bestimmte Aufgaben.\n","\n","**Zusammenfassend:**\n","\n","Dieses Programm demonstriert eine einfache Implementierung eines Chatbots mit LangChain und OpenAI. Es dient als Grundlage f√ºr komplexere Chatbot-Anwendungen, die zus√§tzliche Funktionen wie Datenintegration, Prompt-Engineering und Kontextmanagement beinhalten k√∂nnen.\n"],"metadata":{"id":"YshNJYISL3hc"},"id":"YshNJYISL3hc"},{"cell_type":"markdown","source":["\n","\n","# **1 <font color='orange'>|</font> Setup und Installation**\n","---"],"metadata":{"id":"gzaJfnP8_e7I"},"id":"gzaJfnP8_e7I"},{"cell_type":"code","execution_count":null,"id":"30eefdcb","metadata":{"id":"30eefdcb"},"outputs":[],"source":["%%writefile requirements.txt\n","gradio>=3.0.0\n","httpx==0.27.2\n","langchain-community>=0.0.1\n","langchain-openai>=0.0.1\n","openai==1.55.3\n","anyio==3.7.1"]},{"cell_type":"code","execution_count":null,"id":"4dd60e1d","metadata":{"id":"4dd60e1d"},"outputs":[],"source":["# Install\n","!uv pip install -q -U --system -r requirements.txt"]},{"cell_type":"code","source":["# Bei Proxi Fehler\n","# !pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet\n","# import os\n","# os.kill(os.getpid(), 9)"],"metadata":{"id":"xcgIGsfaCVek"},"id":"xcgIGsfaCVek","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"89aca166","metadata":{"id":"89aca166"},"outputs":[],"source":["# Standardbibliotheken\n","import os\n","\n","# Drittanbieterbibliotheken\n","import gradio as gr\n","from google.colab import userdata\n","from langchain_openai import ChatOpenAI\n","from langchain.schema import AIMessage, HumanMessage"]},{"cell_type":"markdown","id":"d7d8f5dd","metadata":{"id":"d7d8f5dd"},"source":["# **2 <font color='orange'>|</font> Konfiguration und Umgebungsvariablen**\n","---"]},{"cell_type":"code","execution_count":null,"id":"c357da0f","metadata":{"id":"c357da0f"},"outputs":[],"source":["# OpenAI API Key setzen\n","OPENAI_API_KEY = userdata.get('OpenAI-API-Key')\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n","\n","# Model Parameter\n","MODEL_NAME = \"gpt-3.5-turbo\"\n","\n","# Modell erstellen\n","model = ChatOpenAI(model=MODEL_NAME)"]},{"cell_type":"markdown","id":"ca1d6111","metadata":{"id":"ca1d6111"},"source":["# **3 <font color='orange'>|</font> Datenvorverarbeitung und Embedding**\n","---"]},{"cell_type":"markdown","source":["\n","*nicht relevant f√ºr diesen einfachen Chatbot*"],"metadata":{"id":"-KE1eOok--tW"},"id":"-KE1eOok--tW"},{"cell_type":"markdown","source":["# **4 <font color='orange'>|</font> Memory und Kontextmanagement**\n","---"],"metadata":{"id":"A7Ux3S6m_AB6"},"id":"A7Ux3S6m_AB6"},{"cell_type":"markdown","source":["\n","*nicht relevant f√ºr diesen einfachen Chatbot*"],"metadata":{"id":"a4voi7oEMzpt"},"id":"a4voi7oEMzpt"},{"cell_type":"markdown","id":"93924adc","metadata":{"id":"93924adc"},"source":["# **5 <font color='orange'>|</font> Prompt-Engineering**\n","---"]},{"cell_type":"markdown","source":["\n","*nicht relevant f√ºr diesen einfachen Chatbot*"],"metadata":{"id":"iKsp66ja_DJJ"},"id":"iKsp66ja_DJJ"},{"cell_type":"markdown","source":["\n","\n","# **6 <font color='orange'>|</font> RAG-Chatbot-Architektur**\n","---"],"metadata":{"id":"3efgFizS_EXt"},"id":"3efgFizS_EXt"},{"cell_type":"code","source":["def predict(message, history):\n","    \"\"\"\n","    Verarbeitet die Chat Nachrichten und gibt die Modelantwort zur√ºck\n","\n","    Args:\n","        message: Aktuelle Nachricht\n","        history: Chat Historie\n","\n","    Returns:\n","        str: Antwort des Models\n","    \"\"\"\n","\n","    # Konvertiere Chat Historie in LangChain Format\n","    history_langchain_format = []\n","    for msg in history:\n","        if msg['role'] == \"user\":\n","            history_langchain_format.append(HumanMessage(content=msg['content']))\n","        elif msg['role'] == \"assistant\":\n","            history_langchain_format.append(AIMessage(content=msg['content']))\n","\n","    # F√ºge aktuelle Nachricht hinzu\n","    history_langchain_format.append(HumanMessage(content=message))\n","\n","    # Model Antwort generieren\n","    gpt_response = model.invoke(history_langchain_format)\n","    return gpt_response.content"],"metadata":{"id":"OPJWAlSiM046"},"id":"OPJWAlSiM046","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","# **7 <font color='orange'>|</font> Interaktions- und Testfunktionen**\n","---"],"metadata":{"id":"0o17l_BJ_F3G"},"id":"0o17l_BJ_F3G"},{"cell_type":"code","execution_count":null,"id":"ae2d7707","metadata":{"id":"ae2d7707"},"outputs":[],"source":["demo = gr.ChatInterface(\n","    predict,\n","    type=\"messages\",\n","    title=\"ü§ñ Einfacher LangChain ChatBot\",\n","    description=\"Ein einfacher Chatbot basierend auf LangChain und OpenAI GPT\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"8c27bccb","metadata":{"lines_to_next_cell":0,"id":"8c27bccb"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    demo.launch()"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"collapsed_sections":["YshNJYISL3hc","gzaJfnP8_e7I","d7d8f5dd","ca1d6111","A7Ux3S6m_AB6","93924adc","3efgFizS_EXt","0o17l_BJ_F3G"],"toc_visible":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}