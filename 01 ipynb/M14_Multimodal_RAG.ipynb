{"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"Ih2CTVBnArVZ"},"id":"Ih2CTVBnArVZ"},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Multimodales RAG\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"},"id":"6jJZ7wbdArVc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c8df5ef"},"outputs":[],"source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/Python_Modules\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"id":"9c8df5ef"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d2e699d"},"outputs":[],"source":["#@title üõ†Ô∏è Installationen { display-mode: \"form\" }\n","install_packages([\n","    ('markitdown[all]', 'markitdown'),\n","    'langchain_chroma',\n","])"],"id":"4d2e699d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"da4cf78d"},"outputs":[],"source":["#@title üìÇ Dokumente, Bilder, Modul { display-mode: \"form\" }\n","!rm -rf files\n","!mkdir files\n","\n","# --- Texte\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_1.txt -o files/biografien_1.txt\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_2.md -o files/biografien_2.md\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_3.pdf -o files/biografien_3.pdf\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_4.docx -o files/biografien_4.docx\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/roboter.txt -o files/roboter.txt\n","\n","# --- Bilder\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/retro_robot.jpg -o files/retro_robot.jpg\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/hedra_cyborg.png -o files/hedra_cyborg.png\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/apfel.png -o files/apfel.png\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/zwei_roboter.png -o zwei_roboter.png\n","\n","# --- Python-Modul\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/01%20ipynb/multimodal_rag_modul.py -o multimodal_rag_modul.py"],"id":"da4cf78d"},{"cell_type":"markdown","source":["# 1 | RAG-Prozess\n","---"],"metadata":{"id":"B41ZbXwBQ2eW"},"id":"B41ZbXwBQ2eW"},{"cell_type":"markdown","source":["In dem entwickelten **multimodalen Retrieval-Augmented-Generation (RAG)**-System werden sowohl Text- als auch Bilddaten verarbeitet.\n","F√ºr die **Bildverarbeitung** kommt ein zweistufiger Ansatz zum Einsatz:\n","\n","1. **Image-Embedding:**\n","   Das Bild wird in einen hochdimensionalen Vektorraum eingebettet, um visuelle Merkmale wie Formen, Farben und Strukturen numerisch zu repr√§sentieren.\n","\n","2. **Textbeschreibung und Text-Embedding:**\n","   Zus√§tzlich wird mit *gpt-4o-mini* eine sprachliche Beschreibung des Bildes erzeugt. Diese Beschreibung wird anschlie√üend in ein Text-Embedding √ºberf√ºhrt, um semantische Informationen textbasiert nutzbar zu machen.\n","\n","---\n","\n","**Vorteile des Ansatzes:**\n","\n","* **Erweiterte semantische Repr√§sentation:**\n","  Durch die Kombination von visuellen und sprachlichen Embeddings werden sowohl konkrete als auch konzeptuelle Eigenschaften eines Bildes abgebildet.\n","\n","* **Verbesserte Retrieval-Qualit√§t:**\n","  Textbasierte Suchanfragen k√∂nnen nicht nur √ºber visuelle √Ñhnlichkeiten, sondern auch √ºber die semantisch beschriebene Bedeutung der Bilder beantwortet werden.\n","\n","* **H√∂here Interpretierbarkeit:**\n","  Die generierte Bildbeschreibung erm√∂glicht eine transparente Nachvollziehbarkeit der zugrunde liegenden Repr√§sentationen und unterst√ºtzt bei der Evaluierung der Ergebnisse.\n","\n","* **Gute Erweiterbarkeit:**\n","  Das Verfahren ist modular aufgebaut und l√§sst sich leicht um weitere Modalit√§ten wie Audio oder Video erg√§nzen.\n"],"metadata":{"id":"w8JVLgSaEljT"},"id":"w8JVLgSaEljT"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","RAG-Prozess f√ºr Texte\n","</font></p>"],"metadata":{"id":"RQ6sRV_FCboz"},"id":"RQ6sRV_FCboz"},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/rag_process.png\" width=\"600\" alt=\"Avatar\">"],"metadata":{"id":"bC_Exz8iWjIN"},"id":"bC_Exz8iWjIN"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","RAG-Prozess f√ºr Bilder\n","</font></p>"],"metadata":{"id":"a2aUO4bhCgtv"},"id":"a2aUO4bhCgtv"},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/rag_process_03.png\" width=\"600\" alt=\"Avatar\">"],"metadata":{"id":"Uubxl-tr_1I_"},"id":"Uubxl-tr_1I_"},{"cell_type":"markdown","id":"ce95c6f6","metadata":{"id":"ce95c6f6"},"source":["# 2 | Modul `multimodal_rag`\n","---"]},{"cell_type":"markdown","source":["Python-Modul f√ºr ein **funktionales multimodales RAG-System**, das Text- und Bilddokumente in einer einheitlichen Vektordatenbank verwaltet und durchsucht.\n","\n","**Modalit√§tsrichtungen**\n","\n","| Eingabe (Query) | Ausgabe (Antwort) | Beispiel / Beschreibung | Status |\n","|-----------------|-------------------|-------------------------|--------|\n","| **Text ‚Üí Text** | Textbasierte Frage f√ºhrt zu Textantwort | Klassisches RAG-System (z.B. Chatbot, Q&A) | ‚úÖ |\n","| **Text ‚Üí Bild** | Textanfrage findet relevante Bilder | \"Zeige mir Roboter-Bilder\" | ‚úÖ |\n","| **Bild ‚Üí Text** | Bildanalyse oder Captioning | \"Was ist auf diesem Foto zu sehen?\" | ‚úÖ |\n","| **Bild ‚Üí Bild** | Bildretrieval oder visuelle Transformation | \"Finde √§hnliche Bilder\" | ‚úÖ |\n","| **Text + Bild ‚Üí Text** | Kombination zur Textgenerierung | \"Welche Informationen enth√§lt dieses Diagramm?\" | ‚ùå |\n","| **Text + Bild ‚Üí Bild** | Bedingte Bildgenerierung | \"Mach aus diesem Bild eine Winterversion\" | ‚ùå |\n","\n","**Hauptvorteile**\n","\n","1. **Funktionale Architektur**: Klare Trennung von Konfiguration, Komponenten und Funktionen\n","2. **Einheitliche Datenbank**: ChromaDB mit separaten Collections f√ºr Text und Bilder\n","3. **Hybride Suche**: Text-Embeddings (OpenAI) + Bild-Embeddings (CLIP)\n","4. **Flexible Konfiguration**: Alle Parameter √ºber RAGConfig anpassbar\n","5. **Bildbeschreibung**: Zu jedem Bild wird zus√§tzlich eine Bildbeschreibung erstellt."],"metadata":{"id":"goAFmj5RYrAK"},"id":"goAFmj5RYrAK"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Aufbau\n","</font></p>\n","\n","**RAGConfig**\n","- Zentrale Konfigurationsklasse\n","- Anpassbare Parameter (chunk_size, models, thresholds)\n","\n","**RAGComponents**\n","- Container f√ºr alle System-Komponenten\n","- Text-Embeddings, CLIP-Model, LLMs, Collections\n","\n","**Hauptfunktionen**\n","- Datensammlung\n","    - `init_rag_system()`: System-Initialisierung\n","    - `process_directory()`: Bulk-Import von Dateien\n","    - `add_text_document()`: Einzelnes Dokument hinzuf√ºgen\n","    - `add_image_with_description()`: Bild mit Auto-Beschreibung\n","- Abruf & Erweiterung\n","    - `search_texts()`: Text-Suche inkl. Bildbeschreibungen\n","    - `search_images()`: CLIP-basierte Bildsuche\n","    - `search_similar_images()`: Bild‚ÜíBild √Ñhnlichkeitssuche\n","    - `search_text_by_image()`: Bild‚ÜíText Suche\n","    - `multimodal_search()`: Erweiterte multimodale Suche"],"metadata":{"id":"ce_ZmxwJMiNd"},"id":"ce_ZmxwJMiNd"},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/multimodal_rag_function_call.png\" width=\"1100\" alt=\"Avatar\">\n","\n","\n"],"metadata":{"id":"5kK-F9_0ugNW"},"id":"5kK-F9_0ugNW"},{"cell_type":"code","source":["# Import des Moduls\n","from multimodal_rag_modul import (\n","    init_rag_system,\n","    process_directory,\n","    multimodal_search,\n","    search_text_by_image,\n","    search_similar_images,\n","    add_text_document,\n","    add_image_with_description,\n","    get_system_status\n",")"],"metadata":{"id":"JkDO4IE9T7fl"},"id":"JkDO4IE9T7fl","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | RAG initialisieren\n","---"],"metadata":{"id":"Szr8GWgQHRaY"},"id":"Szr8GWgQHRaY"},{"cell_type":"code","source":["# Initialisierung\n","rag = init_rag_system()"],"metadata":{"id":"pLf6ZW9b7N2r"},"id":"pLf6ZW9b7N2r","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Konfiguration abfragen\n","print(rag.config)\n","\n","# Konfiguration √§ndern (Beispiel: chunk_size √§ndern)\n","# rag.config.chunk_size = 300"],"metadata":{"id":"jHAP9o6hXJHs"},"id":"jHAP9o6hXJHs","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 | Bilder/Texte in RAG √ºbernehmen\n","---"],"metadata":{"id":"BMa1SMEvU5GO"},"id":"BMa1SMEvU5GO"},{"cell_type":"code","source":["# Dokumente/Bilder laden & verarbeiten\n","process_directory(rag, './files', auto_describe_images=True)"],"metadata":{"id":"ADyLHzEPKBqE"},"id":"ADyLHzEPKBqE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5 | Suche Text -> Text/Bild\n","---"],"metadata":{"id":"P3qn5ylkQM43"},"id":"P3qn5ylkQM43"},{"cell_type":"code","source":["result = multimodal_search(rag, \"Was weisst Du √ºber Cyborgs?\")\n","mprint(result)"],"metadata":{"id":"wNUlfGbzJ_mx"},"id":"wNUlfGbzJ_mx","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6 | Suche Bild -> Text/Bild\n","---"],"metadata":{"id":"MKp-dUs0d5lS"},"id":"MKp-dUs0d5lS"},{"cell_type":"code","source":["# Bild ‚Üí Bild: Finde visuell √§hnliche Bilder\n","similar_images = search_similar_images(rag, \"./zwei_roboter.png\", k=5)\n","mprint(\"## üñºÔ∏è Suche Bild ‚Üí Bild\")\n","mprint(\"---\")\n","for img in similar_images:\n","    mprint(f\"{img['filename']}: √Ñhnlichkeit: {img['similarity']}\")"],"metadata":{"id":"dMaVQXrwd96e"},"id":"dMaVQXrwd96e","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bild ‚Üí Text: Finde Textinformationen zu dem Bild\n","text_result = search_text_by_image(rag, \"./zwei_roboter.png\", k=5)\n","mprint(text_result)"],"metadata":{"id":"5GBaaj6QUIq_"},"id":"5GBaaj6QUIq_","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"v1pnxcg3exq","source":["# 7 | Aufgabe\n","---"],"metadata":{"id":"v1pnxcg3exq"}},{"cell_type":"markdown","id":"vfr2jthhvw8","source":["<p><font color='black' size=\"5\">\n","Teste das Multimodale RAG-System mit eigenen Queries\n","</font></p>\n","\n","**Ziel**: Nutze das fertige multimodale RAG-System, um verschiedene Such-Operationen durchzuf√ºhren.\n","\n"],"metadata":{"id":"vfr2jthhvw8"}},{"cell_type":"markdown","source":["**Schritt 1: Einfache Queries testen**\n","\n","F√ºhre die folgenden Queries mit dem RAG-System aus und beobachte, welche Ergebnisse zur√ºckgeliefert werden:\n","\n","```python\n","# Query 1: Text ‚Üí Text (Klassisches RAG)\n","result = multimodal_search(rag, \"Wer war Alan Turing?\")\n","mprint(result)\n","\n","# Query 2: Text ‚Üí Bild (Textanfrage findet Bilder)\n","result = multimodal_search(rag, \"Zeige mir Bilder von Robotern\")\n","mprint(result)\n","\n","# Query 3: Bild ‚Üí Bild (Finde √§hnliche Bilder)\n","similar_images = search_similar_images(rag, \"./files/apfel.jpg\", k=3)\n","mprint(\"## üñºÔ∏è √Ñhnliche Bilder:\")\n","for img in similar_images:\n","    mprint(f\"  ‚Ä¢ {img['filename']}: √Ñhnlichkeit {img['similarity']:.2f}\")\n","\n","# Query 4: Bild ‚Üí Text (Finde Textinformationen zu einem Bild)\n","text_result = search_text_by_image(rag, \"./files/hedra_cyborg.png\", k=3)\n","mprint(text_result)\n","```\n","\n"],"metadata":{"id":"a9_HhGimXnlO"},"id":"a9_HhGimXnlO"},{"cell_type":"markdown","source":["**Schritt 2: Eigene Queries erstellen**\n","\n","Entwickle mindestens **3 eigene Queries**, die verschiedene Modalit√§ten nutzen:\n","\n","**Beispiele f√ºr kreative Queries:**\n","\n","- **Text‚ÜíText**: \"Was ist der Unterschied zwischen Robotern und Cyborgs?\"\n","- **Text‚ÜíBild**: \"Finde alle futuristischen Bilder\"\n","- **Bild‚ÜíBild**: Suche √§hnliche Bilder zu `a_retro-futuristic_robot_dall_e.jpg`\n","- **Bild‚ÜíText**: Finde Textinformationen, die zum Apfel-Bild passen\n","\n"],"metadata":{"id":"jGDaXV7rXqSO"},"id":"jGDaXV7rXqSO"},{"cell_type":"markdown","source":["**Schritt 3: Bonus-Challenge (Optional)**\n","\n","Experimentiere mit den Suchparametern:\n","\n","```python\n","# √Ñndere die Anzahl der Ergebnisse (k)\n","result = multimodal_search(rag, \"Roboter\", k=5)\n","\n","# Vergleiche verschiedene Bilder f√ºr die Bild‚ÜíBild Suche\n","similar_1 = search_similar_images(rag, \"./files/apfel.jpg\", k=3)\n","similar_2 = search_similar_images(rag, \"./files/hedra_cyborg.png\", k=3)\n","\n","# Finde heraus, welche Bilder am √§hnlichsten zueinander sind\n","```"],"metadata":{"id":"v_WzXtmKXsGa"},"id":"v_WzXtmKXsGa"},{"cell_type":"markdown","source":["# A | √Ñhnlichkeitsmessung\n","---"],"metadata":{"id":"knkBxX2Two-i"},"id":"knkBxX2Two-i"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","1. Text-√Ñhnlichkeit (semantisch)\n","</font></p>\n","\n","  Embedding-Modell: OpenAI text-embedding-3-small\n","\n","  Messmethode:\n","  - ChromaDB nutzt L2-Distanz (Euklidische Distanz) f√ºr Text-Embeddings\n","  - Werte: 0 = identisch, 2 = maximal entfernt\n","  - Konvertierung Distanz zu √Ñhnlichkeit: similarity = max(0, 1 - (score / 2))\n","  - Threshold: text_threshold: 1.2 (Zeile 51), Mindest-√Ñhnlichkeit: 0.3\n","\n","  Verwendung in:\n","  - search_texts() - Text-Dokumente und Bildbeschreibungen durchsuchen\n","  - multimodal_search() - Kombinierte Suche\n","\n","  ---"],"metadata":{"id":"U0zYvcUGwtel"},"id":"U0zYvcUGwtel"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","2. Bild-√Ñhnlichkeit (visuell)\n","</font></p>\n","\n","  Embedding-Modell: CLIP clip-ViT-B-32\n","\n","  Messmethode:\n","  - ChromaDB nutzt Cosine-Distanz f√ºr Bild-Embeddings (Zeile 131: \"hnsw:space\": \"cosine\")\n","  - Werte: 0 = identisch, 2 = maximal entfernt\n","  - Konvertierung zu √Ñhnlichkeit:\n","  similarity = round(max(0, 1 - distance), 3)\n","  - Threshold: image_threshold: 0.8\n","\n","  Verwendung in:\n","  - search_images() - Text ‚Üí Bild Suche √ºber CLIP   \n","  - search_similar_images() - Bild ‚Üí Bild Suche  \n","\n","  ---\n","  "],"metadata":{"id":"JHroT_lGw4YI"},"id":"JHroT_lGw4YI"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","3. Cross-Modal-Retrieval (Text ‚Üî Bild)\n","</font></p>\n","\n","\n","  Methode: Indirekte √Ñhnlichkeit √ºber Bildbeschreibungen\n","\n","  Ablauf:\n","  1. Text ‚Üí Bild: Text-Suche findet Bildbeschreibungen ‚Üí verkn√ºpfte Bilder werden abgerufen  \n","  2. Bild ‚Üí Text: Bild-Suche findet √§hnliche Bilder ‚Üí deren Beschreibungen werden f√ºr semantische Textsuche verwendet\n","\n","  Verkn√ºpfung: Beide Collections sind √ºber text_doc_id ‚Üî image_doc_id referenziert\n","\n","  ---\n","  "],"metadata":{"id":"n-wEhLp4w9Vs"},"id":"n-wEhLp4w9Vs"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Zusammenfassung der Metriken:\n","</font></p>\n","\n","  | Modalit√§t | Embedding-Modell              | Distanzmetrik  | Threshold | √Ñhnlichkeitsbereich |\n","  |-----------|-------------------------------|----------------|-----------|---------------------|\n","  | Text      | OpenAI text-embedding-3-small | L2-Distanz     | 1.2       | 0.3 - 1.0           |\n","  | Bild      | CLIP ViT-B-32                 | Cosine-Distanz | 0.8       | 0.0 - 1.0           |\n","\n","  Die Konvertierung 1 - (distance / 2) normalisiert beide Distanzma√üe auf einen √Ñhnlichkeitswert von 0 bis 1, wobei 1 = maximale √Ñhnlichkeit bedeutet."],"metadata":{"id":"hYXY40XQxHDo"},"id":"hYXY40XQxHDo"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"colab":{"provenance":[],"collapsed_sections":["B41ZbXwBQ2eW","ce95c6f6","Szr8GWgQHRaY","BMa1SMEvU5GO","P3qn5ylkQM43","MKp-dUs0d5lS","v1pnxcg3exq","knkBxX2Two-i"],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}