{"cells":[{"cell_type":"markdown","id":"e773f4c7","metadata":{"id":"e773f4c7"},"source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)\n"]},{"cell_type":"markdown","source":["\n","<p><font size=\"5\" color='grey'> <b>\n","Multimodales RAG - Retrieval Augmented Generation\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"j5LeGSUFR_Id"},"id":"j5LeGSUFR_Id"},{"cell_type":"code","execution_count":null,"id":"9c8df5ef","metadata":{"id":"9c8df5ef"},"outputs":[],"source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/genai_lib\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"]},{"cell_type":"code","execution_count":null,"id":"4d2e699d","metadata":{"id":"4d2e699d"},"outputs":[],"source":["#@title üõ†Ô∏è Installationen { display-mode: \"form\" }\n","install_packages([\n","    ('markitdown[all]', 'markitdown'),\n","    'langchain_chroma',\n","])"]},{"cell_type":"code","execution_count":null,"id":"da4cf78d","metadata":{"id":"da4cf78d"},"outputs":[],"source":["#@title üìÇ Dokumente & Bilder kopieren { display-mode: \"form\" }\n","!rm -rf files\n","!mkdir files\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_1.txt -o files/biografien_1.txt\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_2.md -o files/biografien_2.md\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_3.pdf -o files/biografien_3.pdf\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/biografien_4.docx -o files/biografien_4.docx\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/a_retro-futuristic_robot_dall_e.jpg -o files/a_retro-futuristic_robot_dall_e.jpg\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/hedra_cyborg.png -o files/hedra_cyborg.png\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02%20data/apfel.jpg -o files/apfel.jpg"]},{"cell_type":"markdown","source":["# 1 | Funktionale Architektur\n","---"],"metadata":{"id":"gcqh-rJGyUIv"},"id":"gcqh-rJGyUIv"},{"cell_type":"markdown","source":["\n","\n","<p><font color='black' size=\"5\">\n","Aufbau des funktionalen RAG-Systems\n","</font></p>\n","\n","Das funktionale System besteht aus drei Hauptkomponenten:\n","\n","**1. Konfiguration & Setup:**\n","- `RAGConfig`: Zentrale Konfiguration als Dataclass\n","- `RAGComponents`: Container f√ºr alle System-Komponenten\n","- `init_rag_system()`: Einmalige Initialisierung\n","\n","**2. Dokumenten-Verarbeitung:**\n","- `add_text_document()`: Einzelnes Text-Dokument hinzuf√ºgen\n","- `add_image()`: Einzelnes Bild hinzuf√ºgen  \n","- `process_directory()`: Gesamtes Verzeichnis verarbeiten\n","\n","**3. Suche & Abfrage:**\n","- `search_texts()`: Reine Text-Suche\n","- `search_images()`: Reine Bild-Suche\n","- `multimodal_search()`: Kombinierte Suche\n","\n","**Datenfluss:**\n","```\n","Dokumente ‚Üí Verarbeitung ‚Üí Embeddings ‚Üí Vektordatenbank ‚Üí Suche ‚Üí LLM ‚Üí Antwort\n","```\n","\n"],"metadata":{"id":"YuZDTIWgyXc2"},"id":"YuZDTIWgyXc2"},{"cell_type":"markdown","source":["# 2 | Implementierung\n","---\n","\n"],"metadata":{"id":"lB1uwPlKyab1"},"id":"lB1uwPlKyab1"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Importe und Grundkonfiguration\n","</font></p>"],"metadata":{"id":"htIYL48CycKx"},"id":"htIYL48CycKx"},{"cell_type":"code","execution_count":null,"id":"3b54d595","metadata":{"id":"3b54d595"},"outputs":[],"source":["from pathlib import Path\n","from typing import List, Dict, Any, Tuple\n","import uuid\n","from dataclasses import dataclass\n","\n","from markitdown import MarkItDown\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n","from langchain_chroma import Chroma\n","from langchain_core.documents import Document\n","from sentence_transformers import SentenceTransformer\n","from PIL import Image\n","import chromadb"]},{"cell_type":"markdown","id":"75fc0fb8","metadata":{"id":"75fc0fb8"},"source":["\n","<p><font color='black' size=\"5\">\n","Konfiguration und Datenstrukturen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"370d35e2","metadata":{"id":"370d35e2"},"outputs":[],"source":["@dataclass\n","class RAGConfig:\n","    \"\"\"Zentrale Konfiguration f√ºr das RAG-System\"\"\"\n","    chunk_size: int = 200\n","    chunk_overlap: int = 20\n","    text_threshold: float = 1.2\n","    image_threshold: float = 0.8\n","    clip_model: str = 'clip-ViT-B-32'\n","    text_model: str = 'text-embedding-3-small'\n","    llm_model: str = 'gpt-4o-mini'\n","    db_path: str = './multimodal_rag_db'\n","\n","@dataclass\n","class RAGComponents:\n","    \"\"\"Container f√ºr alle RAG-System-Komponenten\"\"\"\n","    text_embeddings: OpenAIEmbeddings\n","    clip_model: SentenceTransformer\n","    llm: ChatOpenAI\n","    text_splitter: RecursiveCharacterTextSplitter\n","    markitdown: MarkItDown\n","    chroma_client: chromadb.PersistentClient\n","    text_collection: Chroma\n","    image_collection: Any"]},{"cell_type":"markdown","id":"6ff1941e","metadata":{"id":"6ff1941e"},"source":["\n","<p><font color='black' size=\"5\">\n","System-Initialisierung\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"2b5966d8","metadata":{"id":"2b5966d8"},"outputs":[],"source":["def init_rag_system(config: RAGConfig = RAGConfig()) -> RAGComponents:\n","    \"\"\"Initialisiert alle RAG-Komponenten\"\"\"\n","    print(f\"üöÄ Initialisiere RAG-System in {config.db_path}\")\n","\n","    # KI-Modelle laden\n","    text_embeddings = OpenAIEmbeddings(model=config.text_model)\n","    print(\"‚úÖ OpenAI Text-Embeddings initialisiert\")\n","\n","    print(\"üñºÔ∏è Lade CLIP-Modell...\")\n","    clip_model = SentenceTransformer(config.clip_model)\n","    print(\"‚úÖ CLIP-Modell geladen\")\n","\n","    llm = ChatOpenAI(model=config.llm_model, temperature=0)\n","\n","    # Text-Verarbeitung\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=config.chunk_size,\n","        chunk_overlap=config.chunk_overlap\n","    )\n","    markitdown = MarkItDown()\n","\n","    # Datenbank einrichten\n","    Path(config.db_path).mkdir(exist_ok=True)\n","    chroma_client = chromadb.PersistentClient(path=config.db_path)\n","\n","    # Text-Collection\n","    text_collection = Chroma(\n","        collection_name=\"texts\",\n","        embedding_function=text_embeddings,\n","        persist_directory=config.db_path\n","    )\n","\n","    # Bild-Collection\n","    collections = [c.name for c in chroma_client.list_collections()]\n","    if \"images\" in collections:\n","        image_collection = chroma_client.get_collection(\"images\")\n","    else:\n","        image_collection = chroma_client.create_collection(\n","            name=\"images\", metadata={\"hnsw:space\": \"cosine\"}\n","        )\n","\n","    print(\"‚úÖ Collections initialisiert\")\n","\n","    return RAGComponents(\n","        text_embeddings, clip_model, llm, text_splitter,\n","        markitdown, chroma_client, text_collection, image_collection\n","    )"]},{"cell_type":"markdown","id":"c57b7490","metadata":{"id":"c57b7490"},"source":["\n","<p><font color='black' size=\"5\">\n","Text-Dokument hinzuf√ºgen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"5a073c04","metadata":{"id":"5a073c04"},"outputs":[],"source":["def add_text_document(components: RAGComponents, file_path: str) -> bool:\n","    \"\"\"F√ºgt ein Text-Dokument zur Datenbank hinzu\"\"\"\n","    path = Path(file_path).absolute()\n","\n","    # Duplikatspr√ºfung\n","    if components.text_collection.get(where={\"source\": str(path)})['ids']:\n","        print(f\"‚ö†Ô∏è {path.name} bereits vorhanden\")\n","        return False\n","\n","    try:\n","        # Dokument mit MarkItDown konvertieren\n","        result = components.markitdown.convert(str(path))\n","        if not result or not result.text_content.strip():\n","            print(f\"‚ö†Ô∏è {path.name} enth√§lt keinen Text\")\n","            return False\n","\n","        # Text in Chunks aufteilen\n","        chunks = components.text_splitter.split_text(result.text_content)\n","        documents = [\n","            Document(\n","                page_content=chunk.strip(),\n","                metadata={\"source\": str(path), \"filename\": path.name, \"chunk_id\": i}\n","            ) for i, chunk in enumerate(chunks) if chunk.strip()\n","        ]\n","\n","        # Zur Datenbank hinzuf√ºgen\n","        if documents:\n","            components.text_collection.add_documents(documents)\n","            print(f\"‚úÖ {len(documents)} Chunks von '{path.name}' hinzugef√ºgt\")\n","            return True\n","\n","    except Exception as e:\n","        print(f\"‚ùå Fehler bei {path.name}: {e}\")\n","\n","    return False"]},{"cell_type":"markdown","id":"d224cb50","metadata":{"id":"d224cb50"},"source":["\n","<p><font color='black' size=\"5\">\n","Bild hinzuf√ºgen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"6de7c817","metadata":{"id":"6de7c817"},"outputs":[],"source":["def add_image(components: RAGComponents, image_path: str, description: str = \"\") -> bool:\n","    \"\"\"F√ºgt ein Bild zur Datenbank hinzu\"\"\"\n","    path = Path(image_path).absolute()\n","\n","    if not path.exists():\n","        print(f\"‚ùå Bild nicht gefunden: {path}\")\n","        return False\n","\n","    # Duplikatspr√ºfung\n","    if components.image_collection.get(where={\"source\": str(path)})['ids']:\n","        print(f\"‚ö†Ô∏è Bild bereits vorhanden: {path.name}\")\n","        return False\n","\n","    try:\n","        # Bild laden und Embedding erstellen\n","        image = Image.open(path).convert('RGB')\n","        embedding = components.clip_model.encode(image).tolist()\n","        print(f\"üñºÔ∏è Bild-Embedding erstellt f√ºr {path.name}\")\n","\n","        # Metadaten vorbereiten\n","        doc_id = f\"img_{uuid.uuid4().hex[:8]}_{path.name}\"\n","        content = f\"Bild: {path.name}\"\n","        if description.strip():\n","            content += f\" - {description.strip()}\"\n","\n","        # Zur Datenbank hinzuf√ºgen\n","        components.image_collection.add(\n","            ids=[doc_id],\n","            embeddings=[embedding],\n","            documents=[content],\n","            metadatas=[{\n","                \"source\": str(path),\n","                \"filename\": path.name,\n","                \"description\": description.strip()\n","            }]\n","        )\n","\n","        print(f\"‚úÖ Bild '{path.name}' hinzugef√ºgt\")\n","        return True\n","\n","    except Exception as e:\n","        print(f\"‚ùå Fehler bei Bild {path.name}: {e}\")\n","        return False"]},{"cell_type":"markdown","id":"3062a44f","metadata":{"id":"3062a44f"},"source":["\n","<p><font color='black' size=\"5\">\n","Verzeichnis verarbeiten\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"b32039a0","metadata":{"id":"b32039a0"},"outputs":[],"source":["def process_directory(components: RAGComponents, directory: str, include_images: bool = True) -> Dict[str, int]:\n","    \"\"\"Verarbeitet alle Dateien in einem Verzeichnis\"\"\"\n","    dir_path = Path(directory)\n","    if not dir_path.exists():\n","        print(f\"‚ùå Verzeichnis nicht gefunden: {directory}\")\n","        return {\"texts\": 0, \"images\": 0}\n","\n","    # Unterst√ºtzte Dateitypen\n","    text_extensions = {'.pdf', '.docx', '.txt', '.md', '.html'}\n","    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}\n","\n","    # Dateien sammeln\n","    text_files = [f for f in dir_path.rglob(\"*\") if f.suffix.lower() in text_extensions]\n","    image_files = [f for f in dir_path.rglob(\"*\") if f.suffix.lower() in image_extensions] if include_images else []\n","\n","    print(f\"üìä Gefunden: {len(text_files)} Text-Dateien, {len(image_files)} Bilder\")\n","\n","    # Text-Dateien verarbeiten\n","    text_count = 0\n","    for file_path in text_files:\n","        print(f\"üìÑ {file_path.name}\")\n","        if add_text_document(components, str(file_path)):\n","            text_count += 1\n","\n","    # Bild-Dateien verarbeiten\n","    image_count = 0\n","    for img_path in image_files:\n","        print(f\"üñºÔ∏è {img_path.name}\")\n","        # Automatische Beschreibung aus Dateiname\n","        description = img_path.stem.replace('_', ' ').replace('-', ' ')\n","        if add_image(components, str(img_path), description):\n","            image_count += 1\n","\n","    return {\"texts\": text_count, \"images\": image_count}"]},{"cell_type":"markdown","id":"5b7f9a06","metadata":{"id":"5b7f9a06"},"source":["<p><font color='black' size=\"5\">\n","Text-Suche\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"ecf07009","metadata":{"id":"ecf07009"},"outputs":[],"source":["def search_texts(components: RAGComponents, query: str, k: int = 3, config: RAGConfig = RAGConfig()) -> str:\n","    \"\"\" Durchsucht Text-Dokumente mit einheitlicher √Ñhnlichkeits-Terminologie \"\"\"\n","\n","    if not components.text_collection.get()['ids']:\n","        return \"‚ùå Keine Text-Dokumente gefunden\"\n","\n","    # √Ñhnlichkeitssuche durchf√ºhren\n","    docs_with_scores = components.text_collection.similarity_search_with_score(query, k=k*2)\n","    if not docs_with_scores:\n","        return \"‚ùå Keine relevanten Dokumente gefunden\"\n","\n","    # Score in √Ñhnlichkeit umwandeln (0-1, wobei 1 = identisch)\n","    docs_with_similarity = []\n","    for doc, score in docs_with_scores:\n","        # Annahme: Score ist Distanz (niedrig = √§hnlich)\n","        # Umwandlung in √Ñhnlichkeit mit exponentieller D√§mpfung f√ºr bessere Verteilung\n","        similarity = max(0, min(1, 2.0 / (1 + score)))\n","        docs_with_similarity.append((doc, similarity))\n","\n","    # Nach √Ñhnlichkeit sortieren (h√∂chste zuerst)\n","    docs_with_similarity.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Top k Dokumente nehmen, die einen Mindest-√Ñhnlichkeitswert erreichen\n","    min_similarity = 0.3  # Anpassbarer Schwellenwert (entspricht etwa score < 1.2 im Original)\n","    relevant_docs = [(doc, sim) for doc, sim in docs_with_similarity[:k]\n","                     if sim >= min_similarity]\n","\n","    if not relevant_docs:\n","        return \"‚ùå Keine ausreichend √§hnlichen Dokumente gefunden\"\n","\n","    # Kontext f√ºr LLM zusammenstellen\n","    context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in relevant_docs])\n","    sources = [\n","        {\n","            \"filename\": doc.metadata.get(\"filename\", \"Unbekannt\"),\n","            \"similarity\": round(sim, 3)\n","        }\n","        for doc, sim in relevant_docs\n","    ]\n","\n","    # LLM-Antwort generieren\n","    prompt = f\"\"\"Beantworte die Frage pr√§zise basierend auf dem Kontext.\n","\n","KONTEXT:\n","{context}\n","\n","FRAGE: {query}\n","\n","ANTWORT:\"\"\"\n","\n","    response = components.llm.invoke(prompt).content\n","\n","    # Einheitliche Ausgabe mit √Ñhnlichkeits-Terminologie\n","    source_text = f\"\\n\\nüìö Quellen ({len(sources)}): \" + \"\\n\".join([\n","        f\"   ‚Ä¢ {src['filename']} (√Ñhnlichkeit: {src['similarity']})\" for src in sources\n","    ])\n","\n","    return f\"{response}{source_text}\""]},{"cell_type":"markdown","id":"f6fa135f","metadata":{"id":"f6fa135f"},"source":["\n","<p><font color='black' size=\"5\">\n","Bild-Suche\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"c8746b0b","metadata":{"id":"c8746b0b"},"outputs":[],"source":["def search_images(components: RAGComponents, query: str, k: int = 3, config: RAGConfig = RAGConfig()) -> List[Dict[str, Any]]:\n","    \"\"\"Durchsucht Bilder mit Text-Query\"\"\"\n","    if components.image_collection.count() == 0:\n","        return []\n","\n","    # Text-Query in Bild-Embedding-Raum umwandeln\n","    query_embedding = components.clip_model.encode(query).tolist()\n","\n","    # Suche in Bild-Collection\n","    results = components.image_collection.query(\n","        query_embeddings=[query_embedding],\n","        n_results=min(k*2, components.image_collection.count()),\n","        include=['documents', 'metadatas', 'distances']\n","    )\n","\n","    if not results['ids'][0]:\n","        return []\n","\n","    # Ergebnisse filtern und formatieren\n","    return [\n","        {\n","            \"filename\": metadata.get(\"filename\", \"Unbekannt\"),\n","            \"path\": metadata.get(\"source\", \"\"),\n","            \"description\": metadata.get(\"description\", \"\"),\n","            \"similarity\": round(max(0, 1 - distance), 3)\n","        }\n","        for distance, metadata in zip(results['distances'][0], results['metadatas'][0])\n","        if distance < config.image_threshold\n","    ]"]},{"cell_type":"markdown","id":"ff5a2d38","metadata":{"id":"ff5a2d38"},"source":["\n","<p><font color='black' size=\"5\">\n","Multimodale Suche\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"41dce188","metadata":{"id":"41dce188"},"outputs":[],"source":["def multimodal_search(components: RAGComponents, query: str, k_text: int = 3, k_images: int = 3) -> str:\n","    \"\"\"F√ºhrt multimodale Suche durch (Text + Bilder)\"\"\"\n","    mprint(f\"## üîç Multimodale Suche: {query}\")\n","\n","    # Parallele Suche in beiden Modalit√§ten\n","    text_results = search_texts(components, query, k_text)\n","    image_results = search_images(components, query, k_images)\n","\n","    # Ergebnisse zusammenfassen\n","    result = f\"### üìÑ TEXT-ERGEBNISSE:\\n{text_results}\\n\\n\"\n","\n","    if image_results:\n","        result += f\"### üñºÔ∏è BILD-ERGEBNISSE ({len(image_results)} gefunden):\\n\"\n","        for i, img in enumerate(image_results, 1):\n","            result += f\"   {i}. {img['filename']} (√Ñhnlichkeit: {img['similarity']})\\n\"\n","            if img['description']:\n","                result += f\"      üìù {img['description']}\\n\"\n","    else:\n","        result += \"üñºÔ∏è Keine relevanten Bilder gefunden.\\n\"\n","\n","    return result"]},{"cell_type":"markdown","id":"6bc42912","metadata":{"id":"6bc42912"},"source":["\n","<p><font color='black' size=\"5\">\n","Hilfsfunktionen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"5db2b962","metadata":{"id":"5db2b962"},"outputs":[],"source":["def get_system_status(components: RAGComponents) -> Dict[str, Any]:\n","    \"\"\"Gibt detaillierten System-Status zur√ºck\"\"\"\n","    text_data = components.text_collection.get()\n","    text_count = len(text_data['ids'])\n","    image_count = components.image_collection.count()\n","\n","    # print(f\"üìä Status: {text_count} Text-Chunks, {image_count} Bilder\")\n","\n","    return {\n","        \"text_chunks\": text_count,\n","        \"images\": image_count,\n","        \"total_documents\": text_count + image_count\n","    }\n","\n","def cleanup_database(db_path: str = './multimodal_rag_db'):\n","    \"\"\"L√∂scht die Datenbank komplett\"\"\"\n","    import shutil\n","    if Path(db_path).exists():\n","        shutil.rmtree(db_path)\n","        print(f\"üóëÔ∏è Datenbank gel√∂scht: {db_path}\")"]},{"cell_type":"markdown","id":"b147567e","metadata":{"id":"b147567e"},"source":["# 3 | Hands-On: Multimodales RAG\n","---\n"]},{"cell_type":"markdown","source":["## 3.1 *Alte* Datenbank l√∂schen"],"metadata":{"id":"6rXJZa-l9UIp"},"id":"6rXJZa-l9UIp"},{"cell_type":"code","execution_count":null,"id":"699c8fe0","metadata":{"id":"699c8fe0"},"outputs":[],"source":["# Aufr√§umen vor Neustart\n","cleanup_database('./multimodal_rag_db')"]},{"cell_type":"markdown","id":"acb01149","metadata":{"id":"acb01149"},"source":["## 3.2 System initialisieren"]},{"cell_type":"code","execution_count":null,"id":"0254b3bd","metadata":{"id":"0254b3bd"},"outputs":[],"source":["# Konfiguration erstellen\n","config = RAGConfig(db_path='./multimodal_rag_db')\n","\n","# RAG-System initialisieren\n","rag_components = init_rag_system(config)"]},{"cell_type":"markdown","id":"67f8e067","metadata":{"id":"67f8e067"},"source":["## 3.3 Dokumente verarbeiten"]},{"cell_type":"code","execution_count":null,"id":"fd5e896e","metadata":{"id":"fd5e896e"},"outputs":[],"source":["# Alle Dateien im files-Verzeichnis verarbeiten\n","results = process_directory(rag_components, './files', include_images=True)\n","\n","mprint(f\"### üìä Verarbeitungsergebnis:\")\n","print(f\"   üìÑ Text-Dokumente: {results['texts']}\")\n","print(f\"   üñºÔ∏è Bilder: {results['images']}\")\n","print(f\"   üì¶ Gesamt: {results['texts'] + results['images']}\")"]},{"cell_type":"markdown","id":"be4d3679","metadata":{"id":"be4d3679"},"source":["## 3.4 System-Status anzeigen"]},{"cell_type":"code","execution_count":null,"id":"92e92e5c","metadata":{"id":"92e92e5c"},"outputs":[],"source":["# Aktueller Status der Datenbank\n","status = get_system_status(rag_components)\n","mprint(f\"### Datenbank enth√§lt:\")\n","print(f\"   üìÑ {status['text_chunks']} Text-Chunks\")\n","print(f\"   üñºÔ∏è {status['images']} Bilder\")\n","print(f\"   üì¶ {status['total_documents']} Dokumente insgesamt\")"]},{"cell_type":"markdown","id":"d3fef2e8","metadata":{"id":"d3fef2e8"},"source":["## 3.5 Text-Suche testen"]},{"cell_type":"code","execution_count":null,"id":"7f984d5c","metadata":{"id":"7f984d5c"},"outputs":[],"source":["# Reine Text-Suche\n","query = \"Wer ist Thoren Navarro?\"\n","result = search_texts(rag_components, query)\n","\n","mprint(f\"### üîç TEXT-SUCHE\")\n","mprint(f\"**Query:** {query}\")\n","mprint(\"---\")\n","mprint(result)"]},{"cell_type":"markdown","id":"3c958b9f","metadata":{"id":"3c958b9f"},"source":["## 3.6 Bild-Suche testen"]},{"cell_type":"code","execution_count":null,"id":"397aeedd","metadata":{"id":"397aeedd"},"outputs":[],"source":["# Reine Bild-Suche\n","query = \"Roboter\"\n","images = search_images(rag_components, query)\n","\n","mprint(f\"### üñºÔ∏è BILD-SUCHE\")\n","mprint(f\"**Query:** {query}\")\n","mprint(\"---\")\n","\n","if images:\n","    mprint(f\"**{len(images)} Bilder gefunden:**\")\n","    for i, img in enumerate(images, 1):\n","        mprint(f\"{i}. **{img['filename']}** (√Ñhnlichkeit: {img['similarity']})\")\n","        if img['description']:\n","            mprint(f\"   üìù *{img['description']}*\")\n","else:\n","    mprint(\"Keine relevanten Bilder gefunden.\")"]},{"cell_type":"markdown","id":"88e8c594","metadata":{"id":"88e8c594"},"source":["## 3.7 Multimodale Suche testen"]},{"cell_type":"code","execution_count":null,"id":"a6d4ce51","metadata":{"id":"a6d4ce51"},"outputs":[],"source":["# Kombinierte Text- und Bild-Suche\n","test_queries = [\n","    \"Wer ist Thoren Navarro?\",\n","    \"Zeige mir Bilder von Robotern\",\n","    \"Was sind KI-Modelle?\",\n","    \"Futuristische Technologien\"\n","]\n","\n","for query in test_queries:\n","    print()\n","    result = multimodal_search(rag_components, query, k_text=2, k_images=2)\n","    mprint(result)"]},{"cell_type":"markdown","source":["# 4 | Erweiterte Funktionen\n","---\n","\n"],"metadata":{"id":"YDDqKbqH9X4o"},"id":"YDDqKbqH9X4o"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Batch-Verarbeitung\n","</font></p>"],"metadata":{"id":"M54yxJHz9aGZ"},"id":"M54yxJHz9aGZ"},{"cell_type":"code","execution_count":null,"id":"11a93f8b","metadata":{"id":"11a93f8b"},"outputs":[],"source":["def process_multiple_directories(components: RAGComponents, directories: List[str]) -> Dict[str, Any]:\n","    \"\"\"Verarbeitet mehrere Verzeichnisse in einem Durchgang\"\"\"\n","    total_results = {\"texts\": 0, \"images\": 0}\n","\n","    for directory in directories:\n","        print(f\"\\nüìÅ Verarbeite Verzeichnis: {directory}\")\n","        results = process_directory(components, directory, include_images=True)\n","        total_results[\"texts\"] += results[\"texts\"]\n","        total_results[\"images\"] += results[\"images\"]\n","\n","    return total_results\n","\n","# Usage\n","directories = ['./docs', './images', './pdfs']\n","# total = process_multiple_directories(rag_components, directories)"]},{"cell_type":"markdown","id":"a54a67df","metadata":{"id":"a54a67df"},"source":["\n","<p><font color='black' size=\"5\">\n","Erweiterte Suchoptionen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"9fd73092","metadata":{"id":"9fd73092"},"outputs":[],"source":["def advanced_search(components: RAGComponents, query: str, filters: Dict[str, Any] = None) -> Dict[str, Any]:\n","    \"\"\"Erweiterte Suche mit Filtern\"\"\"\n","    filters = filters or {}\n","\n","    # Text-Suche mit optionalen Filtern\n","    text_results = []\n","    if not filters.get('images_only', False):\n","        text_results = search_texts(components, query, k=filters.get('k_text', 3))\n","\n","    # Bild-Suche mit optionalen Filtern\n","    image_results = []\n","    if not filters.get('text_only', False):\n","        image_results = search_images(components, query, k=filters.get('k_images', 3))\n","\n","    return {\n","        \"query\": query,\n","        \"text_results\": text_results,\n","        \"image_results\": image_results,\n","        \"total_found\": len(text_results) + len(image_results)\n","    }\n","\n","# Usage Examples\n","# result = advanced_search(rag_components, \"KI\", {\"text_only\": True})\n","# result = advanced_search(rag_components, \"Roboter\", {\"images_only\": True})"]},{"cell_type":"markdown","id":"67b9ec37","metadata":{"id":"67b9ec37"},"source":["\n","<p><font color='black' size=\"5\">\n","Performance-Monitoring\n","</font></p>"]},{"cell_type":"code","execution_count":null,"id":"40c35f8a","metadata":{"id":"40c35f8a"},"outputs":[],"source":["import time\n","from functools import wraps\n","\n","def measure_time(func):\n","    \"\"\"Decorator f√ºr Performance-Messung\"\"\"\n","    @wraps(func)\n","    def wrapper(*args, **kwargs):\n","        start = time.time()\n","        result = func(*args, **kwargs)\n","        duration = time.time() - start\n","        print(f\"‚è±Ô∏è {func.__name__} dauerte {duration:.2f}s\")\n","        return result\n","    return wrapper\n","\n","@measure_time\n","def timed_multimodal_search(components: RAGComponents, query: str) -> str:\n","    \"\"\"Multimodale Suche mit Zeitmessung\"\"\"\n","    return multimodal_search(components, query)\n","\n","# Usage\n","result = timed_multimodal_search(rag_components, \"Test Query\")"]},{"cell_type":"markdown","id":"f82003ec","metadata":{"id":"f82003ec"},"source":["# 5 | Performance Test\n","---\n"]},{"cell_type":"code","execution_count":null,"id":"a91a40e3","metadata":{"id":"a91a40e3"},"outputs":[],"source":["import time\n","from typing import Callable\n","\n","def benchmark_function(func: Callable, *args, iterations: int = 10) -> Dict[str, float]:\n","    \"\"\"Benchmarkt eine Funktion √ºber mehrere Iterationen\"\"\"\n","    times = []\n","\n","    for _ in range(iterations):\n","        start = time.time()\n","        func(*args)\n","        end = time.time()\n","        times.append(end - start)\n","\n","    return {\n","        \"avg_time\": sum(times) / len(times),\n","        \"min_time\": min(times),\n","        \"max_time\": max(times),\n","        \"total_time\": sum(times)\n","    }\n","\n","# Usage Example\n","benchmark_result = benchmark_function(search_texts, rag_components, \"test query\")\n","print(f\"Durchschnittliche Suchzeit: {benchmark_result['avg_time']:.3f}s\")"]},{"cell_type":"markdown","id":"5607f07f","metadata":{"id":"5607f07f"},"source":["# 6 | Gradio Interface\n","---"]},{"cell_type":"code","execution_count":null,"id":"56a493d3","metadata":{"id":"56a493d3"},"outputs":[],"source":["import gradio as gr\n","\n","def create_gradio_interface(components: RAGComponents) -> gr.Blocks:\n","    \"\"\"Erstellt eine benutzerfreundliche Web-Oberfl√§che\"\"\"\n","\n","    with gr.Blocks(title=\"Funktionales Multimodales RAG\") as interface:\n","        gr.HTML(\"<h1>üîç Multimodales RAG System</h1>\")\n","\n","        with gr.Tab(\"Suchen\"):\n","            with gr.Row():\n","                with gr.Column(scale=2):\n","                    query_input = gr.Textbox(\n","                        label=\"Ihre Frage\",\n","                        placeholder=\"z.B. 'Wer ist Thoren Navarro?' oder 'Zeige mir Roboter-Bilder'\",\n","                        lines=3\n","                    )\n","\n","                    with gr.Row():\n","                        search_btn = gr.Button(\"üîç Suchen\", variant=\"primary\")\n","                        clear_btn = gr.Button(\"üóëÔ∏è L√∂schen\")\n","\n","                with gr.Column(scale=1):\n","                    search_type = gr.Radio(\n","                        choices=[\"multimodal\", \"text\", \"images\"],\n","                        value=\"multimodal\",\n","                        label=\"Suchtyp\"\n","                    )\n","                    k_text = gr.Slider(1, 10, 3, label=\"Anzahl Text-Ergebnisse\")\n","                    k_images = gr.Slider(1, 10, 3, label=\"Anzahl Bild-Ergebnisse\")\n","\n","            result_output = gr.Markdown(label=\"Ergebnisse\")\n","\n","            def perform_search(query, stype, kt, ki):\n","                if not query.strip():\n","                    return \"‚ùå Bitte geben Sie eine Frage ein.\"\n","\n","                try:\n","                    if stype == \"text\":\n","                        return search_texts(components, query, int(kt))\n","                    elif stype == \"images\":\n","                        images = search_images(components, query, int(ki))\n","                        if images:\n","                            result = f\"### üñºÔ∏è {len(images)} Bilder gefunden:\\n\"\n","                            for i, img in enumerate(images, 1):\n","                                result += f\"{i}. **{img['filename']}** (√Ñhnlichkeit: {img['similarity']})\\n\"\n","                                if img['description']:\n","                                    result += f\"   üìù *{img['description']}*\\n\"\n","                            return result\n","                        else:\n","                            return \"‚ùå Keine relevanten Bilder gefunden.\"\n","                    else:  # multimodal\n","                        return multimodal_search(components, query, int(kt), int(ki))\n","\n","                except Exception as e:\n","                    return f\"‚ùå Fehler bei der Suche: {str(e)}\"\n","\n","            search_btn.click(\n","                perform_search,\n","                inputs=[query_input, search_type, k_text, k_images],\n","                outputs=result_output\n","            )\n","\n","            clear_btn.click(\n","                lambda: (\"\", \"\"),\n","                outputs=[query_input, result_output]\n","            )\n","\n","        with gr.Tab(\"System Status\"):\n","            status_btn = gr.Button(\"üìä Status aktualisieren\")\n","            status_output = gr.JSON(label=\"System-Informationen\")\n","\n","            def update_status():\n","                return get_system_status(components)\n","\n","            status_btn.click(update_status, outputs=status_output)\n","\n","        with gr.Tab(\"Dokumente hinzuf√ºgen\"):\n","            with gr.Row():\n","                file_input = gr.File(\n","                    label=\"Dokument hochladen\",\n","                    file_types=[\".txt\", \".md\", \".pdf\", \".docx\"]\n","                )\n","                upload_btn = gr.Button(\"üìÑ Hinzuf√ºgen\")\n","\n","            upload_output = gr.Textbox(label=\"Upload-Status\")\n","\n","            def upload_document(file):\n","                if file is None:\n","                    return \"‚ùå Keine Datei ausgew√§hlt.\"\n","\n","                try:\n","                    success = add_text_document(components, file.name)\n","                    if success:\n","                        return f\"‚úÖ Dokument '{file.name}' erfolgreich hinzugef√ºgt.\"\n","                    else:\n","                        return f\"‚ö†Ô∏è Dokument '{file.name}' konnte nicht hinzugef√ºgt werden.\"\n","                except Exception as e:\n","                    return f\"‚ùå Fehler beim Upload: {str(e)}\"\n","\n","            upload_btn.click(upload_document, inputs=file_input, outputs=upload_output)\n","\n","    return interface\n","\n","# Interface starten\n","interface = create_gradio_interface(rag_components)\n","interface.launch(share=True)"]},{"cell_type":"markdown","source":["# Exkurs: √Ñhnlichkeitswerte\n","---"],"metadata":{"id":"XtYfb6REe4f7"},"id":"XtYfb6REe4f7"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Wertebereich und Bedeutung\n","</font></p>\n","\n","**√Ñhnlichkeitswerte bewegen sich zwischen 0 und 1:**\n","\n","- **1.0 = Identisch**: Perfekte √úbereinstimmung (sehr selten)\n","- **0.8 - 0.99 = Sehr √§hnlich**: Hohe thematische √úbereinstimmung, fast wortgleiche Inhalte\n","- **0.6 - 0.79 = √Ñhnlich**: Starke thematische Verbindung, verwandte Konzepte\n","- **0.4 - 0.59 = M√§√üig √§hnlich**: Teilweise √úbereinstimmung, gemeinsame Themen\n","- **0.2 - 0.39 = Schwach √§hnlich**: Geringe Verbindung, wenige gemeinsame Begriffe\n","- **0.0 - 0.19 = Nicht √§hnlich**: Keine erkennbare thematische Verbindung\n","\n"],"metadata":{"id":"YcppR51ffFId"},"id":"YcppR51ffFId"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Empfohlene Schwellenwerte\n","</font></p>\n","\n","- **Text-Suche**: Mindestens 0.3 f√ºr brauchbare Ergebnisse\n","- **Bild-Suche**: Mindestens 0.2 f√ºr relevante Treffer\n","- **Hochpr√§zise Suche**: Mindestens 0.6 f√ºr sehr spezifische Anfragen\n"],"metadata":{"id":"pW6UGQyzfPSq"},"id":"pW6UGQyzfPSq"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Praktische Beispiele\n","</font></p>\n","\n","\n","**Bei der Frage \"Wer ist Thoren Navarro?\":**\n","- √Ñhnlichkeit 0.76: Dokument enth√§lt direkte Informationen zu Thoren Navarro\n","- √Ñhnlichkeit 0.45: Dokument erw√§hnt Unterwasserarch√§ologie (verwandtes Thema)\n","- √Ñhnlichkeit 0.23: Dokument √ºber Roboter (wenig relevant)\n","\n"],"metadata":{"id":"lPAgGakcfyhe"},"id":"lPAgGakcfyhe"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Berechnungslogik\n","</font></p>\n","\n"],"metadata":{"id":"hf-JVQdCfVn0"},"id":"hf-JVQdCfVn0"},{"cell_type":"markdown","source":["\n","<p><font color='blue' size=\"4\">\n","Text-√Ñhnlichkeit\n","</font></p>\n","\n","**Urspr√ºnglicher Score ‚Üí √Ñhnlichkeit (similarity):**\n","```\n","√Ñhnlichkeit = 2.0 / (1 + Score)\n","```\n","\n","- **Score 0** (perfekte √úbereinstimmung) ‚Üí √Ñhnlichkeit 1.0\n","- **Score 0.5** ‚Üí √Ñhnlichkeit 0.67\n","- **Score 1.0** ‚Üí √Ñhnlichkeit 0.5\n","- **Score 2.0** ‚Üí √Ñhnlichkeit 0.25\n","\n","*Der urspr√ºngliche Score (**Cosine Similarity**, Kosinus-√Ñhnlichkeit) ist eine Distanz zwischen Embeddings - niedrigere Werte bedeuten √§hnlichere Vektoren.*\n","\n"],"metadata":{"id":"6v8cZKKxf4MU"},"id":"6v8cZKKxf4MU"},{"cell_type":"markdown","source":["\n","<p><font color='blue' size=\"4\">\n","Bild-√Ñhnlichkeit\n","</font></p>\n","\n","**Distanz ‚Üí √Ñhnlichkeit:**\n","```\n","√Ñhnlichkeit = max(0, 1 - Distanz)\n","```\n","\n","- **Distanz 0** (identisch) ‚Üí √Ñhnlichkeit 1.0\n","- **Distanz 0.3** ‚Üí √Ñhnlichkeit 0.7\n","- **Distanz 0.8** ‚Üí √Ñhnlichkeit 0.2\n","- **Distanz ‚â• 1.0** ‚Üí √Ñhnlichkeit 0.0\n","\n","*Die Distanz stammt aus dem CLIP-Modell Vektorvergleich - **Cosinus-Distanz** zwischen Bild-Embeddings. Berechnung: 1 - Cosine Similarity*\n","\n"],"metadata":{"id":"uWVpIT28f5O2"},"id":"uWVpIT28f5O2"},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Wichtige Hinweise\n","</font></p>\n","\n","- √Ñhnlichkeitswerte sind **relativ** - sie h√§ngen von der Qualit√§t und Vielfalt der Dokumentensammlung ab\n","- **Niedrigere Werte** bedeuten nicht unbedingt irrelevante Inhalte, sondern k√∂nnen auf eine diverse Dokumentenbasis hinweisen\n","- Bei **spezifischen Fachbereichen** k√∂nnen bereits Werte ab 0.2 sehr relevante Informationen enthalten\n","- **Kontext ist wichtig** - ein Dokument mit 0.4 √Ñhnlichkeit kann trotzdem die gesuchte Antwort enthalten\n","- **Verschiedene Modelle** (OpenAI Embeddings vs. CLIP) k√∂nnen unterschiedliche Verteilungen der √Ñhnlichkeitswerte erzeugen"],"metadata":{"id":"3fOBHXRkft_J"},"id":"3fOBHXRkft_J"},{"cell_type":"markdown","id":"ecd2748f","metadata":{"id":"ecd2748f"},"source":["# A | Aufgaben\n","---"]},{"cell_type":"markdown","source":["## A.1 Erweiterte Suchfunktion"],"metadata":{"id":"PDd9yUxNAKzQ"},"id":"PDd9yUxNAKzQ"},{"cell_type":"markdown","source":["\n","\n","Implementieren Sie eine `similarity_search` Funktion, die Dokumente nach √Ñhnlichkeit zu einem gegebenen Text-Embedding findet:"],"metadata":{"id":"6cql5L7vAMug"},"id":"6cql5L7vAMug"},{"cell_type":"code","execution_count":null,"id":"5c18f08f","metadata":{"id":"5c18f08f"},"outputs":[],"source":["def similarity_search(components: RAGComponents,\n","                     target_embedding: List[float],\n","                     k: int = 5,\n","                     threshold: float = 0.8) -> List[Dict[str, Any]]:\n","    \"\"\"\n","    Findet √§hnliche Dokumente basierend auf einem Embedding\n","\n","    Args:\n","        components: RAG-System-Komponenten\n","        target_embedding: Ziel-Embedding f√ºr Vergleich\n","        k: Anzahl der zur√ºckzugebenden Ergebnisse\n","        threshold: Mindest-√Ñhnlichkeit (0-1)\n","\n","    Returns:\n","        Liste von √§hnlichen Dokumenten mit Metadaten\n","    \"\"\"\n","    # TODO: Implementierung\n","    pass\n","\n","# Test der Funktion\n","# text_embedding = components.text_embeddings.embed_query(\"K√ºnstliche Intelligenz\")\n","# similar_docs = similarity_search(rag_components, text_embedding, k=3, threshold=0.7)"]},{"cell_type":"markdown","id":"f6b21e8b","metadata":{"id":"f6b21e8b"},"source":["## A.2 Batch-Embedding"]},{"cell_type":"markdown","source":["\n","\n","Erstellen Sie eine Funktion f√ºr effiziente Batch-Verarbeitung von Embeddings:"],"metadata":{"id":"cZkeymCtAPOt"},"id":"cZkeymCtAPOt"},{"cell_type":"code","execution_count":null,"id":"ee3cc740","metadata":{"id":"ee3cc740"},"outputs":[],"source":["from typing import Iterator\n","\n","def batch_create_embeddings(components: RAGComponents,\n","                           texts: List[str],\n","                           batch_size: int = 10) -> Iterator[List[List[float]]]:\n","    \"\"\"\n","    Erstellt Embeddings in Batches f√ºr bessere Performance\n","\n","    Args:\n","        components: RAG-System-Komponenten\n","        texts: Liste von Texten\n","        batch_size: Gr√∂√üe der Batches\n","\n","    Yields:\n","        Batches von Embeddings\n","    \"\"\"\n","    # TODO: Implementierung mit Batch-Processing\n","    pass\n","\n","# Usage Example\n","# texts = [\"Text 1\", \"Text 2\", \"Text 3\", ...]\n","# for embedding_batch in batch_create_embeddings(rag_components, texts, batch_size=5):\n","#     print(f\"Verarbeitet {len(embedding_batch)} Embeddings\")"]},{"cell_type":"markdown","id":"bea55894","metadata":{"id":"bea55894"},"source":["## A.3 Evaluations-Framework"]},{"cell_type":"markdown","source":["\n","\n","Entwickeln Sie ein System zur Bewertung der Suchqualit√§t:"],"metadata":{"id":"nIwQU-3EATp8"},"id":"nIwQU-3EATp8"},{"cell_type":"code","execution_count":null,"id":"9c1e6cfe","metadata":{"id":"9c1e6cfe"},"outputs":[],"source":["@dataclass\n","class EvaluationResult:\n","    \"\"\"Ergebnis einer Evaluation\"\"\"\n","    precision: float\n","    recall: float\n","    f1_score: float\n","    avg_response_time: float\n","    total_queries: int\n","\n","def evaluate_search_quality(components: RAGComponents,\n","                          test_queries: List[str],\n","                          expected_results: List[List[str]]) -> EvaluationResult:\n","    \"\"\"\n","    Evaluiert die Qualit√§t des Suchsystems\n","\n","    Args:\n","        components: RAG-System-Komponenten\n","        test_queries: Liste von Test-Anfragen\n","        expected_results: Erwartete Ergebnisse pro Anfrage\n","\n","    Returns:\n","        Evaluations-Ergebnis mit Metriken\n","    \"\"\"\n","    # TODO: Implementierung der Evaluation\n","    pass\n","\n","# Test Data\n","test_data = [\n","    (\"Wer ist Thoren Navarro?\", [\"biografien_2.md\"]),\n","    (\"Roboter Bilder\", [\"robot_image.jpg\", \"cyborg.png\"]),\n","    # ... weitere Test-F√§lle\n","]\n","\n","# Usage\n","# queries, expected = zip(*test_data)\n","# results = evaluate_search_quality(rag_components, queries, expected)\n","# print(f\"F1-Score: {results.f1_score:.3f}\")"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all","text_representation":{"extension":".md","format_name":"markdown"}},"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["gcqh-rJGyUIv","lB1uwPlKyab1","b147567e","6rXJZa-l9UIp","acb01149","67f8e067","be4d3679","d3fef2e8","3c958b9f","88e8c594","YDDqKbqH9X4o","f82003ec","5607f07f","XtYfb6REe4f7","ecd2748f","PDd9yUxNAKzQ","f6b21e8b","bea55894"],"machine_shape":"hm","gpuType":"L4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}