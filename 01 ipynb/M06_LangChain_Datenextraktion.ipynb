{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOhEWsz8+E62uXyaoGBUhYq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"7\" color='grey'> <b>\n","Anwendung Generativer KI\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"}},{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Modul 06: LangChain: Datenextraktion\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"}},{"cell_type":"markdown","source":["# 1 | Übersicht\n","---"],"metadata":{"id":"oYvUY6gMBKO1"}},{"cell_type":"markdown","metadata":{"id":"pC9A-LaYhsta"},"source":["# 5.1: Strukturierter Ausgabeparser\n","\n","LangChain bietet eine breite Palette von Ausgabeparsern, die darauf ausgelegt sind, Informationen aus den von großen Sprachmodellen (LLMs) zurückgegebenen Ausgaben effizient zu extrahieren und zu strukturieren. Diese Ausgabeparser spielen eine entscheidende Rolle in der Architektur von LangChain und bilden in der Regel integrale Komponenten der sogenannten LangChain-Ketten. Diese Ketten sind konfigurierbare Operationssequenzen, die Modellausgaben verarbeiten und mit ihnen interagieren, um komplexe Aufgaben auszuführen. Um die Erstellung und Verwaltung dieser Ketten zu erleichtern, führt LangChain die LangChain Expression Language (LCEL) ein.\n","\n","Als Nächstes werden wir uns damit befassen, wie LCEL die erweiterte Erstellung und Ausführung von LangChain-Ketten ermöglicht, und anschließend untersuchen, wie verschiedene Ausgabeparser innerhalb dieser Ketten genutzt werden können, um aus den LLM-Ausgaben präzise und umsetzbare Erkenntnisse zu gewinnen.\n","\n","## LangChain Expression Language oder LCEL\n","\n","LangChain Expression Language oder [LCEL](https://python.langchain.com/docs/expression_language/) bietet eine deklarative Möglichkeit, Ketten einfach zusammenzustellen. Von Anfang an hat LCEL die Überführung von Prototypen in die Produktion ohne Codeänderungen unterstützt. Dies umfasst alles von einfachen „Prompt + LLM“-Ketten bis hin zu hochkomplexen Ketten, die einige Benutzer erfolgreich mit Hunderten von Schritten in Produktionsumgebungen implementiert haben. Hier sind einige Gründe, warum Sie sich für LCEL entscheiden könnten:\n","\n","* [First-class streaming support](https://python.langchain.com/docs/expression_language/streaming/): Indem Sie Ihre Ketten mit LCEL erstellen, erreichen Sie die optimale Zeit bis zum ersten Token, also die Zeit, die vergeht, bis der erste Ausgabeblock erscheint. In einigen Fällen bedeutet dies, Token direkt von einem LLM an einen Streaming-Ausgabeparser zu streamen, der analysierte, inkrementelle Ausgabeblöcke mit derselben Geschwindigkeit liefert, mit der der LLM-Anbieter die Rohtoken freigibt.\n","\n","* [Async support](https://python.langchain.com/docs/expression_language/interface/): Mit LCEL erstellte Ketten können sowohl synchrone APIs (z. B. in Ihrem Jupyter-Notebook während der Prototyperstellung) als auch asynchrone APIs (z. B. in einem LangServe-Server) verwenden. Diese doppelte Fähigkeit ermöglicht es, dass derselbe Code sowohl in Prototypen als auch in der Produktion effizient ausgeführt wird und viele gleichzeitige Anfragen auf demselben Server verarbeitet.\n","\n","* [Optimized parallel execution](https://python.langchain.com/docs/expression_language/primitives/parallel/): LCEL führt automatisch parallelisierbare Schritte in Ihren Ketten gleichzeitig aus, unabhängig davon, ob Sie synchrone oder asynchrone Schnittstellen verwenden, und minimiert so die Latenz.\n","\n","* [Retries and fallbacks](https://python.langchain.com/docs/guides/productionization/fallbacks/): Sie können Wiederholungsversuche und Fallbacks für jeden Teil Ihrer LCEL-Kette konfigurieren und so die Zuverlässigkeit im großen Maßstab verbessern. Wir verbessern auch die Streaming-Unterstützung für Wiederholungsversuche und Fallbacks, um die Zuverlässigkeit zu verbessern, ohne die Latenz zu erhöhen.\n","\n","* [Access to intermediate results](https://python.langchain.com/docs/expression_language/interface/#async-stream-events-beta): Bei komplexeren Ketten kann der Zugriff auf Zwischenergebnisse entscheidend sein. Mit dieser Funktion können Endbenutzer den Fortschritt sehen oder Entwickler beim Debuggen der Kette unterstützen. Zwischenergebnisse sind streambar und auf jedem LangServe-Server verfügbar.\n","\n","* [Input and output schemas](https://python.langchain.com/docs/expression_language/interface/#input-schema): Jede LCEL-Kette enthält Pydantic- und JSONSchema-Schemata, die aus der Struktur Ihrer Kette abgeleitet werden. Diese Schemata sind für die Validierung von Ein- und Ausgaben unerlässlich und stellen eine Kernfunktion von LangServe dar.\n","\n","* [Seamless LangSmith tracing](https://python.langchain.com/docs/langsmith/): Da Ketten immer komplexer werden, ist es wichtig, jeden Schritt nachzuverfolgen. LCEL protokolliert alle Schritte automatisch in LangSmith, um die Beobachtung und Debugging zu verbessern.\n","\n","* [Seamless LangServe deployment](https://python.langchain.com/docs/langserve/): Die Bereitstellung einer mit LCEL erstellten Kette ist mit LangServe unkompliziert und ermöglicht nahtlose Übergänge von der Entwicklung zur Produktion."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Vds7BAWITTH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HMLrKTqgSRkM"},"source":["# Einführung in den StructuredOutputParser\n","\n","LangChain bietet eine Vielzahl von Tools, die dabei helfen, Informationen aus der Ausgabe großer Sprachmodelle (LLMs) zu verarbeiten und zu extrahieren. In diesem Abschnitt werden wir die Funktionen des Structured Output Parser untersuchen, der besonders nützlich ist, wenn Sie Informationen aus mehreren Feldern zurückgeben müssen. Dieser Parser ist gut darin, Modellausgaben in unterschiedliche Kategorien zu organisieren und zu segmentieren, wodurch die Daten besser handhabbar und interpretierbar werden. Obwohl der Pydantic/JSON-Parser eine robustere und funktionsreichere Option für die Handhabung komplexer Datenstrukturen bietet, ist der Structured Output Parser eine ausgezeichnete Wahl für Umgebungen mit begrenzten Rechenressourcen oder bei Verwendung weniger leistungsstarker Modelle. Er bietet eine unkomplizierte und effiziente Möglichkeit, die Ausgabe zu strukturieren, ohne das Modell oder das System zu überfordern.\n","\n","Wir beginnen mit der Erstellung eines ResponseSchemas für jeden Wert, den wir extrahieren möchten. Wir müssen jeden Wert beschreiben. Wir konstruieren den StructuredOutputParser aus einer Liste dieser Schemata."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uu5zOki19kKR"},"outputs":[],"source":["from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","response_schemas = [\n","    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n","    ResponseSchema(\n","        name=\"source\",\n","        description=\"source used to answer the user's question, should be a website.\",\n","    ),\n","]\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"]},{"cell_type":"markdown","metadata":{"id":"_dQTrDn8TuUk"},"source":["Wir erstellen nun eine Eingabeaufforderungsvorlage, in der sowohl die Frage als auch die Formatierungsanweisungen angegeben werden können. Die soeben erstellten Schemata generieren die Formatierungsanweisungen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXwzsoJU9kAY"},"outputs":[],"source":["format_instructions = output_parser.get_format_instructions()\n","prompt = PromptTemplate(\n","    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n","    input_variables=[\"question\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")"]},{"cell_type":"markdown","metadata":{"id":"_DDMfoBUUDjs"},"source":["Bevor wir das LLM abfragen, stellen wir eine Frage und sehen uns an, wie LangChang die Eingabeaufforderung erstellt."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IX9IhDJpBDNN","outputId":"d2f9fcb1-a3a6-4f05-f26a-72080ac7e355"},"outputs":[{"name":"stdout","output_type":"stream","text":["answer the users question as best as possible.\n","The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"answer\": string  // answer to the user's question\n","\t\"source\": string  // source used to answer the user's question, should be a website.\n","}\n","```\n","When was the Python programming language introduced?\n"]}],"source":["question = \"When was the Python programming language introduced?\"\n","\n","print(prompt.invoke(question).text)"]},{"cell_type":"markdown","metadata":{"id":"sCC1bV0dUZgt"},"source":["Wie Sie sehen, verwendet LangChain die Schemata, um ein JSON-Format für die Rückgabe der Antwort anzugeben. Mit der Antwort in diesem JSON-Format ist es unkompliziert, die einzelnen Werte zu analysieren.\n","\n","Wir konstruieren nun eine Kette, um den StructuredOutputParser zu verwenden und das LLM abzufragen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWjcI5zB9j9k"},"outputs":[],"source":["MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")\n","chain = prompt | llm | output_parser"]},{"cell_type":"markdown","metadata":{"id":"gux36efBgSR9"},"source":["Nun präsentieren wir eine Frage, eine Antwort und eine Quelle für die Frage."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SxxA2nKN9j7B","outputId":"f035418e-3968-45a7-f1a4-d79d62a8f954"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'answer': 'Python programming language was introduced in 1991.', 'source': 'https://en.wikipedia.org/wiki/Python_(programming_language)'}\n"]}],"source":["result = chain.invoke({\"question\": question})\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"wR5J9U9bg5Br"},"source":["## Erkennen und Übersetzen\n","\n","Wir versuchen es jetzt mit einem Beispiel mit mehr Werten. Das folgende Programm akzeptiert Text in jeder Sprache und übersetzt ihn ins Französische, Spanische und Chinesische."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9snGgL4riemY"},"outputs":[],"source":["response_schemas = [\n","    ResponseSchema(name=\"detected\", description=\"The language of the user's input\"),\n","    ResponseSchema(name=\"spanish\", description=\"Spanish translation\"),\n","    ResponseSchema(name=\"french\", description=\"French translation\"),\n","    ResponseSchema(name=\"chinese\", description=\"Chinese translation\"),\n","]\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n","prompt = PromptTemplate(\n","    template=\"translate into the requested languages.\\n{format_instructions}\\n{question}\",\n","    input_variables=[\"question\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","chain = prompt | llm | output_parser"]},{"cell_type":"markdown","metadata":{"id":"sa6_dAk2ugre"},"source":["Wir beginnen mit dem Ausprobieren eines englischen Satzes und beobachten, wie er in die anderen drei Sprachen übersetzt wird."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9wKUJR3tiYP","outputId":"2e7a2aa4-8758-4135-d2e3-d834ccfcf44a"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'detected': 'en', 'spanish': '¿Cuándo se introdujo el lenguaje de programación Python?', 'french': 'Quand le langage de programmation Python a-t-il été introduit?', 'chinese': 'Python编程语言是什么时候推出的？'}\n"]}],"source":["question = \"When was the Python programming language introduced?\"\n","result = chain.invoke({\"question\": question})\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"MQFjKL7uDgfA"},"source":["# 5.2: Andere Parser (Kommaliste, JSON, Pandas, Datetime)\n","\n","\n","In diesem Abschnitt werden wir untersuchen, wie LangChain vielseitige Parser bietet, die eine Vielzahl von Datenformaten verarbeiten können, was seine Funktionalität in zahlreichen Anwendungen verbessert. Unter anderem kann es nahtlos in Daten in Form von Pandas-Datenrahmen, kommagetrennten Listen, JSON-Strukturen und Datums-/Uhrzeitobjekten integriert werden. Diese Fähigkeit stellt sicher, dass sich LangChain an unterschiedliche Dateneingaben anpassen kann, was es zu einem leistungsstarken Werkzeug für die Datenmanipulation und -analyse in verschiedenen Kontexten macht. Wir werden einige dieser Parser näher betrachten und ihre praktischen Anwendungen demonstrieren und hervorheben, wie sie genutzt werden können, um Prozesse zu optimieren und aussagekräftige Erkenntnisse aus Daten zu gewinnen.\n","\n","## Analysieren Sie die durch Kommas getrennte Listenantwort\n","\n","Wir beginnen mit dem Parser „CommaSeparatedListOutputParser“, der die LLM-Ausgabe in einer durch Kommas getrennten Liste übernehmen und als Python-Liste extrahieren kann."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gryn5FVuDgfB"},"outputs":[],"source":["from langchain.output_parsers import CommaSeparatedListOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","output_parser = CommaSeparatedListOutputParser()\n","\n","format_instructions = output_parser.get_format_instructions()\n","prompt = PromptTemplate(\n","    template=\"List ten {subject}.\\n{format_instructions}\",\n","    input_variables=[\"subject\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")\n","\n","chain = prompt | llm | output_parser"]},{"cell_type":"markdown","metadata":{"id":"vs9tTrVh78Sy"},"source":["Extrahieren Sie eine Liste von Städten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7gvIB0kxORP","outputId":"f6e4b2c4-0153-4e77-b9df-263f48b32b9a"},"outputs":[{"data":{"text/plain":["['New York City',\n"," 'Los Angeles',\n"," 'Chicago',\n"," 'Houston',\n"," 'Phoenix',\n"," 'Philadelphia',\n"," 'San Antonio',\n"," 'San Diego',\n"," 'Dallas',\n"," 'San Jose']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"subject\": \"cities\"})"]},{"cell_type":"markdown","metadata":{"id":"7z-cMptW7-wq"},"source":["Extrahieren Sie eine Liste von Programmiersprachen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljZKh6PKxOIi","outputId":"ab7548ff-3013-42df-9eda-f84b378be275"},"outputs":[{"data":{"text/plain":["['Java',\n"," 'Python',\n"," 'C++',\n"," 'JavaScript',\n"," 'Ruby',\n"," 'Swift',\n"," 'PHP',\n"," 'C#',\n"," 'Go',\n"," 'Kotlin']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"subject\": \"programming languages\"})"]},{"cell_type":"markdown","metadata":{"id":"mE2avWGaysc3"},"source":["## JSON-Antwort analysieren\n","\n","Wir können die Ausgabe des LLM in JSON formatieren. Für dieses Beispiel akzeptieren wir einen Satz, den wir als Englisch erkennen, und übersetzen ihn dann ins Spanische, Französische und Chinesische."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pvbqwz9xOAQ","outputId":"603e3fd8-6991-444d-c88c-e48438b8a04b"},"outputs":[{"data":{"text/plain":["{'detected': 'English',\n"," 'spanish': '¿Cuál es tu nombre?',\n"," 'french': 'Quel est ton nom?',\n"," 'chinese': '你叫什么名字？'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.output_parsers import JsonOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_openai import ChatOpenAI\n","\n","# Definieren Sie Ihre gewünschte Datenstruktur.\n","class Translate(BaseModel):\n","  detected: str = Field(description=\"the detected language of the input\")\n","  spanish: str = Field(description=\"the input translated to Spanish\")\n","  french: str = Field(description=\"the input translated to French\")\n","  chinese: str = Field(description=\"the input translated to Chinese\")\n","\n","# Und eine Abfrage, die ein Sprachmodell zum Auffüllen der Datenstruktur veranlassen soll.\n","input_text = \"What is your name?\"\n","\n","# Richten Sie einen Parser ein und fügen Sie Anweisungen in die Eingabeaufforderungsvorlage ein.\n","parser = JsonOutputParser(pydantic_object=Translate)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{input}\\n\",\n","    input_variables=[\"input\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"input\": input_text})"]},{"cell_type":"markdown","metadata":{"id":"dAY721mN14kp"},"source":["## Pandas-Dataframe abfragen\n","\n","Zu den Funktionen von Langchain gehört das Parsen und Analysieren von Pandas-Datenrahmen mithilfe des PandasDataFrameOutputParser. Mit dieser Funktion können Benutzer in Pandas-Datenrahmen gespeicherte Daten nahtlos integrieren und mit Langchain diese Daten abfragen und daraus Erkenntnisse gewinnen. Durch die Nutzung des PandasDataFrameOutputParser kann Langchain die Struktur, den Inhalt und den Kontext des Datenrahmens interpretieren und so genaue Antworten auf Benutzeranfragen liefern. Diese Integration ist besonders nützlich für die Datenanalyse, da sie eine interaktivere und auf natürlicher Sprache basierende Untersuchung der in Pandas-Datenrahmen gespeicherten Daten ermöglicht.\n","\n","Der folgende Code liest und zeigt die ersten Zeilen des klassischen [iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) an."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMP2U3ZJ0hDP","outputId":"5cc7b4c6-2ad6-4458-ec38-32a9f8095de7"},"outputs":[{"name":"stdout","output_type":"stream","text":["   sepal_l  sepal_w  petal_l  petal_w      species\n","0      5.1      3.5      1.4      0.2  Iris-setosa\n","1      4.9      3.0      1.4      0.2  Iris-setosa\n","2      4.7      3.2      1.3      0.2  Iris-setosa\n","3      4.6      3.1      1.5      0.2  Iris-setosa\n","4      5.0      3.6      1.4      0.2  Iris-setosa\n"]}],"source":["import pprint\n","from typing import Any, Dict\n","\n","import pandas as pd\n","from langchain.output_parsers import PandasDataFrameOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Laden Sie den Iris-Datensatz\n","df = pd.read_csv(\n","    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=[\"NA\", \"?\"]\n",")\n","\n","print(df.head())"]},{"cell_type":"markdown","metadata":{"id":"6errbnrFA1SC"},"source":["Als nächstes laden wir den Iris-Datenrahmen in eine PandasDataFrameOutputParser-Klasse."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5h1Y5yhKxNzS"},"outputs":[],"source":["parser = PandasDataFrameOutputParser(dataframe=df)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser"]},{"cell_type":"markdown","metadata":{"id":"5dPMQYCXA8r_"},"source":["Wir fragen den Mittelwert einer der Spalten ab."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dLvNJv62fIQ","outputId":"92779e74-1eba-4c1b-c103-b0d5f55b85af"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'mean': 5.843333333333334}\n"]}],"source":["query = \"Get the mean of the sepal_l column.\"\n","parser_output = chain.invoke({\"query\": query})\n","print(parser_output)"]},{"cell_type":"markdown","metadata":{"id":"ZhroER0yBG5G"},"source":["Wir fragen nach dem Unterelement einer der Spalten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lE-U8jO24oBY","outputId":"82e8b8d4-4ffc-4597-8b11-de4825923f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'sum': 179.90000000000003}\n"]}],"source":["query = \"Get the sum of petal_w column.\"\n","parser_output = chain.invoke({\"query\": query})\n","print(parser_output)"]},{"cell_type":"markdown","metadata":{"id":"Y09-epHS5McO"},"source":["## Datum/Uhrzeit\n","\n","Langchain enthält eine Funktion namens DatetimeOutputParser, die speziell zum Parsen von Datums- und Uhrzeitwerten aus Text entwickelt wurde. Diese Funktion ermöglicht es, in verschiedenen Formaten ausgedrückte Daten und Zeiten zu erkennen und zu interpretieren und sie in ein standardisiertes Datums- und Uhrzeitformat umzuwandeln. Diese Funktionalität ist von unschätzbarem Wert in Anwendungen, die Terminplanung, Datenanalyse oder jeden anderen Kontext beinhalten, in dem die genaue Handhabung von Daten und Zeiten unerlässlich ist. Durch die Verwendung des DatetimeOutputParser können Entwickler die Verarbeitung zeitlicher Daten optimieren und sicherstellen, dass ihre Anwendungen zeitbezogene Informationen effektiv verwalten und darauf reagieren können."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRuzzhXF5Oa1"},"outputs":[],"source":["from langchain.output_parsers import DatetimeOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import OpenAI\n","\n","output_parser = DatetimeOutputParser()\n","template = \"\"\"Answer the users question:\n","\n","{question}\n","\n","{format_instructions}\"\"\"\n","prompt = PromptTemplate.from_template(\n","    template,\n","    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",")"]},{"cell_type":"markdown","metadata":{"id":"roqInbqGFdUb"},"source":["Wir können die Eingabeaufforderung anzeigen, die wir zum Abrufen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HecixPQl6kYk","outputId":"e688b1a8-b675-4793-d8c9-e0ac2fe01142"},"outputs":[{"name":"stdout","output_type":"stream","text":["input_variables=['question'] partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1327-02-03T20:56:56.489822Z, 1058-10-02T02:08:23.921844Z, 682-08-19T01:21:02.307266Z\\n\\nReturn ONLY this string, no other words!\"} template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}'\n"]}],"source":["print(prompt)"]},{"cell_type":"markdown","metadata":{"id":"kg5ZkOetFiPx"},"source":["Wir erstellen die Kette, die wir zum Parsen von Daten verwenden werden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2w5gYty_5pKd"},"outputs":[],"source":["chain = prompt | llm | output_parser"]},{"cell_type":"markdown","metadata":{"id":"dD-gNvBHFooj"},"source":["Wir werden nach zwei Daten fragen, einem realen und einem fiktiven."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ymu48Ggg518q","outputId":"4aa29516-440c-4cd7-8ee7-ec18a8a4c4bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["1991-02-20 00:00:00\n"]}],"source":["output = chain.invoke({\"question\": \"When was the Python language introduced?\"})\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOPWYpxr6As1","outputId":"b9529904-92e8-4248-f686-a1208ef6be09"},"outputs":[{"name":"stdout","output_type":"stream","text":["2077-10-23 08:00:00\n"]}],"source":["output = chain.invoke({\"question\": \"What is the date of the war in the video game Fallout?\"})\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"Q6PFBjUSDo_N"},"source":["# 5.3: Pydantic Parser\n","\n","Pydantic ist eine Datenvalidierungs- und Einstellungsverwaltungsbibliothek in Python, die Python-Typanmerkungen verwendet. Sie ist so konzipiert, dass sie eine schnelle und einfache Datenanalyse und -validierung mithilfe des Standardtypisierungssystems von Python ermöglicht.\n","\n","Einige der Hauptfunktionen von Pydantic:\n","\n","* Datenvalidierung: Es validiert die Daten, um sicherzustellen, dass sie dem erwarteten Format entsprechen, und konvertiert Typen bei Bedarf.\n","* Editor-Unterstützung: Pydantic-Modelle sind Klassen, die die Typhinweise von Python nutzen und dadurch einfach mit modernen Editoren verwendet werden können, die Funktionen wie Typprüfung und Autovervollständigung bieten.\n","* Fehlerbehandlung: Es werden detaillierte und für Menschen lesbare Fehlerberichte bereitgestellt, um zu ermitteln, wo und warum die Datenvalidierung fehlgeschlagen ist.\n","* Einstellungsverwaltung: Pydantic wird häufig zum Verwalten von Einstellungen/Konfigurationen verwendet und erleichtert das Laden von Parametern aus Umgebungsvariablen, JSON-Dateien oder anderen Quellen.\n","* Erweiterbar: Sie können Modelle mit Methoden und Eigenschaften erweitern und die Validierungsdekoratoren von Pydantic verwenden, um benutzerdefinierte Validierungen durchzuführen.\n","* Integration mit anderen Bibliotheken: Es funktioniert gut mit vielen anderen Bibliotheken, wie z. B. FastAPI zum Erstellen von APIs, und verbessert deren Benutzerfreundlichkeit und Funktionalität.\n","\n","Insgesamt wird Pydantic wegen seiner Robustheit und Benutzerfreundlichkeit beim Sicherstellen der Konformität der Dateneingaben mit angegebenen Formaten sehr geschätzt, was es zu einem wertvollen Werkzeug in der modernen Python-Entwicklung macht, insbesondere in der Webentwicklung und bei Datenverarbeitungsanwendungen.\n","\n","LangChain, eine Bibliothek, die die Erstellung von Anwendungen mit Sprachmodellen erleichtern soll, bietet verschiedene Tools zur Verwaltung und Verbesserung der Interaktion mit diesen Modellen. Eines dieser Tools ist der PydanticOutputParser, der die leistungsstarken Validierungsfunktionen von Pydantic mit der Ausgabe großer Sprachmodelle (LLMs) wie GPT integriert.\n","\n","Das Hauptziel des PydanticOutputParser besteht darin, sicherzustellen, dass die Ausgaben eines Sprachmodells strukturiert sind und einem vordefinierten Schema entsprechen. Dies ist insbesondere bei Anwendungen wichtig, bei denen konsistente und zuverlässige Datenformate entscheidend sind, z. B. bei Datenextraktionsaufgaben, API-Antworten oder jedem Szenario, das eine anschließende automatisierte Verarbeitung der Ausgabe des Modells erfordert."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_J3QNntH18p"},"outputs":[],"source":["from typing import List\n","\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field, validator\n","from langchain_openai import ChatOpenAI\n","\n","MODEL = \"gpt-4o-mini\"\n","TEMPERATURE = 0\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")"]},{"cell_type":"markdown","metadata":{"id":"KUsS8qUHO2oc"},"source":["Der folgende Code verwendet ein LLM, um einen Witz zu erzählen. Der pydantische Parser stellt sicher, dass der Witz mit einem Fragezeichen endet. Diese Überprüfung stellt sicher, dass das eher zufällige LLM eine Ausgabe erzeugt, die unseren Erwartungen entspricht."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tn-F_KZQI9WK","outputId":"8784a6cf-6e23-4930-eed2-a510831b7fe7"},"outputs":[{"data":{"text/plain":["Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Definieren Sie Ihre gewünschte Datenstruktur.\n","class Joke(BaseModel):\n","    setup: str = Field(description=\"question to set up a joke\")\n","    punchline: str = Field(description=\"answer to resolve the joke\")\n","\n","    # Mit Pydantic können Sie ganz einfach benutzerdefinierte Validierungslogik hinzufügen.\n","    @validator(\"setup\")\n","    def question_ends_with_question_mark(cls, field):\n","        if field[-1] != \"?\":\n","            raise ValueError(\"Badly formed question!\")\n","        return field\n","\n","\n","# Und eine Abfrage, die ein Sprachmodell zum Auffüllen der Datenstruktur veranlassen soll.\n","joke_query = \"Tell me a joke about cats.\"\n","\n","# Richten Sie einen Parser ein und fügen Sie Anweisungen in die Eingabeaufforderungsvorlage ein.\n","parser = PydanticOutputParser(pydantic_object=Joke)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": joke_query})"]},{"cell_type":"markdown","metadata":{"id":"Fl9oeUkBPsIu"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SOwX3ue7JH5v","outputId":"a7696808-720b-4bb0-a16f-2d5d81dbda93"},"outputs":[{"data":{"text/plain":["Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Cast Away', 'Saving Private Ryan', 'Toy Story', 'The Green Mile'])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["class Actor(BaseModel):\n","    name: str = Field(description=\"name of an actor\")\n","    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n","    @validator('name')\n","    def validate_name(cls, value):\n","        parts = value.split()\n","        if len(parts) < 2:\n","            raise ValueError(\"Name must contain at least two words.\")\n","        if not all(part[0].isupper() for part in parts):\n","            raise ValueError(\"Each word in the name must start with a capital letter.\")\n","        return value\n","\n","actor_query = \"Generate the filmography for a random actor.\"\n","\n","parser = PydanticOutputParser(pydantic_object=Actor)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": actor_query})"]},{"cell_type":"markdown","metadata":{"id":"hzCTsn14DyU0"},"source":["# 5.4: Benutzerdefinierte Ausgabeparser\n","\n","In bestimmten Szenarien möchten Sie möglicherweise einen benutzerdefinierten Parser erstellen, um die Modellausgabe eindeutig zu formatieren.\n","\n","Es gibt zwei Möglichkeiten, einen benutzerdefinierten Parser zu erstellen:\n","\n","* Verwenden von **RunnableLambda** oder **RunnableGenerator** in LCEL – Dies ist für die meisten Fälle der empfohlene Ansatz.\n","* Erben von einer der Basisklassen zur Ausgabeanalyse – Dies ist die anspruchsvollere Methode.\n","\n","Die Unterschiede zwischen diesen Ansätzen sind meist oberflächlicher Natur und bestehen hauptsächlich darin, welche Rückrufe ausgelöst werden (z. B. on_chain_start vs. on_parser_start) und wie ein ausführbares Lambda im Vergleich zu einem Parser in einer Tracing-Plattform wie LangSmith visualisiert wird.\n","\n","Ich schlage vor, zum Parsen ausführbare Lambdas und ausführbare Generatoren zu verwenden.\n","\n","Der folgende Code erstellt ein grundlegendes LLM-Modell zur Verwendung.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMgvbZVmxgdv"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPERATURE = 0.0\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")"]},{"cell_type":"markdown","metadata":{"id":"mDH-sL9WNP4v"},"source":["In diesem Abschnitt erstellen wir einen einfachen Parser, der die Groß-/Kleinschreibung der Modellausgabe umkehrt.\n","\n","Wenn das Modell beispielsweise „Hallo Welt“ ausgibt, wandelt der Parser es in „HALLO WELT“ um."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uC_-RKjzwxtH","outputId":"3a3c02a1-85b0-4c01-a819-c583c407d066"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hELLO! hOW CAN i ASSIST YOU TODAY?'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from typing import Iterable\n","\n","from langchain_core.messages import AIMessage, AIMessageChunk\n","\n","def parse(ai_message: AIMessage) -> str:\n","    \"\"\"Parse the AI message.\"\"\"\n","    return ai_message.content.swapcase()\n","\n","\n","chain = llm | parse\n","chain.invoke(\"hello\")"]},{"cell_type":"markdown","metadata":{"id":"iC5GdyhEy2oh"},"source":["## Erben aus Parsing-Basisklassen\n","\n","Eine andere Möglichkeit, einen Parser zu implementieren, besteht in der Erbung von BaseOutputParser, BaseGenerationOutputParser oder einem anderen Basisparser, je nach Bedarf.\n","\n","Für die meisten Anwendungsfälle empfehlen wir diesen Ansatz grundsätzlich nicht, da er mehr Code erfordert, ohne nennenswerte Vorteile zu bieten.\n","\n","Der einfachste Typ eines Ausgabeparsers erweitert die Klasse BaseOutputParser und muss die folgenden Methoden implementieren:\n","\n","* **parsen**: Nimmt die String-Ausgabe vom Modell und analysiert sie.\n","* **(optional) _type**: Identifiziert den Namen des Parsers.\n","Wenn die Ausgabe des Chat-Modells oder LLM fehlerhaft ist, kann der Parser eine OutputParserException auslösen, um anzuzeigen, dass die Analyse aufgrund einer fehlerhaften Eingabe fehlgeschlagen ist. Durch die Verwendung dieser Ausnahme kann Code, der den Parser verwendet, Ausnahmen konsistent behandeln.\n","\n","Da BaseOutputParser die Runnable-Schnittstelle implementiert, wird jeder benutzerdefinierte Parser, den Sie auf diese Weise erstellen, zu einem gültigen LangChain Runnable und profitiert von automatischer asynchroner Unterstützung, Batch-Schnittstelle, Protokollierungsunterstützung und mehr.\n","\n","Hier ist ein einfacher Parser, der eine Zeichenfolgendarstellung eines Booleschen Werts (z. B. JA oder NEIN) analysieren und in den entsprechenden Booleschen Typ konvertieren kann."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKS6XvUKwxhz"},"outputs":[],"source":["from langchain_core.exceptions import OutputParserException\n","from langchain_core.output_parsers import BaseOutputParser\n","\n","\n","class BooleanOutputParser(BaseOutputParser[bool]):\n","    \"\"\"Custom parser to interpret 'YES'/'NO' strings as boolean values.\"\"\"\n","\n","    true_val: str = \"YES\"\n","    false_val: str = \"NO\"\n","\n","    def parse(self, text: str) -> bool:\n","        \"\"\"\n","        Parse the input text and return a boolean value.\n","\n","        Args:\n","            text (str): The input text to parse.\n","\n","        Returns:\n","            bool: True if text matches true_val, False if it matches false_val.\n","\n","        Raises:\n","            OutputParserException: If the text does not match true_val or false_val.\n","        \"\"\"\n","        cleaned_text = text.strip().upper()\n","        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n","            raise OutputParserException(\n","                f\"BooleanOutputParser expected output value to be either \"\n","                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n","                f\"Received {cleaned_text}.\"\n","            )\n","        return cleaned_text == self.true_val.upper()\n","\n","    @property\n","    def _type(self) -> str:\n","        \"\"\"\n","        Return the type of the parser.\n","\n","        Returns:\n","            str: The type of the parser.\n","        \"\"\"\n","        return \"boolean_output_parser\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ki6OVZpOzhoE","outputId":"c381fffe-ad6a-4bea-e750-141643f8451a"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["parser = BooleanOutputParser()\n","parser.invoke(\"YES\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iw04HNY-wxOf","outputId":"121938db-dfb8-43a6-8f96-6368e6f68d12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>\n"]}],"source":["try:\n","    parser.invoke(\"MEOW\")\n","except Exception as e:\n","print(f\"Eine Ausnahme vom Typ {type(e)} wurde ausgelöst.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43wfaEfpzrOh","outputId":"ec65bf24-aa94-42f9-8f8e-c07ab8b76b1a"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["parser = BooleanOutputParser(true_val=\"OKAY\")\n","parser.invoke(\"OKAY\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgAU4on6zvBh","outputId":"0864b706-a6ee-4026-a582-d0908beeca59"},"outputs":[{"data":{"text/plain":["[True, False]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["parser.batch([\"OKAY\", \"NO\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNPJtPDwz5VC","outputId":"b7715e0f-d714-49f8-cc96-c0a174e0cf63"},"outputs":[{"data":{"text/plain":["[True, False]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["await parser.abatch([\"OKAY\", \"NO\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMGThhGn0A3e","outputId":"36fe3baa-a72b-4038-df8d-165b93c424dc"},"outputs":[{"data":{"text/plain":["AIMessage(content='OKAY', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 13, 'total_tokens': 15}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b969e2cc-df17-4c98-a890-703318c5a4c2-0')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["llm.invoke(\"say either OKAY or NO\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMNLEDsE0LqJ","outputId":"8149ed7c-c703-43ee-83a7-f641f1f53e93"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["chain = llm | parser\n","chain.invoke(\"say either OKAY or NO\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UV2coxRD57Wh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"isGwPhF4GUM5"},"source":["### Entfernen von Nicht-Python-Text\n","\n","Large Language Models (LLMs) wie GPT-4 können Text generieren, der Code und erklärende Beschreibungen nahtlos vermischt. Dies kann zwar für Lern- und Dokumentationszwecke unglaublich nützlich sein, kann aber eine Herausforderung darstellen, wenn aus solchen Ausgaben mit gemischtem Inhalt nur der Code extrahiert und ausgeführt werden muss. Um dies zu beheben, implementieren wir eine einfache Funktion, die nicht-Python-Codezeilen aus einer gegebenen Textzeichenfolge entfernt.\n","\n","Bei diesem Ansatz werden reguläre Ausdrücke verwendet, um Zeilen zu identifizieren und beizubehalten, die der typischen Python-Syntax entsprechen, während Zeilen verworfen werden, die beschreibender Text zu sein scheinen. Aufgrund der inhärenten Komplexität und Variabilität sowohl von Python-Code als auch von natürlicher Sprache kann diese Methode jedoch nie perfekt sein. Sie basiert auf heuristischen Mustern, die Code manchmal fälschlicherweise als Text klassifizieren oder umgekehrt.\n","\n","Im nächsten Abschnitt werden wir untersuchen, wie ein anderes LLM beim Entfernen von Nicht-Python-Code helfen kann und möglicherweise eine ausgefeiltere und genauere Lösung bietet. Das folgende Beispiel enthält eine Mischung aus LLM-Kommentaren und generiertem Code.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjKY36CmGaW_"},"outputs":[],"source":["# Beispielverwendung\n","mixed_text = \"\"\"\n","Yes, you can estimate the value of Pi using various methods in Python. One\n","common approach is the Monte Carlo method. Here's a simple example:\n","\n","```python\n","import random\n","\n","def estimate_pi(num_samples):\n","    inside_circle = 0\n","\n","    for _ in range(num_samples):\n","        x = random.uniform(0, 1)\n","        y = random.uniform(0, 1)\n","        distance = x**2 + y**2\n","\n","        if distance <= 1:\n","            inside_circle += 1\n","\n","    pi_estimate = (inside_circle / num_samples) * 4\n","    return pi_estimate\n","\n","num_samples = 1000000\n","pi_estimate = estimate_pi(num_samples)\n","print(f\"Geschätzter Wert von Pi: {pi_estimate}\")\n","```\n","\n","This code uses the Monte Carlo method to estimate Pi by generating random points\n","within a unit square and checking how many fall inside a quarter circle. The\n","ratio of points inside the circle to the total points, multiplied by 4, gives an\n","estimate of Pi.\n","\n","Would you like to explore other methods or need further explanation on this\n","approach?\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"FuJeEXjrJujm"},"source":["Wir bieten jetzt eine Funktion zum Entfernen des nicht-Python-Texts. Die Funktion extract_python_code verwendet reguläre Ausdrücke, um Python-Codeblöcke zu finden und zu extrahieren, die in drei Backticks eingeschlossen sind. Sie verwendet die Funktion re.findall mit einem Muster, das Text zwischen Python und Trennzeichen abgleicht. Das Flag re.DOTALL ist enthalten, um sicherzustellen, dass der reguläre Ausdruck mit Zeilenumbruchzeichen innerhalb des Codeblocks übereinstimmen kann, wodurch die Extraktion mehrzeiliger Codes ermöglicht wird. Die übereinstimmenden Codeblöcke werden dann zu einer einzigen Zeichenfolge zusammengefügt, wobei führende oder nachfolgende Leerzeichen mithilfe der Strip-Methode entfernt werden. Dieser Ansatz isoliert den Python-Code effektiv vom umgebenden gemischten Text und erleichtert so das Extrahieren und unabhängige Verwenden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PR7NDFTXJc6K"},"outputs":[],"source":["import re\n","\n","def extract_python_code(mixed_text):\n","    code_blocks = re.findall(r'```python(.*?)```', mixed_text, re.DOTALL)\n","    return \"\\n\".join(code_blocks).strip()"]},{"cell_type":"markdown","metadata":{"id":"WmzgoZKULQ5F"},"source":["Im Folgenden wird gezeigt, wie wir extract_python_code verwenden können, um den Python-Code zu extrahieren.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmDfdbgpJevN","outputId":"c8db4e30-d467-447f-d3b8-6ca4cb980a57"},"outputs":[{"name":"stdout","output_type":"stream","text":["import random\n","\n","def estimate_pi(num_samples):\n","    inside_circle = 0\n","\n","    for _ in range(num_samples):\n","        x = random.uniform(0, 1)\n","        y = random.uniform(0, 1)\n","        distance = x**2 + y**2\n","\n","        if distance <= 1:\n","            inside_circle += 1\n","\n","    pi_estimate = (inside_circle / num_samples) * 4\n","    return pi_estimate\n","\n","num_samples = 1000000\n","pi_estimate = estimate_pi(num_samples)\n","print(f\"Estimated value of Pi: {pi_estimate}\")\n"]}],"source":["python_code = extract_python_code(mixed_text)\n","print(python_code)"]},{"cell_type":"markdown","metadata":{"id":"56odnzkBHRDh"},"source":["### Erstellen eines Code-Ausgabeparsers.\n","\n","Wir erstellen jetzt einen benutzerdefinierten Ausgabeparser, um allen nicht-Python-Code zu entfernen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1V60nfQ8lDa"},"outputs":[],"source":["from langchain_core.exceptions import OutputParserException\n","from langchain_core.output_parsers import BaseOutputParser\n","\n","class CodeOutputParser(BaseOutputParser[str]):\n","    \"\"\"Custom code parser.\"\"\"\n","\n","    def parse(self, text):\n","      return extract_python_code(text)\n","\n","    @property\n","    def _type(self) -> str:\n","        return \"CodeOutputParser\""]},{"cell_type":"markdown","metadata":{"id":"80uVtlDxL7rr"},"source":["Wie hier gezeigt, wird nur der Python-Code ausgegeben."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"ILEcSf8c8_4P","outputId":"74e40f5e-a348-47d4-a352-74c3f7cce207"},"outputs":[{"data":{"text/html":["<style>pre { line-height: 125%; }\n","td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n","span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n","td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n","span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",".output_html .hll { background-color: #ffffcc }\n",".output_html { background: #f8f8f8; }\n",".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",".output_html .err { border: 1px solid #FF0000 } /* Error */\n",".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",".output_html .o { color: #666666 } /* Operator */\n",".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",".output_html .ge { font-style: italic } /* Generic.Emph */\n",".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",".output_html .gr { color: #E40000 } /* Generic.Error */\n",".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",".output_html .gi { color: #008400 } /* Generic.Inserted */\n",".output_html .go { color: #717171 } /* Generic.Output */\n",".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",".output_html .gs { font-weight: bold } /* Generic.Strong */\n",".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",".output_html .kt { color: #B00040 } /* Keyword.Type */\n",".output_html .m { color: #666666 } /* Literal.Number */\n",".output_html .s { color: #BA2121 } /* Literal.String */\n",".output_html .na { color: #687822 } /* Name.Attribute */\n",".output_html .nb { color: #008000 } /* Name.Builtin */\n",".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",".output_html .no { color: #880000 } /* Name.Constant */\n",".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",".output_html .nf { color: #0000FF } /* Name.Function */\n",".output_html .nl { color: #767600 } /* Name.Label */\n",".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",".output_html .nv { color: #19177C } /* Name.Variable */\n",".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",".output_html .sx { color: #008000 } /* Literal.String.Other */\n",".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">random</span>\n","\n","<span class=\"k\">def</span> <span class=\"nf\">estimate_pi</span><span class=\"p\">(</span><span class=\"n\">num_points</span><span class=\"p\">):</span>\n","    <span class=\"n\">inside_circle</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n","    <span class=\"n\">total_points</span> <span class=\"o\">=</span> <span class=\"n\">num_points</span>\n","\n","    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_points</span><span class=\"p\">):</span>\n","        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n","        <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n","\n","        <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">**</span><span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">y</span><span class=\"o\">**</span><span class=\"mi\">2</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">1</span><span class=\"p\">:</span>\n","            <span class=\"n\">inside_circle</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n","\n","    <span class=\"n\">pi_estimate</span> <span class=\"o\">=</span> <span class=\"mi\">4</span> <span class=\"o\">*</span> <span class=\"n\">inside_circle</span> <span class=\"o\">/</span> <span class=\"n\">total_points</span>\n","    <span class=\"k\">return</span> <span class=\"n\">pi_estimate</span>\n","\n","<span class=\"n\">num_points</span> <span class=\"o\">=</span> <span class=\"mi\">1000000</span>\n","<span class=\"n\">pi_estimate</span> <span class=\"o\">=</span> <span class=\"n\">estimate_pi</span><span class=\"p\">(</span><span class=\"n\">num_points</span><span class=\"p\">)</span>\n","<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Estimated value of Pi using </span><span class=\"si\">{</span><span class=\"n\">num_points</span><span class=\"si\">}</span><span class=\"s2\"> points: </span><span class=\"si\">{</span><span class=\"n\">pi_estimate</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n","</pre></div>\n"],"text/latex":["\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n","\\PY{k+kn}{import} \\PY{n+nn}{random}\n","\n","\\PY{k}{def} \\PY{n+nf}{estimate\\PYZus{}pi}\\PY{p}{(}\\PY{n}{num\\PYZus{}points}\\PY{p}{)}\\PY{p}{:}\n","    \\PY{n}{inside\\PYZus{}circle} \\PY{o}{=} \\PY{l+m+mi}{0}\n","    \\PY{n}{total\\PYZus{}points} \\PY{o}{=} \\PY{n}{num\\PYZus{}points}\n","\n","    \\PY{k}{for} \\PY{n}{\\PYZus{}} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{num\\PYZus{}points}\\PY{p}{)}\\PY{p}{:}\n","        \\PY{n}{x} \\PY{o}{=} \\PY{n}{random}\\PY{o}{.}\\PY{n}{uniform}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\n","        \\PY{n}{y} \\PY{o}{=} \\PY{n}{random}\\PY{o}{.}\\PY{n}{uniform}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{)}\n","\n","        \\PY{k}{if} \\PY{n}{x}\\PY{o}{*}\\PY{o}{*}\\PY{l+m+mi}{2} \\PY{o}{+} \\PY{n}{y}\\PY{o}{*}\\PY{o}{*}\\PY{l+m+mi}{2} \\PY{o}{\\PYZlt{}}\\PY{o}{=} \\PY{l+m+mi}{1}\\PY{p}{:}\n","            \\PY{n}{inside\\PYZus{}circle} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n","\n","    \\PY{n}{pi\\PYZus{}estimate} \\PY{o}{=} \\PY{l+m+mi}{4} \\PY{o}{*} \\PY{n}{inside\\PYZus{}circle} \\PY{o}{/} \\PY{n}{total\\PYZus{}points}\n","    \\PY{k}{return} \\PY{n}{pi\\PYZus{}estimate}\n","\n","\\PY{n}{num\\PYZus{}points} \\PY{o}{=} \\PY{l+m+mi}{1000000}\n","\\PY{n}{pi\\PYZus{}estimate} \\PY{o}{=} \\PY{n}{estimate\\PYZus{}pi}\\PY{p}{(}\\PY{n}{num\\PYZus{}points}\\PY{p}{)}\n","\\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Estimated value of Pi using }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{num\\PYZus{}points}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{ points: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{pi\\PYZus{}estimate}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n","\\end{Verbatim}\n"],"text/plain":["import random\n","\n","def estimate_pi(num_points):\n","    inside_circle = 0\n","    total_points = num_points\n","\n","    for _ in range(num_points):\n","        x = random.uniform(0, 1)\n","        y = random.uniform(0, 1)\n","\n","        if x**2 + y**2 <= 1:\n","            inside_circle += 1\n","\n","    pi_estimate = 4 * inside_circle / total_points\n","    return pi_estimate\n","\n","num_points = 1000000\n","pi_estimate = estimate_pi(num_points)\n","print(f\"Estimated value of Pi using {num_points} points: {pi_estimate}\")"]},"metadata":{},"output_type":"display_data"}],"source":["from IPython.display import Code, display\n","\n","parser = CodeOutputParser()\n","chain = llm | parser\n","result = chain.invoke(\"Can I create Python code to estimate the value of Pi.\")\n","display(Code(result, language='python'))"]},{"cell_type":"markdown","metadata":{"id":"fniH9uRZD5ia"},"source":["# 5.5: Ausgabe-Fixing-Parser\n","\n","Dieser Ausgabeparser umschließt einen anderen Ausgabeparser und ruft, falls der erste fehlschlägt, einen anderen LLM auf, um etwaige Fehler zu beheben.\n","\n","Aber wir können auch andere Dinge tun, außer Fehler zu werfen. Insbesondere können wir die falsch formatierte Ausgabe zusammen mit den formatierten Anweisungen an das Modell übergeben und es bitten, sie zu korrigieren.\n","\n","Für dieses Beispiel verwenden wir den oben genannten Pydantic-Ausgabeparser. Folgendes passiert, wenn wir ihm ein Ergebnis übergeben, das nicht dem Schema entspricht:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qMYMUdUD5ib"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","MODEL = 'gpt-4o-mini'\n","TEMPERATURE = 0.0\n","\n","# Initialisieren Sie das OpenAI LLM mit Ihrem API-Schlüssel\n","llm = ChatOpenAI(\n","    model=MODEL,\n","    temperature=TEMPERATURE,\n","    n=1\n",")"]},{"cell_type":"markdown","metadata":{"id":"lgzKjYtqO9P2"},"source":["\n","Der Ausgabekorrekturparser umschließt nicht nur einen anderen Parser, sondern ruft auch ein sekundäres Sprachmodell auf, um Fehler zu korrigieren, wenn der erste fehlschlägt. Dieser innovative Parser kann mehr als nur Fehler behandeln – er verarbeitet aktiv falsch formatierte Ausgaben und verwendet formatierte Anweisungen, um das Modell um Korrekturen zu bitten.\n","\n","In diesem Szenario demonstrieren wir die Fähigkeiten eines Pydantic-Ausgabeparsers. Folgendes passiert, wenn wir ihm ein Ergebnis übergeben, das nicht dem Schema entspricht:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TP1vPCUS1dgl"},"outputs":[],"source":["from typing import List\n","\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","class Actor(BaseModel):\n","    name: str = Field(description=\"name of an actor\")\n","    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n","\n","\n","actor_query = \"Generate the filmography for a random actor.\"\n","\n","parser = PydanticOutputParser(pydantic_object=Actor)"]},{"cell_type":"markdown","metadata":{"id":"QOa9oMkZPYh1"},"source":["Wir simulieren jetzt eine falsch formatierte Antwort."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-YZryFf2PF8"},"outputs":[],"source":["misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\""]},{"cell_type":"markdown","metadata":{"id":"Jx_QcHADPx86"},"source":["Wir überprüfen, ob tatsächlich eine Ausnahme ausgelöst wird."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"0ErKED932TMc","outputId":"29c56bd3-a203-4f12-f154-4cd473f9db9b"},"outputs":[{"ename":"OutputParserException","evalue":"Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/json.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Parse the JSON string into a Python dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# for the original string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-92abc77851ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisformatted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTBaseModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ) -> TBaseModel:\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/json.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid json output: {text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutputParserException\u001b[0m: Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}"]}],"source":["try:\n","    parser.parse(misformatted)\n","except Exception as e:\n","print(f\"Eine Ausnahme vom Typ {type(e)} wurde ausgelöst.\")"]},{"cell_type":"markdown","metadata":{"id":"-6uDtWvrTZix"},"source":["Jetzt nutzen wir den OutputFixingParser, um das Problem mithilfe eines LLM zu beheben."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLwFLvFL2WQq"},"outputs":[],"source":["from langchain.output_parsers import OutputFixingParser\n","\n","new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)"]},{"cell_type":"markdown","metadata":{"id":"LJT8Cx5hThT_"},"source":["Wir sehen jetzt den richtig geladenen, falsch formatierten Text."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJq1gfTD2ab8","outputId":"62e149e0-92f6-493f-eb7c-5f46c64b5b59"},"outputs":[{"data":{"text/plain":["Actor(name='Tom Hanks', film_names=['Forrest Gump'])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["new_parser.parse(misformatted)"]},{"cell_type":"markdown","metadata":{"id":"hkDds1iecZNy"},"source":["Beachten Sie, dass der Zielparser den Methodenaufruf **get_format_instructions** unterstützen muss, damit der Formatkorrekturparser funktioniert, um eine Zeichenfolge zurückzugeben, die beschreibt, wie das Format angefordert wurde."]},{"cell_type":"markdown","metadata":{"id":"w7QKN6j8vNGF"},"source":["Wir stellen auch fest, dass es Swahili erkennen und übersetzen kann."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDtvdS6htpMg","outputId":"80957b38-8ad2-4586-bcc9-6f8045462ca7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'detected': 'Swahili', 'spanish': '¿Qué está pasando?', 'french': \"Qu'est-ce qui se passe?\", 'chinese': '我不知道发生了什么？'}\n"]}],"source":["question = \"Sijui nini kinaendelea?\"\n","result = chain.invoke({\"question\": question})\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"3TjZs_TRht1n"},"source":["# Modul 5 Aufgabe\n","\n","Die erste Aufgabe findet ihr hier: [assignment 5](https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class5.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vtxjKVLDWB6"},"outputs":[],"source":[]}]}