{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0684551f",
   "metadata": {
    "id": "0684551f"
   },
   "source": [
    "<p><font size=\"6\" color='grey'> <b>\n",
    "\n",
    "Generative KI. Verstehen. Anwenden. Gestalten.\n",
    "</b></font> </br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font size=\"5\" color='grey'> <b>\n",
    "Agenten\n",
    "</b></font> </br></p>\n",
    "\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "ogH-Fzpmbueo"
   },
   "id": "ogH-Fzpmbueo"
  },
  {
   "cell_type": "code",
   "source": "#@title ğŸ”§ Umgebung einrichten{ display-mode: \"form\" }\n!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\nfrom genai_lib.utilities import (\n    check_environment,\n    get_ipinfo,\n    setup_api_keys,\n    mprint,\n    install_packages,\n    mermaid,\n    get_model_profile,\n    extract_thinking,\n    load_prompt\n)\nsetup_api_keys(['OPENAI_API_KEY', 'SERPAPI_API_KEY'], create_globals=False)\nprint()\ncheck_environment()\nprint()\nget_ipinfo()",
   "metadata": {
    "id": "XUp8KhfjqR2N",
    "collapsed": true
   },
   "id": "XUp8KhfjqR2N",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title ğŸ› ï¸ Installationen { display-mode: \"form\" }\n",
    "install_packages([('google-search-results', 'serpapi'), 'ddgs', 'wikipedia'])"
   ],
   "metadata": {
    "id": "lG5yZ6lr4U3V",
    "collapsed": true
   },
   "id": "lG5yZ6lr4U3V",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "yldg73nnm3d",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "â¸ï¸ 5-Minuten-Check:\n",
    "</font></p>\n",
    "\n",
    "**Ziel:** PrÃ¼fen, ob du das vorherige Kapitel verstanden hast â€“ nicht, ob es gerade lÃ¤uft.\n",
    "\n",
    "**Aufgabe** (5 Minuten, ohne Vorlage):\n",
    "\n",
    "Rekonstruiere die zentrale Idee oder Code-Struktur des letzten Abschnitts selbststÃ¤ndig\n",
    "(kein Copy & Paste, kein Nachschlagen).\n",
    "\n",
    "WÃ¤hle eine der folgenden Optionen:\n",
    "\n",
    "+ ErklÃ¤re in 1â€“2 SÃ¤tzen, was hier konzeptionell passiert.\n",
    "\n",
    "+ VerÃ¤ndere eine Kleinigkeit (z. B. Prompt, Parameter, Reihenfolge) und beschreibe die Auswirkung.\n",
    "\n",
    "+ Markiere eine Stelle, die du nicht sicher erklÃ¤ren kannst, und formuliere eine konkrete Frage dazu.\n",
    "\n",
    "**Hinweis:**\n",
    "Nicht alles muss â€fertig\" oder â€korrekt\" sein. Entscheidend ist, wo dein VerstÃ¤ndnis gerade endet"
   ],
   "metadata": {
    "id": "yldg73nnm3d"
   }
  },
  {
   "cell_type": "markdown",
   "id": "bf088ba7",
   "metadata": {
    "id": "bf088ba7"
   },
   "source": [
    "# 1 | Was ist ein echter Agent?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wenn man sich mit generativer KI beschÃ¤ftigt, stÃ¶ÃŸt man frÃ¼her oder spÃ¤ter auf den Begriff **Agent** â€“ also ein System, das Aufgaben eigenstÃ¤ndig ausfÃ¼hrt. Doch was genau ist ein *â€echterâ€œ* Agent? Muss er vollstÃ¤ndig autonom sein? Solche Fragen fÃ¼hren schnell zu endlosen Grundsatzdiskussionen â€“ und genau das ist nicht hilfreich, wenn man einfach anfangen mÃ¶chte, mit GenAI zu arbeiten."
   ],
   "metadata": {
    "id": "kNOAqFifGB1d"
   },
   "id": "kNOAqFifGB1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/agentisch_1.png\" class=\"logo\" width=\"500\"/>"
   ],
   "metadata": {
    "id": "C4MsmT0v2WX0"
   },
   "id": "C4MsmT0v2WX0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Der bekannte KI-Experte **Andrew Ng** hat einen anderen, praktischeren Vorschlag gemacht: Statt darÃ¼ber zu streiten, ob etwas ein Agent ist oder nicht, sollten wir lieber davon sprechen, wie **agentisch** ein System ist â€“ also wie **selbststÃ¤ndig** es arbeitet. So kann man sich auf das konzentrieren, was wirklich zÃ¤hlt: Was kann das System leisten, und wo kann es sinnvoll eingesetzt werden?"
   ],
   "metadata": {
    "id": "rXYh9twZ2X_3"
   },
   "id": "rXYh9twZ2X_3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/agentisch_2.png\" class=\"logo\" width=\"900\"/>"
   ],
   "metadata": {
    "id": "RFiEEcrQ2nuB"
   },
   "id": "RFiEEcrQ2nuB"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Besonders einfach ist der Einstieg bei eher einfachen Aufgaben â€“ also bei Prozessen, die heute noch manuell erledigt werden, wie das AusfÃ¼llen von Formularen, das Nachschlagen in einer Datenbank oder das Kopieren von Informationen zwischen verschiedenen Systemen. Diese Aufgaben lassen sich gut in sogenannte agentische Workflows Ã¼berfÃ¼hren â€“ also in AblÃ¤ufe, bei denen die KI (teilweise) selbststÃ¤ndig handelt.\n",
    "\n",
    "\n",
    "NatÃ¼rlich gibt es auch deutlich komplexere Anwendungen, bei denen die KI viele Entscheidungen trifft, Schleifen durchlÃ¤uft und sich an neue Situationen anpasst. Solche Systeme sind spannend â€“ aber gerade fÃ¼r den Anfang ist es oft sinnvoller, mit kleineren, Ã¼berschaubaren Schritten zu starten. Dort liegen aktuell auch die meisten Chancen, GenAI im Alltag oder im Beruf sinnvoll einzusetzen.\n",
    "\n"
   ],
   "metadata": {
    "id": "SmvdRxMM2pAu"
   },
   "id": "SmvdRxMM2pAu"
  },
  {
   "cell_type": "markdown",
   "id": "0c0d5d3zhgst",
   "source": [
    "**Beispiele:**\n",
    "\n",
    "| Autonomiegrad      | Entscheidungsspielraum                         | Beispielhafter Agent                             | Kontrolle | Vorhersagbarkeit | Konkreter Anwendungsfall                                                                                                                                      |\n",
    "|--------------------|------------------------------------------------|--------------------------------------------------|----------|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Niedrig            | Keine â€“ fester Ablauf                          | Skript mit harter Toolverkettung                | Hoch     | Voll             | Unterrichts-Agent, der immer: (1) feste Suchbegriffe zu â€schwarzen LÃ¶chern\" nutzt, <br>(2) definierte Seiten lÃ¤dt und (3) aus diesen Quellen einen Aufsatz schreibt. |\n",
    "| Mittel (semi)      | Einige Entscheidungen erlaubt                  | Agent wÃ¤hlt Tools aus vordefinierter Liste      | Mittel   | Hoch bis mittel  | Recherche-Agent, der bei â€Aufsatz Ã¼ber schwarze LÃ¶cher\" selbst entscheidet, ob er <br>Websuche, News-Suche oder Papers (arXiv) nutzt und wie viele Seiten er lÃ¤dt. |\n",
    "| Hoch               | Plant und handelt weitgehend selbststÃ¤ndig     | Agent erstellt Tools oder neue Strategien       | Niedrig  | Gering           | Forschungs-Agent, der nur das Ziel â€aktuelle Ãœbersicht zu schwarzer-Loch-Forschung\" <br>bekommt, selbst Rechercheplan, Toolaufrufe und ggf. eigenen Parser-Code entwickelt. |"
   ],
   "metadata": {
    "id": "0c0d5d3zhgst"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Fazit:**     \n",
    "Es muss nicht gleich ein â€superintelligenterâ€œ Agent sein. Besser ist es, pragmatisch zu denken, einfache Prozesse zu automatisieren â€“ und so Schritt fÃ¼r Schritt Erfahrungen zu sammeln."
   ],
   "metadata": {
    "id": "PYc7Gtkl21R-"
   },
   "id": "PYc7Gtkl21R-"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Agenten erweitern LLMs**\n",
    "\n",
    "Agenten sind mehr als nur Sprachmodelle. Sie verbinden die SprachfÃ¤higkeiten eines LLMs mit praktischer HandlungsfÃ¤higkeit:\n",
    "\n",
    "+ LLM als Denkmodul: Das LLM Ã¼bernimmt das SprachverstÃ¤ndnis und das logische Schlussfolgern.\n",
    "\n",
    "+ Erweiterbarkeit durch Tools: Agenten greifen z.â€¯B. auf Web, Datenbanken oder externe APIs zu.\n",
    "\n",
    "+ Transparenter Denkprozess: Der Agent zeigt, wie er zum Ergebnis kommt â€“ ideal zum Lernen und Verstehen.\n",
    "\n",
    "+ Entscheidungen treffen: Agenten analysieren, planen und wÃ¤hlen aus mehreren Optionen â€“ nicht nur einmal, sondern iterativ."
   ],
   "metadata": {
    "id": "-Pieqmzvw1nn"
   },
   "id": "-Pieqmzvw1nn"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 | Anatomie eines Agenten\n",
    "---"
   ],
   "metadata": {
    "id": "UkgEROmi1gRU"
   },
   "id": "UkgEROmi1gRU"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Was macht einen KI-Agenten aus?**\n",
    "\n",
    "Ein Agent ist mehr als ein LLM mit Werkzeugen. Er arbeitet nicht nur reaktiv, sondern verfolgt Ziele, trifft Entscheidungen und passt sein Verhalten an. Um das zu erreichen, braucht er eine klar definierte Architektur â€“ sonst bleibt er ein Tool-Controller statt ein intelligentes System.\n",
    "\n"
   ],
   "metadata": {
    "id": "ibKl3w4g1lwb"
   },
   "id": "ibKl3w4g1lwb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Die 6 Kernkomponenten eines Agenten**\n",
    "\n",
    "Diese Komponenten bilden ein vollstÃ¤ndiges Agentenmodell. Fehlt eine davon, kommt der Agent schnell an seine Grenzen (z. B. endlose Schleifen, fehlende Zielorientierung, chaotische Tool-Nutzung).\n",
    "\n",
    "| Komponente                        | Rolle im Agenten                                                                |\n",
    "| --------------------------------- | ------------------------------------------------------------------------------- |\n",
    "| **1. Wahrnehmung (Perception)**   | Versteht Eingaben aus der Umgebung â€“ Sprache, Sensoren, API-Ergebnisse.         |\n",
    "| **2. Ziel- & Aufgabenmanagement** | Verwaltet Ziele, priorisiert Aufgaben, kennt Abbruchkriterien.                  |\n",
    "| **3. Reasoning & Planung**        | Entwickelt Strategien, zerlegt Aufgaben und passt den Plan bei FehlschlÃ¤gen an. |\n",
    "| **4. Tools & Aktionen**           | Interagiert mit der AuÃŸenwelt â€“ Ã¼ber APIs, Datenbanken, Code, Hardware etc.     |\n",
    "| **5. GedÃ¤chtnis & Kontext**       | Speichert Wissen, Verlauf und ZustÃ¤nde â€“ kurzfristig oder langfristig.          |\n",
    "| **6. Monitoring & Feedback**      | Bewertet Handlungen, erkennt Fehlverhalten und optimiert Strategien.            |\n",
    "\n",
    "*Das LLM ist dabei **eine mÃ¶gliche Komponente**, meist im Bereich Reasoning/Planung â€“ aber es ist nicht der Agent selbst.*\n",
    "\n"
   ],
   "metadata": {
    "id": "NozIvH_1YuKQ"
   },
   "id": "NozIvH_1YuKQ"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Der Denk- und Handlungszyklus**\n",
    "\n",
    "Ein Agent verarbeitet Informationen nicht linear wie ein LLM, sondern dynamisch und kontrolliert. Typischer Ablauf:\n",
    "\n",
    "1. **Verstehen** â†’ Eingabe interpretieren, Kontext bestimmen\n",
    "2. **Ziel definieren / Ã¼berprÃ¼fen**\n",
    "3. **Plan entwickeln** â†’ einzelne Schritte bestimmen\n",
    "4. **Handeln** â†’ Tools einsetzen, Daten abrufen, Aktionen durchfÃ¼hren\n",
    "5. **Auswerten** â†’ Erfolg/Misserfolg erkennen\n",
    "6. **Lernen / Anpassen** â†’ Strategie Ã¤ndern oder Ziel neu formulieren\n",
    "7. **Antwort geben oder weiterarbeiten**\n",
    "\n",
    "Dieser Zyklus kann mehrfach durchlaufen werden â€“ oder dauerhaft aktiv bleiben (autonomer Modus).\n",
    "\n",
    "\n",
    "Ein Agent ist ein **entscheidungsfÃ¤higes System**, kein schnell zusammengebauter Prompt mit Tools. Erst wenn Zielmanagement, GedÃ¤chtnis, Feedback und Handlungskompetenz zusammenspielen, entsteht echte Intelligenz â€“ und erst dann sind Agenten produktiv einsetzbar.\n"
   ],
   "metadata": {
    "id": "-w1fndSBloLt"
   },
   "id": "-w1fndSBloLt"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 | Direkter Vergleich\n",
    "---"
   ],
   "metadata": {
    "id": "9lDnaWpPxdUN"
   },
   "id": "9lDnaWpPxdUN"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Setup und Tools\n",
    "\n",
    "Bevor wir vergleichen kÃ¶nnen, mÃ¼ssen wir die notwendigen Tools fÃ¼r unseren Agenten definieren. Diese Tools reprÃ¤sentieren die erweiterten FÃ¤higkeiten, die einem einfachen LLM fehlen.\n",
    "\n"
   ],
   "metadata": {
    "id": "DkYGsPkJx0xc"
   },
   "id": "DkYGsPkJx0xc"
  },
  {
   "cell_type": "markdown",
   "id": "jjw0m7adp7n",
   "source": [
    "Der `@tool`-Decorator aus langchain_core.tools wandelt normale Python-Funktionen automatisch in LangChain-Tools um, die Agents/LLMs aufrufen kÃ¶nnen. Er extrahiert Name (Funktionsname), Beschreibung (Docstring) und Parameter (Type-Hints/Signature) und erzeugt eine JSON-Schema-kompatible Tool-Definition."
   ],
   "metadata": {
    "id": "jjw0m7adp7n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title ğŸ”§ Agenten-Tools { display-mode: \"form\" }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Alle Tool-Definitionen (zentral, werden in Abschnitt 3 und 4 wiederverwendet)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.serpapi import SerpAPIWrapper\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from serpapi import GoogleSearch\n",
    "import os, io, sys\n",
    "\n",
    "# ---- calculator\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"PrÃ¤zise mathematische Berechnungen durchfÃ¼hren.\n",
    "\n",
    "    Args:\n",
    "        expression: Mathematischer Ausdruck, z.B. '2847 * 1923'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if any(x in expression for x in ['import', 'exec', '__']):\n",
    "            return \"Unsichere Operation\"\n",
    "        result = eval(expression)\n",
    "        return f\"{expression} = {result}\"\n",
    "    except:\n",
    "        return \"Berechnungsfehler\"\n",
    "\n",
    "# ---- search\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Aktuelle Informationen im Internet suchen (News, Fakten, Daten, Wetter).\n",
    "\n",
    "    Args:\n",
    "        query: Suchbegriff in natÃ¼rlicher Sprache\n",
    "    \"\"\"\n",
    "    try:\n",
    "        serpapi = SerpAPIWrapper(params={\"engine\": \"google\"})\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = io.StringIO()\n",
    "        try:\n",
    "            result = serpapi.run(query)\n",
    "        finally:\n",
    "            sys.stdout = original_stdout\n",
    "\n",
    "        if not result or result.strip() == \"\":\n",
    "            return f\"Keine Suchergebnisse fÃ¼r '{query}' gefunden.\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"JSONDecodeError\" in error_msg or \"Expecting value\" in error_msg:\n",
    "            return f\"SerpAPI-Fehler: Leere oder ungÃ¼ltige API-Antwort fÃ¼r '{query}'.\"\n",
    "        return f\"Suchfehler fÃ¼r '{query}': {error_msg}\"\n",
    "\n",
    "# ---- stock_price\n",
    "@tool\n",
    "def stock_price(ticker: str) -> str:\n",
    "    \"\"\"Aktuelle BÃ¶rsenkurse abrufen via Google Finance.\n",
    "\n",
    "    Args:\n",
    "        ticker: Ticker im Format SYMBOL:BÃ–RSE, z.B. RHM:ETR (Rheinmetall XETRA),\n",
    "                SAP:ETR (SAP), BMW:ETR (BMW), VOW3:ETR (VW), SIE:ETR (Siemens)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            \"engine\": \"google_finance\",\n",
    "            \"q\": ticker,\n",
    "            \"hl\": \"de\",\n",
    "            \"api_key\": os.environ.get(\"SERPAPI_API_KEY\")\n",
    "        }\n",
    "        results = GoogleSearch(params).get_dict()\n",
    "\n",
    "        summary = results.get(\"summary\", {})\n",
    "        price = summary.get(\"price\")\n",
    "        currency = summary.get(\"currency\")\n",
    "        change = summary.get(\"price_change\")\n",
    "        change_pct = summary.get(\"price_change_percentage\")\n",
    "        stock_name = summary.get(\"title\", ticker)\n",
    "        exchange = summary.get(\"stock\", ticker)\n",
    "\n",
    "        if price:\n",
    "            parts = [f\"{stock_name} ({exchange}): {price} {currency or ''}\"]\n",
    "            if change is not None and change_pct is not None:\n",
    "                direction = \"ğŸ“ˆ\" if float(str(change).replace(\",\", \".\")) >= 0 else \"ğŸ“‰\"\n",
    "                parts.append(f\"{direction} VerÃ¤nderung: {change} ({change_pct}%)\")\n",
    "            return \" | \".join(parts)\n",
    "\n",
    "        return f\"Keine Kursdaten fÃ¼r '{ticker}' gefunden. API-Antwort: {results.get('error', 'unbekannt')}\"\n",
    "    except Exception as e:\n",
    "        return f\"Fehler bei Kursabfrage fÃ¼r {ticker}: {str(e)}\"\n",
    "\n",
    "# ---- read_file\n",
    "@tool\n",
    "def read_file(filename: str) -> str:\n",
    "    \"\"\"Datei vom Dateisystem lesen und Inhalt zurÃ¼ckgeben.\n",
    "\n",
    "    Args:\n",
    "        filename: Pfad zur Datei, z.B. 'notiz.txt'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return f.read()\n",
    "    except:\n",
    "        return f\"Datei {filename} nicht gefunden\"\n",
    "\n",
    "# ---- write_file\n",
    "@tool\n",
    "def write_file(filename: str, content: str) -> str:\n",
    "    \"\"\"Datei erstellen oder Ã¼berschreiben mit angegebenem Inhalt.\n",
    "\n",
    "    Args:\n",
    "        filename: Pfad zur Datei, z.B. 'notiz.txt'\n",
    "        content: Text-Inhalt der Datei\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        return f\"Datei {filename} erfolgreich geschrieben.\"\n",
    "    except Exception as e:\n",
    "        return f\"Fehler beim Schreiben der Datei: {str(e)}\"\n",
    "\n",
    "# ---- wiki\n",
    "@tool\n",
    "def wiki(term: str) -> str:\n",
    "    \"\"\"Einen Begriff in Wikipedia nachschlagen und Zusammenfassung abrufen.\n",
    "\n",
    "    Args:\n",
    "        term: Suchbegriff, z.B. 'Taylor Swift' oder 'Quantencomputer'\n",
    "    \"\"\"\n",
    "    wiki_api = WikipediaAPIWrapper()\n",
    "    try:\n",
    "        return wiki_api.run(term)\n",
    "    except Exception as e:\n",
    "        return f\"Wikipedia-Fehler: {e}\"\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Tool-Listen fÃ¼r die verschiedenen Abschnitte\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "tools = [calculator, search, stock_price, read_file, write_file, wiki]\n",
    "\n",
    "print(\"âœ… Alle Tools definiert:\")\n",
    "for t in tools:\n",
    "    print(f\" â€¢ {t.name:18s}:  {t.description.splitlines()[0]}\")"
   ],
   "metadata": {
    "id": "80D6VNn-yT5Y"
   },
   "id": "80D6VNn-yT5Y",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Vergleichstest"
   ],
   "metadata": {
    "id": "O5uiRNfWynCU"
   },
   "id": "O5uiRNfWynCU"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wir verwenden eine Frage, die sowohl aktuelle Daten als auch eine Berechnung erfordert, um die Grenzen eines LLMs und die StÃ¤rken eines Agenten zu demonstrieren."
   ],
   "metadata": {
    "id": "bNWuv_Mmyy_o"
   },
   "id": "bNWuv_Mmyy_o"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "Basismodell\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "hsWgy53xcTOe"
   },
   "id": "hsWgy53xcTOe"
  },
  {
   "cell_type": "code",
   "source": [
    "# Alle Imports\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "import time"
   ],
   "metadata": {
    "id": "R-IEl4pFkswZ"
   },
   "id": "R-IEl4pFkswZ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# LLM (Kurznotation: \"provider:model\")\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# Test-Frage die Grenzen aufzeigt\n",
    "test_question = \"Wie ist das Wetter in Berlin, was ist 2847 * 1923, wie ist der heutige XETRA (in EURO) Kurs der Aktie von Rheinmetall? Halte dich konsequent an die zu beantwortenden Fragen.\""
   ],
   "metadata": {
    "id": "UhXf4Oh5y1tN"
   },
   "id": "UhXf4Oh5y1tN",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "LLM only\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "LlGK2-pDcXMh"
   },
   "id": "LlGK2-pDcXMh"
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. EINFACHES LLM PROBIEREN\n",
    "mprint(\"### 1ï¸âƒ£ EINFACHES LLM:\")\n",
    "mprint(\"---\")\n",
    "\n",
    "start_time = time.time()\n",
    "llm_response = llm.invoke(test_question)\n",
    "llm_time = time.time() - start_time\n",
    "\n",
    "mprint(f\"**Antwort:** {llm_response.content}\")\n",
    "mprint(f\"**Zeit:** {llm_time:.2f}s\")"
   ],
   "metadata": {
    "id": "jN8RDdgyilCv"
   },
   "id": "jN8RDdgyilCv",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "Agent\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "kVEOCOmxcaUw"
   },
   "id": "kVEOCOmxcaUw"
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. AGENT MIT TOOLS\n",
    "mprint(\"### 2ï¸âƒ£ AGENT MIT TOOLS:\")\n",
    "mprint(\"---\")\n",
    "\n",
    "# Agent mit create_agent erstellen\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"Du bist ein hilfreicher Agent. Beantworte ALLE Teile einer Frage vollstÃ¤ndig.\n",
    "Nutze fÃ¼r jede Teilfrage das passende Tool:\n",
    "- calculator: fÃ¼r Berechnungen\n",
    "- stock_price: fÃ¼r Aktienkurse (Ticker im Format SYMBOL:BÃ–RSE, z.B. RHM:ETR)\n",
    "- search: fÃ¼r aktuelle Informationen (Wetter, News, Fakten)\n",
    "Formatiere das Ergebnis im Markdown-Format, Formeln: $ Formel $\"\"\",\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "agent_response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": test_question}]})\n",
    "agent_time = time.time() - start_time\n",
    "\n",
    "mprint(f\"## ğŸ¤– KI-Agent: \")\n",
    "mprint(\"---\")\n",
    "if isinstance(agent_response, dict) and 'messages' in agent_response:\n",
    "    last_message = agent_response['messages'][-1]\n",
    "    output = last_message.content if hasattr(last_message, 'content') else str(last_message)\n",
    "else:\n",
    "    output = str(agent_response)\n",
    "\n",
    "mprint(f\"{output}\")\n",
    "mprint(f\"**Zeit:** {agent_time:.2f}s\")"
   ],
   "metadata": {
    "id": "jP27gUApidiV"
   },
   "id": "jP27gUApidiV",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Unterschiede"
   ],
   "metadata": {
    "id": "r_Z7XTBky8Bj"
   },
   "id": "r_Z7XTBky8Bj"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Die Unterschiede zwischen LLM und Agent lassen sich in fÃ¼nf Kernbereichen zusammenfassen, die den Paradigmenwechsel von statischer zu dynamischer KI verdeutlichen.\n",
    "\n",
    "**Vergleich der FÃ¤higkeiten:**\n",
    "\n",
    "| Aspekt | Einfaches LLM | Agent |\n",
    "|--------|---------------|-------|\n",
    "| **Aktuelle Daten** | âŒ Nur Trainingsdaten | âœ… Ãœber Tools |\n",
    "| **Berechnungen** | âš ï¸ Oft ungenau | âœ… PrÃ¤zise Tools |\n",
    "| **Externe APIs** | âŒ UnmÃ¶glich | âœ… Beliebig erweiterbar |\n",
    "| **Transparenz** | ğŸ”’ Verborgen | ğŸ‘ï¸ Sichtbar |\n",
    "| **Erweiterbarkeit** | âŒ Statisch | âœ… Modular |\n"
   ],
   "metadata": {
    "id": "i_nWQCHa04cu"
   },
   "id": "i_nWQCHa04cu"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**ğŸ¯ FAZIT:**\n",
    "- **Agent = LLM + Tools + Reasoning**\n",
    "- â¡ï¸ Aus reaktiv wird proaktiv\n",
    "- â¡ï¸ Aus statisch wird dynamisch\n",
    "- â¡ï¸ Aus isoliert wird vernetzt\n"
   ],
   "metadata": {
    "id": "ifSi5c34092O"
   },
   "id": "ifSi5c34092O"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 | Hands-On: Agent bauen\n",
    "---"
   ],
   "metadata": {
    "id": "zpLyGf08b8JZ"
   },
   "id": "zpLyGf08b8JZ"
  },
  {
   "cell_type": "markdown",
   "id": "1b7594mxbll",
   "source": [
    "âš ï¸ Debug-Hinweis\n",
    "\n",
    "<details>\n",
    "\n",
    "\n",
    "**Problem mit `debug=True` in Jupyter/Colab:**\n",
    "\n",
    "Der Parameter `debug=True` kann in Jupyter/Colab zu folgendem Fehler fÃ¼hren:\n",
    "```\n",
    "AttributeError: 'OutStream' object has no attribute 'watch_fd_thread'\n",
    "```\n",
    "\n",
    "**Ursache:** LangGraph's Debug-Output versucht, auf Output-Streams zuzugreifen, die in Jupyter nicht korrekt initialisiert sind.\n",
    "\n",
    "**LÃ¶sungen:**\n",
    "1. **Einfachste LÃ¶sung:** `debug=True` Parameter entfernen oder auf `False` setzen\n",
    "2. **Alternative:** Verwenden Sie `stream_mode=\"values\"` statt `debug=True`:\n",
    "   ```python\n",
    "   for chunk in agent.stream(input, stream_mode=\"values\"):\n",
    "       print(chunk)\n",
    "   ```\n",
    "3. **Production:** Verwenden Sie LangSmith fÃ¼r professionelles Debugging\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "1b7594mxbll"
   }
  },
  {
   "cell_type": "code",
   "id": "rf5a4jo9yfp",
   "source": [
    "#@markdown   <p><font size=\"4\" color='green'>  ğŸ§œâ€â™€ï¸ Agent mit Tools-Architektur</font> </br></p>\n",
    "\n",
    "diagram = \"\"\"\n",
    "graph TB\n",
    "    A[\"User Input\"] --> B[\"Agent Core<br/>LLM + Reasoning\"]\n",
    "\n",
    "    B --> C{Tool<br/>benÃ¶tigt?}\n",
    "\n",
    "    C -->|Berechnung| D1[\"calculator\"]\n",
    "    C -->|Internet| D2[\"search\"]\n",
    "    C -->|Aktienkurs| D3[\"stock_price\"]\n",
    "    C -->|Datei lesen| D4[\"read_file\"]\n",
    "    C -->|Datei schreiben| D5[\"write_file\"]\n",
    "    C -->|Wikipedia| D6[\"wiki\"]\n",
    "    C -->|Kein Tool| E[\"Direkte Antwort\"]\n",
    "\n",
    "    D1 --> F[\"Tool-Ergebnisse\"]\n",
    "    D2 --> F\n",
    "    D3 --> F\n",
    "    D4 --> F\n",
    "    D5 --> F\n",
    "    D6 --> F\n",
    "\n",
    "    F --> G[\"LLM verarbeitet<br/>Ergebnisse\"]\n",
    "    G --> H[\"Finale Antwort\"]\n",
    "    E --> H\n",
    "\n",
    "    I[\"Agent Scratchpad<br/>GedÃ¤chtnis\"] -.-> B\n",
    "    B -.-> I\n",
    "    F -.-> I\n",
    "\n",
    "    style A fill:#e1f5ff\n",
    "    style B fill:#e1ffe1\n",
    "    style C fill:#f0e1ff\n",
    "    style D1 fill:#ffe1f5\n",
    "    style D2 fill:#ffe1f5\n",
    "    style D3 fill:#ffe1f5\n",
    "    style D4 fill:#ffe1f5\n",
    "    style D5 fill:#ffe1f5\n",
    "    style D6 fill:#ffe1f5\n",
    "    style E fill:#fff4e1\n",
    "    style F fill:#fff4e1\n",
    "    style G fill:#e1ffe1\n",
    "    style H fill:#e1ffe1\n",
    "    style I fill:#f0e1ff\n",
    "\"\"\"\n",
    "mermaid(diagram, width=900, height=600)"
   ],
   "metadata": {
    "cellView": "form",
    "id": "rf5a4jo9yfp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ğŸ”§ Agenten-Logik\n",
    "from datetime import date\n",
    "today = date.today().strftime(\"%d.%m.%Y\")\n",
    "\n",
    "# Agent mit create_agent erstellen (LangChain 1.0+ API)\n",
    "custom_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=f\"\"\"\n",
    "    Du bist ein hilfreicher Assistent mit Zugriff auf Tools. Bearbeite ALLE Aufgaben vollstÃ¤ndig.\n",
    "    Das heutige Datum ist {today}. Verwende IMMER die Tools fÃ¼r aktuelle Daten â€“ verweigere niemals mit der BegrÃ¼ndung, ein Datum liege in der Zukunft.\n",
    "    Nutze fÃ¼r jede Aufgabe das passende Tool:\n",
    "    - stock_price: fÃ¼r Aktienkurse (Ticker im Format SYMBOL:BÃ–RSE, z.B. RHM:ETR)\n",
    "    - search: fÃ¼r aktuelle Informationen (Software-Versionen, News). Formuliere gezielte Suchanfragen.\n",
    "    - wiki: fÃ¼r Wissen Ã¼ber Personen, Konzepte, Geschichte\n",
    "    - read_file / write_file: fÃ¼r Dateioperationen\n",
    "    Gib bei Suchergebnissen konkrete Zahlen und Fakten an, nicht nur Links.\n",
    "\"\"\",\n",
    ")"
   ],
   "metadata": {
    "id": "kwTEHHgPb8Jb"
   },
   "execution_count": null,
   "outputs": [],
   "id": "kwTEHHgPb8Jb"
  },
  {
   "cell_type": "code",
   "source": [
    "# ğŸ”§ Test\n",
    "input_text = f\"\"\"\n",
    "Erstelle eine Datei 'notiz.txt' mit dem Inhalt 'Agenten kÃ¶nnen autonom agieren. ğŸ¤–'.\n",
    "Wie ist der aktuelle XETRA Kurs der Aktie von Rheinmetall?\n",
    "Lese die Datei 'notiz.txt' und verÃ¤ndere die Zeitform von Gegenwart in Zukunft.\n",
    "Was ist die aktuelle Version von Python?\n",
    "Was steht zu Taylor Swift auf Wikipedia.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------âš ï¸ Workaround fÃ¼r Colab/Jupyter Stream-Problem -------------------------\n",
    "# Redirecte stdout/stderr temporÃ¤r, um OutStream-Fehler zu vermeiden\n",
    "original_stdout = sys.stdout\n",
    "original_stderr = sys.stderr\n",
    "sys.stdout = io.StringIO()\n",
    "sys.stderr = io.StringIO()\n",
    "\n",
    "try:\n",
    "    # Agent aufrufen mit korrektem Input-Format\n",
    "    response = custom_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": input_text}]})\n",
    "finally:\n",
    "    # Stelle Original-Streams wieder her\n",
    "    sys.stdout = original_stdout\n",
    "    sys.stderr = original_stderr"
   ],
   "metadata": {
    "id": "gnCj90b8b8Jb"
   },
   "execution_count": null,
   "outputs": [],
   "id": "gnCj90b8b8Jb"
  },
  {
   "cell_type": "code",
   "source": [
    "mprint(\"## ğŸ› ï¸ Hands-On Agent\")\n",
    "mprint(\"---\")\n",
    "\n",
    "# Extrahiere letzte Nachricht\n",
    "if isinstance(response, dict) and 'messages' in response:\n",
    "    last_message = response['messages'][-1]\n",
    "    output = last_message.content if hasattr(last_message, 'content') else str(last_message)\n",
    "\n",
    "    # Alle Messages anzeigen (um den Prozess zu sehen)\n",
    "    mprint(\"### Agent-Verlauf:\")\n",
    "    for i, msg in enumerate(response['messages'], 1):\n",
    "        role = getattr(msg, 'type', 'unknown')\n",
    "        content_str = str(msg.content if hasattr(msg, 'content') else msg)\n",
    "        content_preview = content_str[:200]\n",
    "        suffix = \"...\" if len(content_str) > 200 else \"\"\n",
    "        mprint(f\"{i}. {role}: {content_preview}{suffix}\")\n",
    "\n",
    "    mprint(\"\")\n",
    "    mprint(\"### Finale Antwort:\")\n",
    "    mprint(output)\n",
    "else:\n",
    "    mprint(\"### Output:\")\n",
    "    mprint(str(response))"
   ],
   "metadata": {
    "id": "BDiNrVhNb8Jb"
   },
   "execution_count": null,
   "outputs": [],
   "id": "BDiNrVhNb8Jb"
  },
  {
   "cell_type": "markdown",
   "id": "s9vcy09t8eh",
   "source": [
    "# 5 | Middleware\n",
    "---"
   ],
   "metadata": {
    "id": "s9vcy09t8eh"
   }
  },
  {
   "cell_type": "markdown",
   "id": "rm3owe6oum",
   "source": [
    "**Middleware** fungiert als  Zwischenschicht im Datenfluss zwischen der Nutzereingabe und der Modellausgabe. Sie ermÃ¶glicht es, Prompts und Ergebnisse gezielt zu manipulieren, zu validieren oder anzureichern, ohne den eigentlichen Modellkern modifizieren zu mÃ¼ssen.\n",
    "\n",
    "**Zentrale Aufgaben der Zwischenschichten:**\n",
    "\n",
    "* **Vorverarbeitung (Preprocessing):** Bereinigung von Eingabedaten, Strukturierung von Abfragen oder ErgÃ¤nzung durch Kontext (z. B. RAG â€“ Retrieval Augmented Generation).\n",
    "* **Kontrolle & Sicherheit:** Implementierung von Content-Filtern, PII-Anonymisierung (personenbezogene Daten) und Validierung von Eingabeparametern.\n",
    "* **Nachbearbeitung (Postprocessing):** Formatierung der Rohdaten (z. B. in JSON), KÃ¼rzung von Texten oder Anreicherung der Antwort mit Metadaten.\n",
    "* **Instrumentierung & Monitoring:** Systematisches Logging, Performance-Tracking sowie Debugging des gesamten Workflows.\n",
    "\n",
    "Middleware bietet maximale **FlexibilitÃ¤t und Kontrolle** Ã¼ber den KI-Output. Damit sie jedoch nicht zum Flaschenhals wird, ist eine modulare und saubere Architektur essenziell â€“ andernfalls steigt die SystemkomplexitÃ¤t schneller als der funktionale Mehrwert."
   ],
   "metadata": {
    "id": "rm3owe6oum"
   }
  },
  {
   "cell_type": "code",
   "id": "qcs2mkf6kl",
   "source": [
    "#@markdown   <p><font size=\"4\" color='green'>  ğŸ§œâ€â™€ï¸ Prozess-Diagramm</font> </br></p>\n",
    "\n",
    "diagram = \"\"\"\n",
    "flowchart TD\n",
    "\n",
    "    A[User Input] --> B[before_model<br/>Was geht rein?]\n",
    "    B --> C[MODEL<br/>LLM denkt nach]\n",
    "    C --> D[after_model<br/>Was kam raus?]\n",
    "    D --> E{Tool-Aufruf?}\n",
    "\n",
    "    E -->|Nein| F[Fertig]\n",
    "    E -->|Ja| G[wrap_tool_call<br/>Welches Tool? Mit welchen Args?]\n",
    "\n",
    "    G --> B\n",
    "\"\"\"\n",
    "mermaid(diagram, width=800, height=600)"
   ],
   "metadata": {
    "cellView": "form",
    "id": "qcs2mkf6kl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "rsjdtap6xi",
   "source": [
    "# Importe fÃ¼r Mideelware\n",
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import before_model, after_model, wrap_tool_call\n",
    "from langchain.tools.tool_node import ToolCallRequest\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ],
   "metadata": {
    "id": "rsjdtap6xi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "v93f4nuv5ci",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Middleware\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@before_model\n",
    "def log_before(state: AgentState, runtime):\n",
    "    \"\"\"state + runtime als Parameter (nicht ModelRequest!)\"\"\"\n",
    "    print(f\"\\nğŸ§  Model wird aufgerufen mit {len(state['messages'])} Nachrichten\")\n",
    "    for msg in state[\"messages\"][-2:]:\n",
    "        role = msg.type if hasattr(msg, \"type\") else \"unknown\"\n",
    "        content = str(msg.content)[:80]\n",
    "        print(f\"   [{role}]: {content}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_after(state: AgentState, runtime):\n",
    "    \"\"\"state + runtime als Parameter\"\"\"\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(f\"âš¡ Tool-Aufruf: {[tc['name'] for tc in msg.tool_calls]}\")\n",
    "    else:\n",
    "        print(f\"ğŸ’¬ Antwort generiert\")\n",
    "    return None\n",
    "\n",
    "\n",
    "@wrap_tool_call\n",
    "def log_tool(request: ToolCallRequest, handler):\n",
    "    \"\"\"request + handler als Parameter\"\"\"\n",
    "    print(f\"ğŸ”§ FÃ¼hre aus: {request.tool_call['name']}({request.tool_call['args']})\")\n",
    "    result = handler(request)\n",
    "    print(f\"âœ… Ergebnis: {str(result.content)[:100]}...\")\n",
    "    return result"
   ],
   "metadata": {
    "id": "v93f4nuv5ci"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gsse9k1631a",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Agent erstellen und ausfÃ¼hren\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ddg_search = DuckDuckGoSearchRun(name=\"WebSearch\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[ddg_search],\n",
    "    system_prompt=\"Du bist ein hilfreicher Assistent. Antworte auf Deutsch.\",\n",
    "    middleware=[log_before, log_after, log_tool]\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Wie ist das Wetter in Berlin?\"}]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINALE ANTWORT:\")\n",
    "print(result[\"messages\"][-1].content)"
   ],
   "metadata": {
    "id": "gsse9k1631a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6 | Wann braucht man einen Agent?\n",
    "---"
   ],
   "metadata": {
    "id": "PXIIt7Hc3TPW"
   },
   "id": "PXIIt7Hc3TPW"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Entscheidung zwischen einem einfachen LLM und einem Agenten hÃ¤ngt von den spezifischen Anforderungen Ihrer Anwendung ab. Eine klare Entscheidungsmatrix hilft dabei, die richtige Technologie fÃ¼r den jeweiligen Anwendungsfall zu wÃ¤hlen und Ressourcen effizient einzusetzen.\n",
    "\n"
   ],
   "metadata": {
    "id": "JS-ztBp43dPn"
   },
   "id": "JS-ztBp43dPn"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Wahl der richtigen Technologie beginnt mit der Analyse der Aufgabenanforderungen. WÃ¤hrend LLMs fÃ¼r viele Textverarbeitungsaufgaben ausreichen, sind Agenten unverzichtbar, wenn externe Interaktionen oder aktuelle Daten benÃ¶tigt werden.\n",
    "\n",
    "**Verwenden Sie einen Agenten wenn:**\n",
    "\n",
    "+ Sie **aktuelle** oder **dynamische** Daten benÃ¶tigen, die sich hÃ¤ufig Ã¤ndern (Aktienkurse, Wetter, Nachrichten). Agenten kÃ¶nnen Ã¼ber APIs auf Live-Daten zugreifen und diese in ihre Antworten integrieren.\n",
    "\n",
    "+ PrÃ¤zise Berechnungen erforderlich sind, bei denen **Genauigkeit** kritisch ist. LLMs approximieren mathematische Operationen, wÃ¤hrend Agenten echte Rechner-Tools verwenden.\n",
    "\n",
    "+ **Externe** Systeme angesprochen werden mÃ¼ssen, wie Datenbanken, APIs oder andere Services. Agenten kÃ¶nnen diese Integrationen nahtlos abwickeln.\n",
    "\n",
    "+ Komplexe, **mehrstufige Prozesse** durchgefÃ¼hrt werden sollen, bei denen jeder Schritt vom vorherigen abhÃ¤ngt. Der Agent-Reasoning-Loop ist fÃ¼r solche Szenarien optimiert.\n",
    "\n",
    "**Ein einfaches LLM reicht wenn:**\n",
    "\n",
    "+ Reine Textverarbeitung ohne externe Daten im Fokus steht. FÃ¼r Zusammenfassungen, Ãœbersetzungen oder Textanalysen sind LLMs optimal.\n",
    "\n",
    "+ Kreative Aufgaben gelÃ¶st werden sollen, wie das Schreiben von Geschichten, Gedichten oder Marketing-Texten. Hier sind die kreativen FÃ¤higkeiten des LLMs gefragt.\n",
    "\n",
    "+ ErklÃ¤rungen oder Bildungsinhalt basierend auf allgemeinem Wissen benÃ¶tigt werden. LLMs haben Zugang zu einem enormen Wissensfundus.\n",
    "\n",
    "+ Statische Code-Generierung ohne externe AbhÃ¤ngigkeiten erforderlich ist. FÃ¼r einfache Programmieraufgaben sind LLMs sehr effektiv.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Die Faustregel lautet**:    \n",
    "Wenn Sie Tools, aktuelle Daten oder externe Interaktionen benÃ¶tigen, wÃ¤hlen Sie einen Agenten. FÃ¼r reine Textverarbeitung reicht ein LLM aus."
   ],
   "metadata": {
    "id": "IyRu2Fbu3hrs"
   },
   "id": "IyRu2Fbu3hrs"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A | Aufgabe\n",
    "---"
   ],
   "metadata": {
    "id": "Pzc1rzQlNV8J"
   },
   "id": "Pzc1rzQlNV8J"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Aufgabestellungen unten bieten Anregungen, Sie kÃ¶nnen aber auch gerne eine andere Herausforderung angehen."
   ],
   "metadata": {
    "id": "QQUImb-86GUw"
   },
   "id": "QQUImb-86GUw"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "Kalkulation\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "gkF5wVxdx_iA"
   },
   "id": "gkF5wVxdx_iA"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gegeben ist eine Datei, die eine Reihe von Gleichungen enthÃ¤lt.\n",
    "Der Dateiname ist GenAI/02 data/gleichungen.txt\n",
    "\n",
    "**Gleichung:**    \n",
    "41748459 - 87226336    \n",
    "92995162 * 46769739    \n",
    "61530438 * 56074589    \n",
    "95329602 + 45418854    \n",
    "412907 + 3731910    \n",
    "...\n",
    "\n",
    "Verwenden Sie einen LangChain-Agenten mit einem Tool, um jede dieser Gleichungen zu berechnen, und erstellen Sie eine Datei Ã¤hnlich dieser:\n",
    "\n",
    "**Ergebnisse:**  \n",
    "41748459 - 87226336 = 45477877   \n",
    "92995162 * 46769739 = 4349359455002718   \n",
    "61530438 * 56074589 = 3450294021839982   \n",
    "95329602 + 45418854 = 140748456   \n",
    "412907 + 3731910 = 4144817   \n",
    "... ...\n",
    "\n"
   ],
   "metadata": {
    "id": "Y5y-OP9OemcW"
   },
   "id": "Y5y-OP9OemcW"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "bf088ba7",
    "UkgEROmi1gRU",
    "9lDnaWpPxdUN",
    "DkYGsPkJx0xc",
    "O5uiRNfWynCU",
    "r_Z7XTBky8Bj",
    "zpLyGf08b8JZ",
    "s9vcy09t8eh",
    "PXIIt7Hc3TPW",
    "Pzc1rzQlNV8J"
   ],
   "toc_visible": true
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}