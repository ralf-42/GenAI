{"cells":[{"cell_type":"markdown","id":"0684551f","metadata":{"id":"0684551f"},"source":["<p><font size=\"6\" color='grey'> <b>\n","\n","Generative KI. Verstehen. Anwenden. Gestalten.\n","</b></font> </br></p>"]},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Agenten\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"ogH-Fzpmbueo"},"id":"ogH-Fzpmbueo"},{"cell_type":"code","source":["#@title ğŸ”§ Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\n","from genai_lib.utilities import (\n","    check_environment,\n","    get_ipinfo,\n","    setup_api_keys,\n","    mprint,\n","    install_packages,\n","    mermaid,\n","    get_model_profile,\n","    extract_thinking,\n","    load_chat_prompt_template\n",")\n","setup_api_keys(['OPENAI_API_KEY', 'SERPAPI_API_KEY'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"metadata":{"id":"XUp8KhfjqR2N","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770921398555,"user_tz":-60,"elapsed":65180,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"52738200-805b-45bd-c068-97418a5ffbd3"},"id":"XUp8KhfjqR2N","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ OPENAI_API_KEY erfolgreich gesetzt\n","âœ“ SERPAPI_API_KEY erfolgreich gesetzt\n","\n","Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n","\n","Installierte LangChain- und LangGraph-Bibliotheken:\n","langchain                                1.2.8\n","langchain-chroma                         1.1.0\n","langchain-classic                        1.0.1\n","langchain-community                      0.4.1\n","langchain-core                           1.2.9\n","langchain-ollama                         1.0.1\n","langchain-openai                         1.1.8\n","langchain-text-splitters                 1.1.0\n","langgraph                                1.0.7\n","langgraph-checkpoint                     4.0.0\n","langgraph-prebuilt                       1.0.7\n","langgraph-sdk                            0.3.3\n","\n","IP-Adresse: 34.23.48.8\n","Hostname: 8.48.23.34.bc.googleusercontent.com\n","Stadt: North Charleston\n","Region: South Carolina\n","Land: US\n","Koordinaten: 32.8546,-79.9748\n","Provider: AS396982 Google LLC\n","Postleitzahl: 29415\n","Zeitzone: America/New_York\n"]}]},{"cell_type":"code","source":["#@title ğŸ› ï¸ Installationen { display-mode: \"form\" }\n","install_packages([('google-search-results', 'serpapi'), 'ddgs', 'wikipedia'])"],"metadata":{"id":"lG5yZ6lr4U3V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770921411264,"user_tz":-60,"elapsed":12705,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"15f52e16-3eb8-4e7d-bdb8-c516b34f346f"},"id":"lG5yZ6lr4U3V","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”„ Installiere google-search-results...\n","âœ… google-search-results erfolgreich installiert und importiert\n","ğŸ”„ Installiere ddgs...\n","âœ… ddgs erfolgreich installiert und importiert\n","ğŸ”„ Installiere wikipedia...\n","âœ… wikipedia erfolgreich installiert und importiert\n"]}]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","â¸ï¸ 5-Minuten-Check:\n","</font></p>\n","\n","**Ziel:** PrÃ¼fen, ob du das vorherige Kapitel verstanden hast â€“ nicht, ob es gerade lÃ¤uft.\n","\n","**Aufgabe** (5 Minuten, ohne Vorlage):\n","\n","Rekonstruiere die zentrale Idee oder Code-Struktur des letzten Abschnitts selbststÃ¤ndig\n","(kein Copy & Paste, kein Nachschlagen).\n","\n","WÃ¤hle eine der folgenden Optionen:\n","\n","+ ErklÃ¤re in 1â€“2 SÃ¤tzen, was hier konzeptionell passiert.\n","\n","+ VerÃ¤ndere eine Kleinigkeit (z. B. Prompt, Parameter, Reihenfolge) und beschreibe die Auswirkung.\n","\n","+ Markiere eine Stelle, die du nicht sicher erklÃ¤ren kannst, und formuliere eine konkrete Frage dazu.\n","\n","**Hinweis:**\n","Nicht alles muss â€fertigâ€œ oder â€korrektâ€œ sein. Entscheidend ist, wo dein VerstÃ¤ndnis gerade endet"],"metadata":{"id":"KVBRJzqaZuHY"},"id":"KVBRJzqaZuHY"},{"cell_type":"markdown","id":"bf088ba7","metadata":{"id":"bf088ba7"},"source":["# 1 | Was ist ein echter Agent?\n","---"]},{"cell_type":"markdown","source":["Wenn man sich mit generativer KI beschÃ¤ftigt, stÃ¶ÃŸt man frÃ¼her oder spÃ¤ter auf den Begriff **Agent** â€“ also ein System, das Aufgaben eigenstÃ¤ndig ausfÃ¼hrt. Doch was genau ist ein *â€echterâ€œ* Agent? Muss er vollstÃ¤ndig autonom sein? Solche Fragen fÃ¼hren schnell zu *Grundsatzdiskussionen* â€“ und genau das ist nicht hilfreich, wenn man einfach anfangen mÃ¶chte, mit GenAI zu arbeiten."],"metadata":{"id":"kNOAqFifGB1d"},"id":"kNOAqFifGB1d"},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/agentisch_1.png\" class=\"logo\" width=\"650\"/>"],"metadata":{"id":"C4MsmT0v2WX0"},"id":"C4MsmT0v2WX0"},{"cell_type":"markdown","source":["\n","\n","Praktischeren Vorschlag: Statt darÃ¼ber zu diskutieren, ob etwas ein Agent ist oder nicht, sollte man lieber davon sprechen, wie **agentisch** ein System ist â€“ also wie **selbststÃ¤ndig** es arbeitet. So kann man sich auf das konzentrieren, was wirklich zÃ¤hlt: Was kann das System leisten, und wo kann es sinnvoll eingesetzt werden?"],"metadata":{"id":"rXYh9twZ2X_3"},"id":"rXYh9twZ2X_3"},{"cell_type":"markdown","source":["\n","\n","\n","<img src=\"https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/agentisch_2.png\" class=\"logo\" width=\"900\"/>"],"metadata":{"id":"RFiEEcrQ2nuB"},"id":"RFiEEcrQ2nuB"},{"cell_type":"markdown","source":["\n","\n","Besonders einfach ist der Einstieg bei eher einfachen Aufgaben â€“ also bei Prozessen, die heute noch manuell erledigt werden, wie das AusfÃ¼llen von Formularen, das Nachschlagen in einer Datenbank oder das Kopieren von Informationen zwischen verschiedenen Systemen. Diese Aufgaben lassen sich gut in sogenannte agentische Workflows Ã¼berfÃ¼hren â€“ also in AblÃ¤ufe, bei denen die KI (teilweise) selbststÃ¤ndig handelt.\n","\n","\n","NatÃ¼rlich gibt es auch deutlich komplexere Anwendungen, bei denen die KI viele Entscheidungen trifft, Schleifen durchlÃ¤uft und sich an neue Situationen anpasst. Solche Systeme sind spannend â€“ aber gerade fÃ¼r den Anfang ist es oft sinnvoller, mit kleineren, Ã¼berschaubaren Schritten zu starten. Dort liegen aktuell auch die meisten Chancen, GenAI im Alltag oder im Beruf sinnvoll einzusetzen.\n","\n"],"metadata":{"id":"SmvdRxMM2pAu"},"id":"SmvdRxMM2pAu"},{"cell_type":"markdown","source":["**Beispiele:**\n","\n","| Autonomiegrad      | Entscheidungsspielraum                         | Beispielhafter Agent                             | Kontrolle | Vorhersagbarkeit | Konkreter Anwendungsfall                                                                                                                                      |\n","|--------------------|------------------------------------------------|--------------------------------------------------|----------|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| Niedrig            | Keine â€“ fester Ablauf                          | Skript mit harter Toolverkettung                | Hoch     | Voll             | Unterrichts-Agent, der immer: (1) feste Suchbegriffe zu â€schwarzen LÃ¶chernâ€œ nutzt, <br>(2) definierte Seiten lÃ¤dt und (3) aus diesen Quellen einen Aufsatz schreibt. |\n","| Mittel (semi)      | Einige Entscheidungen erlaubt                  | Agent wÃ¤hlt Tools aus vordefinierter Liste      | Mittel   | Hoch bis mittel  | Recherche-Agent, der bei â€Aufsatz Ã¼ber schwarze LÃ¶cherâ€œ selbst entscheidet, ob er <br>Websuche, News-Suche oder Papers (arXiv) nutzt und wie viele Seiten er lÃ¤dt. |\n","| Hoch               | Plant und handelt weitgehend selbststÃ¤ndig     | Agent erstellt Tools oder neue Strategien       | Niedrig  | Gering           | Forschungs-Agent, der nur das Ziel â€aktuelle Ãœbersicht zu schwarzer-Loch-Forschungâ€œ <br>bekommt, selbst Rechercheplan, Toolaufrufe und ggf. eigenen Parser-Code entwickelt. |"],"metadata":{"id":"VIEfNUVx4g5h"},"id":"VIEfNUVx4g5h"},{"cell_type":"markdown","source":["**Fazit:**     \n","Es muss nicht gleich ein â€superintelligenterâ€œ Agent sein. Besser ist es, pragmatisch zu denken, einfache Prozesse zu automatisieren â€“ und so Schritt fÃ¼r Schritt Erfahrungen zu sammeln."],"metadata":{"id":"PYc7Gtkl21R-"},"id":"PYc7Gtkl21R-"},{"cell_type":"markdown","source":["# 2 | Anatomie eines Agenten\n","---"],"metadata":{"id":"UkgEROmi1gRU"},"id":"UkgEROmi1gRU"},{"cell_type":"markdown","source":["**Was macht einen KI-Agenten aus?**\n","\n","Ein Agent ist mehr als ein LLM mit Werkzeugen. Er arbeitet nicht nur reaktiv, sondern verfolgt Ziele, trifft Entscheidungen und passt sein Verhalten an. Um das zu erreichen, braucht er eine klar definierte Architektur â€“ sonst bleibt er ein Tool-Controller statt ein intelligentes System.\n","\n"],"metadata":{"id":"ibKl3w4g1lwb"},"id":"ibKl3w4g1lwb"},{"cell_type":"markdown","source":["\n","**Die 6 Kernkomponenten eines Agenten**\n","\n","Diese Komponenten bilden ein vollstÃ¤ndiges Agentenmodell. Fehlt eine davon, kommt der Agent schnell an seine Grenzen (z. B. endlose Schleifen, fehlende Zielorientierung, chaotische Tool-Nutzung).\n","\n","| Komponente                        | Rolle im Agenten                                                                |\n","| --------------------------------- | ------------------------------------------------------------------------------- |\n","| **1. Wahrnehmung (Perception)**   | Versteht Eingaben aus der Umgebung â€“ Sprache, Sensoren, API-Ergebnisse.         |\n","| **2. Ziel- & Aufgabenmanagement** | Verwaltet Ziele, priorisiert Aufgaben, kennt Abbruchkriterien.                  |\n","| **3. Reasoning & Planung**        | Entwickelt Strategien, zerlegt Aufgaben und passt den Plan bei FehlschlÃ¤gen an. |\n","| **4. Tools & Aktionen**           | Interagiert mit der AuÃŸenwelt â€“ Ã¼ber APIs, Datenbanken, Code, Hardware etc.     |\n","| **5. GedÃ¤chtnis & Kontext**       | Speichert Wissen, Verlauf und ZustÃ¤nde â€“ kurzfristig oder langfristig.          |\n","| **6. Monitoring & Feedback**      | Bewertet Handlungen, erkennt Fehlverhalten und optimiert Strategien.            |\n","\n","*Das LLM ist dabei **eine mÃ¶gliche Komponente**, meist im Bereich Reasoning/Planung â€“ aber es ist nicht der Agent selbst.*\n","\n","\n","**Der Denk- und Handlungszyklus**\n","\n","Ein Agent verarbeitet Informationen nicht linear wie ein LLM, sondern dynamisch und kontrolliert. Typischer Ablauf:\n","\n","1. **Verstehen** â†’ Eingabe interpretieren, Kontext bestimmen\n","2. **Ziel definieren / Ã¼berprÃ¼fen**\n","3. **Plan entwickeln** â†’ einzelne Schritte bestimmen\n","4. **Handeln** â†’ Tools einsetzen, Daten abrufen, Aktionen durchfÃ¼hren\n","5. **Auswerten** â†’ Erfolg/Misserfolg erkennen\n","6. **Lernen / Anpassen** â†’ Strategie Ã¤ndern oder Ziel neu formulieren\n","7. **Antwort geben oder weiterarbeiten**\n","\n","Dieser Zyklus kann mehrfach durchlaufen werden â€“ oder dauerhaft aktiv bleiben (autonomer Modus).\n","\n","\n","\n","**Warum diese Struktur wichtig ist**\n","\n","Ohne klare Architektur treten typische Probleme auf:\n","\n","* Endlosschleifen (â€Agent denkt sich festâ€œ)\n","* ziellose Tool-Aufrufe\n","* keine Erfolgskriterien\n","* keine LernfÃ¤higkeit\n","* mangelnde Nachvollziehbarkeit (Problem fÃ¼r Audits/Sicherheit)\n","* schwer zu debuggen\n","\n","**Die eigentliche Designaufgabe eines Agenten liegt nicht im LLM â€“ sondern im System drum herum.**\n","\n","\n","Ein Agent ist ein **entscheidungsfÃ¤higes System**, kein schnell zusammengebauter Prompt mit Tools. Erst wenn Zielmanagement, GedÃ¤chtnis, Feedback und Handlungskompetenz zusammenspielen, entsteht echte Intelligenz â€“ und erst dann sind Agenten produktiv einsetzbar.\n"],"metadata":{"id":"NozIvH_1YuKQ"},"id":"NozIvH_1YuKQ"},{"cell_type":"markdown","source":["# 3 | Direkter Vergleich\n","---"],"metadata":{"id":"9lDnaWpPxdUN"},"id":"9lDnaWpPxdUN"},{"cell_type":"markdown","source":["## 3.1 Setup und Tools\n","\n","Bevor wir vergleichen kÃ¶nnen, mÃ¼ssen wir die notwendigen Tools fÃ¼r unseren Agenten definieren. Diese Tools reprÃ¤sentieren die erweiterten FÃ¤higkeiten, die einem einfachen LLM fehlen.\n","\n"],"metadata":{"id":"DkYGsPkJx0xc"},"id":"DkYGsPkJx0xc"},{"cell_type":"markdown","source":["Der `@tool`-Decorator aus langchain_core.tools wandelt normale Python-Funktionen automatisch in LangChain-Tools um, die Agents/LLMs aufrufen kÃ¶nnen. Er extrahiert Name (Funktionsname), Beschreibung (Docstring) und Parameter (Type-Hints/Signature) und erzeugt eine JSON-Schema-kompatible Tool-Definition."],"metadata":{"id":"FQlrkQavkWus"},"id":"FQlrkQavkWus"},{"cell_type":"code","source":["# ---- Tool 3 - weather (via SerpApi/Google)\n","@tool\n","def weather(city: str) -> str:\n","    \"\"\"ğŸŒ¤ï¸ WETTER - Aktuelle Wetterdaten abrufen (via Google Search)\n","    Gibt Temperatur, Luftfeuchtigkeit, Wind und weitere Details zurÃ¼ck.\n","    \"\"\"\n","    try:\n","        serpapi = SerpAPIWrapper(params={\"engine\": \"google\"})\n","        # Gezielte Abfrage fÃ¼r maximale Detailtiefe\n","        result = serpapi.run(f\"Wetter in {city} Temperatur Luftfeuchtigkeit Luftdruck\")\n","        return result\n","    except Exception as e:\n","        return f\"Wetterfehler fÃ¼r {city}: {str(e)}\"\n"],"metadata":{"id":"80D6VNn-yT5Y","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1770921411382,"user_tz":-60,"elapsed":102,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"d77cc370-2797-4416-b67c-e192a8d73235"},"id":"80D6VNn-yT5Y","execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tool' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-670866376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ---- Tool 3 - weather (via SerpApi/Google)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"ğŸŒ¤ï¸ WETTER - Aktuelle Wetterdaten abrufen (via Google Search)\n\u001b[1;32m      5\u001b[0m     \u001b[0mGibt\u001b[0m \u001b[0mTemperatur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLuftfeuchtigkeit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWind\u001b[0m \u001b[0mund\u001b[0m \u001b[0mweitere\u001b[0m \u001b[0mDetails\u001b[0m \u001b[0mzurÃ¼ck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tool' is not defined"]}]},{"cell_type":"markdown","source":["## 3.2 Vergleichstest"],"metadata":{"id":"O5uiRNfWynCU"},"id":"O5uiRNfWynCU"},{"cell_type":"markdown","source":["Wir verwenden eine Frage, die sowohl aktuelle Daten als auch eine Berechnung erfordert, um die Grenzen eines LLMs und die StÃ¤rken eines Agenten zu demonstrieren."],"metadata":{"id":"bNWuv_Mmyy_o"},"id":"bNWuv_Mmyy_o"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Basismodell\n","</font></p>"],"metadata":{"id":"hsWgy53xcTOe"},"id":"hsWgy53xcTOe"},{"cell_type":"code","source":["from langchain.chat_models import init_chat_model\n","from langchain.agents import create_agent\n","\n","import time\n","\n","# LLM (Kurznotation: \"provider:model\")\n","llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.0)\n","\n","# Test-Frage die Grenzen aufzeigt\n","test_question = \"Wie ist das Wetter in Berlin, was ist 2847 * 1923, wie ist der heutige XETRA (in EURO) Kurs der Aktie von Rheinmetall? Halte dich konsequent an die zu beantwortenden Fragen.\"\n","\n","mprint(\"### ğŸ§ª VERGLEICHSTEST\")\n","mprint(\"---\")\n","mprint(f\"**Frage:** {test_question}\")\n","print()"],"metadata":{"id":"UhXf4Oh5y1tN","executionInfo":{"status":"aborted","timestamp":1770921411375,"user_tz":-60,"elapsed":78133,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"UhXf4Oh5y1tN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","LLM only\n","</font></p>"],"metadata":{"id":"LlGK2-pDcXMh"},"id":"LlGK2-pDcXMh"},{"cell_type":"code","source":["# 1. EINFACHES LLM PROBIEREN\n","mprint(\"### 1ï¸âƒ£ EINFACHES LLM:\")\n","mprint(\"---\")\n","\n","start_time = time.time()\n","llm_response = llm.invoke(test_question)\n","llm_time = time.time() - start_time\n","\n","mprint(f\"**Antwort:** {llm_response.content}\")\n","mprint(f\"**Zeit:** {llm_time:.2f}s\")"],"metadata":{"id":"jN8RDdgyilCv","executionInfo":{"status":"aborted","timestamp":1770921411387,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"jN8RDdgyilCv","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Agent\n","</font></p>"],"metadata":{"id":"kVEOCOmxcaUw"},"id":"kVEOCOmxcaUw"},{"cell_type":"code","source":["# 2. AGENT MIT TOOLS\n","mprint(\"### 2ï¸âƒ£ AGENT MIT TOOLS:\")\n","mprint(\"---\")\n","\n","# Agent mit create_agent erstellen\n","agent = create_agent(\n","    model=llm,\n","    tools=tools,\n","    system_prompt=\"Du bist ein hilfreicher Agent. Nutze Tools fÃ¼r aktuelle Daten und Berechnungen. Formatiere das Ergebnis im Markdown-Format, Formeln: $ Formel $\",\n",")\n","\n","start_time = time.time()\n","agent_response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": test_question}]})\n","agent_time = time.time() - start_time\n","\n","mprint(f\"## ğŸ¤– KI-Agent: \")\n","mprint(\"---\")\n","\n","# Agent-Antwort extrahieren (letztes Message in messages-Liste)\n","if isinstance(agent_response, dict) and 'messages' in agent_response:\n","    last_message = agent_response['messages'][-1]\n","    output = last_message.content if hasattr(last_message, 'content') else str(last_message)\n","else:\n","    output = str(agent_response)\n","\n","mprint(f\"{output}\")\n","mprint(f\"**Zeit:** {agent_time:.2f}s\")"],"metadata":{"id":"jP27gUApidiV","executionInfo":{"status":"aborted","timestamp":1770921411448,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"jP27gUApidiV","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.3 Unterschiede"],"metadata":{"id":"r_Z7XTBky8Bj"},"id":"r_Z7XTBky8Bj"},{"cell_type":"markdown","source":["\n","\n","Die Unterschiede zwischen LLM und Agent lassen sich in fÃ¼nf Kernbereichen zusammenfassen, die den Paradigmenwechsel von statischer zu dynamischer KI verdeutlichen.\n","\n","**Vergleich der FÃ¤higkeiten:**\n","\n","| Aspekt | Einfaches LLM | Agent |\n","|--------|---------------|-------|\n","| **Aktuelle Daten** | âŒ Nur Trainingsdaten | âœ… Ãœber Tools |\n","| **Berechnungen** | âš ï¸ Oft ungenau | âœ… PrÃ¤zise Tools |\n","| **Externe APIs** | âŒ UnmÃ¶glich | âœ… Beliebig erweiterbar |\n","| **Transparenz** | ğŸ”’ Verborgen | ğŸ‘ï¸ Sichtbar |\n","| **Erweiterbarkeit** | âŒ Statisch | âœ… Modular |\n"],"metadata":{"id":"i_nWQCHa04cu"},"id":"i_nWQCHa04cu"},{"cell_type":"markdown","source":["\n","**ğŸ¯ FAZIT:**\n","- **Agent = LLM + Tools + Reasoning**\n","- â¡ï¸ Aus reaktiv wird proaktiv\n","- â¡ï¸ Aus statisch wird dynamisch\n","- â¡ï¸ Aus isoliert wird vernetzt\n"],"metadata":{"id":"ifSi5c34092O"},"id":"ifSi5c34092O"},{"cell_type":"markdown","source":["# 4 | Hands-On: Agent bauen\n","---"],"metadata":{"id":"zpLyGf08b8JZ"},"id":"zpLyGf08b8JZ"},{"cell_type":"markdown","id":"1b7594mxbll","source":["âš ï¸ Debug-Hinweis\n","\n","<details>\n","\n","\n","**Problem mit `debug=True` in Jupyter/Colab:**\n","\n","Der Parameter `debug=True` kann in Jupyter/Colab zu folgendem Fehler fÃ¼hren:\n","```\n","AttributeError: 'OutStream' object has no attribute 'watch_fd_thread'\n","```\n","\n","**Ursache:** LangGraph's Debug-Output versucht, auf Output-Streams zuzugreifen, die in Jupyter nicht korrekt initialisiert sind.\n","\n","**LÃ¶sungen:**\n","1. **Einfachste LÃ¶sung:** `debug=True` Parameter entfernen oder auf `False` setzen\n","2. **Alternative:** Verwenden Sie `stream_mode=\"values\"` statt `debug=True`:\n","   ```python\n","   for chunk in agent.stream(input, stream_mode=\"values\"):\n","       print(chunk)\n","   ```\n","3. **Production:** Verwenden Sie LangSmith fÃ¼r professionelles Debugging\n","\n","</details>"],"metadata":{"id":"1b7594mxbll"}},{"cell_type":"code","source":["# Moderne LangChain 1.0+ Imports\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import SystemMessage\n","from langchain_core.tools import tool\n","from langchain.chat_models import init_chat_model\n","from langchain.agents import create_agent\n","from langchain_community.utilities import WikipediaAPIWrapper\n","from langchain_community.utilities.serpapi import SerpAPIWrapper\n","\n","import os\n","import io\n","import sys"],"metadata":{"id":"oalufamCb8JZ","executionInfo":{"status":"aborted","timestamp":1770921411452,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"oalufamCb8JZ"},{"cell_type":"code","source":["# --- Tool 1 - Datei lesen\n","@tool\n","def read_file(filename: str) -> str:\n","    \"\"\"Datei lesen\n","    \"\"\"\n","    try:\n","        with open(filename, 'r') as f:\n","            return f.read()\n","    except:\n","        return f\"Datei {filename} nicht gefunden\"\n","\n","# --- Tool 2 - Datei schreiben\n","@tool\n","def write_file(filename: str, content: str) -> str:\n","    \"\"\"Datei schreiben. Erstellt oder Ã¼berschreibt eine Datei mit dem angegebenen Inhalt.\n","    \"\"\"\n","    try:\n","        with open(filename, 'w', encoding='utf-8') as f:\n","            f.write(content)\n","        return f\"Datei {filename} erfolgreich geschrieben.\"\n","    except Exception as e:\n","        return f\"Fehler beim Schreiben der Datei: {str(e)}\"\n","\n","# ---- Tool 3 - search (mit robuster Fehlerbehandlung)\n","@tool\n","def search(query: str) -> str:\n","    \"\"\"INTERNETSUCHE - Aktuelle Informationen finden (was LLM NICHT kann)\n","    \"\"\"\n","    try:\n","        serpapi = SerpAPIWrapper(params={\\\"engine\\\": \\\"google\\\"})\n","        original_stdout = sys.stdout\n","        sys.stdout = io.StringIO()\n","        try:\n","            result = serpapi.run(query)\n","        finally:\n","            sys.stdout = original_stdout\n","\n","        # PrÃ¼fe ob Ergebnis leer oder None ist\n","        if not result or result.strip() == \"\":\n","            return f\"Keine Suchergebnisse fÃ¼r '{query}' gefunden. MÃ¶glicherweise ist der SERPAPI_API_KEY ungÃ¼ltig oder das Limit erreicht.\"\n","\n","        return result\n","\n","    except Exception as e:\n","        error_msg = str(e)\n","        if \"JSONDecodeError\" in error_msg or \"Expecting value\" in error_msg:\n","            return f\"SerpAPI-Fehler: Leere oder ungÃ¼ltige API-Antwort fÃ¼r '{query}'. Bitte SERPAPI_API_KEY prÃ¼fen.\"\n","        return f\"Suchfehler fÃ¼r '{query}': {error_msg}\"\n","\n","# Tool 4 - Wikipedia-Suche\n","@tool\n","def wiki(term: str) -> str:\n","    \"\"\"Frage einen Begriff in Wikipedia nach\n","    \"\"\"\n","    wiki_api = WikipediaAPIWrapper()\n","    try:\n","        return wiki_api.run(term)\n","    except Exception as e:\n","        return f\"Wikipedia-Fehler: {e}\"\n","\n","# Tool-Liste erstellen\n","custom_tools = [read_file, write_file, search, wiki]"],"metadata":{"id":"JVJKY8Flb8Ja","executionInfo":{"status":"aborted","timestamp":1770921411456,"user_tz":-60,"elapsed":15,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"JVJKY8Flb8Ja"},{"cell_type":"code","source":["print(\"âœ… Tools definiert:\")\n","for t in custom_tools:\n","    print(f\" â€¢ {t.name:18s}:  {t.description}\")"],"metadata":{"id":"YN-EmW59u-BX","executionInfo":{"status":"aborted","timestamp":1770921411459,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"YN-EmW59u-BX","execution_count":null,"outputs":[]},{"cell_type":"code","id":"xjq5tiklson","source":["#@markdown   <p><font size=\"4\" color='green'>  ğŸ§œâ€â™€ï¸ Agent mit Tools-Architektur</font> </br></p>\n","\n","diagram = \"\"\"\n","graph TB\n","    A[\"User Input\"] --> B[\"Agent Core<br/>LLM + Reasoning\"]\n","\n","    B --> C{Tool<br/>benÃ¶tigt?}\n","\n","    C -->|Datei lesen| D1[\"read_file\"]\n","    C -->|Datei schreiben| D2[\"write_file\"]\n","    C -->|Internet| D3[\"search\"]\n","    C -->|Wikipedia| D4[\"wiki\"]\n","    C -->|Kein Tool| E[\"Direkte Antwort\"]\n","\n","    D1 --> F[\"Tool-Ergebnisse\"]\n","    D2 --> F\n","    D3 --> F\n","    D4 --> F\n","\n","    F --> G[\"LLM verarbeitet<br/>Ergebnisse\"]\n","    G --> H[\"Finale Antwort\"]\n","    E --> H\n","\n","    I[\"Agent Scratchpad<br/>GedÃ¤chtnis\"] -.-> B\n","    B -.-> I\n","    F -.-> I\n","\n","    style A fill:#e1f5ff\n","    style B fill:#e1ffe1\n","    style C fill:#f0e1ff\n","    style D1 fill:#ffe1f5\n","    style D2 fill:#ffe1f5\n","    style D3 fill:#ffe1f5\n","    style D4 fill:#ffe1f5\n","    style E fill:#fff4e1\n","    style F fill:#fff4e1\n","    style G fill:#e1ffe1\n","    style H fill:#e1ffe1\n","    style I fill:#f0e1ff\n","\"\"\"\n","mermaid(diagram, width=900, height=600)"],"metadata":{"cellView":"form","id":"xjq5tiklson","executionInfo":{"status":"aborted","timestamp":1770921411463,"user_tz":-60,"elapsed":18,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prompt als Template definieren\n","prompt = load_chat_prompt_template(\"../05_prompt/agent_prompt.md\")\n","\n","# Modell (Kurznotation: \"provider:model\")\n","llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.0)"],"metadata":{"id":"JlWAX21eb8Jb","executionInfo":{"status":"aborted","timestamp":1770921411469,"user_tz":-60,"elapsed":22,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"JlWAX21eb8Jb"},{"cell_type":"code","source":["# ğŸ”§ Agenten-Logik\n","# Agent mit create_agent erstellen (LangChain 1.0+ API)\n","custom_agent = create_agent(\n","    model=llm,\n","    tools=custom_tools,\n","    system_prompt=\"Du bist ein hilfreicher Assistent mit Zugriff auf Tools.\",\n","    # debug=True kann Fehler in Colab/Jupyter verursachen\n",")"],"metadata":{"id":"kwTEHHgPb8Jb","executionInfo":{"status":"aborted","timestamp":1770921411474,"user_tz":-60,"elapsed":78221,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"kwTEHHgPb8Jb"},{"cell_type":"code","source":["# ğŸ”§ Test\n","from datetime import date\n","today = date.today().strftime(\"%d.%m.%Y\")\n","\n","input_text = f\"\"\"\n","Erstelle eine Datei 'notiz.txt' mit dem Inhalt 'Agenten kÃ¶nnen autonom agieren. ğŸ¤–'.\n","Wie ist der aktuelle XETRA Kurs der Aktie von Rheinmetall von heute {today}?\n","Lese die Datei 'notiz.txt' und verÃ¤ndere die Zeitform von Gegenwart in Zukunft.\n","Was ist die AKTUELLE Version von Python, die heute vom {today} installiert werden kÃ¶nnte?\n","Was steht zu Taylor Swift auf Wikipedia.\n","\"\"\"\n","\n","# ---------------âš ï¸ Workaround fÃ¼r Colab/Jupyter Stream-Problem -------------------------\n","# Redirecte stdout/stderr temporÃ¤r, um OutStream-Fehler zu vermeiden\n","original_stdout = sys.stdout\n","original_stderr = sys.stderr\n","sys.stdout = io.StringIO()\n","sys.stderr = io.StringIO()\n","\n","try:\n","    # Agent aufrufen mit korrektem Input-Format\n","    response = custom_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": input_text}]})\n","finally:\n","    # Stelle Original-Streams wieder her\n","    sys.stdout = original_stdout\n","    sys.stderr = original_stderr"],"metadata":{"id":"gnCj90b8b8Jb","executionInfo":{"status":"aborted","timestamp":1770921411476,"user_tz":-60,"elapsed":78222,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"gnCj90b8b8Jb"},{"cell_type":"code","source":["mprint(\"## ğŸ› ï¸ Hands-On Agent\")\n","mprint(\"---\")\n","\n","# Extrahiere letzte Nachricht\n","if isinstance(response, dict) and 'messages' in response:\n","    last_message = response['messages'][-1]\n","    output = last_message.content if hasattr(last_message, 'content') else str(last_message)\n","\n","    # Alle Messages anzeigen (um den Prozess zu sehen)\n","    mprint(\"### Agent-Verlauf:\")\n","    for i, msg in enumerate(response['messages'], 1):\n","        role = getattr(msg, 'type', 'unknown')\n","        content_preview = str(msg.content if hasattr(msg, 'content') else msg)[:100]\n","        mprint(f\"{i}. {role}: {content_preview}...\")\n","\n","    mprint(\"\")\n","    mprint(\"### Finale Antwort:\")\n","    mprint(output)\n","else:\n","    mprint(\"### Output:\")\n","    mprint(str(response))"],"metadata":{"id":"BDiNrVhNb8Jb","executionInfo":{"status":"aborted","timestamp":1770921411510,"user_tz":-60,"elapsed":78255,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"BDiNrVhNb8Jb"},{"cell_type":"markdown","source":["# 5 | Middelware\n","---"],"metadata":{"id":"Va7a3hxJw4wu"},"id":"Va7a3hxJw4wu"},{"cell_type":"markdown","source":["**Middleware** fungiert als  Zwischenschicht im Datenfluss zwischen der Nutzereingabe und der Modellausgabe. Sie ermÃ¶glicht es, Prompts und Ergebnisse gezielt zu manipulieren, zu validieren oder anzureichern, ohne den eigentlichen Modellkern modifizieren zu mÃ¼ssen.\n","\n","**Zentrale Aufgaben der Zwischenschichten:**\n","\n","* **Vorverarbeitung (Preprocessing):** Bereinigung von Eingabedaten, Strukturierung von Abfragen oder ErgÃ¤nzung durch Kontext (z. B. RAG â€“ Retrieval Augmented Generation).\n","* **Kontrolle & Sicherheit:** Implementierung von Content-Filtern, PII-Anonymisierung (personenbezogene Daten) und Validierung von Eingabeparametern.\n","* **Nachbearbeitung (Postprocessing):** Formatierung der Rohdaten (z. B. in JSON), KÃ¼rzung von Texten oder Anreicherung der Antwort mit Metadaten.\n","* **Instrumentierung & Monitoring:** Systematisches Logging, Performance-Tracking sowie Debugging des gesamten Workflows.\n","\n","Middleware bietet maximale **FlexibilitÃ¤t und Kontrolle** Ã¼ber den KI-Output. Damit sie jedoch nicht zum Flaschenhals wird, ist eine modulare und saubere Architektur essenziell â€“ andernfalls steigt die SystemkomplexitÃ¤t schneller als der funktionale Mehrwert.\n"],"metadata":{"id":"KxwAXciNyZfD"},"id":"KxwAXciNyZfD"},{"cell_type":"code","source":["#@markdown   <p><font size=\"4\" color='green'>  ğŸ§œâ€â™€ï¸ Prozess-Diagramm</font> </br></p>\n","\n","diagram = \"\"\"\n","flowchart TD\n","\n","    A[User Input] --> B[before_model<br/>Was geht rein?]\n","    B --> C[MODEL<br/>LLM denkt nach]\n","    C --> D[after_model<br/>Was kam raus?]\n","    D --> E{Tool-Aufruf?}\n","\n","    E -->|Nein| F[Fertig]\n","    E -->|Ja| G[wrap_tool_call<br/>Welches Tool? Mit welchen Args?]\n","\n","    G --> B\n","\"\"\"\n","mermaid(diagram, width=800, height=600)"],"metadata":{"cellView":"form","id":"MzdiqfyCx4zG","executionInfo":{"status":"aborted","timestamp":1770921411517,"user_tz":-60,"elapsed":78262,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"MzdiqfyCx4zG"},{"cell_type":"code","source":["from langchain.agents import create_agent, AgentState\n","from langchain.agents.middleware import before_model, after_model, wrap_tool_call\n","from langchain.tools.tool_node import ToolCallRequest\n","from langchain_core.messages import ToolMessage\n","from langchain_community.tools import DuckDuckGoSearchRun"],"metadata":{"id":"WfzqB_1Ms7K3","executionInfo":{"status":"aborted","timestamp":1770921411525,"user_tz":-60,"elapsed":78269,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":null,"outputs":[],"id":"WfzqB_1Ms7K3"},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# Middleware\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","@before_model\n","def log_before(state: AgentState, runtime):\n","    \"\"\"state + runtime als Parameter (nicht ModelRequest!)\"\"\"\n","    print(f\"\\nğŸ§  Model wird aufgerufen mit {len(state['messages'])} Nachrichten\")\n","    for msg in state[\"messages\"][-2:]:\n","        role = msg.type if hasattr(msg, \"type\") else \"unknown\"\n","        content = str(msg.content)[:80]\n","        print(f\"   [{role}]: {content}\")\n","    return None\n","\n","\n","@after_model\n","def log_after(state: AgentState, runtime):\n","    \"\"\"state + runtime als Parameter\"\"\"\n","    msg = state[\"messages\"][-1]\n","    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n","        print(f\"âš¡ Tool-Aufruf: {[tc['name'] for tc in msg.tool_calls]}\")\n","    else:\n","        print(f\"ğŸ’¬ Antwort generiert\")\n","    return None\n","\n","\n","@wrap_tool_call\n","def log_tool(request: ToolCallRequest, handler):\n","    \"\"\"request + handler als Parameter\"\"\"\n","    print(f\"ğŸ”§ FÃ¼hre aus: {request.tool_call['name']}({request.tool_call['args']})\")\n","    result = handler(request)\n","    print(f\"âœ… Ergebnis: {str(result.content)[:100]}...\")\n","    return result"],"metadata":{"id":"2deAaFZKzoRI","executionInfo":{"status":"aborted","timestamp":1770921411535,"user_tz":-60,"elapsed":78278,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"2deAaFZKzoRI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","# Agent erstellen und ausfÃ¼hren\n","# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","\n","search = DuckDuckGoSearchRun(name=\"WebSearch\")\n","\n","agent = create_agent(\n","    model=\"openai:gpt-4o-mini\",\n","    tools=[search],\n","    system_prompt=\"Du bist ein hilfreicher Assistent. Antworte auf Deutsch.\",\n","    middleware=[log_before, log_after, log_tool]\n",")\n","\n","result = agent.invoke({\n","    \"messages\": [{\"role\": \"user\", \"content\": \"Wie ist das Wetter in Berlin?\"}]\n","})\n","\n","print(\"\\n\" + \"=\" * 50)\n","print(\"FINALE ANTWORT:\")\n","print(result[\"messages\"][-1].content)"],"metadata":{"id":"OtFASnC1zpv_","executionInfo":{"status":"aborted","timestamp":1770921411538,"user_tz":-60,"elapsed":78281,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"id":"OtFASnC1zpv_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6 | Wann braucht man einen Agent?\n","---"],"metadata":{"id":"PXIIt7Hc3TPW"},"id":"PXIIt7Hc3TPW"},{"cell_type":"markdown","source":["Die Entscheidung zwischen einem einfachen LLM und einem Agenten hÃ¤ngt von den spezifischen Anforderungen Ihrer Anwendung ab. Eine klare Entscheidungsmatrix hilft dabei, die richtige Technologie fÃ¼r den jeweiligen Anwendungsfall zu wÃ¤hlen und Ressourcen effizient einzusetzen.\n","\n"],"metadata":{"id":"JS-ztBp43dPn"},"id":"JS-ztBp43dPn"},{"cell_type":"markdown","source":["Die Wahl der richtigen Technologie beginnt mit der Analyse der Aufgabenanforderungen. WÃ¤hrend LLMs fÃ¼r viele Textverarbeitungsaufgaben ausreichen, sind Agenten unverzichtbar, wenn externe Interaktionen oder aktuelle Daten benÃ¶tigt werden.\n","\n","**Verwenden Sie einen Agenten wenn:**\n","\n","+ Sie **aktuelle** oder **dynamische** Daten benÃ¶tigen, die sich hÃ¤ufig Ã¤ndern (Aktienkurse, Wetter, Nachrichten). Agenten kÃ¶nnen Ã¼ber APIs auf Live-Daten zugreifen und diese in ihre Antworten integrieren.\n","\n","+ PrÃ¤zise Berechnungen erforderlich sind, bei denen **Genauigkeit** kritisch ist. LLMs approximieren mathematische Operationen, wÃ¤hrend Agenten echte Rechner-Tools verwenden.\n","\n","+ **Externe** Systeme angesprochen werden mÃ¼ssen, wie Datenbanken, APIs oder andere Services. Agenten kÃ¶nnen diese Integrationen nahtlos abwickeln.\n","\n","+ Komplexe, **mehrstufige Prozesse** durchgefÃ¼hrt werden sollen, bei denen jeder Schritt vom vorherigen abhÃ¤ngt. Der Agent-Reasoning-Loop ist fÃ¼r solche Szenarien optimiert.\n","\n","**Ein einfaches LLM reicht wenn:**\n","\n","+ Reine Textverarbeitung ohne externe Daten im Fokus steht. FÃ¼r Zusammenfassungen, Ãœbersetzungen oder Textanalysen sind LLMs optimal.\n","\n","+ Kreative Aufgaben gelÃ¶st werden sollen, wie das Schreiben von Geschichten, Gedichten oder Marketing-Texten. Hier sind die kreativen FÃ¤higkeiten des LLMs gefragt.\n","\n","+ ErklÃ¤rungen oder Bildungsinhalt basierend auf allgemeinem Wissen benÃ¶tigt werden. LLMs haben Zugang zu einem enormen Wissensfundus.\n","\n","+ Statische Code-Generierung ohne externe AbhÃ¤ngigkeiten erforderlich ist. FÃ¼r einfache Programmieraufgaben sind LLMs sehr effektiv.\n","\n","<br>\n","\n","**Die Faustregel lautet**:    \n","Wenn Sie Tools, aktuelle Daten oder externe Interaktionen benÃ¶tigen, wÃ¤hlen Sie einen Agenten. FÃ¼r reine Textverarbeitung reicht ein LLM aus."],"metadata":{"id":"IyRu2Fbu3hrs"},"id":"IyRu2Fbu3hrs"},{"cell_type":"markdown","source":["# A | Aufgabe\n","---"],"metadata":{"id":"Pzc1rzQlNV8J"},"id":"Pzc1rzQlNV8J"},{"cell_type":"markdown","source":["Die Aufgabestellungen unten bieten Anregungen, Sie kÃ¶nnen aber auch gerne eine andere Herausforderung angehen."],"metadata":{"id":"QQUImb-86GUw"},"id":"QQUImb-86GUw"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kalkulation\n","</font></p>"],"metadata":{"id":"gkF5wVxdx_iA"},"id":"gkF5wVxdx_iA"},{"cell_type":"markdown","source":["Gegeben ist eine Datei, die eine Reihe von Gleichungen enthÃ¤lt.\n","Der Dateiname ist GenAI/02 data/gleichungen.txt\n","\n","**Gleichung:**    \n","41748459 - 87226336    \n","92995162 * 46769739    \n","61530438 * 56074589    \n","95329602 + 45418854    \n","412907 + 3731910    \n","...\n","\n","Verwenden Sie einen LangChain-Agenten mit einem Tool, um jede dieser Gleichungen zu berechnen, und erstellen Sie eine Datei Ã¤hnlich dieser:\n","\n","**Ergebnisse:**  \n","41748459 - 87226336 = 45477877   \n","92995162 * 46769739 = 4349359455002718   \n","61530438 * 56074589 = 3450294021839982   \n","95329602 + 45418854 = 140748456   \n","412907 + 3731910 = 4144817   \n","... ...\n","\n"],"metadata":{"id":"Y5y-OP9OemcW"},"id":"Y5y-OP9OemcW"}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"collapsed_sections":["bf088ba7","UkgEROmi1gRU","9lDnaWpPxdUN","DkYGsPkJx0xc","O5uiRNfWynCU","r_Z7XTBky8Bj","zpLyGf08b8JZ","Va7a3hxJw4wu","PXIIt7Hc3TPW","Pzc1rzQlNV8J"],"toc_visible":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}