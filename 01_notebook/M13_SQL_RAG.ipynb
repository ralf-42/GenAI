{"cells":[{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","\n","Generative KI. Verstehen. Anwenden. Gestalten.\n","</b></font> </br></p>"],"metadata":{"id":"Ih2CTVBnArVZ"},"id":"Ih2CTVBnArVZ"},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","SQL RAG mit Chat-Historie\n","</b></font> </br></p>\n","\n","\n","---"],"metadata":{"id":"6jJZ7wbdArVc"},"id":"6jJZ7wbdArVc"},{"cell_type":"code","source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages, mermaid\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"metadata":{"id":"9_to7o1IrIS6"},"id":"9_to7o1IrIS6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title üìÇ Datenbank { display-mode: \"form\" }\n","# Northwind-Datenbank herunterladen\n","!rm -rf northwind.db\n","!curl -L https://raw.githubusercontent.com/ralf-42/GenAI/main/02_daten/05_sonstiges/northwind.db -o northwind.db"],"metadata":{"id":"Vh2pSo-SF0fj"},"id":"Vh2pSo-SF0fj","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"3ad5a1fc","metadata":{"id":"3ad5a1fc"},"source":["# 1 | Einf√ºhrung in SQL RAG\n","---"]},{"cell_type":"markdown","source":["SQL RAG ist eine Technologie, die Large Language Models (LLMs) mit Datenbankabfragen kombiniert. Sie erm√∂glicht es, nat√ºrlichsprachliche Anfragen in SQL-Abfragen zu √ºbersetzen und die Ergebnisse intelligent zu interpretieren.\n","\n","Diese Technologie √ºberbr√ºckt die L√ºcke zwischen menschlicher Sprache und Datenbankstrukturen, indem sie:\n","\n","- Nat√ºrliche Sprache in pr√§zise SQL-Abfragen umwandelt\n","- Datenbankschemas analysiert, um korrekte Abfragen zu generieren\n","- Die Abfrageergebnisse in verst√§ndliche Antworten umformuliert\n","\n","SQL RAG erweitert die F√§higkeiten von LLMs, indem es ihnen Zugriff auf strukturierte Daten erm√∂glicht und so pr√§zisere, faktenbasierte Antworten liefert."],"metadata":{"id":"Wx7yOhj4Kspy"},"id":"Wx7yOhj4Kspy"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Warum SQL f√ºr RAG?\n","</font></p>"],"metadata":{"id":"DggTS2gNf6G6"},"id":"DggTS2gNf6G6"},{"cell_type":"markdown","source":["\n","\n","Das Erstellen eines Retrieval-Augmented Generation (RAG)-Systems bringt mehrere Herausforderungen mit sich, aber SQL k√∂nnte helfen, diese zu bew√§ltigen:\n","\n","- **SQL kann helfen, komplexe Daten abzurufen**\n","    \n","    Das Abrufen relevanter Informationen aus riesigen und vielf√§ltigen Datens√§tzen kann komplex sein, insbesondere beim Umgang mit unstrukturierten oder semistrukturierten Datenquellen wie Textdokumenten, Bildern oder Multimedia. Die Integration effizienter Retrieval-Mechanismen, die diese Komplexit√§t bew√§ltigen k√∂nnen, ist eine bedeutende Herausforderung. Die Abfragefunktionen von SQL erm√∂glichen den effizienten Abruf relevanter Informationen aus diesen Datenquellen. Durch das Generieren von SQL-Abfragen, die auf bestimmte Kriterien zugeschnitten sind, und die Nutzung erweiterter Suchfunktionen kann SQL den Datenabrufprozess optimieren und so die Komplexit√§t des Zugriffs auf verschiedene Datens√§tze bew√§ltigen.\n","    \n","- **SQL kann helfen, Qualit√§tsdaten abzurufen**\n","    \n","    Die Sicherstellung der Qualit√§t und Relevanz der abgerufenen Daten ist entscheidend f√ºr die Generierung genauer und sinnvoller Antworten. Verrauschte oder veraltete Daten sowie irrelevante Informationen k√∂nnen die Leistung des RAG-Systems jedoch negativ beeinflussen. Die Entwicklung von Algorithmen zum effektiven Filtern und Ranking abgerufener Daten ist eine Herausforderung. SQL bietet Mechanismen zum Filtern und Ranking abgerufener Daten basierend auf verschiedenen Kriterien wie Zeitstempeln, Kategorien oder Relevanzwerten.\n","    \n","- **SQL bietet Skalierbarkeit und Flexibilit√§t**\n","    \n","    Da Datens√§tze an Gr√∂√üe und Komplexit√§t zunehmen, wird Skalierbarkeit zu einer gro√üen Herausforderung f√ºr RAG-Systeme. Die Sicherstellung, dass das System mit zunehmenden Datenmengen umgehen kann und gleichzeitig Leistung und Reaktionsf√§higkeit aufrechterh√§lt, erfordert ein effizientes Architekturdesign und Optimierungsstrategien. SQL-Datenbanken sind darauf ausgelegt, riesige Mengen strukturierter Daten effizient zu verwalten. Die Integration von SQL in RAG-Systeme adressiert eine der wichtigsten Herausforderungen im Bereich der KI: die Skalierung des Retrieval-Mechanismus zur Handhabung umfangreicher Datens√§tze, ohne die Leistung zu beeintr√§chtigen. Dar√ºber hinaus erm√∂glicht die Flexibilit√§t von SQL bei der Formulierung von Abfragen RAG, komplexe Informationen abzurufen und dabei die Breite und Tiefe der w√§hrend des Generierungsprozesses ber√ºcksichtigten Daten anzupassen.\n","    \n","- **SQL hilft beim Abrufen von Echtzeitdaten**\n","    \n","    Die Bereitstellung von Echtzeitantworten ist f√ºr viele Anwendungen von RAG-Systemen, wie z. B. Chatbots oder virtuelle Assistenten, von entscheidender Bedeutung. Das Erreichen niedriger Latenzzeiten bei gleichzeitiger Aufrechterhaltung der Qualit√§t der generierten Inhalte stellt eine Herausforderung dar, insbesondere in Szenarien mit strengen Latenzanforderungen. Die Optimierungstechniken von SQL, wie z. B. Query-Caching und Indizierung, k√∂nnen die Query-Verarbeitungszeiten erheblich reduzieren und es RAG-Systemen erm√∂glichen, Echtzeitantworten bereitzustellen.\n","    "],"metadata":{"id":"JMP9WkF3gAGw"},"id":"JMP9WkF3gAGw"},{"cell_type":"markdown","source":["\n","# 2 | Vergleich SQL RAG vs RAG\n","---"],"metadata":{"id":"aMxxLrPYK6Io"},"id":"aMxxLrPYK6Io"},{"cell_type":"markdown","source":["W√§hrend sowohl SQL RAG als auch RAG (Retrieval-Augmented Generation) die F√§higkeiten von LLMs erweitern, gibt es wichtige Unterschiede:"],"metadata":{"id":"HVkPTuFpLAFE"},"id":"HVkPTuFpLAFE"},{"cell_type":"markdown","source":["\n","\n","| Merkmal         | SQL RAG      | Retrieval-Augmented Generation (RAG)    |\n","| --------------- | ------------------------------------ | --------------------------------------- |\n","| Datenquelle     | Strukturierte Datenbanken            | Textdokumente, Wissensbasen             |\n","| Abfragemethode  | SQL-Generierung                      | Semantische Suche, Embedding-Vergleiche |\n","| Datenstruktur   | Schema-basiert, tabellarisch         | Unstrukturiert oder semi-strukturiert   |\n","| Genauigkeit     | Pr√§zise durch Datenbankintegrit√§t    | Abh√§ngig von der Retrieval-Qualit√§t     |\n","| Anwendungsf√§lle | Gesch√§ftsanalysen, Berichterstellung | Dokumentensuche, Wissensbasis-Anfragen  |\n","| Aktualisierung  | In Echtzeit durch aktuelle DB-Daten  | Erfordert Neuindexierung bei √Ñnderungen |\n","\n"],"metadata":{"id":"RqgbzPt8LDIH"},"id":"RqgbzPt8LDIH"},{"cell_type":"markdown","source":["SQL RAG eignet sich besonders f√ºr Szenarien, in denen pr√§zise, aktuelle Daten ben√∂tigt werden, w√§hrend RAG St√§rken bei der Verarbeitung gro√üer Textmengen hat.\n","\n"],"metadata":{"id":"SYeaWetzbl_w"},"id":"SYeaWetzbl_w"},{"cell_type":"markdown","source":["# 3 | Integration LLM und DB\n","---"],"metadata":{"id":"qTgb-CXuLGCR"},"id":"qTgb-CXuLGCR"},{"cell_type":"markdown","source":["\n","\n","Die Integration von LLMs mit Datenbanken erfolgt √ºber mehrere Komponenten:\n","\n","1. **Schema-Analyse**: Das LLM muss das Datenbankschema verstehen (Tabellen, Spalten, Beziehungen)\n","2. **Anfrage-√úbersetzung**: Umwandlung der nat√ºrlichsprachlichen Anfrage in SQL\n","3. **Abfrage-Ausf√ºhrung**: Verbindung zur Datenbank und Ausf√ºhrung der generierten SQL-Abfrage\n","4. **Ergebnis-Interpretation**: Analyse und Interpretation der Abfrageergebnisse"],"metadata":{"id":"YV5hDrg4LLz2"},"id":"YV5hDrg4LLz2"},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/sql_rag_process.png\" width=\"750\" alt=\"Avatar\">\n"],"metadata":{"id":"fO8BNt8AG4n8"},"id":"fO8BNt8AG4n8"},{"cell_type":"code","execution_count":null,"id":"c5661311","metadata":{"id":"c5661311","collapsed":true},"outputs":[],"source":["# Grundlegender SQL RAG-Ablauf\n","from langchain.chat_models import init_chat_model\n","from langchain_community.utilities import SQLDatabase\n","\n","# 1. Datenbankverbindung herstellen\n","db = SQLDatabase.from_uri(\"sqlite:///northwind.db\")\n","\n","# 2. LLM initialisieren (Kurznotation: \"provider:model\")\n","llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.0)"]},{"cell_type":"code","source":["# 3. Datenbankschema abrufen\n","schema = db.get_table_info()\n","print(schema)"],"metadata":{"id":"VKT9Z5TDbysQ"},"id":"VKT9Z5TDbysQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Nat√ºrlichsprachliche Anfrage\n","user_query = \"Wie viele Mitarbeiter haben wir?\"\n","\n","# 5. SQL-Abfrage generieren und ausf√ºhren\n","# (Detaillierte Umsetzung folgt in sp√§teren Abschnitten)"],"metadata":{"id":"2lqQ4_Pbb0o9"},"id":"2lqQ4_Pbb0o9","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"da0302b4","metadata":{"id":"da0302b4"},"source":["Die Herausforderung liegt in der korrekten Interpretation des Schemas und der pr√§zisen √úbersetzung der Anfragen.\n","\n"]},{"cell_type":"markdown","source":["# 4 | SQL-Generierung mit LLMs\n","---"],"metadata":{"id":"Qxs8-gyWLWPm"},"id":"Qxs8-gyWLWPm"},{"cell_type":"markdown","source":["\n","\n","Die SQL-Generierung ist ein kritischer Bestandteil von SQL RAG und erfolgt in mehreren Schritten:\n","\n","1. **Prompt-Engineering**: Entwicklung spezifischer Prompts, die das Datenbankschema und die Anforderungen enthalten\n","2. **Query-Planung**: Analyse der Anfrage, um die ben√∂tigten Tabellen und Joins zu identifizieren\n","3. **SQL-Syntax-Generierung**: Erzeugung syntaktisch korrekter SQL-Abfragen\n","4. **Validierung**: √úberpr√ºfung der generierten Abfrage vor der Ausf√ºhrung"],"metadata":{"id":"iQwq7rRiLck1"},"id":"iQwq7rRiLck1"},{"cell_type":"code","execution_count":null,"id":"28424d61","metadata":{"id":"28424d61"},"outputs":[],"source":["import re\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough"]},{"cell_type":"code","source":["# ChatPromptTemplate mit System/Human Messages\n","sql_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"\"\"Du bist ein SQL-Experte. Deine Aufgabe ist es, Benutzeranfragen in SQL-Abfragen zu √ºbersetzen.\n","Verwende die SQLite-Syntax und nur die Tabellen und Spalten aus dem bereitgestellten Schema.\n","\n","WICHTIG: Schreibe NUR die reine SQL-Abfrage.\n","KEINE Markdown-Formatierung, KEINE Code-Bl√∂cke (```), KEINE Erkl√§rungen.\n","\n","Datenbank-Schema:\n","{schema}\"\"\"),\n","    (\"human\", \"{query}\")\n","])\n","\n","# parser\n","parser = StrOutputParser()"],"metadata":{"id":"Kx5BbzkccJW1"},"id":"Kx5BbzkccJW1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SQL-Generator-Chain (mit ChatPromptTemplate)\n","sql_generator = (\n","    RunnablePassthrough.assign(schema=lambda _: db.get_table_info())\n","    | sql_prompt\n","    | llm\n","    | parser\n",")"],"metadata":{"id":"iFN86D4IcMa_"},"id":"iFN86D4IcMa_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verwendung\n","sql_query = sql_generator.invoke({\"query\": user_query})\n","print(f\"Generierte SQL: {sql_query}\")"],"metadata":{"id":"MLy5yMEScP7G"},"id":"MLy5yMEScP7G","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Regex-Bereinigung meist nicht mehr n√∂tig!\n","# Falls doch noch Markdown auftaucht, nur als Fallback:\n","if \"```\" in sql_query:\n","    sql_query = re.sub(r'```sql\\s*(.*?)\\s*```', r'\\1', sql_query, flags=re.DOTALL)\n","    sql_query = sql_query.replace(\"```\", \"\").strip()\n","    print(\"‚ö†Ô∏è Markdown entfernt. Erw√§ge Prompt-Verbesserung!\")\n","\n","print(f\"Bereinigte SQL: {sql_query}\")"],"metadata":{"id":"714TernwcXPG"},"id":"714TernwcXPG","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6e76c949"},"source":["# 5 | Hands-On: SQL RAG `northwind.db`\n","---"],"id":"6e76c949"},{"cell_type":"markdown","source":["\n","LangChain bietet leistungsstarke Tools f√ºr die Implementierung von SQL RAG-L√∂sungen:\n","\n","1. **SQLDatabase**: Verbindung zur Datenbank mit `db.run()` Methode\n","2. **ChatPromptTemplate**: Strukturierte Prompts mit System/Human Messages  \n","3. **LCEL**: LangChain Expression Language f√ºr Chains\n","4. **SQL Agent** (optional): Intelligente Agents f√ºr komplexe Queries\n"],"metadata":{"id":"ppNTXuFaMDjy"},"id":"ppNTXuFaMDjy"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Erl√§uterung des SQL RAG-Beispiels\n","</font></p>"],"metadata":{"id":"HAYfITzEMgAq"},"id":"HAYfITzEMgAq"},{"cell_type":"markdown","source":["Das Beispiel demonstriert eine vollst√§ndige SQL RAG-Anwendung mit folgenden Komponenten:\n","\n","1. **Datenbankintegration**: Northwind-Datenbank √ºber SQLite\n","2. **LLM-Anbindung**: Verwendung des ChatOpenAI-Modells von OpenAI\n","3. **SQL-Generierungs-Chain**: Umwandlung nat√ºrlicher Sprache in SQL\n","4. **Abfrageausf√ºhrung**: Sichere Ausf√ºhrung und Formatierung der Ergebnisse\n","5. **Ergebnisanalyse**: Intelligente Interpretation der Daten\n","6. **Benutzeroberfl√§che**: Gradio-basiertes Chatinterface f√ºr einfache Interaktion\n","\n","Die Anwendung zeigt den vollst√§ndigen Workflow von SQL RAG:\n","\n","1. Der Benutzer stellt eine Frage in nat√ºrlicher Sprache\n","2. Das LLM generiert eine passende SQL-Abfrage\n","3. Die Abfrage wird ausgef√ºhrt und die Ergebnisse formatiert\n","4. Ein zweiter LLM-Aufruf analysiert und interpretiert die Ergebnisse\n","5. Die formatierte Antwort wird dem Benutzer pr√§sentiert\n","\n","Diese Implementierung demonstriert, wie SQL RAG komplexe Datenanalysen f√ºr Benutzer ohne SQL-Kenntnisse zug√§nglich macht und gleichzeitig pr√§zise, datenbasierte Antworten liefert.\n","\n"],"metadata":{"id":"Cuxz-_O_MlfS"},"id":"Cuxz-_O_MlfS"},{"cell_type":"markdown","id":"81ucxai2tip","source":["<p><font color='black' size=\"5\">\n","üí¨ Chat-Historie\n","</font></p>\n","\n","Das System unterst√ºtzt **kontextbewusste Konversationen** durch Chat-Historie:\n","\n","**Wie funktioniert es?**\n","1. **Historie-Speicherung**: Gradio speichert automatisch die letzten Konversationen\n","2. **Kontext-Extraktion**: Die letzten 3 Frage-Antwort-Paare werden in den Prompt eingebettet\n","3. **Intelligente SQL-Generierung**: Das LLM nutzt den Kontext f√ºr Folge-Fragen\n","4. **Kontextuelle Analyse**: Antworten beziehen sich auf vorherige Ergebnisse\n","\n","**Beispiel-Konversation:**\n","```\n","üë§ User: \"Welche Produkte sind nicht auf Lager?\"\n","ü§ñ Bot: [Zeigt 3 Produkte: Chai, Chang, Gorgonzola]\n","\n","üë§ User: \"Zeige mir mehr Details zu diesen Produkten\"\n","ü§ñ Bot: [Generiert SQL mit WHERE-Klausel f√ºr die 3 Produkte]\n","\n","üë§ User: \"Welche Lieferanten haben diese Produkte geliefert?\"\n","ü§ñ Bot: [JOIN mit Suppliers-Tabelle basierend auf Kontext]\n","```\n","\n","**Implementierung:**\n","- System/Human Message Templates mit `{history_text}` Platzhalter\n","- Automatische Extraktion relevanter Informationen aus vorherigen Antworten\n","- Limitierung auf letzte 3 Eintr√§ge zur Token-Optimierung"],"metadata":{"id":"81ucxai2tip"}},{"cell_type":"markdown","source":["[DatenbankSchema](https://upload.wikimedia.org/wikiversity/en/a/ac/Northwind_E-R_Diagram.png)\n"],"metadata":{"id":"_P07Zx9BO3Po"},"id":"_P07Zx9BO3Po"},{"cell_type":"markdown","source":["\n","[Datenbankbeschreibung](https://techwriter.me/downloads/samples/Database/Access2003Northwind.pdf)"],"metadata":{"id":"q5NT5QdO_xIi"},"id":"q5NT5QdO_xIi"},{"cell_type":"code","source":["#@markdown   <p><font size=\"4\" color='green'> üßú Mermaid-Diagramm</font> </br></p>\n","\n","diagram = \"\"\"\n","flowchart LR\n","    USER[\"User\"] --> Gradio[\"Gradio: chatbot_response()\"]\n","\n","    subgraph SQL[\"<b>SQL-Abfrage</b>\"]\n","        direction TB\n","        get_schema[\"get_schema()\"]\n","        sql_gen[\"sql_generator()\"]\n","        exec[\"execute_query()\"]\n","        get_schema --> sql_gen --> exec\n","    end\n","\n","    subgraph Output[\"<b>Erstellung Output </b>\"]\n","        direction TB\n","        analyze[\"analyze_results()\"]\n","    end\n","\n","    Gradio --> get_schema\n","    Gradio --> LLM[\"LLM\"]\n","    exec --> analyze\n","    analyze --> RESULT[\"Gradio: Antwort\"]\n","\n","    DB[(northwind.db)] -.-> |\"Schema\"| get_schema\n","    exec -.-> |\"SQL\"| DB\n","    DB -.-> |\"Ergebnis\"| exec\n","\n","    LLM -.-> sql_gen\n","    LLM -.-> analyze\n","\"\"\"\n","mermaid(diagram, width=1100, height=400)"],"metadata":{"cellView":"form","id":"abUNHGcezTgZ"},"id":"abUNHGcezTgZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Programm\n","</font></p>"],"metadata":{"id":"TVFPnZITNbOM"},"id":"TVFPnZITNbOM"},{"cell_type":"code","source":["# Standard & Third Party Libraries\n","import re\n","import gradio as gr\n","from langchain_community.utilities import SQLDatabase\n","from langchain.chat_models import init_chat_model\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough"],"metadata":{"id":"uBP6DJpdEPiE"},"execution_count":null,"outputs":[],"id":"uBP6DJpdEPiE"},{"cell_type":"code","source":["DB_PATH = \"/content/northwind.db\"\n","DB_URI = f\"sqlite:///{DB_PATH}\""],"metadata":{"id":"ivAQuft7Hr2D"},"execution_count":null,"outputs":[],"id":"ivAQuft7Hr2D"},{"cell_type":"code","source":["# LLM (Kurznotation: \"provider:model\")\n","llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.0)\n","\n","# SQL-Datenbank initialisieren\n","db = SQLDatabase.from_uri(DB_URI)"],"metadata":{"id":"7i71YL5THyox"},"execution_count":null,"outputs":[],"id":"7i71YL5THyox"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","SQL & Analyse Prompts\n","</font></p>"],"metadata":{"id":"KHlG3A7P8xac"},"id":"KHlG3A7P8xac"},{"cell_type":"code","source":["# ChatPromptTemplate mit Chat-Historie\n","sql_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"\"\"Du bist ein SQL-Experte. Deine Aufgabe ist es, Benutzeranfragen in SQL-Abfragen zu √ºbersetzen.\n","Verwende die SQLite-Syntax und nur die Tabellen und Spalten aus dem bereitgestellten Schema.\n","\n","WICHTIG: Schreibe NUR die reine SQL-Abfrage ohne jegliche Formatierung.\n","KEINE Markdown-Codebl√∂cke, KEINE Pr√§fixe, KEINE Kommentare.\n","\n","Gebe neben den Id auch den Namen von Produkten, Kunden, etc. mit aus.\n","Gebe maximal 10 Zeilen einer Liste aus.\n","\n","Bei Ja/Nein-Fragen oder Fragen, die eine Analyse erfordern (z.B. \"Sind alle Artikel auf Lager?\"),\n","erstelle eine SQL-Abfrage, die ALLE relevanten Daten zur√ºckgibt, damit eine fundierte Antwort gegeben werden kann.\n","\n","KONTEXT: Ber√ºcksichtige die bisherige Gespr√§chshistorie, um Folge-Fragen korrekt zu interpretieren.\n","Wenn sich die aktuelle Frage auf vorherige Ergebnisse bezieht (z.B. \"Und wie viele davon...\", \"Zeige mir mehr Details dazu\"),\n","nutze den Kontext aus der Historie.\n","\n","Datenbank-Schema:\n","{schema}\"\"\"),\n","    (\"human\", \"{history_text}\\n\\nAktuelle Frage: {query}\")\n","])"],"metadata":{"id":"MxHL8c_EH2CC"},"execution_count":null,"outputs":[],"id":"MxHL8c_EH2CC"},{"cell_type":"code","source":["# Template f√ºr die Ergebnisinterpretation mit Historie\n","analysis_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"\"\"Du bist ein Business-Analyst, der SQL-Abfrageergebnisse interpretiert und verst√§ndliche Antworten gibt.\n","\n","Beantworte die Benutzeranfrage basierend auf den SQL-Ergebnissen.\n","Bei Ja/Nein-Fragen gib eine klare Antwort und erkl√§re die Gr√ºnde.\n","Bei Fragen nach Empfehlungen oder notwendigen Anpassungen, analysiere die Daten und gib konkrete Vorschl√§ge.\n","\n","KONTEXT: Ber√ºcksichtige die bisherige Gespr√§chshistorie, um deine Antwort im Kontext zu formulieren.\n","Wenn dies eine Folge-Frage ist, beziehe dich auf vorherige Ergebnisse.\"\"\"),\n","    (\"human\", \"\"\"{history_text}\n","\n","Aktuelle Benutzeranfrage: {query}\n","SQL-Abfrage: {sql_query}\n","Abfrageergebnisse:\n","{results}\n","\n","Deine Analyse und Antwort:\"\"\")\n","])\n","\n","# parser\n","parser = StrOutputParser()"],"metadata":{"id":"2ElHZl4q8uSg"},"id":"2ElHZl4q8uSg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","SQL-Abfrage\n","</font></p>"],"metadata":{"id":"F2TaVk4E8In8"},"id":"F2TaVk4E8In8"},{"cell_type":"code","source":["#@markdown   <p><font size=\"4\" color='green'> üßú Mermaid-Diagramm</font> </br></p>\n","\n","diagram = \"\"\"\n","flowchart LR\n","    USER[\"User\"] --> Gradio[\"Gradio: chatbot_response()\"]\n","\n","    subgraph SQL[\"<b>SQL-Abfrage</b>\"]\n","        direction TB\n","        get_schema[\"get_schema()\"]\n","        sql_gen[\"sql_generator()\"]\n","        exec[\"execute_query()\"]\n","        get_schema --> sql_gen --> exec\n","    end\n","\n","    subgraph Output[\"<b>Erstellung Output </b>\"]\n","        direction TB\n","        analyze[\"analyze_results()\"]\n","    end\n","\n","    Gradio --> get_schema\n","    Gradio --> LLM[\"LLM\"]\n","    exec --> analyze\n","    analyze --> RESULT[\"Gradio: Antwort\"]\n","\n","    DB[(northwind.db)] -.-> |\"Schema\"| get_schema\n","    exec -.-> |\"SQL\"| DB\n","    DB -.-> |\"Ergebnis\"| exec\n","\n","    LLM -.-> sql_gen\n","    LLM -.-> analyze\n","\n","\n","style SQL fill:#4a90d9,stroke:#2d5a87,color:#fff\n","\"\"\"\n","mermaid(diagram, width=1100, height=400)"],"metadata":{"cellView":"form","id":"WJNI1Ryg96Ss"},"id":"WJNI1Ryg96Ss","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funktion zur Abfrage Datenbank-Schema\n","def get_schema(_):\n","    return db.get_table_info()"],"metadata":{"id":"Ofl1iaZR7nNg"},"id":"Ofl1iaZR7nNg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SQL erstellen mit Historie-Unterst√ºtzung -Y Chain\n","sql_generator = (\n","    RunnablePassthrough.assign(schema=get_schema)\n","    | sql_prompt\n","    | llm\n","    | parser\n",")"],"metadata":{"id":"5c_SVsedH55v"},"execution_count":null,"outputs":[],"id":"5c_SVsedH55v"},{"cell_type":"code","source":["# Funktion zur SQL Abfrage\n","def execute_query(sql_query: str) -> str:\n","    \"\"\"F√ºhrt eine SQL-Abfrage aus und gibt die Ergebnisse zur√ºck.\"\"\"\n","    try:\n","        # LangChain's eingebaute Methode verwenden!\n","        result = db.run(sql_query)\n","\n","        # Keine Ergebnisse\n","        if not result or result.strip() == \"\":\n","            return \"Keine Ergebnisse gefunden.\"\n","\n","        return result\n","\n","    except Exception as e:\n","        return f\"Fehler bei der Ausf√ºhrung der Abfrage: {str(e)}\\nAbfrage: {sql_query}\""],"metadata":{"id":"PV4ufw1RH_Pm"},"execution_count":null,"outputs":[],"id":"PV4ufw1RH_Pm"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Erstellung Output\n","</font></p>"],"metadata":{"id":"uU2XnpPN8YEG"},"id":"uU2XnpPN8YEG"},{"cell_type":"code","source":["#@markdown   <p><font size=\"4\" color='green'> üßú Mermaid-Diagramm</font> </br></p>\n","\n","diagram = \"\"\"\n","flowchart LR\n","    USER[\"User\"] --> Gradio[\"Gradio: chatbot_response()\"]\n","\n","    subgraph SQL[\"<b>SQL-Abfrage</b>\"]\n","        direction TB\n","        get_schema[\"get_schema()\"]\n","        sql_gen[\"sql_generator()\"]\n","        exec[\"execute_query()\"]\n","        get_schema --> sql_gen --> exec\n","    end\n","\n","    subgraph Output[\"<b>Erstellung Output </b>\"]\n","        direction TB\n","        analyze[\"analyze_results()\"]\n","    end\n","\n","    Gradio --> get_schema\n","    Gradio --> LLM[\"LLM\"]\n","    exec --> analyze\n","    analyze --> RESULT[\"Gradio: Antwort\"]\n","\n","    DB[(northwind.db)] -.-> |\"Schema\"| get_schema\n","    exec -.-> |\"SQL\"| DB\n","    DB -.-> |\"Ergebnis\"| exec\n","\n","    LLM -.-> sql_gen\n","    LLM -.-> analyze\n","\n","\n","style Output fill:#4a90d9,stroke:#2d5a87,color:#fff\n","\"\"\"\n","mermaid(diagram, width=1100, height=400)"],"metadata":{"cellView":"form","id":"jCqpuF0D-CjR"},"id":"jCqpuF0D-CjR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funktion zur Analyse des Ergebnisses der Datenbank-Abfrage mit Historie\n","def analyze_results(query, sql_query, results, history_text=\"\"):\n","    \"\"\"Analysiert die Ergebnisse und gibt eine nat√ºrlichsprachliche Antwort zur√ºck.\"\"\"\n","    analysis_chain = analysis_prompt | llm | parser\n","\n","    return analysis_chain.invoke({\n","        \"query\": query,\n","        \"sql_query\": sql_query,\n","        \"results\": results,\n","        \"history_text\": history_text\n","    })"],"metadata":{"id":"iUsFc2mEIGnw"},"execution_count":null,"outputs":[],"id":"iUsFc2mEIGnw"},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","UI Gradio In/Out\n","</font></p>"],"metadata":{"id":"7rIJQmnj8Ukk"},"id":"7rIJQmnj8Ukk"},{"cell_type":"code","source":["#@markdown   <p><font size=\"4\" color='green'> üßú Mermaid-Diagramm</font> </br></p>\n","\n","diagram = \"\"\"\n","flowchart LR\n","    USER[\"User\"] --> Gradio[\"Gradio: chatbot_response()\"]\n","\n","    subgraph SQL[\"<b>SQL-Abfrage</b>\"]\n","        direction TB\n","        get_schema[\"get_schema()\"]\n","        sql_gen[\"sql_generator()\"]\n","        exec[\"execute_query()\"]\n","        get_schema --> sql_gen --> exec\n","    end\n","\n","    subgraph Output[\"<b>Erstellung Output </b>\"]\n","        direction TB\n","        analyze[\"analyze_results()\"]\n","    end\n","\n","    Gradio --> get_schema\n","    Gradio --> LLM[\"LLM\"]\n","    exec --> analyze\n","    analyze --> RESULT[\"Gradio: Antwort\"]\n","\n","    DB[(northwind.db)] -.-> |\"Schema\"| get_schema\n","    exec -.-> |\"SQL\"| DB\n","    DB -.-> |\"Ergebnis\"| exec\n","\n","    LLM -.-> sql_gen\n","    LLM -.-> analyze\n","\n","\n","style Gradio fill:#4a90d9,stroke:#2d5a87,color:#fff\n","style RESULT fill:#4a90d9,stroke:#2d5a87,color:#fff\n","\"\"\"\n","mermaid(diagram, width=1100, height=400)"],"metadata":{"cellView":"form","id":"6oFo2hzQ-H3D"},"id":"6oFo2hzQ-H3D","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funktion f√ºr das Gradio Interface mit Historie-Unterst√ºtzung\n","def chatbot_response(message, history):\n","    \"\"\"Verarbeitet Benutzeranfragen, erstellt SQL und gibt formatierte Ergebnisse mit Analyse zur√ºck.\"\"\"\n","    try:\n","        # Historie formatieren f√ºr LLM-Kontext\n","        history_text = \"\"\n","        if history:\n","            history_parts = []\n","            for i, (user_msg, bot_msg) in enumerate(history[-3:], 1):  # Nur letzte 3 Eintr√§ge\n","                history_parts.append(f\"[Vorherige Frage {i}]: {user_msg}\")\n","                # Extrahiere nur die Analyse aus der Bot-Antwort (falls vorhanden)\n","                if \"### Analyse\" in bot_msg:\n","                    analysis_part = bot_msg.split(\"### Analyse\")[-1].strip()\n","                    history_parts.append(f\"[Vorherige Antwort {i}]: {analysis_part[:300]}...\")\n","            history_text = \"\\n\".join(history_parts)\n","\n","        # SQL-Abfrage mit LLM generieren (mit Historie)\n","        sql_query = sql_generator.invoke({\n","            \"query\": message,\n","            \"history_text\": history_text\n","        })\n","\n","        # Nur als Fallback: Markdown-Bereinigung\n","        if \"```\" in sql_query:\n","            sql_query = re.sub(r'```sql\\s*(.*?)\\s*```', r'\\1', sql_query, flags=re.DOTALL)\n","            sql_query = sql_query.replace(\"```\", \"\").strip()\n","\n","        # Debug-Ausgabe\n","        print(f\"Generierte SQL: {sql_query}\")\n","\n","        # Abfrage Datenbank\n","        results = execute_query(sql_query)\n","\n","        # Analysiere die Ergebnisse f√ºr komplexe Fragen (mit Historie)\n","        analysis = analyze_results(message, sql_query, results, history_text)\n","\n","        # Antwort formatieren\n","        response = f\"\"\"### Deine Anfrage\n","{message}\n","\n","### SQL-Abfrage\n","```sql\n","{sql_query}\n","```\n","\n","### Ergebnisse\n","{results}\n","\n","### Analyse\n","{analysis}\"\"\"\n","\n","        return response\n","\n","    except Exception as e:\n","        import traceback\n","        error_details = traceback.format_exc()\n","        print(f\"Fehler Details:\\n{error_details}\")\n","        return f\"Ein Fehler ist aufgetreten: {str(e)}\\n\\nDetails siehe Console-Output.\""],"metadata":{"id":"mDZ1B8zTIU6-"},"execution_count":null,"outputs":[],"id":"mDZ1B8zTIU6-"},{"cell_type":"code","source":["# Beispielfragen f√ºr Gradio-Interface definieren\n","example_questions = [\n","    \"Welche Produkte sind aktuell nicht mehr auf Lager? Nenne die Top 3.\",\n","    \"Welche Bestellung von welchem Kunden hatte den h√∂chsten Gesamtwert? Nenne die Top 3.\",\n","    \"Aus welchen L√§ndern stammen die meisten Kunden? Nenne die Top 3.\",\n","    \"Sind alle Artikel der Bestellung der Rattlesnake Canyon Grocery vom 1998-05-06 in ausreichender Anzahl auf Lager?\",\n","]"],"metadata":{"id":"3pp8xlzVIcw0"},"execution_count":null,"outputs":[],"id":"3pp8xlzVIcw0"},{"cell_type":"code","source":["# Gradio Interface erstellen\n","demo = gr.ChatInterface(\n","    fn=chatbot_response,\n","    title=\"üìö SQL RAG - Verbesserte Version (LangChain 1.0+)\",\n","    description=\"\"\"**Features:**\n","- üí¨ **Chat-Historie**: Stelle Folge-Fragen basierend auf vorherigen Antworten\n","- ü§ñ **LLM-basierte SQL-Generierung**: Nat√ºrliche Sprache wird automatisch in SQL √ºbersetzt\n","- üìä **Intelligente Analyse**: Automatische Interpretation der Ergebnisse\n","\n","\"\"\",\n","    examples=example_questions,\n",")"],"metadata":{"id":"wr3BmBX-GWol"},"id":"wr3BmBX-GWol","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Starten der App\n","</font></p>"],"metadata":{"id":"5xzKJbtpNihq"},"id":"5xzKJbtpNihq"},{"cell_type":"markdown","source":["**Beispiel-Fragen:**\n","\n","\n","\n","+ Gib die Artikelliste f√ºr die Bestellung 11031 mit Einzelpreis und Gesamtpreis aus, wobei sich der Gesamtpreis aus der Anzahl und dem Einzelpreis ergibt.\n","+ Welcher Mitarbeiter ist f√ºr die Bestellung mit der Nummer 10266 zust√§ndig?\n","+ √úber welche Versandfirma wurde die Bestellung 10266 ausgeliefert?\n","+ Sind alle Artikel der Bestellung der Rattlesnake Canyon Grocery vom 1998-05-06 in ausreichender Anzahl auf Lager?\n","+ Welche Kunden haben schon Artikel der Firma 'Escargots Nouveaux' gekauft?\n","\n","\n"],"metadata":{"id":"kNVVG6MqA8J0"},"id":"kNVVG6MqA8J0"},{"cell_type":"code","source":["# App starten\n","demo.launch()"],"metadata":{"id":"zHbIbeic_RHK"},"execution_count":null,"outputs":[],"id":"zHbIbeic_RHK"},{"cell_type":"markdown","source":["\n","# 6 | Validierung und Sicherheit\n","---"],"metadata":{"id":"AEx2tAuLLjjH"},"id":"AEx2tAuLLjjH"},{"cell_type":"markdown","source":["\n","\n","Die Sicherheit ist bei der Arbeit mit datenbankgesteuerten Anwendungen von entscheidender Bedeutung. SQL RAG-Implementierungen m√ºssen folgende Sicherheitsaspekte ber√ºcksichtigen:\n","\n","1. **SQL-Injection-Pr√§vention**:\n","    \n","    - Validierung und Bereinigung generierter SQL-Abfragen\n","    - Verwendung von parametrisierten Abfragen\n","    - Beschr√§nkung der SQL-Befehle (z.B. nur SELECT-Anweisungen zulassen)\n","2. **Zugriffskontrolle**:\n","    \n","    - Verwendung von Datenbanknutzern mit eingeschr√§nkten Rechten\n","    - Zugriffsbeschr√§nkungen auf bestimmte Tabellen oder Ansichten\n","    - Implementierung von Row-Level-Security\n","3. **Datenvalidierung**:\n","    \n","    - √úberpr√ºfung der generierten SQL-Abfragen auf verd√§chtige Muster\n","    - Begrenzung der Abfragekomplexit√§t und -l√§nge\n","    - Timeouts f√ºr lang laufende Abfragen\n"],"metadata":{"id":"YbTW2r6uLuo1"},"id":"YbTW2r6uLuo1"},{"cell_type":"code","execution_count":null,"id":"eb50c446","metadata":{"id":"eb50c446"},"outputs":[],"source":["# Pr√ºft Synthax und Zul√§ssigkeit\n","def validate_sql_query(sql_query):\n","    \"\"\"Validiert eine SQL-Abfrage auf potenziell gef√§hrliche Muster.\"\"\"\n","\n","    # Nur SELECT-Anweisungen erlauben\n","    if not sql_query.strip().upper().startswith(\"SELECT\"):\n","        return False, \"Nur SELECT-Anweisungen sind erlaubt.\"\n","\n","    # Keine gef√§hrlichen SQL-Befehle erlauben\n","    dangerous_commands = [\"DROP\", \"DELETE\", \"TRUNCATE\", \"UPDATE\", \"INSERT\", \"ALTER\"]\n","    for command in dangerous_commands:\n","        if f\" {command} \" in sql_query.upper():\n","            return False, f\"Unerlaubter SQL-Befehl: {command}\"\n","\n","    # Weitere Validierungsregeln...\n","\n","    return True, \"SQL-Abfrage ist g√ºltig.\"\n","\n","# Verwendung\n","is_valid, mesSQL = validate_sql_query(sql_query)\n","is_valid, mesSQL"]},{"cell_type":"markdown","id":"c0422019","metadata":{"id":"c0422019"},"source":["Eine gr√ºndliche Validierung vor der Ausf√ºhrung ist entscheidend f√ºr die Sicherheit der Anwendung."]},{"cell_type":"markdown","source":["\n","# 7 | Praktische Anwendungsf√§lle\n","---"],"metadata":{"id":"B20qLn3ALxVG"},"id":"B20qLn3ALxVG"},{"cell_type":"markdown","source":["SQL RAG eignet sich f√ºr zahlreiche praktische Anwendungsf√§lle:\n","\n","1. **Business Intelligence Dashboards**:\n","    \n","    - Nat√ºrlichsprachliche Abfragen f√ºr Gesch√§ftskennzahlen\n","    - Dynamische Berichte basierend auf Benutzeranfragen\n","    - Trends und Anomalien in Daten identifizieren\n","2. **Datenanalyse f√ºr Nicht-Techniker**:\n","    \n","    - Erm√∂glicht Benutzern ohne SQL-Kenntnisse, komplexe Datenabfragen durchzuf√ºhren\n","    - Vereinfacht den Zugang zu Unternehmensdaten\n","3. **Automatisierte Berichterstellung**:\n","    \n","    - Generierung regelm√§√üiger Berichte basierend auf Datenabfragen\n","    - Intelligente Zusammenfassung und Interpretation von Gesch√§ftsdaten\n","4. **Kundenservice-Anwendungen**:\n","    \n","    - Schneller Zugriff auf Kundendaten f√ºr Support-Mitarbeiter\n","    - Automatisierte Beantwortung h√§ufiger Kundenanfragen\n","5. **Interne Wissensmanagement-Systeme**:\n","    \n","    - Intelligente Suche in Unternehmensdaten\n","    - Verkn√ºpfung verschiedener Datenquellen f√ºr umfassende Antworten\n","\n","Durch die Kombination von LLMs mit Datenbankabfragen kann SQL RAG komplexe Analyseaufgaben automatisieren und den Zugang zu Daten demokratisieren.\n","\n"],"metadata":{"id":"wlQ9zPVEL3Rg"},"id":"wlQ9zPVEL3Rg"},{"cell_type":"markdown","source":["# A | Aufgabe\n","---"],"metadata":{"id":"1GScznOTY691"},"id":"1GScznOTY691"},{"cell_type":"markdown","source":["Die Aufgabestellungen unten bieten Anregungen, Sie k√∂nnen aber auch gerne eine andere Herausforderung angehen."],"metadata":{"id":"p96Q-N7C6eJv"},"id":"p96Q-N7C6eJv"},{"cell_type":"markdown","source":["Angenommen, es wird f√ºr ein kleines Unternehmen gearbeitet, das eine Kundendatenbank verwaltet. Ziel ist es, eine generative KI einzusetzen, um Anfragen in nat√ºrlicher Sprache zu verstehen und relevante Informationen aus der Datenbank abzurufen.  \n","\n","**Datenbankstruktur (SQLite-Format)**  \n","Die Kundendatenbank enth√§lt eine Tabelle `customers.db` mit den folgenden Spalten:  \n","\n","| id | name  | city    | purchases |\n","|----|-------|--------|-----------|\n","| 1  | Alice  | Berlin  | 5         |\n","| 2  | Bob    | Hamburg | 2         |\n","| 3  | Carol  | M√ºnchen | 7         |\n","| 4  | David  | K√∂ln    | 3         |\n","\n"],"metadata":{"id":"98SUK94XY7oe"},"id":"98SUK94XY7oe"},{"cell_type":"markdown","source":["**Aufgabenstellung**  \n","1. **Abfrage erstellen**, um die Anzahl der Eink√§ufe (`purchases`) eines bestimmten Kunden anhand seines Namens abzurufen.  \n","2. **Python-Funktion entwickeln**, die eine GPT-API nutzt, um nat√ºrliche Sprachabfragen in SQL-Abfragen zu √ºbersetzen.  \n","3. **Funktion testen**, indem eine Frage wie *‚ÄûWie viele Eink√§ufe hat Alice gemacht?‚Äú* gestellt wird, woraufhin das System automatisch die entsprechende SQL-Abfrage generiert.  \n","\n"],"metadata":{"id":"sIQ1-u06ZzEx"},"id":"sIQ1-u06ZzEx"}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"collapsed_sections":["3ad5a1fc","aMxxLrPYK6Io","qTgb-CXuLGCR","Qxs8-gyWLWPm","6e76c949","AEx2tAuLLjjH","B20qLn3ALxVG","1GScznOTY691"],"toc_visible":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}