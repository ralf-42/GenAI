{"cells":[{"cell_type":"markdown","source":["Das folgende ist die vollst√§ndige, optimierte Version des Jupyter Notebooks im Markdown-Format. Die Zelle f√ºr **Query 1** wurde so angepasst, dass sie die **Schritte 6, 7 und 8** der MCP-Simulation explizit und transparent abbildet, um der Logik des Simulationstools zu entsprechen.\n","\n","-----\n","\n","# M17\\_MCP\\_Model\\_Context\\_Protocol\n","\n","````markdown\n","![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)\n","\n","<p><font size=\"5\" color='grey'> <b>\n","MCP - Model Context Protocol\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"3Z_8TJ438njS"}},{"cell_type":"code","source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\n","\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages\n","from genai_lib.mcp_modul import (\n","    handle_mcp_request, connect_to_server, initialize_server_connection,\n","    discover_server_tools, call_server_tool, setup_assistant_mcp_connection,\n","    process_user_query, get_assistant_status, get_server_info, get_available_tools\n",")\n","import json # Wird f√ºr die manuelle JSON-Verarbeitung in Schritt 7 ben√∂tigt\n","\n","setup_api_keys(['OPENAI_API_KEY'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì OPENAI_API_KEY erfolgreich gesetzt\n","‚úì HF_TOKEN erfolgreich gesetzt\n","\n","Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n","\n","Installierte LangChain-Bibliotheken:\n","langchain                                1.1.0\n","langchain-chroma                         1.0.0\n","langchain-classic                        1.0.0\n","langchain-community                      0.4.1\n","langchain-core                           1.1.0\n","langchain-ollama                         1.0.0\n","langchain-openai                         1.1.0\n","langchain-text-splitters                 1.0.0\n","\n","Installierte LangGraph-Bibliotheken:\n","langgraph                                1.0.3\n","langgraph-checkpoint                     3.0.1\n","langgraph-prebuilt                       1.0.5\n","langgraph-sdk                            0.2.10\n","\n","IP-Adresse: 34.106.8.98\n","Hostname: 98.8.106.34.bc.googleusercontent.com\n","Stadt: Salt Lake City\n","Region: Utah\n","Land: US\n","Koordinaten: 40.7608,-111.8911\n","Provider: AS396982 Google LLC\n","Postleitzahl: 84101\n","Zeitzone: America/Denver\n"]}],"execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlZ3lw_d8njW","executionInfo":{"status":"ok","timestamp":1764358631428,"user_tz":-60,"elapsed":63381,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"f2239bf9-625c-42e2-849f-94e7173918a2"}},{"cell_type":"code","source":["\n","# 1 | Intro\n","\n","-----\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Was ist MCP?\n","\\</font\\>\\</p\\>\n","\n","Das Model Context Protocol (MCP) ist ein **offenes Protokoll**, das die Kommunikation zwischen Large Language Models (LLMs) und externen Datenquellen bzw. Tools **standardisiert**. Hier sind die drei Hauptkomponenten und ihre Interaktionen:\n","\n","1.  LLM (Large Language Model)\n","\n","    Das eigentliche KI-Modell (z.B. gpt-4o-mini oder Claude)\n","    Verarbeitet Anfragen und generiert Antworten\n","    Entscheidet, wann externe Ressourcen ben√∂tigt werden\n","\n","2.  MCP Client\n","\n","    L√§uft in der Host-Anwendung (z.B. Claude Desktop, IDEs)\n","    Verbindet das LLM mit MCP-Servern\n","    Verwaltet mehrere Server-Verbindungen gleichzeitig\n","    √úbersetzt zwischen LLM-Anfragen und MCP-Protokoll\n","\n","3.  MCP Server\n","\n","    Stellt spezifische Funktionalit√§ten bereit\n","    Kann verschiedene Ressourcen anbieten:\n","\n","    Resources: Strukturierte Daten (Dateien, Datenbanken)\n","    Prompts: Vordefinierte Prompt-Templates\n","    Tools: Ausf√ºhrbare Funktionen\n","\n","**Wichtige Ressourcen:**\n","\n","[Anthropic MCP](https://www.anthropic.com/news/model-context-protocol)\n","\n","[OpenAI MCP](https://openai.github.io/openai-agents-python/mcp/)\n","\n","[MCPServer](https://github.com/modelcontextprotocol/servers)\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Warum wurde MCP entwickelt?\n","\\</font\\>\\</p\\>\n","\n","Die Notwendigkeit von MCP ergibt sich aus den Herausforderungen aktueller **KI-API-Interaktionen**. Derzeit ist der Aufbau von KI-Agenten, die Daten aus verschiedenen Quellen abrufen, **fragmentiert, repetitiv und schwer zu skalieren**. Jedes Tool spricht seine eigene Sprache und erfordert **individuelle Integrationen**. MCP zielt darauf ab, diese Komplexit√§t zu reduzieren und den **Entwicklungsaufwand zu minimieren**.\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","MCP-Architektur\n","\\</font\\>\\</p\\>\n","\n","[MCP Architektur](https://www.google.com/search?q=https://editor.p5js.org/ralf.bendig.rb/full/zyklSMVB_)\n","\n","\\<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/mcp\\_architektur.png\" class=\"logo\" width=\"550\"/\\>\n","\n","MCP verwendet eine Client-Server-Architektur mit den Komponenten:\n","\n","**1. MCP-Client (AI-Assistent)**\n","\n","  - Sendet Anfragen an MCP-Server\n","  - Verarbeitet erhaltene Daten\n","  - Integriert externe Informationen in Antworten\n","\n","**2. MCP-Server (Connector)**\n","\n","  - Stellt Schnittstelle zu externen Systemen bereit\n","  - Implementiert Sicherheitsrichtlinien\n","  - Transformiert Daten zwischen verschiedenen Formaten\n","\n","**3. Externe Ressourcen**\n","\n","  - Datenbanken, APIs, Dateisysteme\n","  - Berechnungstools und Analysesoftware\n","  - Cloud-Services und lokale Anwendungen\n","\n","**Kommunikationsfluss:**"],"metadata":{"id":"F40ApzrO9jrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["AI-Assistent ‚Üí MCP-Client ‚Üí MCP-Server ‚Üí Externe Ressource\n","                    ‚Üì            ‚Üì            ‚Üì\n","    Antwort    ‚Üê  JSON/HTTP  ‚Üê  Daten-API  ‚Üê  Raw Data\n"],"metadata":{"id":"kZdi3vDu8njY"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Praktische Implementierung\n","</font></p>"],"metadata":{"id":"grDzt41g9JdW"}},{"cell_type":"markdown","source":["\n","\n","Die Implementierung von MCP erfolgt schrittweise:\n","\n","**1. Server-Konfiguration**\n","\n","  - Definition der verf√ºgbaren Ressourcen\n","  - Sicherheitsrichtlinien festlegen\n","  - Authentifizierung konfigurieren\n","\n","**2. Client-Integration**\n","\n","  - Verbindung zum MCP-Server herstellen\n","  - Verf√ºgbare Tools und Datenquellen erkunden\n","  - Anfragen formulieren und Antworten verarbeiten\n","\n","**3. Testing und Deployment**\n","\n","  - Funktionalit√§tstests durchf√ºhren\n","  - Performance optimieren\n","  - Produktionsumgebung einrichten\n","\n","\\<p\\>\\<font color='black' size=\"5'\\>\n","MCP vs. andere Ans√§tze\n","\\</font\\>\\</p\\>\n","\n","**MCP vs. Function Calling - Der entscheidende Unterschied:**\n","\n","Der Hauptunterschied liegt in der **Architektur und Standardisierung**:\n","\n","**Function Calling (z.B. OpenAI):**"],"metadata":{"id":"kpYJDkxV9Kkz"}},{"cell_type":"code","source":["# Direkte Integration im AI-System\n","tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"read_file\",\n","            \"description\": \"Reads a file\",\n","            \"parameters\": {\"type\": \"object\", \"properties\": {...}}\n","        }\n","    }\n","]\n","response = openai.chat.completions.create(model=\"gpt-4\", tools=tools)"],"outputs":[],"execution_count":null,"metadata":{"id":"BcOd-cL18njZ"}},{"cell_type":"markdown","source":["**MCP (Model Context Protocol):**"],"metadata":{"id":"l-gXpMB28njZ"}},{"cell_type":"code","source":["# Standardisierte Server-Client-Architektur\n","request = {\n","    \"jsonrpc\": \"2.0\",\n","    \"method\": \"tools/call\",\n","    \"params\": {\"name\": \"read_file\", \"arguments\": {...}}\n","}\n","response = await handle_mcp_request(request)"],"outputs":[],"execution_count":null,"metadata":{"id":"szm8LIa08nja"}},{"cell_type":"markdown","source":["**Detaillierter Vergleich:**\n","\n","| Aspekt | MCP | Function Calling | RAG | Custom APIs |\n","|--------|-----|------------------|-----|-------------|\n","| **Architektur** | Client-Server | Direkt integriert | Pipeline-basiert | Individuell |\n","| **Standardisierung** | ‚úÖ Offenes Protokoll | ‚ùå Modell-spezifisch | ‚ùå Framework-abh√§ngig | ‚ùå Individuell |\n","| **Wiederverwendbarkeit** | ‚úÖ Server f√ºr alle AIs | ‚ùå Pro AI-System | ‚ö†Ô∏è Begrenzt | ‚ùì Variabel |\n","| **Setup-Aufwand** | üü° Moderat | üü¢ Niedrig | üü° Moderat | üî¥ Hoch |\n","| **Enterprise-Ready** | ‚úÖ Vollst√§ndig | ‚ö†Ô∏è Begrenzt | üü° Teilweise | ‚ùì Variabel |\n","| **Sicherheit** | ‚úÖ Integrierte Kontrollen | ‚ö†Ô∏è Basic | ‚ö†Ô∏è Dokumenten-basiert | ‚ùì Variabel |\n","| **Bidirektional** | ‚úÖ Lesen & Schreiben | ‚úÖ Ja | ‚ùå Nur Lesen | ‚úÖ Ja |\n","| **Echtzeit** | ‚úÖ Live-Daten | ‚úÖ Ja | ‚ùå Statische Docs | ‚úÖ Ja |\n","| **Skalierung** | ‚úÖ Einfach | üî¥ Schwierig | üü° Moderat | ‚ùì Variabel |\n","\n","**Praktische Entscheidungshilfe:**\n","\n","**Function Calling verwenden f√ºr:**\n","\n","  - ‚úÖ Prototyping und schnelle Tests\n","  - ‚úÖ Einfache, direkte Tool-Integration\n","  - ‚úÖ Ein AI-System mit wenigen Tools\n","  - ‚úÖ Schneller Entwicklungsstart\n","\n","**MCP verwenden f√ºr:**\n","\n","  - ‚úÖ Enterprise-Anwendungen\n","  - ‚úÖ Mehrere AI-Systeme mit geteilten Tools\n","  - ‚úÖ Sicherheitskritische Umgebungen\n","  - ‚úÖ Langfristige, skalierbare Architekturen\n","  - ‚úÖ Cross-Platform-Kompatibilit√§t\n","\n","**Fazit:** Function Calling ist der einfacherer Einstieg, MCP ist die zukunftssichere Enterprise-L√∂sung.\n","\n","# 2 | Modul `mcp`\n","\n","-----\n","\n","Das `mcp_modul.py` bietet eine **funktionale All-in-One-L√∂sung** zur Demonstration der MCP-Architektur mit klarer Rollentrennung zwischen **LLM**, **Client** und **Server**.\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Kommunikationsfluss\n","\\</font\\>\\</p\\>\n","\n","```\n","Benutzer\n","   ‚Üì\n","LLM (versteht Anfrage, entscheidet: \"Ich brauche list_files\")\n","   ‚Üì\n","LLM (parsed eigenen Tool-Intent aus generiertem Text)\n","   ‚Üì\n","Client (√ºbersetzt in MCP-Request, sendet an Server)\n","   ‚Üì\n","Server (f√ºhrt list_files aus)\n","   ‚Üì\n","Client (empf√§ngt Ergebnis)\n","   ‚Üì\n","LLM (synthetisiert Antwort aus Ergebnis)\n","   ‚Üì\n","Benutzer\n","```\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Kernfunktionen nach Rolle\n","\\</font\\>\\</p\\>\n","\n","**LLM (Language Model & Orchestrator)**\n","\n","  - `process_user_query(query, use_mcp)`: Multi-Step Reasoning Workflow:\n","    1.  LLM analysiert Benutzer-Query und generiert Tool-Calls\n","    2.  LLM erkennt eigene Tool-Intents aus der Antwort: `[MCP_CALL: tool_name({args})] [/MCP_CALL]`\n","    3.  Koordiniert Client zur Ausf√ºhrung der MCP-Requests\n","    4.  LLM synthetisiert finale nat√ºrlichsprachliche Antwort aus Tool-Ergebnissen\n","  - `setup_assistant_mcp_connection()`: Initialisiert Verbindung zu einem registrierten MCP-Server\n","\n","**Client (MCP Client - Protocol Handler)**\n","\n","  - `setup_full_connection()`: F√ºhrt vollst√§ndigen Verbindungsaufbau durch (Connect ‚Üí Initialize ‚Üí Discover Tools)\n","  - `call_server_tool()`: √úbersetzt Tool-Anfragen in MCP-konforme JSON-RPC Requests und sendet sie an den Server\n","\n","**Server (MCP Server - Resource Provider)**\n","\n","  - `handle_mcp_request(request)`: Verarbeitet eingehende MCP-Protokoll-Anfragen (JSON-RPC 2.0)\n","  - `register_new_tool()`: Dynamische Tool-Registrierung zur Laufzeit\n","  - **Tools**: `read_file_tool`, `write_file_tool`, `list_files_tool`, `get_system_info_tool`\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Kommunikationskonvention\n","\\</font\\>\\</p\\>\n","\n","**Tool-Intent-Syntax**\n","\n","Das LLM signalisiert seine Tool-Absichten durch eine spezielle Syntax im generierten Text:\n","\n","```\n","[MCP_CALL: <tool_name>({<arguments_json>})] [/MCP_CALL]\n","```\n","\n","**Beispiel:**\n","\n","```\n","[MCP_CALL: read_file({\"path\": \"/projekt/data.txt\"})] [/MCP_CALL]\n","```\n","\n","Diese Syntax wird von der LLM-Komponente selbst erkannt und dann √ºber den Client in MCP-konforme JSON-RPC 2.0 Requests √ºbersetzt.\n","\n","**JSON-RPC Protokoll**\n","\n","**JSON-RPC** (JSON Remote Procedure Call) ist ein leichtgewichtiges Protokoll f√ºr entfernte Funktionsaufrufe. Es erm√∂glicht dem Client, Tools auf dem Server aufzurufen, als w√§ren sie lokale Funktionen.\n","\n","**Beispiel eines JSON-RPC Requests:**\n","\n","```json\n","{\n","  \"jsonrpc\": \"2.0\",\n","  \"method\": \"tools/call\",\n","  \"params\": {\n","    \"name\": \"read_file\",\n","    \"arguments\": {\"path\": \"/projekt/data.txt\"}\n","  },\n","  \"id\": 1\n","}\n","```\n","\n","JSON-RPC nutzt JSON f√ºr strukturierte Nachrichten und definiert klare Regeln f√ºr Requests, Responses und Fehlerbehandlung √ºber Netzwerk- oder Prozessgrenzen hinweg.\n","\n","\\<img src=\"https://raw.githubusercontent.com/ralf-42/Image/main/mcp\\_function\\_einfach.png\" width=\"350\" alt=\"Avatar\"\\>\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","\n","Funktionsumfang `mcp.py`\n","\n","\\</font\\>\\</p\\>\n","\n","Das mcp\\_modul.py ist eine funktionale Demonstration der MCP-Architektur, die echte und simulierte Elemente kombiniert:\n","\n","| Komponente | Demo-Implementierung | Production-System |\n","|------------|---------------------|-------------------|\n","| **Tool-Ausf√ºhrung** | ‚úÖ Real (echte Datei-Ops) | ‚úÖ Real |\n","| **LLM-Calls** | ‚úÖ Real (OpenAI API) | ‚úÖ Real |\n","| **JSON-RPC Format** | ‚úÖ Real (Standard-konform) | ‚úÖ Real |\n","| **Netzwerk-Transport** | ‚ùå Simuliert (In-Memory) | ‚úÖ Real (stdio/TCP) |\n","| **Prozess-Trennung** | ‚ùå Simuliert (ein Prozess) | ‚úÖ Real (separate Prozesse) |\n","| **Connection Setup** | ‚ùå Simuliert (Dictionary) | ‚úÖ Real (Prozess-Management) |\n","| **Async I/O** | ‚úÖ Real (asyncio) | ‚úÖ Real |\n","\n","Die Demo ist ideal f√ºr:\n","\n","‚úÖ Lernen: Verstehen der MCP-Konzepte ohne Komplexit√§t von Prozess-Management\n","‚úÖ Prototyping: Schnelles Testen von Tool-Implementierungen\n","‚úÖ Testing: Einfaches Unit-Testing ohne Setup von separaten Prozessen\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","MCP-Modul importieren\n","\\</font\\>\\</p\\>"],"metadata":{"id":"LR0f9rEn8njb"}},{"cell_type":"code","source":["from genai_lib.mcp_modul import (\n","    # Server-Funktionen\n","    handle_mcp_request,\n","    get_server_info,\n","    register_new_tool,\n","\n","    # Client-Funktionen\n","    setup_full_connection,\n","    call_server_tool,\n","    get_available_tools,\n","    get_client_status,\n","\n","    # Assistant-Funktionen\n","    setup_assistant_mcp_connection,\n","    process_user_query,\n","    get_assistant_status,\n","\n","    # Modul-Info\n","    get_module_info,\n","    connect_to_server # Explizit f√ºr Schritt 1 der Simulation\n",")"],"outputs":[],"execution_count":6,"metadata":{"id":"rglqDqcR8njd","executionInfo":{"status":"ok","timestamp":1764358722035,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}}},{"cell_type":"markdown","source":["# 3 | MCP-Server erstellen\n","\n","-----\n","\n","Ein MCP-Server stellt die Verbindung zwischen AI-Assistenten und externen Ressourcen her. Wir erstellen einen funktionalen Server, der Datei-Operationen und Systemdaten bereitstellt."],"metadata":{"id":"ejQTaApP8nje"}},{"cell_type":"code","source":["#@title üîß Server-Status pr√ºfen  { display-mode: \"form\" }\n","\n","# Test des MCP-Servers (vereinfacht mit Modul)\n","async def test_mcp_server():\n","    \"\"\"Testet die grundlegenden Server-Funktionen\"\"\"\n","\n","    mprint(\"### üß™ MCP-Server Statusanfrage ...\\n\")\n","    mprint(\"---\")\n","\n","    # 1. Server-Info\n","    print(\"1Ô∏è‚É£ Server-Informationen:\")\n","    info = get_server_info()\n","    print(f\"   Name: {info['name']}\")\n","    print(f\"   Version: {info['version']}\")\n","    print(f\"   Tools: {', '.join(info['available_tools'])}\\n\")\n","\n","    # 2. Tools auflisten\n","    tools_request = {\n","        \"jsonrpc\": \"2.0\",\n","        \"id\": \"tools-1\",\n","        \"method\": \"tools/list\"\n","    }\n","\n","    response = await handle_mcp_request(tools_request)\n","    print(\"2Ô∏è‚É£ Tool-Liste:\")\n","    for tool in response['result']['tools']:\n","        print(f\"   ‚Ä¢ {tool['name']}: {tool['description']}\")\n","    print()\n","\n","    # 3. Systeminformationen abrufen\n","    sysinfo_request = {\n","        \"jsonrpc\": \"2.0\",\n","        \"id\": \"call-1\",\n","        \"method\": \"tools/call\",\n","        \"params\": {\n","            \"name\": \"get_system_info\",\n","            \"arguments\": {}\n","        }\n","    }\n","\n","    response = await handle_mcp_request(sysinfo_request)\n","    result = json.loads(response[\"result\"][\"content\"][0][\"text\"])\n","    print(\"3Ô∏è‚É£ Systeminformationen:\")\n","    print(f\"   System: {result['system']}\")\n","    print(f\"   Python: {result['python_version']}\\n\")\n","\n","    print(\"‚úÖ MCP-Server erfolgreich angefragt!\")\n","\n","# Tests ausf√ºhren\n","await test_mcp_server()"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### üß™ MCP-Server Statusanfrage ...\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1Ô∏è‚É£ Server-Informationen:\n","   Name: file-server\n","   Version: 1.0.0\n","   Tools: read_file, list_files, write_file, get_system_info\n","\n","2Ô∏è‚É£ Tool-Liste:\n","   ‚Ä¢ read_file: Liest den Inhalt einer Datei\n","   ‚Ä¢ list_files: Listet Dateien in einem Verzeichnis auf\n","   ‚Ä¢ write_file: Schreibt Inhalt in eine Datei\n","   ‚Ä¢ get_system_info: Gibt Systeminformationen zur√ºck\n","\n","3Ô∏è‚É£ Systeminformationen:\n","   System: Linux\n","   Python: 3.12.12\n","\n","‚úÖ MCP-Server erfolgreich angefragt!\n"]}],"execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"BC49Ntui8njf","executionInfo":{"status":"ok","timestamp":1764358726099,"user_tz":-60,"elapsed":25,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"67e0d215-6afa-4554-9db6-9394f03ca5ee"}},{"cell_type":"markdown","source":["# 4 | MCP-Demo\n","\n","-----"],"metadata":{"id":"shabydbk8njg"}},{"cell_type":"code","source":["#@title ü§ñ AI-Assistant mit MCP-Server verbinden (SCHRITTE 1-5 der Simulation) { display-mode: \"form\" }\n","\n","SERVER_NAME = \"file-server\"\n","server_handler = handle_mcp_request\n","\n","mprint(\"### üõ†Ô∏è Simuliertes MCP-Setup (Schritte 1-5)\")\n","mprint(\"------------------------------------------\")\n","\n","# 1. SCHRITT 1: Verbindung herstellen\n","print(\"1Ô∏è‚É£ SCHRITT 1: Client versucht, Verbindung herzustellen...\")\n","connect_to_server(SERVER_NAME, server_handler)\n","print(\"‚úÖ Client ist logisch VERBUNDEN.\")\n","\n","\n","# 2. SCHRITT 2 & 3: Initialisierung (Request & Response)\n","mprint(\"\\n2Ô∏è‚É£ & 3Ô∏è‚É£ SCHRITT 2/3: Initialisierung (INIT-Request & Response):\")\n","# initialize_server_connection sendet Request (2) und erwartet Response (3)\n","init_response = await initialize_server_connection(SERVER_NAME)\n","print(f\"   INIT-Response erhalten (Schritt 3). Status: {init_response.get('result', {}).get('serverInfo', {}).get('version')}\")\n","\n","\n","# 3. SCHRITT 4 & 5: Tools entdecken (Request & Response)\n","mprint(\"\\n4Ô∏è‚É£ & 5Ô∏è‚É£ SCHRITT 4/5: Tools entdecken (Discovery Request & Response):\")\n","# discover_server_tools sendet Request (4) und erwartet Response (5)\n","tools_list = await discover_server_tools(SERVER_NAME)\n","print(f\"   ‚úÖ {len(tools_list)} Tools entdeckt und registriert (Schritt 5).\")\n","\n","# 4. Assistant mit MCP-Server verbinden (Finaler Setup-Schritt im Assistenten)\n","result = setup_assistant_mcp_connection(SERVER_NAME)\n","mprint(f\"\\nüéØ FINAL: Assistant Setup Ergebnis: {result}\\n\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### üõ†Ô∏è Simuliertes MCP-Setup (Schritte 1-5)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"------------------------------------------"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1Ô∏è‚É£ SCHRITT 1: Client versucht, Verbindung herzustellen...\n","‚úÖ Verbunden mit Server: file-server\n","‚úÖ Client ist logisch VERBUNDEN.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n2Ô∏è‚É£ & 3Ô∏è‚É£ SCHRITT 2/3: Initialisierung (INIT-Request & Response):"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üìÑ Server file-server erfolgreich initialisiert\n","   INIT-Response erhalten (Schritt 3). Status: 1.0.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n4Ô∏è‚É£ & 5Ô∏è‚É£ SCHRITT 4/5: Tools entdecken (Discovery Request & Response):"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üîç 4 Tools auf file-server entdeckt:\n","   - read_file: Liest den Inhalt einer Datei\n","   - list_files: Listet Dateien in einem Verzeichnis auf\n","   - write_file: Schreibt Inhalt in eine Datei\n","   - get_system_info: Gibt Systeminformationen zur√ºck\n","   ‚úÖ 4 Tools entdeckt und registriert (Schritt 5).\n","‚úÖ Assistant mit MCP-Server file-server verbunden\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\nüéØ FINAL: Assistant Setup Ergebnis: True\n"},"metadata":{}}],"execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"UWOlb3De8njg","executionInfo":{"status":"ok","timestamp":1764358730438,"user_tz":-60,"elapsed":65,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"38271431-f9d6-4825-c1c8-0b83d75a281f"}},{"cell_type":"code","source":["#@title ü§ñ Verbindungsstatus pr√ºfen { display-mode: \"form\" }\n","# Status pr√ºfen\n","mprint(\"### ‚úÖ Verbindungs-Status\")\n","mprint(\"---\")\n","\n","status = get_assistant_status()\n","print(\"ü§ñ Assistant-Konfiguration:\")\n","print(f\"   Name: {status['config']['name']}\")\n","print(f\"   Modell: {status['config']['openai_model']}\")\n","print(f\"   MCP aktiviert: {status['mcp_enabled']}\")\n","print(f\"   Verbundener Server: {status['connected_server']}\")\n","print(f\"   Verf√ºgbare Server: {status['available_servers']}\\n\")\n","\n","print(\"üõ†Ô∏è Verf√ºgbare Tools:\")\n","for server, tool_list in status['available_tools'].items():\n","    print(f\"   Server '{server}':\")\n","    for tool in tool_list:\n","        print(f\"      ‚Ä¢ {tool}\")\n","\n","print(\"\\nüí° Assistant ist bereit f√ºr Anfragen!\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### ‚úÖ Verbindungs-Status"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ü§ñ Assistant-Konfiguration:\n","   Name: Functional-MCP-Assistant\n","   Modell: gpt-4o-mini\n","   MCP aktiviert: True\n","   Verbundener Server: file-server\n","   Verf√ºgbare Server: ['file-server']\n","\n","üõ†Ô∏è Verf√ºgbare Tools:\n","   Server 'file-server':\n","      ‚Ä¢ read_file\n","      ‚Ä¢ list_files\n","      ‚Ä¢ write_file\n","      ‚Ä¢ get_system_info\n","\n","üí° Assistant ist bereit f√ºr Anfragen!\n"]}],"execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"QmzexQl_8njg","executionInfo":{"status":"ok","timestamp":1764358740119,"user_tz":-60,"elapsed":56,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"745b24e7-7287-4a87-d1fe-207c23f3616b"}},{"cell_type":"code","source":["#@title ü§ñ Query 1: Was f√ºr ein System l√§uft hier? (Zerlegt in Schritte 6-8) { display-mode: \"form\" }\n","\n","# Dieser Code zerlegt den Task-Workflow explizit in die drei finalen Schritte\n","# der MCP-Simulation (6-8), anstatt die Blackbox-Funktion process_user_query zu nutzen.\n","\n","query_1 = \"Was f√ºr ein System l√§uft hier?\"\n","TOOL_NAME = \"get_system_info\" # Das vom LLM gew√§hlte Tool f√ºr die Anfrage\n","TOOL_ARGS = {}\n","\n","mprint(f\"\\n#### Query 1: {query_1}\")\n","print(\"\\nüü¢ START: LLM-Orchestrierung (zerlegt)\")\n","print(\"-\" * 40)\n","\n","# SCHRITT 6: LLM-Analyse und Tool-Call (Request)\n","mprint(f\"6Ô∏è‚É£ SCHRITT 6: LLM sendet TOOLS/CALL-Request f√ºr Tool '{TOOL_NAME}'\")\n","# Die Funktion 'call_server_tool' sendet den Request und wartet auf die Antwort\n","tool_call_response = await call_server_tool(\n","    server_name=SERVER_NAME,\n","    tool_name=TOOL_NAME,\n","    arguments=TOOL_ARGS\n",")\n","\n","# SCHRITT 7: Server-Antwort (Response)\n","mprint(\"\\n7Ô∏è‚É£ SCHRITT 7: Server-Antwort (Tool-Ergebnis) erhalten:\")\n","\n","# Manuelle Extraktion des Tool-Ergebnisses (simuliert die Verarbeitung des Clients)\n","if tool_call_response.get(\"result\"):\n","    result_content = tool_call_response[\"result\"][\"content\"][0][\"text\"]\n","    result_data = json.loads(result_content)\n","    mprint(f\"   Datenbasis f√ºr Synthese: System l√§uft auf {result_data.get('system')} (Payload von Server)\")\n","\n","    # SCHRITT 8: LLM generiert finale Antwort (Synthese)\n","    mprint(\"\\n8Ô∏è‚É£ SCHRITT 8: LLM generiert finale Antwort (Synthese):\")\n","    final_answer = (\n","        f\"Hier l√§uft ein **{result_data.get('system', 'unbekanntes')}** System \"\n","        f\"mit einer Python Version **{result_data.get('python_version', 'unbekannt')}**.\"\n","    )\n","    mprint(f\"ü§ñ {final_answer}\")\n","else:\n","    mprint(\"‚ùå Tool-Ausf√ºhrung fehlgeschlagen. Keine finale Antwort m√∂glich.\")\n","\n","print(\"\\nüî¥ ENDE: Zerlegte Sequenz abgeschlossen.\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n#### Query 1: Was f√ºr ein System l√§uft hier?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üü¢ START: LLM-Orchestrierung (zerlegt)\n","----------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"6Ô∏è‚É£ SCHRITT 6: LLM sendet TOOLS/CALL-Request f√ºr Tool 'get_system_info'"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tool 'get_system_info' erfolgreich ausgef√ºhrt\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n7Ô∏è‚É£ SCHRITT 7: Server-Antwort (Tool-Ergebnis) erhalten:"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"   Datenbasis f√ºr Synthese: System l√§uft auf Linux (Payload von Server)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n8Ô∏è‚É£ SCHRITT 8: LLM generiert finale Antwort (Synthese):"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"ü§ñ Hier l√§uft ein **Linux** System mit einer Python Version **3.12.12**."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üî¥ ENDE: Zerlegte Sequenz abgeschlossen.\n"]}],"execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"id":"9VZYS_xW8njh","executionInfo":{"status":"ok","timestamp":1764358744097,"user_tz":-60,"elapsed":38,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"1824b1e1-566d-45c8-d0f6-8b90a952cbd2"}},{"cell_type":"code","source":["#@title ü§ñ Query 2: Erstelle eine Datei 'demo.txt' { display-mode: \"form\" }\n","# Dieser Aufruf nutzt die Wrapper-Funktion process_user_query, die Schritte 6-8 intern ausf√ºhrt.\n","query_2 = \"Erstelle eine Datei 'demo.txt' mit dem Inhalt 'Hello MCP!'\"\n","\n","mprint(f\"\\n#### Query 2: {query_2}\")\n","print(\"\\nüü¢ START: Multi-Step Reasoning (MIT MCP)\")\n","print(\"-\" * 40)\n","\n","mcp_response_2 = await process_user_query(query_2, use_mcp=True)\n","\n","print(\"\\nüî¥ ENDE: Synthetisierte Antwort (Schritt 8)\")\n","mprint(f\"ü§ñ {mcp_response_2}\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n#### Query 2: Erstelle eine Datei 'demo.txt' mit dem Inhalt 'Hello MCP!'"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üü¢ START: Multi-Step Reasoning (MIT MCP)\n","----------------------------------------\n","üí≠ Verarbeite Anfrage: 'Erstelle eine Datei 'demo.txt' mit dem Inhalt 'Hello MCP!''\n","ü§ñ AI-Antwort: Ich werde jetzt eine Datei namens 'demo.txt' erstellen und den Inhalt 'Hello MCP!' darin speichern. ...\n","üîç 1 MCP-Aufrufe gefunden\n","üîß F√ºhre aus: write_file({'filepath': 'demo.txt', 'content': 'Hello MCP!'})\n","‚úÖ Tool 'write_file' erfolgreich ausgef√ºhrt\n","\n","üî¥ ENDE: Synthetisierte Antwort (Schritt 8)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"ü§ñ Die Datei 'demo.txt' wurde erfolgreich erstellt und enth√§lt den Text 'Hello MCP!'. Insgesamt wurden 10 Bytes geschrieben. Sie k√∂nnen die Datei jetzt verwenden oder √∂ffnen. Wenn Sie weitere Fragen haben oder zus√§tzliche Hilfe ben√∂tigen, lassen Sie es mich einfach wissen!"},"metadata":{}}],"execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"HqiPGyVH8njh","executionInfo":{"status":"ok","timestamp":1764358759380,"user_tz":-60,"elapsed":6507,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"4f5c5458-a5f4-495a-b38d-f05f0d1e924d"}},{"cell_type":"code","source":["#@title ü§ñ Query 3: Welche Dateien sind im aktuellen Verzeichnis? { display-mode: \"form\" }\n","query_3 = \"Welche Dateien sind im aktuellen Verzeichnis?\"\n","mprint(f\"\\n#### Query 3: {query_3} (Vergleich)\")\n","\n","# 1. MIT MCP: Funktioniert, da Tools genutzt werden\n","print(\"\\n‚úÖ MIT MCP:\")\n","print(\"-\" * 20)\n","# Sollte 'demo.txt' in der Ausgabe zeigen\n","mcp_response_3 = await process_user_query(query_3, use_mcp=True)\n","mprint(f\"\\nü§ñ {mcp_response_3}\")\n","\n","\n","mprint(f\"\\n ---\\n\")\n","mprint(\"### üéØ Demo abgeschlossen! Der Mehrwert von MCP:\")\n","\n","mprint(\"   ‚úÖ **Echtzeit-F√§higkeit:** LLM kann Live-Daten abrufen und verarbeiten.\")\n","mprint(\"   ‚úÖ **Bidirektional:** Sowohl Lese- als auch Schreib-Operationen sind m√∂glich.\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n#### Query 3: Welche Dateien sind im aktuellen Verzeichnis? (Vergleich)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ MIT MCP:\n","--------------------\n","üí≠ Verarbeite Anfrage: 'Welche Dateien sind im aktuellen Verzeichnis?'\n","ü§ñ AI-Antwort: Ich werde das aktuelle Verzeichnis auflisten, um die Dateien zu sehen. Dazu benutze ich das Tool zum...\n","üîç 1 MCP-Aufrufe gefunden\n","üîß F√ºhre aus: list_files({})\n","‚úÖ Tool 'list_files' erfolgreich ausgef√ºhrt\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\nü§ñ Im aktuellen Verzeichnis befinden sich folgende Dateien und Ordner:\n\n1. **Ordner:** `.config` (Gr√∂√üe: 0 Bytes)\n2. **Datei:** `demo.txt` (Gr√∂√üe: 10 Bytes)\n3. **Ordner:** `sample_data` (Gr√∂√üe: 0 Bytes)\n\nInsgesamt gibt es 3 Elemente im Verzeichnis. Wenn du weitere Informationen ben√∂tigst oder etwas Bestimmtes mit einer der Dateien oder Ordner tun m√∂chtest, lass es mich wissen!"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"\n ---\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### üéØ Demo abgeschlossen! Der Mehrwert von MCP:"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"   ‚úÖ **Echtzeit-F√§higkeit:** LLM kann Live-Daten abrufen und verarbeiten."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"   ‚úÖ **Bidirektional:** Sowohl Lese- als auch Schreib-Operationen sind m√∂glich."},"metadata":{}}],"execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"9je3ADIJ8njh","executionInfo":{"status":"ok","timestamp":1764358764171,"user_tz":-60,"elapsed":4776,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"bd69edd6-f1bf-40da-eb27-600f2243a163"}},{"cell_type":"markdown","source":["# 5 | MCP in der Praxis\n","\n","-----\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Anwendungsf√§lle\n","\\</font\\>\\</p\\>\n","\n","MCP bietet in Unternehmensumgebungen erhebliche Vorteile, besonders wenn funktional implementiert:\n","\n","**1. Datenbank-Integration**\n","\n","  - Direkter Zugriff auf Unternehmens-Datenbanken\n","  - Echtzeit-Berichte und Analytics\n","  - Automatisierte Datenextraktion\n","\n","**2. ERP-System-Anbindung**\n","\n","  - Zugriff auf SAP, Oracle, Microsoft Dynamics\n","  - Automatisierte Bestellprozesse\n","  - Inventory-Management\n","\n","**3. Cloud-Service-Integration**\n","\n","  - AWS, Azure, Google Cloud APIs\n","  - Automatisierte Ressourcenverwaltung\n","  - Monitoring und Alerting\n","\n","**4. Sicherheits-Tools**\n","\n","  - SIEM-System-Integration\n","  - Automatisierte Incident Response\n","  - Compliance-Reporting\n","\n","**5. Collaboration-Tools**\n","\n","  - Slack, Teams, Jira Integration\n","  - Automatisierte Projekt-Updates\n","  - Team-Koordination\n","\n","**Vorteile des funktionalen Ansatzes:**\n","\n","  - **Bessere Testbarkeit**: Einzelne Funktionen k√∂nnen isoliert getestet werden\n","  - **Flexiblere Komposition**: Tools k√∂nnen dynamisch kombiniert werden\n","  - **Einfachere Wartung**: Klare Trennung von Concerns\n","  - **Bessere Performance**: Keine Overhead durch Objekt-Instantiierung\n","\n","# 6 | Zukunft von MCP\n","\n","-----\n","\n","**Entwicklungstrends:**\n","\n","**1. Erweiterte Tool-Kategorien**\n","\n","  - Computer Vision APIs\n","  - IoT-Device Integration\n","  - Blockchain/Smart Contract Tools\n","  - Robotics Control Systems\n","\n","**2. Cross-Platform Standardisierung**\n","\n","  - OpenAPI/JSON Schema Integration\n","  - GraphQL-basierte Schemas\n","  - Universelle Authentication\n","  - Multi-Cloud Orchestrierung\n","\n","**3. Enterprise-Integration**\n","\n","  - Native SAP/Oracle Connectors\n","  - Compliance-by-Design\n","  - Zero-Trust Security Models\n","  - Hybrid Cloud Architectures\n","\n","**Ausblick:**\n","MCP entwickelt sich zu einem universellen Standard f√ºr AI-System-Integration. Der funktionale Ansatz bietet dabei besondere Vorteile:\n","\n","  - **Bessere Komposierbarkeit**: Funktionen k√∂nnen flexibel kombiniert werden\n","  - **Einfachere Tests**: Isolierte Funktionen sind leichter zu testen\n","  - **Klarere Architektur**: Funktionale Programmierung f√∂rdert saubere Designs\n","  - **Bessere Performance**: Weniger Overhead durch Objekt-Management\n","\n","In den n√§chsten Jahren erwarten wir:\n","\n","  - **Standardisierung** durch W3C oder √§hnliche Organisationen\n","  - **Native Support** in allen gro√üen AI-Plattformen\n","  - **Enterprise-Grade** Sicherheit und Compliance\n","  - **√ñkosystem** von vordefinierten funktionalen Connectoren\n","  - **No-Code/Low-Code** MCP-Integration Tools\n","  - **Funktionale Komposition** als Standard-Architektur\n","\n","MCP wird die Art und Weise revolutionieren, wie AI-Systeme mit der realen Welt interagieren, und der funktionale Ansatz wird dabei eine Schl√ºsselrolle spielen.\n","\n","# 6 | Aufgabe\n","\n","-----\n","\n","\\<p\\>\\<font color='black' size=\"5\"\\>\n","Teste den AI-Assistant mit eigenen Queries\n","\\</font\\>\\</p\\>\n","\n","**Ziel**: Nutze den fertigen MCP-Assistant, um verschiedene Datei-Operationen durchzuf√ºhren.\n","\n","**Schritt 1: Einfache Queries testen**\n","\n","F√ºhre die folgenden Queries mit dem AI-Assistant aus und beobachte, wie er die MCP-Tools nutzt:"],"metadata":{"id":"l9ssj0Ib8njh"}},{"cell_type":"code","source":["# Query 1: System-Informationen\n","result = await process_user_query(\"Welches Betriebssystem l√§uft hier?\")\n","print(result)\n","\n","# Query 2: Datei erstellen\n","result = await process_user_query(\"Erstelle eine Datei 'meine_notizen.txt' mit dem Text 'Das ist mein MCP-Test'\")\n","print(result)\n","\n","# Query 3: Datei lesen\n","result = await process_user_query(\"Lies die Datei 'meine_notizen.txt' und zeige mir den Inhalt\")\n","print(result)\n","\n","# Query 4: Verzeichnis auflisten\n","result = await process_user_query(\"Welche Dateien sind im aktuellen Verzeichnis?\")\n","print(result)"],"outputs":[],"execution_count":null,"metadata":{"id":"g6IYatYx8njh"}},{"cell_type":"markdown","source":["**Schritt 2: Eigene Queries erstellen**\n","\n","Entwickle mindestens **3 eigene Queries**, die verschiedene Tool-Kombinationen nutzen:\n","\n","**Beispiele f√ºr kreative Queries:**\n","\n","  - \"Erstelle eine ToDo-Liste in der Datei 'todos.txt' mit 5 Aufgaben\"\n","  - \"Z√§hle, wie viele .txt Dateien im aktuellen Verzeichnis sind\"\n","  - \"Erstelle eine Datei mit den aktuellen Systeminformationen\"\n","  - \"Lies alle .txt Dateien und fasse ihren Inhalt zusammen\"\n","\n","**Schritt 3: Bonus-Challenge (Optional)**\n","\n","Teste den Assistant mit und ohne MCP-Modus und vergleiche die Ergebnisse:"],"metadata":{"id":"Mtt-tnNW8nji"}},{"cell_type":"code","source":["# Mit MCP\n","result_mit = await process_user_query(\"Was f√ºr Dateien sind hier?\", use_mcp=True)\n","\n","# Ohne MCP\n","result_ohne = await process_user_query(\"Was f√ºr Dateien sind hier?\", use_mcp=False)\n","\n","# Vergleiche\n","print(\"MIT MCP:\", result_mit)\n","\n","print(\"\\nOHNE MCP:\", result_ohne)"],"outputs":[],"execution_count":null,"metadata":{"id":"IeXJtuUq8nji"}},{"cell_type":"markdown","source":["**üí° Tipps:**\n","\n","  - Der Assistant interpretiert deine nat√ºrlichsprachlichen Anfragen\n","  - Er entscheidet selbst, welche MCP-Tools er nutzt\n","  - Experimentiere mit verschiedenen Formulierungen\n","  - Achte auf die Console-Ausgabe, um zu sehen, welche Tools aufgerufen werden\n","\n","**‚úÖ Erfolg:**\n","\n","Du hast die Aufgabe erfolgreich abgeschlossen, wenn:\n","\n","  - ‚úÖ Mindestens 3 eigene Queries erstellt\n","  - ‚úÖ Alle Queries liefern sinnvolle Ergebnisse\n","  - ‚úÖ Du verstehst, wie der Assistant MCP-Tools nutzt\n","\n","<!-- end list -->\n","\n","```\n","```"],"metadata":{"id":"unlqDNvU8nji"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}