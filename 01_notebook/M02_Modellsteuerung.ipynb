{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p><font size=\"6\" color='grey'> <b>\n",
    "\n",
    "Generative KI. Verstehen. Anwenden. Gestalten.\n",
    "</b></font> </br></p>"
   ],
   "metadata": {
    "id": "8x1hrQqQ27a3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font size=\"5\" color='grey'> <b>\n",
    "Modellsteuerung\n",
    "</b></font> </br></p>\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "R5CfUEMJdvFQ"
   }
  },
  {
   "cell_type": "code",
   "source": "#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\nfrom genai_lib.utilities import (\n    check_environment,\n    get_ipinfo,\n    setup_api_keys,\n    mprint,\n    install_packages,\n    mermaid,\n    get_model_profile,\n    extract_thinking,\n    load_prompt\n)\nsetup_api_keys(['OPENAI_API_KEY'], create_globals=False)\nprint()\ncheck_environment()\nprint()\nget_ipinfo()",
   "metadata": {
    "id": "PwDTz3VqPy8b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 | Intro Modellsteuerung\n",
    "---\n"
   ],
   "metadata": {
    "id": "PHDCKRbtgVXy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die rasante Entwicklung im Bereich der k√ºnstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei gro√üen Sprachmodellen (LLMs) gef√ºhrt. Diese Modelle erzeugen menschen√§hnlichen Text, √ºbersetzen Sprachen und beantworten komplexe Fragen. Um die gew√ºnschten Ergebnisse zielgerichtet zu erreichen, bedarf es Verfahren zur Modellsteuerung  und -optimierung, die das Modellverhalten steuern, verbessern und an spezifische Anforderungen anpassen. Die nachfolgende Tabelle liefert eine √úbersicht √ºber Verfahren, die zur Modellsteuerung und -optimierung eingesetzt werden k√∂nnen.\n",
    "\n"
   ],
   "metadata": {
    "id": "lSg1eGf95Vz1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Nr. | Methode                        | Relevanz (‚òÖ) | Technischer Aufwand  | Typische Anwendung                   | Erl√§uterung                                                                                     |\n",
    "| :-- | :----------------------------- | :----------- | :------------------- | :----------------------------------- | :---------------------------------------------------------------------------------------------- |\n",
    "| 1   | Prompt Engineering             | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ        | sehr gering          | Basis f√ºr alle LLM-Anwendungen       | Systematische Gestaltung von Eingabetexten zur Optimierung der Modellausgaben.                  |\n",
    "| 2   | Few-Shot Learning              | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ        | sehr gering          | Schnelle Aufgabenanpassung           | Bereitstellung weniger Beispiele im Prompt, damit das Modell neue Aufgaben ohne Training lernt. |\n",
    "| 3   | RAG (Retrieval-Augmented Gen.) | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ        | mittel               | Wissensbasierte Anwendungen          | Kombination von Informationsabruf aus externen Datenquellen mit Textgenerierung.                |\n",
    "| 4   | Chain-of-Thought Prompting     | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ        | sehr gering          | Komplexe Reasoning-Aufgaben          | Anleitung des Modells, Denkschritte explizit zu formulieren f√ºr bessere Probleml√∂sung.          |\n",
    "| 5   | API Parameter Tuning           | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ        | sehr gering          | Optimierung von Output-Qualit√§t      | Anpassung von Temperature, Top-p, Max-Tokens etc. zur Steuerung der Ausgabecharakteristik.      |\n",
    "| 6   | Function Calling / Tool Use    | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ        | gering               | Integration ext. Services/Daten      | Erm√∂glicht dem Modell, strukturierte externe Funktionen und APIs aufzurufen.                    |\n",
    "| 7   | Adapter-Tuning / LoRA          | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ        | mittel ‚Äì hoch        | Effiziente Modellanpassung           | Trainiert nur kleine Adapterschichten statt des gesamten Modells f√ºr spezifische Aufgaben.      |\n",
    "| 8   | LangChain / LCEL Pipelines     | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ        | mittel               | Komplexe LLM-Anwendungsarchitekturen | Framework zur Orchestrierung komplexer LLM-Workflows und -Ketten.                               |\n",
    "| 9   | Self-Consistency Prompting     | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ        | gering               | Verbesserung der Antwortqualit√§t     | Mehrfache Ausf√ºhrung derselben Anfrage und Auswahl der konsistentesten Antwort.                 |\n",
    "| 10  | Context Engineering            | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ        | gering ‚Äì mittel      | Strukturierung komplexer Inputs      | Strategische Anordnung und Strukturierung von Kontextinformationen im Prompt.                   |\n",
    "| 11  | Multimodal Prompting           | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ        | gering               | Text + Bild/Audio/Video Verarbeitung | Verwendung mehrerer Eingabemodali√§ten (Text, Bild, Audio) in einem Prompt.                      |\n",
    "| 12  | Fine-Tuning                    | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ        | hoch                 | Spezialisierung auf Domain/Task      | Training des gesamten Modells auf spezifischen Daten f√ºr maximale Anpassung.                    |\n",
    "| 13  | Agentic Workflows              | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ        | mittel ‚Äì hoch        | Autonome, mehrstufige Prozesse       | Aufbau autonomer Systeme, die eigenst√§ndig Entscheidungen treffen und Aktionen ausf√ºhren.       |\n",
    "| 14  | Instruction Tuning             | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ        | nicht selbst machbar | Grundlegende Verhaltensanpassung     | Training auf Instruktions-Response-Paaren zur Verbesserung der Befolgung von Anweisungen.       |\n",
    "| 15  | Modell-Ensemble / Routing      | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ        | mittel ‚Äì hoch        | Spezial-Anwendungen, Redundanz       | Kombination mehrerer Modelle oder intelligente Weiterleitung an spezialisierte Modelle.         |"
   ],
   "metadata": {
    "id": "GkuWcBW_E_DL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<p><font color='black' size=\"4\">\n",
    "<b>Legende</b>\n",
    "</font></p>\n",
    "\n",
    "- *Relevanz:* Praktische Wichtigkeit f√ºr typische LLM-Projekte (5‚òÖ = essentiell, 1‚òÖ = Nische)\n",
    "- *Technischer Aufwand*: Implementierungsaufwand und Ressourcenbedarf\n",
    "- *Typische Anwendung*: Haupteinsatzgebiete der jeweiligen Methode\n",
    "- *Erl√§uterung*: Kurze Beschreibung der Methode und ihres Zwecks\n",
    "\n",
    "<p><font color='black' size=\"4\">\n",
    "<b>Einordnung</b>\n",
    "</font></p>\n",
    "\n",
    "+ *Einstiegsmethoden (‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ):* Die ersten drei Verfahren bilden das Fundament jeder KI-Anwendung und sollten zuerst beherrscht werden.\n",
    "\n",
    "+ *Erweiterte Techniken (‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ):* Verfahren 4-8 bieten erhebliche Verbesserungen bei moderatem Aufwand und sind f√ºr professionelle Anwendungen essentiell.\n",
    "\n",
    "+ *Spezialisierte Ans√§tze (‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ):* Verfahren 9-13 eignen sich f√ºr spezifische Use Cases und erweiterte Optimierungen.\n",
    "\n",
    "+ *Nischenl√∂sungen (‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ):* Verfahren 14-15 sind f√ºr hochspezialisierte Anwendungen oder wenn andere Methoden nicht ausreichen."
   ],
   "metadata": {
    "id": "er07A5OtG4-s"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Modellsteuerung und -optimierung](https://editor.p5js.org/ralf.bendig.rb/full/um423ggnD)"
   ],
   "metadata": {
    "id": "Hx0SlhwPIlYi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='darkblue' size=\"4\">\n",
    "‚ÑπÔ∏è <b>Information</b>\n",
    "</font></p>\n",
    "\n",
    "Nachfolgend werden in einem ersten Schritt 4 Methoden n√§her betrachtet."
   ],
   "metadata": {
    "id": "bL0TJjVlGY6x"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![My Image](https://raw.githubusercontent.com/ralf-42/GenAI/main/07_image/Modellansteuerung.png)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "4Q2x4Ua6EI9l"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 | Prompt Engineering\n",
    "---"
   ],
   "metadata": {
    "id": "owVDrCRD5hoI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte `Prompt`, gegeben, der die gew√ºnschte Ausgabe beschreibt. Die Qualit√§t der Ausgabe h√§ngt stark von der Qualit√§t des Prompts ab. Ein gut formulierter Prompt sollte klar, pr√§gnant und spezifisch sein.\n"
   ],
   "metadata": {
    "id": "o7lp262M4u0Z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Say What You See](https://artsandculture.google.com/experiment/say-what-you-see/jwG3m7wQShZngw)"
   ],
   "metadata": {
    "id": "pehjX4of6Vht"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "Prompt-Elemente\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "DlkRGwcR3rBp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eingabeaufforderungen bestehen in der Regel aus vier wesentlichen Elementen, die je nach Aufgabe variieren k√∂nnen. Die Hauptbestandteile sind:\n",
    "\n",
    "* **Anweisungen** ‚Äì Definieren die Aufgabe des Modells, entweder als Aufgabenbeschreibung oder als konkrete Handlungsanweisung.  \n",
    "* **Kontext** ‚Äì Liefert erg√§nzende Informationen, um das Modell bei der Bearbeitung zu unterst√ºtzen.  \n",
    "* **Eingabedaten** ‚Äì Enthalten die spezifischen Informationen, zu denen eine Antwort generiert werden soll.  \n",
    "* **Ausgabeindikator** ‚Äì Signalisiert den √úbergang zur erwarteten Modellantwort.  \n",
    "\n",
    "Weitere Beispiele zur Anwendung dieser Struktur folgen sp√§ter."
   ],
   "metadata": {
    "id": "nUJCfQ_-71Ti"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nachfolgend ein Beispiel f√ºr eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n",
    "\n",
    "```\n",
    "Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n",
    "Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n",
    "Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n",
    "dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n",
    "herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n",
    "Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n",
    "benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n",
    "Erscheinungsbild, das wirklich attraktiv ist.\n",
    "\n",
    "\n",
    "Zusammenfassung: ...\n",
    "```\n",
    "\n",
    "Diese Eingabeaufforderung erzeugt m√∂glicherweise die folgende Ausgabe:\n",
    "\n",
    "```\n",
    "Die intelligente digitale Personenwaage wird f√ºr ihre schnelle Einrichtung, die einfache\n",
    "Synchronisierung mit ihrer App auf √§lteren Telefonen zur m√ºhelosen Nachverfolgung, die\n",
    "benutzerfreundlichen Funktionen zur Essensplanung und Kalorienz√§hlung sowie ihr schlankes, modernes\n",
    "Design hoch gelobt.\n",
    "```"
   ],
   "metadata": {
    "id": "rj5-ap_p4Htg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><font color='black' size=\"5\">\n",
    "Code-Beispiel\n",
    "</font></p>"
   ],
   "metadata": {
    "id": "yD8yi1td35er"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from openai import OpenAI, chat\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "user_input = \"\"\"\n",
    "Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n",
    "Produkt: Intelligente digitale Personenwaage f√ºr K√∂rpergewicht, Fett, BMI, Muskelmassezusammensetzung\n",
    "Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n",
    "dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n",
    "herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n",
    "Nachverfolgung m√ºhelos. Die Funktionen zur Essensplanung und Kalorienz√§hlung der App sind unglaublich\n",
    "benutzerfreundlich. Ich bin absolut begeistert! Au√üerdem hat die Waage ein elegantes, modernes\n",
    "Erscheinungsbild, das wirklich attraktiv ist.\n",
    "\"\"\"\n",
    "\n",
    "completion = chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n",
    "    {\"role\": \"user\", \"content\": user_input}\n",
    "  ]\n",
    ")\n",
    "\n",
    "mprint('## ü§ñ KI:')\n",
    "mprint(completion.choices[0].message.content)"
   ],
   "metadata": {
    "id": "HEx8kcdlOKl_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 | Context Engineering\n",
    "---"
   ],
   "metadata": {
    "id": "76cAlIjdQgGe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Context Engineering** erweitert das klassische Prompting, indem nicht nur eine einzelne Eingabe formuliert wird, sondern der *gesamte Kontext* der Kommunikation mit dem Modell bewusst gestaltet wird.\n",
    "\n",
    "**Ziel:**\n",
    "Durch pr√§zise Steuerung von Systemnachricht, Rollen, Beispiel-Dialogen, Formatvorgaben oder eingebetteten Informationen kann das Modell *konsistenter*, *zielgerichteter* und *nachvollziehbarer* antworten.\n",
    "\n",
    "\n",
    "\n",
    "**Typische Elemente des Kontext-Engineerings:**\n",
    "\n",
    "| Element            | Beschreibung                                                                 |\n",
    "|--------------------|------------------------------------------------------------------------------|\n",
    "| **Systemrolle**     | Definiert die grunds√§tzliche Identit√§t oder Aufgabe des Modells             |\n",
    "| **Beispiel-Prompts**| Demonstrieren erwartete Eingabe-/Ausgabeformate                             |\n",
    "| **Formatvorgaben**  | Regeln zur Antwortstruktur (z.‚ÄØB. JSON, Bullet-Points, Markdown etc.)       |\n",
    "| **Dynamische Daten**| Integration von Nutzerprofil, Session-Kontext, Wissensdatenbanken etc.     |\n",
    "\n",
    "\n",
    "\n",
    "**Unterschied zu klassischem Prompting**\n",
    "\n",
    "| Klassisches Prompting                | Context Engineering                                       |\n",
    "|-------------------------------------|-----------------------------------------------------------|\n",
    "| ‚ÄûAntworte als Medizinexperte.‚Äú     | Strukturierter Kontext: Rolle, Regeln, Beispiele, Daten   |\n",
    "| Einzeiliger Prompt                  | Mehrteiliger, kontextreicher Input                        |\n",
    "| Manuell formuliert                  | Automatisiert, modular, oft per Tool gesteuert            |\n",
    "\n",
    "---\n",
    "\n",
    "**Beispiel (mit System- und Nutzerrolle):**\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"Du bist ein rechtssicherer KI-Assistent f√ºr Medizinrecht. Antworte immer in vollst√§ndigen S√§tzen mit Quellenangabe.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Welche Aufbewahrungsfrist gilt f√ºr R√∂ntgenbilder in Deutschland?\"}\n",
    "]\n"
   ],
   "metadata": {
    "id": "EM9JJE6ZQnfX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 | Retrieval-Augmented Generation\n",
    "---"
   ],
   "metadata": {
    "id": "L0grUpA56y3K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RAG (Retrieval-Augmented Generation) ist eine **hybride Methode**, die die St√§rken von **LLMs** mit denen von **Information-Retrieval-Systemen** **kombiniert**. Dabei greift das LLM auf llm-externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n",
    "\n",
    "**Funktionsweise:**\n",
    "\n",
    "+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n",
    "+ Das System sucht in externe Wissens nach relevanten Informationen.\n",
    "+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n",
    "+ Das LLM generiert eine Antwort basierend auf der Anfrage **und** dem Kontext.\n",
    "\n",
    "\n",
    "**Einsatzszenarien:**\n",
    "\n",
    "RAG eignet sich besonders f√ºr Aufgaben, die aktuelle oder dom√§nenspezifische Informationen erfordern, wie z. B.:\n",
    "\n",
    "+ Kundensupport mit Zugriff auf Produktdatenbanken\n",
    "+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n",
    "+ Finanzplanung mit Zugriff auf Marktdaten\n",
    "+ Beantwortung von Fragen zu Unternehmensinformationen\n",
    "\n"
   ],
   "metadata": {
    "id": "EbmfDWKg4xmC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 | Fine-Tuning\n",
    "---"
   ],
   "metadata": {
    "id": "iQpWHr88612f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine-Tuning ist eine Methode, bei der ein bereits **trainiertes LLM** auf einer kleineren, **aufgabenspezifischen** Datenmenge weiter trainiert wird. Dadurch kann das Modell an **spezifische** **Anforderungen** angepasst und seine Leistung f√ºr diese Aufgaben verbessert werden.\n",
    "\n",
    "**Funktionsweise:**\n",
    "\n",
    "+ Ein vortrainiertes LLM wird ausgew√§hlt.\n",
    "+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n",
    "+ Das LLM wird auf dieser Datenmenge trainiert.\n",
    "+ Die Parameter des LLM werden angepasst, um die Leistung f√ºr die spezifische Aufgabe zu optimieren.\n",
    "\n",
    "\n",
    "**Einsatzszenarien:**\n",
    "\n",
    "Fine-Tuning eignet sich besonders f√ºr Aufgaben, die eine hohe Genauigkeit und **Dom√§nenspezialisierung** erfordern, wie z. B.:\n",
    "\n",
    "+ fachlich spezialisierte LLMs (Recht, Medizin, ...)\n",
    "+ Sentimentanalyse\n",
    "+ Textklassifizierung\n",
    "+ Spam-Erkennung\n",
    "+ Personalisierte Kundeninteraktionen\n",
    "\n"
   ],
   "metadata": {
    "id": "WEyWOZtP40s0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 6 | Entscheidungskriterien\n",
    "---"
   ],
   "metadata": {
    "id": "EU_aZQuK5kfc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Wahl der geeigneten Methode h√§ngt von verschiedenen Faktoren ab, darunter:"
   ],
   "metadata": {
    "id": "w4I1UPS97apC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Modellsteuerung Decision Matrix](https://editor.p5js.org/ralf.bendig.rb/full/xb3zPgRSr)"
   ],
   "metadata": {
    "id": "U4MA8tmKM3Wp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "| Kriterium               | Prompt Engineering | Context Engineering | RAG | Fine-Tuning |\n",
    "|-------------------------|-----------|---------------------|-----|-------------|\n",
    "| **Komplexit√§t**         | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>√Ñnderungen am Modell. | Mittel<br><br>Ben√∂tigt durchdachte<br>Strukturierung des Kontexts<br>und ggf. Framework-Einsatz. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n",
    "| **Effizienz**           | Hoch<br><br>Prompting erm√∂glicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Hoch<br><br>Effizient bei wiederverwendbaren<br>Kontextbausteinen und Rollenstrukturen. | Mittel<br><br>RAG ben√∂tigt zus√§tzliche<br>Schritte f√ºr den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n",
    "| **Genauigkeit**         | Niedrig<br><br>Die Genauigkeit h√§ngt stark<br>von der Qualit√§t des<br>Prompts ab. | Mittel<br><br>H√∂here Genauigkeit durch<br>strukturierte Kontexte und<br>Beispiele. | Mittel<br><br>RAG bietet h√∂here<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>F√ºhrt zu h√∂herer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n",
    "| **Flexibilit√§t**        | Hoch<br><br>Sehr flexibel und f√ºr<br>verschiedene Aufgaben<br>einsetzbar. | Hoch<br><br>Erlaubt modulare, kontext-<br>abh√§ngige Anpassung<br>ohne Modell√§nderung. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsf√§hig. |\n",
    "| **Ressourcen-<br>bedarf** | Niedrig<br><br>Ben√∂tigt nur minimale<br>Ressourcen f√ºr die<br>Ausf√ºhrung. | Niedrig‚ÄìMittel<br><br>Abh√§ngig von der<br>Komplexit√§t der Kontextsteuerung. | Mittel<br><br>Ressourcen f√ºr Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>f√ºr Training. |\n",
    "| **Datenbedarf**         | Niedrig<br><br>Keine zus√§tzlichen<br>Trainingsdaten<br>erforderlich. | Niedrig<br><br>Evtl. strukturierte<br>Beispiele oder Metadaten. | Mittel<br><br>Ben√∂tigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Ben√∂tigt gro√üe Mengen an<br>spezifischen<br>Trainingsdaten. |\n",
    "| **Beschreibung**        | Einfache Methode mit<br>Textanweisungen f√ºr das<br>Modell. | Strukturierte Gestaltung<br>von Rollen, Kontext, Beispielen<br>und Regeln f√ºr bessere<br>Steuerbarkeit. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datens√§tzen. |\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "rSAuP0cW54O1"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/empty.ipynb",
     "timestamp": 1736181733357
    }
   ],
   "collapsed_sections": [
    "PHDCKRbtgVXy",
    "owVDrCRD5hoI",
    "76cAlIjdQgGe",
    "L0grUpA56y3K",
    "iQpWHr88612f",
    "EU_aZQuK5kfc"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}