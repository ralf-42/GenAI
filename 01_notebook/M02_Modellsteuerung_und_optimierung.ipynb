{"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)"],"metadata":{"id":"8x1hrQqQ27a3"}},{"cell_type":"markdown","source":["<p><font size=\"5\" color='grey'> <b>\n","Modellsteuerung -und optimierung\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"R5CfUEMJdvFQ"}},{"cell_type":"code","source":["#@title 🔧 Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/Python_Modules\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages\n","setup_api_keys(['OPENAI_API_KEY', 'HF_TOKEN'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()\n","# ---\n","# Bei Bedarf: Trennen zwischen Installationsname () und Importname (für Python) beide Angaben in Klammern\n","# install_packages([('markitdown[all]', 'markitdown'), 'langchain_chroma', ]"],"metadata":{"id":"PwDTz3VqPy8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | Intro Modellsteuerung/-optimierung\n","---\n"],"metadata":{"id":"PHDCKRbtgVXy"}},{"cell_type":"markdown","source":["Die rasante Entwicklung im Bereich der künstlichen Intelligenz (KI) hat zu beeindruckenden Fortschritten bei großen Sprachmodellen (LLMs) geführt. Diese Modelle erzeugen menschenähnlichen Text, übersetzen Sprachen und beantworten komplexe Fragen. Um die gewünschten Ergebnisse zielgerichtet zu erreichen, bedarf es Verfahren zur Modellsteuerung  und -optimierung, die das Modellverhalten steuern, verbessern und an spezifische Anforderungen anpassen. Die nachfolgende Tabelle liefert eine Übersicht über Verfahren, die zur Modellsteuerung und -optimierung eingesetzt werden können.\n","\n"],"metadata":{"id":"lSg1eGf95Vz1"}},{"cell_type":"markdown","source":["| Nr. | Methode                        | Relevanz (★) | Technischer Aufwand  | Typische Anwendung                   | Erläuterung                                                                                     |\n","| :-- | :----------------------------- | :----------- | :------------------- | :----------------------------------- | :---------------------------------------------------------------------------------------------- |\n","| 1   | Prompt Engineering             | ★★★★★        | sehr gering          | Basis für alle LLM-Anwendungen       | Systematische Gestaltung von Eingabetexten zur Optimierung der Modellausgaben.                  |\n","| 2   | Few-Shot Learning              | ★★★★★        | sehr gering          | Schnelle Aufgabenanpassung           | Bereitstellung weniger Beispiele im Prompt, damit das Modell neue Aufgaben ohne Training lernt. |\n","| 3   | RAG (Retrieval-Augmented Gen.) | ★★★★★        | mittel               | Wissensbasierte Anwendungen          | Kombination von Informationsabruf aus externen Datenquellen mit Textgenerierung.                |\n","| 4   | Chain-of-Thought Prompting     | ★★★★☆        | sehr gering          | Komplexe Reasoning-Aufgaben          | Anleitung des Modells, Denkschritte explizit zu formulieren für bessere Problemlösung.          |\n","| 5   | API Parameter Tuning           | ★★★★☆        | sehr gering          | Optimierung von Output-Qualität      | Anpassung von Temperature, Top-p, Max-Tokens etc. zur Steuerung der Ausgabecharakteristik.      |\n","| 6   | Function Calling / Tool Use    | ★★★★☆        | gering               | Integration ext. Services/Daten      | Ermöglicht dem Modell, strukturierte externe Funktionen und APIs aufzurufen.                    |\n","| 7   | Adapter-Tuning / LoRA          | ★★★★☆        | mittel – hoch        | Effiziente Modellanpassung           | Trainiert nur kleine Adapterschichten statt des gesamten Modells für spezifische Aufgaben.      |\n","| 8   | LangChain / LCEL Pipelines     | ★★★★☆        | mittel               | Komplexe LLM-Anwendungsarchitekturen | Framework zur Orchestrierung komplexer LLM-Workflows und -Ketten.                               |\n","| 9   | Self-Consistency Prompting     | ★★★☆☆        | gering               | Verbesserung der Antwortqualität     | Mehrfache Ausführung derselben Anfrage und Auswahl der konsistentesten Antwort.                 |\n","| 10  | Context Engineering            | ★★★☆☆        | gering – mittel      | Strukturierung komplexer Inputs      | Strategische Anordnung und Strukturierung von Kontextinformationen im Prompt.                   |\n","| 11  | Multimodal Prompting           | ★★★☆☆        | gering               | Text + Bild/Audio/Video Verarbeitung | Verwendung mehrerer Eingabemodaliäten (Text, Bild, Audio) in einem Prompt.                      |\n","| 12  | Fine-Tuning                    | ★★★☆☆        | hoch                 | Spezialisierung auf Domain/Task      | Training des gesamten Modells auf spezifischen Daten für maximale Anpassung.                    |\n","| 13  | Agentic Workflows              | ★★★☆☆        | mittel – hoch        | Autonome, mehrstufige Prozesse       | Aufbau autonomer Systeme, die eigenständig Entscheidungen treffen und Aktionen ausführen.       |\n","| 14  | Instruction Tuning             | ★★☆☆☆        | nicht selbst machbar | Grundlegende Verhaltensanpassung     | Training auf Instruktions-Response-Paaren zur Verbesserung der Befolgung von Anweisungen.       |\n","| 15  | Modell-Ensemble / Routing      | ★★☆☆☆        | mittel – hoch        | Spezial-Anwendungen, Redundanz       | Kombination mehrerer Modelle oder intelligente Weiterleitung an spezialisierte Modelle.         |"],"metadata":{"id":"GkuWcBW_E_DL"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"4\">\n","<b>Legende</b>\n","</font></p>\n","\n","- *Relevanz:* Praktische Wichtigkeit für typische LLM-Projekte (5★ = essentiell, 1★ = Nische)\n","- *Technischer Aufwand*: Implementierungsaufwand und Ressourcenbedarf\n","- *Typische Anwendung*: Haupteinsatzgebiete der jeweiligen Methode\n","- *Erläuterung*: Kurze Beschreibung der Methode und ihres Zwecks\n","\n","<p><font color='black' size=\"4\">\n","<b>Einordnung</b>\n","</font></p>\n","\n","+ *Einstiegsmethoden (★★★★★):* Die ersten drei Verfahren bilden das Fundament jeder KI-Anwendung und sollten zuerst beherrscht werden.\n","\n","+ *Erweiterte Techniken (★★★★☆):* Verfahren 4-8 bieten erhebliche Verbesserungen bei moderatem Aufwand und sind für professionelle Anwendungen essentiell.\n","\n","+ *Spezialisierte Ansätze (★★★☆☆):* Verfahren 9-13 eignen sich für spezifische Use Cases und erweiterte Optimierungen.\n","\n","+ *Nischenlösungen (★★☆☆☆):* Verfahren 14-15 sind für hochspezialisierte Anwendungen oder wenn andere Methoden nicht ausreichen."],"metadata":{"id":"er07A5OtG4-s"}},{"cell_type":"markdown","source":["[Modellsteuerung und -optimierung](https://editor.p5js.org/ralf.bendig.rb/full/um423ggnD)"],"metadata":{"id":"Hx0SlhwPIlYi"}},{"cell_type":"markdown","source":["<p><font color='darkblue' size=\"4\">\n","ℹ️ <b>Information</b>\n","</font></p>\n","\n","Nachfolgend werden in einem ersten Schritt 4 Methoden näher betrachtet."],"metadata":{"id":"bL0TJjVlGY6x"}},{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/Modellansteuerung.png)\n","\n","\n"],"metadata":{"id":"4Q2x4Ua6EI9l"}},{"cell_type":"markdown","source":["# 2 | Prompt Engineering\n","---"],"metadata":{"id":"owVDrCRD5hoI"}},{"cell_type":"markdown","source":["Prompting ist die einfachste und direkteste Methode zur Steuerung von LLMs. Dabei wird dem Modell eine Textaufforderung, der sogenannte `Prompt`, gegeben, der die gewünschte Ausgabe beschreibt. Die Qualität der Ausgabe hängt stark von der Qualität des Prompts ab. Ein gut formulierter Prompt sollte klar, prägnant und spezifisch sein.\n"],"metadata":{"id":"o7lp262M4u0Z"}},{"cell_type":"markdown","source":["[Say What You See](https://artsandculture.google.com/experiment/say-what-you-see/jwG3m7wQShZngw)"],"metadata":{"id":"pehjX4of6Vht"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Prompt-Elemente\n","</font></p>"],"metadata":{"id":"DlkRGwcR3rBp"}},{"cell_type":"markdown","source":["Eingabeaufforderungen bestehen in der Regel aus vier wesentlichen Elementen, die je nach Aufgabe variieren können. Die Hauptbestandteile sind:\n","\n","* **Anweisungen** – Definieren die Aufgabe des Modells, entweder als Aufgabenbeschreibung oder als konkrete Handlungsanweisung.  \n","* **Kontext** – Liefert ergänzende Informationen, um das Modell bei der Bearbeitung zu unterstützen.  \n","* **Eingabedaten** – Enthalten die spezifischen Informationen, zu denen eine Antwort generiert werden soll.  \n","* **Ausgabeindikator** – Signalisiert den Übergang zur erwarteten Modellantwort.  \n","\n","Weitere Beispiele zur Anwendung dieser Struktur folgen später."],"metadata":{"id":"nUJCfQ_-71Ti"}},{"cell_type":"markdown","source":["Nachfolgend ein Beispiel für eine Eingabeaufforderung zur Erstellung einer Produktzusammenfassung.\n","\n","```\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage für Körpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung mühelos. Die Funktionen zur Essensplanung und Kalorienzählung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Außerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\n","\n","Zusammenfassung: ...\n","```\n","\n","Diese Eingabeaufforderung erzeugt möglicherweise die folgende Ausgabe:\n","\n","```\n","Die intelligente digitale Personenwaage wird für ihre schnelle Einrichtung, die einfache\n","Synchronisierung mit ihrer App auf älteren Telefonen zur mühelosen Nachverfolgung, die\n","benutzerfreundlichen Funktionen zur Essensplanung und Kalorienzählung sowie ihr schlankes, modernes\n","Design hoch gelobt.\n","```"],"metadata":{"id":"rj5-ap_p4Htg"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Code-Beispiel\n","</font></p>"],"metadata":{"id":"yD8yi1td35er"}},{"cell_type":"code","source":["from openai import OpenAI, chat\n","\n","client = OpenAI()\n","\n","user_input = \"\"\"\n","Fassen Sie die folgende Produktbewertung in einem Satz zusammen:\n","Produkt: Intelligente digitale Personenwaage für Körpergewicht, Fett, BMI, Muskelmassezusammensetzung\n","Produktbewertung: Diese Waage ist fantastisch! Der Einrichtungsvorgang war schnell und einfach und\n","dauerte nur wenige Minuten. Ich konnte die App kostenlos auf mein etwas veraltetes iPhone 8\n","herunterladen. Die Funktion, bei der Ihr Gewicht sofort mit der App synchronisiert wird, macht die\n","Nachverfolgung mühelos. Die Funktionen zur Essensplanung und Kalorienzählung der App sind unglaublich\n","benutzerfreundlich. Ich bin absolut begeistert! Außerdem hat die Waage ein elegantes, modernes\n","Erscheinungsbild, das wirklich attraktiv ist.\n","\"\"\"\n","\n","completion = chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent.\"},\n","    {\"role\": \"user\", \"content\": user_input}\n","  ]\n",")\n","\n","mprint('## 🤖 KI:')\n","mprint(completion.choices[0].message.content)"],"metadata":{"id":"HEx8kcdlOKl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | Context Engineering\n","---"],"metadata":{"id":"76cAlIjdQgGe"}},{"cell_type":"markdown","source":["**Context Engineering** erweitert das klassische Prompting, indem nicht nur eine einzelne Eingabe formuliert wird, sondern der *gesamte Kontext* der Kommunikation mit dem Modell bewusst gestaltet wird.\n","\n","**Ziel:**\n","Durch präzise Steuerung von Systemnachricht, Rollen, Beispiel-Dialogen, Formatvorgaben oder eingebetteten Informationen kann das Modell *konsistenter*, *zielgerichteter* und *nachvollziehbarer* antworten.\n","\n","\n","\n","**Typische Elemente des Kontext-Engineerings:**\n","\n","| Element            | Beschreibung                                                                 |\n","|--------------------|------------------------------------------------------------------------------|\n","| **Systemrolle**     | Definiert die grundsätzliche Identität oder Aufgabe des Modells             |\n","| **Beispiel-Prompts**| Demonstrieren erwartete Eingabe-/Ausgabeformate                             |\n","| **Formatvorgaben**  | Regeln zur Antwortstruktur (z. B. JSON, Bullet-Points, Markdown etc.)       |\n","| **Dynamische Daten**| Integration von Nutzerprofil, Session-Kontext, Wissensdatenbanken etc.     |\n","\n","\n","\n","**Unterschied zu klassischem Prompting**\n","\n","| Klassisches Prompting                | Context Engineering                                       |\n","|-------------------------------------|-----------------------------------------------------------|\n","| „Antworte als Medizinexperte.“     | Strukturierter Kontext: Rolle, Regeln, Beispiele, Daten   |\n","| Einzeiliger Prompt                  | Mehrteiliger, kontextreicher Input                        |\n","| Manuell formuliert                  | Automatisiert, modular, oft per Tool gesteuert            |\n","\n","---\n","\n","**Beispiel (mit System- und Nutzerrolle):**\n","\n","```json\n","[\n","  {\"role\": \"system\", \"content\": \"Du bist ein rechtssicherer KI-Assistent für Medizinrecht. Antworte immer in vollständigen Sätzen mit Quellenangabe.\"},\n","  {\"role\": \"user\", \"content\": \"Welche Aufbewahrungsfrist gilt für Röntgenbilder in Deutschland?\"}\n","]\n"],"metadata":{"id":"EM9JJE6ZQnfX"}},{"cell_type":"markdown","source":["# 4 | Retrieval-Augmented Generation\n","---"],"metadata":{"id":"L0grUpA56y3K"}},{"cell_type":"markdown","source":["RAG (Retrieval-Augmented Generation) ist eine **hybride Methode**, die die Stärken von **LLMs** mit denen von **Information-Retrieval-Systemen** **kombiniert**. Dabei greift das LLM auf llm-externe Wissensdatenbanken zu, um seine Antworten zu verbessern und die Probleme von Halluzinationen und veralteten Informationen zu mindern.\n","\n","**Funktionsweise:**\n","\n","+ Der Benutzer gibt eine Anfrage in das RAG-System ein.\n","+ Das System sucht in externe Wissens nach relevanten Informationen.\n","+ Die relevanten Informationen werden dem LLM als Kontext bereitgestellt.\n","+ Das LLM generiert eine Antwort basierend auf der Anfrage **und** dem Kontext.\n","\n","\n","**Einsatzszenarien:**\n","\n","RAG eignet sich besonders für Aufgaben, die aktuelle oder domänenspezifische Informationen erfordern, wie z. B.:\n","\n","+ Kundensupport mit Zugriff auf Produktdatenbanken\n","+ Medizinische Diagnose mit Zugriff auf aktuelle Forschungsergebnisse\n","+ Finanzplanung mit Zugriff auf Marktdaten\n","+ Beantwortung von Fragen zu Unternehmensinformationen\n","\n"],"metadata":{"id":"EbmfDWKg4xmC"}},{"cell_type":"markdown","source":["# 5 | Fine-Tuning\n","---"],"metadata":{"id":"iQpWHr88612f"}},{"cell_type":"markdown","source":["Fine-Tuning ist eine Methode, bei der ein bereits **trainiertes LLM** auf einer kleineren, **aufgabenspezifischen** Datenmenge weiter trainiert wird. Dadurch kann das Modell an **spezifische** **Anforderungen** angepasst und seine Leistung für diese Aufgaben verbessert werden.\n","\n","**Funktionsweise:**\n","\n","+ Ein vortrainiertes LLM wird ausgewählt.\n","+ Eine aufgabenspezifische Datenmenge wird vorbereitet.\n","+ Das LLM wird auf dieser Datenmenge trainiert.\n","+ Die Parameter des LLM werden angepasst, um die Leistung für die spezifische Aufgabe zu optimieren.\n","\n","\n","**Einsatzszenarien:**\n","\n","Fine-Tuning eignet sich besonders für Aufgaben, die eine hohe Genauigkeit und **Domänenspezialisierung** erfordern, wie z. B.:\n","\n","+ fachlich spezialisierte LLMs (Recht, Medizin, ...)\n","+ Sentimentanalyse\n","+ Textklassifizierung\n","+ Spam-Erkennung\n","+ Personalisierte Kundeninteraktionen\n","\n"],"metadata":{"id":"WEyWOZtP40s0"}},{"cell_type":"markdown","source":["\n","# 6 | Entscheidungskriterien\n","---"],"metadata":{"id":"EU_aZQuK5kfc"}},{"cell_type":"markdown","source":["Die Wahl der geeigneten Methode hängt von verschiedenen Faktoren ab, darunter:"],"metadata":{"id":"w4I1UPS97apC"}},{"cell_type":"markdown","source":["[Modellsteuerung Decision Matrix](https://editor.p5js.org/ralf.bendig.rb/full/xb3zPgRSr)"],"metadata":{"id":"U4MA8tmKM3Wp"}},{"cell_type":"markdown","source":["\n","| Kriterium               | Prompt Engineering | Context Engineering | RAG | Fine-Tuning |\n","|-------------------------|-----------|---------------------|-----|-------------|\n","| **Komplexität**         | Niedrig<br><br>Die Implementierung ist <br>einfach und erfordert keine <br>Änderungen am Modell. | Mittel<br><br>Benötigt durchdachte<br>Strukturierung des Kontexts<br>und ggf. Framework-Einsatz. | Mittel<br><br>RAG erfordert die Integration<br>von Retrieval-Mechanismen<br>und einer Wissensdatenbank. | Hoch<br><br>Fine-Tuning beinhaltet<br>einen komplexeren Prozess<br>des weiteren Trainings. |\n","| **Effizienz**           | Hoch<br><br>Prompting ermöglicht eine<br>schnelle und flexible<br>Interaktion mit dem Modell. | Hoch<br><br>Effizient bei wiederverwendbaren<br>Kontextbausteinen und Rollenstrukturen. | Mittel<br><br>RAG benötigt zusätzliche<br>Schritte für den Datenabruf,<br>was die Effizienz mindert. | Niedrig<br><br>Fine-Tuning ist rechen-<br>intensiv und zeitaufwendig. |\n","| **Genauigkeit**         | Niedrig<br><br>Die Genauigkeit hängt stark<br>von der Qualität des<br>Prompts ab. | Mittel<br><br>Höhere Genauigkeit durch<br>strukturierte Kontexte und<br>Beispiele. | Mittel<br><br>RAG bietet höhere<br>Genauigkeit durch externe<br>Informationen. | Hoch<br><br>Führt zu höherer<br>Genauigkeit bei<br>spezifischen Aufgaben. |\n","| **Flexibilität**        | Hoch<br><br>Sehr flexibel und für<br>verschiedene Aufgaben<br>einsetzbar. | Hoch<br><br>Erlaubt modulare, kontext-<br>abhängige Anpassung<br>ohne Modelländerung. | Mittel<br><br>Flexibler als Fine-Tuning,<br>aber weniger flexibel als<br>Prompting. | Niedrig<br><br>Ist auf bestimmte Aufgaben<br>spezialisiert und weniger<br>anpassungsfähig. |\n","| **Ressourcen-<br>bedarf** | Niedrig<br><br>Benötigt nur minimale<br>Ressourcen für die<br>Ausführung. | Niedrig–Mittel<br><br>Abhängig von der<br>Komplexität der Kontextsteuerung. | Mittel<br><br>Ressourcen für Datenbank-<br>verwaltung und Retrieval<br>erforderlich. | Hoch<br><br>Erfordert erhebliche<br>Rechenleistung und Zeit<br>für Training. |\n","| **Datenbedarf**         | Niedrig<br><br>Keine zusätzlichen<br>Trainingsdaten<br>erforderlich. | Niedrig<br><br>Evtl. strukturierte<br>Beispiele oder Metadaten. | Mittel<br><br>Benötigt Wissensdatenbank<br>mit relevanten<br>Informationen. | Hoch<br><br>Benötigt große Mengen an<br>spezifischen<br>Trainingsdaten. |\n","| **Beschreibung**        | Einfache Methode mit<br>Textanweisungen für das<br>Modell. | Strukturierte Gestaltung<br>von Rollen, Kontext, Beispielen<br>und Regeln für bessere<br>Steuerbarkeit. | Kombination von LLMs mit<br>Information-Retrieval-<br>Systemen. | Weiteres Training des<br>Modells auf spezifischen<br>Datensätzen. |\n","\n","\n"],"metadata":{"id":"rSAuP0cW54O1"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1736181733357}],"collapsed_sections":["PHDCKRbtgVXy","owVDrCRD5hoI","76cAlIjdQgGe","L0grUpA56y3K","iQpWHr88612f","EU_aZQuK5kfc"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}