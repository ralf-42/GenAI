{"cells":[{"cell_type":"markdown","source":["![My Image](https://raw.githubusercontent.com/ralf-42/Image/main/genai-banner-2.jpg)\n"],"metadata":{"id":"3Z_8TJ438njS"}},{"cell_type":"markdown","source":["\n","<p><font size=\"5\" color='grey'> <b>\n","MCP - Model Context Protocol\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"Bd34bGADLRaV"}},{"cell_type":"code","source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\n","\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages, mermaid\n","from genai_lib.mcp_modul import (\n","    handle_mcp_request, connect_to_server, initialize_server_connection,\n","    discover_server_tools, call_server_tool, setup_assistant_mcp_connection,\n","    process_user_query, get_assistant_status, get_server_info, get_available_tools\n",")\n","import json # Wird f√ºr die manuelle JSON-Verarbeitung in Schritt 7 ben√∂tigt\n","\n","setup_api_keys(['OPENAI_API_KEY'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"],"outputs":[],"execution_count":null,"metadata":{"id":"JlZ3lw_d8njW","collapsed":true}},{"cell_type":"markdown","source":["\n","# 1 | Intro\n","\n","-----"],"metadata":{"id":"F40ApzrO9jrA"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Was ist MCP?\n","</font></p>"],"metadata":{"id":"sc-rB6s0FoOJ"}},{"cell_type":"markdown","source":["\n","\n","Das Model Context Protocol (MCP) ist ein **offenes Protokoll**, das die Kommunikation zwischen Large Language Models (LLMs) und externen Datenquellen bzw. Tools **standardisiert**. Hier sind die drei Hauptkomponenten und ihre Interaktionen:\n","\n","1.  LLM (Large Language Model)\n","\n","    Das eigentliche KI-Modell (z.B. gpt-4o-mini oder Claude)\n","    Verarbeitet Anfragen und generiert Antworten\n","    Entscheidet, wann externe Ressourcen ben√∂tigt werden\n","\n","2.  MCP Client\n","\n","    L√§uft in der Host-Anwendung (z.B. Claude Desktop, IDEs)\n","    Verbindet das LLM mit MCP-Servern\n","    Verwaltet mehrere Server-Verbindungen gleichzeitig\n","    √úbersetzt zwischen LLM-Anfragen und MCP-Protokoll\n","\n","3.  MCP Server\n","\n","    Stellt spezifische Funktionalit√§ten bereit\n","    Kann verschiedene Ressourcen anbieten:\n","\n","    Resources: Strukturierte Daten (Dateien, Datenbanken)\n","    Prompts: Vordefinierte Prompt-Templates\n","    Tools: Ausf√ºhrbare Funktionen\n","\n","**Wichtige Ressourcen:**\n","\n","[Anthropic MCP](https://www.anthropic.com/news/model-context-protocol)\n","\n","[OpenAI MCP](https://openai.github.io/openai-agents-python/mcp/)\n","\n","[MCPServer](https://github.com/modelcontextprotocol/servers)\n","\n"],"metadata":{"id":"E5XKamwWF4SF"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Warum wurde MCP entwickelt?\n","</font></p>"],"metadata":{"id":"z4uQqwhwF64Q"}},{"cell_type":"markdown","source":["Die Notwendigkeit von MCP ergibt sich aus den Herausforderungen aktueller **KI-API-Interaktionen**. Derzeit ist der Aufbau von KI-Agenten, die Daten aus verschiedenen Quellen abrufen, **fragmentiert, repetitiv und schwer zu skalieren**. Jedes Tool spricht seine eigene Sprache und erfordert **individuelle Integrationen**. MCP zielt darauf ab, diese Komplexit√§t zu reduzieren und den **Entwicklungsaufwand zu minimieren**.\n"],"metadata":{"id":"7FuCLPs_F_2I"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","MCP-Architektur\n","</font></p>\n"],"metadata":{"id":"_Niyym8NGJRZ"}},{"cell_type":"markdown","source":["\n","\n","MCP verwendet eine Client-Server-Architektur mit den Komponenten:\n","\n","1.  **LLM (Large Language Model)**\n","\n","    + Das eigentliche KI-Modell (z.B. gpt-4o-mini oder Claude)\n","    + Verarbeitet Anfragen und generiert Antworten\n","    + Signalisiert im generierten Output, wenn externe Ressourcen ben√∂tigt werden\n","\n","2.  **MCP Client**\n","\n","    + L√§uft zusammen mit dem LLM in der **Host-Anwendung** (z.B. Claude Desktop, IDEs)\n","    + Verbindet das LLM mit MCP-Servern\n","    + Verwaltet mehrere Server-Verbindungen gleichzeitig\n","    + √úbersetzt zwischen LLM-Anfragen und MCP-Protokoll\n","\n","    **Hinweis:** LLM und Client bilden gemeinsam die Host-Anwendung.\n","\n","3.  **MCP Server**\n","\n","    + Stellt spezifische Funktionalit√§ten bereit\n","    + Kann verschiedene Ressourcen anbieten:\n","\n","        - **Resources**: Strukturierte Daten (Dateien, Datenbanken)\n","        - **Prompts**: Vordefinierte Prompt-Templates\n","        - **Tools**: Ausf√ºhrbare Funktionen\n"],"metadata":{"id":"_RIBdr5OGIBg"}},{"cell_type":"markdown","source":["\n","**Kommunikationsfluss:**"],"metadata":{"id":"XgHOHjIrGNSD"}},{"cell_type":"markdown","source":["AI-Assistent ‚Üí MCP-Client ‚Üí MCP-Server ‚Üí Externe Ressource\n","                    ‚Üì            ‚Üì            ‚Üì\n","    Antwort    ‚Üê  JSON/HTTP  ‚Üê  Daten-API  ‚Üê  Raw Data\n"],"metadata":{"id":"kZdi3vDu8njY"}},{"cell_type":"markdown","source":["\n","<p><font color='black' size=\"5\">\n","Praktische Implementierung\n","</font></p>"],"metadata":{"id":"grDzt41g9JdW"}},{"cell_type":"markdown","source":["\n","\n","Die Implementierung von MCP erfolgt schrittweise:\n","\n","**1. Server-Konfiguration**\n","\n","  - Definition der verf√ºgbaren Ressourcen\n","  - Sicherheitsrichtlinien festlegen\n","  - Authentifizierung konfigurieren\n","\n","**2. Client-Integration**\n","\n","  - Verbindung zum MCP-Server herstellen\n","  - Verf√ºgbare Tools und Datenquellen erkunden\n","  - Anfragen formulieren und Antworten verarbeiten\n","\n","**3. Testing und Deployment**\n","\n","  - Funktionalit√§tstests durchf√ºhren\n","  - Performance optimieren\n","  - Produktionsumgebung einrichten\n"],"metadata":{"id":"kpYJDkxV9Kkz"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","MCP vs. andere Ans√§tze\n","</font></p>\n","\n","**MCP vs. Function Calling - Der entscheidende Unterschied:**\n","\n","Der Hauptunterschied liegt in der **Architektur und Standardisierung**:\n","\n","**Function Calling (z.B. OpenAI):**"],"metadata":{"id":"psDRI1XAGPZv"}},{"cell_type":"markdown","source":["```python\n","# Direkte Integration im AI-System\n","tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"read_file\",\n","            \"description\": \"Reads a file\",\n","            \"parameters\": {\"type\": \"object\", \"properties\": {...}}\n","        }\n","    }\n","]\n","response = openai.chat.completions.create(model=\"gpt-4\", tools=tools)\n","```"],"metadata":{"id":"BcOd-cL18njZ"}},{"cell_type":"markdown","source":["**MCP (Model Context Protocol):**"],"metadata":{"id":"l-gXpMB28njZ"}},{"cell_type":"markdown","source":["```python\n","# Standardisierte Server-Client-Architektur\n","request = {\n","    \"jsonrpc\": \"2.0\",\n","    \"method\": \"tools/call\",\n","    \"params\": {\"name\": \"read_file\", \"arguments\": {...}}\n","}\n","response = await handle_mcp_request(request)\n","```"],"metadata":{"id":"szm8LIa08nja"}},{"cell_type":"markdown","source":["**Detaillierter Vergleich:**\n","\n","| Aspekt | MCP | Function Calling | RAG | Custom APIs |\n","|--------|-----|------------------|-----|-------------|\n","| **Architektur** | Client-Server | Direkt integriert | Pipeline-basiert | Individuell |\n","| **Standardisierung** | ‚úÖ Offenes Protokoll | ‚ùå Modell-spezifisch | ‚ùå Framework-abh√§ngig | ‚ùå Individuell |\n","| **Wiederverwendbarkeit** | ‚úÖ Server f√ºr alle AIs | ‚ùå Pro AI-System | ‚ö†Ô∏è Begrenzt | ‚ùì Variabel |\n","| **Setup-Aufwand** | üü° Moderat | üü¢ Niedrig | üü° Moderat | üî¥ Hoch |\n","| **Enterprise-Ready** | ‚úÖ Vollst√§ndig | ‚ö†Ô∏è Begrenzt | üü° Teilweise | ‚ùì Variabel |\n","| **Sicherheit** | ‚úÖ Integrierte Kontrollen | ‚ö†Ô∏è Basic | ‚ö†Ô∏è Dokumenten-basiert | ‚ùì Variabel |\n","| **Bidirektional** | ‚úÖ Lesen & Schreiben | ‚úÖ Ja | ‚ùå Nur Lesen | ‚úÖ Ja |\n","| **Echtzeit** | ‚úÖ Live-Daten | ‚úÖ Ja | ‚ùå Statische Docs | ‚úÖ Ja |\n","| **Skalierung** | ‚úÖ Einfach | üî¥ Schwierig | üü° Moderat | ‚ùì Variabel |\n","\n","**Praktische Entscheidungshilfe:**\n","\n","**Function Calling verwenden f√ºr:**\n","\n","  - ‚úÖ Prototyping und schnelle Tests\n","  - ‚úÖ Einfache, direkte Tool-Integration\n","  - ‚úÖ Ein AI-System mit wenigen Tools\n","  - ‚úÖ Schneller Entwicklungsstart\n","\n","**MCP verwenden f√ºr:**\n","\n","  - ‚úÖ Enterprise-Anwendungen\n","  - ‚úÖ Mehrere AI-Systeme mit geteilten Tools\n","  - ‚úÖ Sicherheitskritische Umgebungen\n","  - ‚úÖ Langfristige, skalierbare Architekturen\n","  - ‚úÖ Cross-Platform-Kompatibilit√§t\n","\n","**Fazit:** Function Calling ist der einfacherer Einstieg, MCP ist die zukunftssichere Enterprise-L√∂sung."],"metadata":{"id":"LR0f9rEn8njb"}},{"cell_type":"markdown","source":["# 2 | Modul `mcp`\n","---"],"metadata":{"id":"8RZw4su6Gxe3"}},{"cell_type":"markdown","source":["Das `mcp_modul.py` bietet eine **funktionale All-in-One-L√∂sung** zur Demonstration der MCP-Architektur mit klarer Rollentrennung zwischen **LLM**, **Client** und **Server**.\n","\n","<p><font color='black' size=\"5\">\n","Kommunikationsfluss\n","</font></p>\n","\n","```\n","Benutzer\n","   ‚Üì\n","LLM (versteht Anfrage, entscheidet: \"Ich brauche list_files\")\n","   ‚Üì\n","LLM (parsed eigenen Tool-Intent aus generiertem Text)\n","   ‚Üì\n","Client (√ºbersetzt in MCP-Request, sendet an Server)\n","   ‚Üì\n","Server (f√ºhrt list_files aus)\n","   ‚Üì\n","Client (empf√§ngt Ergebnis)\n","   ‚Üì\n","LLM (synthetisiert Antwort aus Ergebnis)\n","   ‚Üì\n","Benutzer\n","```\n"],"metadata":{"id":"ej3MD2pqG0_q"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kernfunktionen nach Rolle\n","</font></p>"],"metadata":{"id":"4HZXVT-AG-Xt"}},{"cell_type":"markdown","source":["[MCP Simulation](https://editor.p5js.org/ralf.bendig.rb/full/CkYSKZe8t)"],"metadata":{"id":"7l43eZDxKRKb"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","8 Schritte der MCP-Simulation\n","</font></p>"],"metadata":{"id":"u591CZJvHGJQ"}},{"cell_type":"markdown","source":["\n","\n","Die MCP-Demo zeigt den vollst√§ndigen Workflow in 8 Schritten:\n","\n","**Schritte 1-5: Verbindungsaufbau (Setup-Phase)**\n","\n","1. **Client ‚Üí Server**: Verbindung herstellen (`connect_to_server`)\n","2. **Client ‚Üí Server**: INIT-Request senden (`initialize_server_connection`)\n","3. **Server ‚Üí Client**: INIT-Response mit Server-Info\n","4. **Client ‚Üí Server**: TOOLS/LIST-Request senden (`discover_server_tools`)\n","5. **Server ‚Üí Client**: TOOLS/LIST-Response mit verf√ºgbaren Tools\n","\n","**Schritte 6-8: Task-Ausf√ºhrung (Query-Phase)**\n","\n","6. **LLM ‚Üí Client ‚Üí Server**: LLM analysiert Query, Client sendet TOOLS/CALL-Request (`call_server_tool`)\n","7. **Server ‚Üí Client**: TOOLS/CALL-Response mit Tool-Ergebnis (JSON-Payload)\n","8. **LLM**: LLM synthetisiert finale nat√ºrlichsprachliche Antwort aus Tool-Ergebnis\n","\n"],"metadata":{"id":"aKADLX2QK-Za"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kernfunktionen nach Schritten\n","</font></p>"],"metadata":{"id":"fiszisPhK1zi"}},{"cell_type":"markdown","source":["\n","\n","**Setup-Phase (Schritte 1-5):**\n","\n","  - `connect_to_server()`: Schritt 1 - Logische Verbindung herstellen\n","  - `initialize_server_connection()`: Schritte 2-3 - Server initialisieren\n","  - `discover_server_tools()`: Schritte 4-5 - Verf√ºgbare Tools entdecken\n","  - `setup_assistant_mcp_connection()`: Wrapper f√ºr vollst√§ndigen Setup\n","\n","**Query-Phase (Schritte 6-8):**\n","\n","  - `call_server_tool()`: Schritt 6 - Tool-Call Request senden\n","  - `handle_mcp_request()`: Schritt 7 - Server verarbeitet Request und sendet Response\n","  - LLM-Synthese: Schritt 8 - Finale Antwort generieren (in Code manuell implementiert)\n","\n","**Server-Komponenten:**\n","\n","  - `handle_mcp_request()`: Verarbeitet alle MCP-Requests (JSON-RPC 2.0)\n","  - `register_new_tool()`: Dynamische Tool-Registrierung zur Laufzeit\n","  - **Tools**: `read_file_tool`, `write_file_tool`, `list_files_tool`, `get_system_info_tool`"],"metadata":{"id":"Jy2haKLaLDtB"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Kommunikationskonvention\n","</font></p>"],"metadata":{"id":"pqLB3L8xHNb_"}},{"cell_type":"markdown","source":["**Tool-Intent-Syntax**\n","\n","Das LLM signalisiert seine Tool-Absichten durch eine spezielle Syntax im generierten Text:\n","\n","```\n","[MCP_CALL: <tool_name>({<arguments_json>})] [/MCP_CALL]\n","```\n","\n","**Beispiel:**\n","\n","```\n","[MCP_CALL: read_file({\"path\": \"/projekt/data.txt\"})] [/MCP_CALL]\n","```\n","\n","Diese Syntax wird von der LLM-Komponente selbst erkannt und dann √ºber den Client in MCP-konforme JSON-RPC 2.0 Requests √ºbersetzt.\n","\n","**JSON-RPC Protokoll**\n","\n","**JSON-RPC** (JSON Remote Procedure Call) ist ein leichtgewichtiges Protokoll f√ºr entfernte Funktionsaufrufe. Es erm√∂glicht dem Client, Tools auf dem Server aufzurufen, als w√§ren sie lokale Funktionen.\n","\n","**Beispiel eines JSON-RPC Requests:**\n","\n","```json\n","{\n","  \"jsonrpc\": \"2.0\",\n","  \"method\": \"tools/call\",\n","  \"params\": {\n","    \"name\": \"read_file\",\n","    \"arguments\": {\"path\": \"/projekt/data.txt\"}\n","  },\n","  \"id\": 1\n","}\n","```\n","\n","JSON-RPC nutzt JSON f√ºr strukturierte Nachrichten und definiert klare Regeln f√ºr Requests, Responses und Fehlerbehandlung √ºber Netzwerk- oder Prozessgrenzen hinweg.\n"],"metadata":{"id":"4Psvk8LDHTOv"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","\n","Funktionsumfang   `mcp.py`  \n","\n","</font></p>"],"metadata":{"id":"02tHSrd3HYSO"}},{"cell_type":"markdown","source":["\n","\n","Das mcp\\_modul.py ist eine funktionale Demonstration der MCP-Architektur, die echte und simulierte Elemente kombiniert:\n","\n","| Komponente | Demo-Implementierung | Production-System |\n","|------------|---------------------|-------------------|\n","| **Tool-Ausf√ºhrung** | ‚úÖ Real (echte Datei-Ops) | ‚úÖ Real |\n","| **LLM-Calls** | ‚úÖ Real (OpenAI API) | ‚úÖ Real |\n","| **JSON-RPC Format** | ‚úÖ Real (Standard-konform) | ‚úÖ Real |\n","| **Netzwerk-Transport** | ‚ùå Simuliert (In-Memory) | ‚úÖ Real (stdio/TCP) |\n","| **Prozess-Trennung** | ‚ùå Simuliert (ein Prozess) | ‚úÖ Real (separate Prozesse) |\n","| **Connection Setup** | ‚ùå Simuliert (Dictionary) | ‚úÖ Real (Prozess-Management) |\n","| **Async I/O** | ‚úÖ Real (asyncio) | ‚úÖ Real |\n","\n","Die Demo ist ideal f√ºr:\n","\n","‚úÖ Lernen: Verstehen der MCP-Konzepte ohne Komplexit√§t von Prozess-Management    \n","‚úÖ Prototyping: Schnelles Testen von Tool-Implementierungen    \n","‚úÖ Testing: Einfaches Unit-Testing ohne Setup von separaten Prozessen    \n"],"metadata":{"id":"iWyZYe9fHeVj"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","MCP-Modul importieren\n","</font></p>"],"metadata":{"id":"WLpFhwVnHp65"}},{"cell_type":"code","source":["from genai_lib.mcp_modul import (\n","    # Server-Funktionen\n","    handle_mcp_request,\n","    get_server_info,\n","    register_new_tool,\n","\n","    # Client-Funktionen\n","    setup_full_connection,\n","    call_server_tool,\n","    get_available_tools,\n","    get_client_status,\n","\n","    # Assistant-Funktionen\n","    setup_assistant_mcp_connection,\n","    process_user_query,\n","    get_assistant_status,\n","\n","    # Modul-Info\n","    get_module_info,\n","    connect_to_server # Explizit f√ºr Schritt 1 der Simulation\n",")"],"outputs":[],"execution_count":null,"metadata":{"id":"rglqDqcR8njd"}},{"cell_type":"markdown","source":["# 3 | MCP-Server erstellen\n","\n","-----\n","\n","Ein MCP-Server stellt die Verbindung zwischen AI-Assistenten und externen Ressourcen her. Wir erstellen einen funktionalen Server, der Datei-Operationen und Systemdaten bereitstellt."],"metadata":{"id":"ejQTaApP8nje"}},{"cell_type":"code","source":["#@title üîß Server-Status pr√ºfen  { display-mode: \"form\" }\n","\n","# Test des MCP-Servers (vereinfacht mit Modul)\n","async def test_mcp_server():\n","    \"\"\"Testet die grundlegenden Server-Funktionen\"\"\"\n","\n","    mprint(\"### üß™ MCP-Server Statusanfrage ...\\n\")\n","    mprint(\"---\")\n","\n","    # 1. Server-Info\n","    print(\"1Ô∏è‚É£ Server-Informationen:\")\n","    info = get_server_info()\n","    print(f\"   Name: {info['name']}\")\n","    print(f\"   Version: {info['version']}\")\n","    print(f\"   Tools: {', '.join(info['available_tools'])}\\n\")\n","\n","    # 2. Tools auflisten\n","    tools_request = {\n","        \"jsonrpc\": \"2.0\",\n","        \"id\": \"tools-1\",\n","        \"method\": \"tools/list\"\n","    }\n","\n","    response = await handle_mcp_request(tools_request)\n","    print(\"2Ô∏è‚É£ Tool-Liste:\")\n","    for tool in response['result']['tools']:\n","        print(f\"   ‚Ä¢ {tool['name']}: {tool['description']}\")\n","    print()\n","\n","    # 3. Systeminformationen abrufen\n","    sysinfo_request = {\n","        \"jsonrpc\": \"2.0\",\n","        \"id\": \"call-1\",\n","        \"method\": \"tools/call\",\n","        \"params\": {\n","            \"name\": \"get_system_info\",\n","            \"arguments\": {}\n","        }\n","    }\n","\n","    response = await handle_mcp_request(sysinfo_request)\n","    result = json.loads(response[\"result\"][\"content\"][0][\"text\"])\n","    print(\"3Ô∏è‚É£ Systeminformationen:\")\n","    print(f\"   System: {result['system']}\")\n","    print(f\"   Python: {result['python_version']}\\n\")\n","\n","    print(\"‚úÖ MCP-Server erfolgreich angefragt!\")\n","\n","# Tests ausf√ºhren\n","await test_mcp_server()"],"outputs":[],"execution_count":null,"metadata":{"id":"BC49Ntui8njf"}},{"cell_type":"markdown","source":["# 4 | MCP-Demo\n","\n","-----"],"metadata":{"id":"shabydbk8njg"}},{"cell_type":"code","source":["#@title ü§ñ AI-Assistant mit MCP-Server verbinden (SCHRITTE 1-5 der Simulation) { display-mode: \"form\" }\n","\n","SERVER_NAME = \"file-server\"\n","server_handler = handle_mcp_request\n","\n","mprint(\"### üõ†Ô∏è Simuliertes MCP-Setup (Schritte 1-5)\")\n","mprint(\"------------------------------------------\")\n","\n","# 1. SCHRITT 1: Verbindung herstellen\n","print(\"1Ô∏è‚É£ SCHRITT 1: Client versucht, Verbindung herzustellen...\")\n","connect_to_server(SERVER_NAME, server_handler)\n","print(\"‚úÖ Client ist logisch VERBUNDEN.\")\n","\n","\n","# 2. SCHRITT 2 & 3: Initialisierung (Request & Response)\n","mprint(\"\\n2Ô∏è‚É£ & 3Ô∏è‚É£ SCHRITT 2/3: Initialisierung (INIT-Request & Response):\")\n","# initialize_server_connection sendet Request (2) und erwartet Response (3)\n","init_response = await initialize_server_connection(SERVER_NAME)\n","print(f\"   INIT-Response erhalten (Schritt 3). Status: {init_response.get('result', {}).get('serverInfo', {}).get('version')}\")\n","\n","\n","# 3. SCHRITT 4 & 5: Tools entdecken (Request & Response)\n","mprint(\"\\n4Ô∏è‚É£ & 5Ô∏è‚É£ SCHRITT 4/5: Tools entdecken (Discovery Request & Response):\")\n","# discover_server_tools sendet Request (4) und erwartet Response (5)\n","tools_list = await discover_server_tools(SERVER_NAME)\n","print(f\"   ‚úÖ {len(tools_list)} Tools entdeckt und registriert (Schritt 5).\")\n","\n","# 4. Assistant mit MCP-Server verbinden (Finaler Setup-Schritt im Assistenten)\n","result = setup_assistant_mcp_connection(SERVER_NAME)\n","mprint(f\"\\nüéØ FINAL: Assistant Setup Ergebnis: {result}\\n\")"],"outputs":[],"execution_count":null,"metadata":{"id":"UWOlb3De8njg"}},{"cell_type":"code","source":["#@title ü§ñ Verbindungsstatus pr√ºfen { display-mode: \"form\" }\n","# Status pr√ºfen\n","mprint(\"### ‚úÖ Verbindungs-Status\")\n","mprint(\"---\")\n","\n","status = get_assistant_status()\n","print(\"ü§ñ Assistant-Konfiguration:\")\n","print(f\"   Name: {status['config']['name']}\")\n","print(f\"   Modell: {status['config']['openai_model']}\")\n","print(f\"   MCP aktiviert: {status['mcp_enabled']}\")\n","print(f\"   Verbundener Server: {status['connected_server']}\")\n","print(f\"   Verf√ºgbare Server: {status['available_servers']}\\n\")\n","\n","print(\"üõ†Ô∏è Verf√ºgbare Tools:\")\n","for server, tool_list in status['available_tools'].items():\n","    print(f\"   Server '{server}':\")\n","    for tool in tool_list:\n","        print(f\"      ‚Ä¢ {tool}\")\n","\n","print(\"\\nüí° Assistant ist bereit f√ºr Anfragen!\")"],"outputs":[],"execution_count":null,"metadata":{"id":"QmzexQl_8njg"}},{"cell_type":"code","source":["#@title ü§ñ Query 1: Was f√ºr ein System l√§uft hier? (Schritte 6-8) { display-mode: \"form\" }\n","\n","# Dieser Code zerlegt den Task-Workflow explizit in die drei finalen Schritte\n","# der MCP-Simulation (6-8), anstatt die Blackbox-Funktion process_user_query zu nutzen.\n","\n","query_1 = \"Was f√ºr ein System l√§uft hier?\"\n","TOOL_NAME = \"get_system_info\" # Das vom LLM gew√§hlte Tool f√ºr die Anfrage\n","TOOL_ARGS = {}\n","\n","mprint(f\"\\n#### Query 1: {query_1}\")\n","print(\"\\nüü¢ START: LLM-Orchestrierung (zerlegt)\")\n","print(\"-\" * 40)\n","\n","# SCHRITT 6: LLM-Analyse und Tool-Call (Request)\n","mprint(f\"6Ô∏è‚É£ SCHRITT 6: LLM sendet TOOLS/CALL-Request f√ºr Tool '{TOOL_NAME}'\")\n","# Die Funktion 'call_server_tool' sendet den Request und wartet auf die Antwort\n","tool_call_response = await call_server_tool(\n","    server_name=SERVER_NAME,\n","    tool_name=TOOL_NAME,\n","    arguments=TOOL_ARGS\n",")\n","\n","# SCHRITT 7: Server-Antwort (Response)\n","mprint(\"\\n7Ô∏è‚É£ SCHRITT 7: Server-Antwort (Tool-Ergebnis) erhalten:\")\n","\n","# Manuelle Extraktion des Tool-Ergebnisses (simuliert die Verarbeitung des Clients)\n","if tool_call_response.get(\"result\"):\n","    result_content = tool_call_response[\"result\"][\"content\"][0][\"text\"]\n","    result_data = json.loads(result_content)\n","    mprint(f\"   Datenbasis f√ºr Synthese: System l√§uft auf {result_data.get('system')} (Payload von Server)\")\n","\n","    # SCHRITT 8: LLM generiert finale Antwort (Synthese)\n","    mprint(\"\\n8Ô∏è‚É£ SCHRITT 8: LLM generiert finale Antwort (Synthese):\")\n","    final_answer = (\n","        f\"Hier l√§uft ein **{result_data.get('system', 'unbekanntes')}** System \"\n","        f\"mit einer Python Version **{result_data.get('python_version', 'unbekannt')}**.\"\n","    )\n","    mprint(f\"ü§ñ {final_answer}\")\n","else:\n","    mprint(\"‚ùå Tool-Ausf√ºhrung fehlgeschlagen. Keine finale Antwort m√∂glich.\")\n","\n","print(\"\\nüî¥ ENDE: Zerlegte Sequenz abgeschlossen.\")"],"outputs":[],"execution_count":null,"metadata":{"id":"9VZYS_xW8njh"}},{"cell_type":"code","source":["#@title ü§ñ Query 2: Erstelle eine Datei 'demo.txt' (Schritte 6-8) { display-mode: \"form\" }\n","\n","# Dieser Code zerlegt den Task-Workflow explizit in die drei finalen Schritte\n","# der MCP-Simulation (6-8), anstatt die Blackbox-Funktion process_user_query zu nutzen.\n","\n","query_2 = \"Erstelle eine Datei 'demo.txt' mit dem Inhalt 'Hello MCP!'\"\n","TOOL_NAME = \"write_file\" # Das vom LLM gew√§hlte Tool f√ºr die Anfrage\n","TOOL_ARGS = {\"filepath\": \"demo.txt\", \"content\": \"Hello MCP!\"}\n","\n","mprint(f\"\\n#### Query 2: {query_2}\")\n","print(\"\\nüü¢ START: LLM-Orchestrierung (zerlegt)\")\n","print(\"-\" * 40)\n","\n","# SCHRITT 6: LLM-Analyse und Tool-Call (Request)\n","mprint(f\"6Ô∏è‚É£ SCHRITT 6: LLM sendet TOOLS/CALL-Request f√ºr Tool '{TOOL_NAME}'\")\n","# Die Funktion 'call_server_tool' sendet den Request und wartet auf die Antwort\n","tool_call_response = await call_server_tool(\n","    server_name=SERVER_NAME,\n","    tool_name=TOOL_NAME,\n","    arguments=TOOL_ARGS\n",")\n","\n","# SCHRITT 7: Server-Antwort (Response)\n","mprint(\"\\n7Ô∏è‚É£ SCHRITT 7: Server-Antwort (Tool-Ergebnis) erhalten:\")\n","\n","# Manuelle Extraktion des Tool-Ergebnisses (simuliert die Verarbeitung des Clients)\n","if tool_call_response.get(\"result\"):\n","    result_content = tool_call_response[\"result\"][\"content\"][0][\"text\"]\n","    result_data = json.loads(result_content)\n","    mprint(f\"   Datenbasis f√ºr Synthese: {result_data.get('message', 'Datei erstellt')} (Payload von Server)\")\n","\n","    # SCHRITT 8: LLM generiert finale Antwort (Synthese)\n","    mprint(\"\\n8Ô∏è‚É£ SCHRITT 8: LLM generiert finale Antwort (Synthese):\")\n","    final_answer = (\n","        f\"Ich habe die Datei **demo.txt** erfolgreich erstellt mit dem Inhalt: **Hello MCP!**\"\n","    )\n","    mprint(f\"ü§ñ {final_answer}\")\n","else:\n","    mprint(\"‚ùå Tool-Ausf√ºhrung fehlgeschlagen. Keine finale Antwort m√∂glich.\")\n","\n","print(\"\\nüî¥ ENDE: Zerlegte Sequenz abgeschlossen.\")"],"outputs":[],"execution_count":null,"metadata":{"id":"HqiPGyVH8njh"}},{"cell_type":"code","source":["#@title ü§ñ Query 3: Welche Dateien sind im aktuellen Verzeichnis? (Schritte 6-8) { display-mode: \"form\" }\n","\n","# Dieser Code zerlegt den Task-Workflow explizit in die drei finalen Schritte\n","# der MCP-Simulation (6-8), anstatt die Blackbox-Funktion process_user_query zu nutzen.\n","\n","query_3 = \"Welche Dateien sind im aktuellen Verzeichnis?\"\n","TOOL_NAME = \"list_files\" # Das vom LLM gew√§hlte Tool f√ºr die Anfrage\n","TOOL_ARGS = {}\n","\n","mprint(f\"\\n#### Query 3: {query_3}\")\n","print(\"\\nüü¢ START: LLM-Orchestrierung (zerlegt)\")\n","print(\"-\" * 40)\n","\n","# SCHRITT 6: LLM-Analyse und Tool-Call (Request)\n","mprint(f\"6Ô∏è‚É£ SCHRITT 6: LLM sendet TOOLS/CALL-Request f√ºr Tool '{TOOL_NAME}'\")\n","# Die Funktion 'call_server_tool' sendet den Request und wartet auf die Antwort\n","tool_call_response = await call_server_tool(\n","    server_name=SERVER_NAME,\n","    tool_name=TOOL_NAME,\n","    arguments=TOOL_ARGS\n",")\n","\n","# SCHRITT 7: Server-Antwort (Response)\n","mprint(\"\\n7Ô∏è‚É£ SCHRITT 7: Server-Antwort (Tool-Ergebnis) erhalten:\")\n","\n","# Manuelle Extraktion des Tool-Ergebnisses (simuliert die Verarbeitung des Clients)\n","if tool_call_response.get(\"result\"):\n","    result_content = tool_call_response[\"result\"][\"content\"][0][\"text\"]\n","    result_data = json.loads(result_content)\n","    files_list = result_data.get('files', [])\n","    mprint(f\"   Datenbasis f√ºr Synthese: {len(files_list)} Dateien gefunden (Payload von Server)\")\n","\n","    # SCHRITT 8: LLM generiert finale Antwort (Synthese)\n","    mprint(\"\\n8Ô∏è‚É£ SCHRITT 8: LLM generiert finale Antwort (Synthese):\")\n","    if files_list:\n","        files_formatted = ', '.join([f\"**{f}**\" for f in files_list])\n","        final_answer = f\"Im aktuellen Verzeichnis befinden sich folgende Dateien: {files_formatted}\"\n","    else:\n","        final_answer = \"Das aktuelle Verzeichnis ist leer.\"\n","    mprint(f\"ü§ñ {final_answer}\")\n","else:\n","    mprint(\"‚ùå Tool-Ausf√ºhrung fehlgeschlagen. Keine finale Antwort m√∂glich.\")\n","\n","print(\"\\nüî¥ ENDE: Zerlegte Sequenz abgeschlossen.\")"],"outputs":[],"execution_count":null,"metadata":{"id":"9je3ADIJ8njh"}},{"cell_type":"markdown","source":["# 5 | MCP in der Praxis\n","---"],"metadata":{"id":"l9ssj0Ib8njh"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Anwendungsf√§lle\n","</font></p>"],"metadata":{"id":"jZo28WOuH_NW"}},{"cell_type":"markdown","source":["\n","\n","MCP bietet in Unternehmensumgebungen erhebliche Vorteile, besonders wenn funktional implementiert:\n","\n","**1. Datenbank-Integration**\n","\n","  - Direkter Zugriff auf Unternehmens-Datenbanken\n","  - Echtzeit-Berichte und Analytics\n","  - Automatisierte Datenextraktion\n","\n","**2. ERP-System-Anbindung**\n","\n","  - Zugriff auf SAP, Oracle, Microsoft Dynamics\n","  - Automatisierte Bestellprozesse\n","  - Inventory-Management\n","\n","**3. Cloud-Service-Integration**\n","\n","  - AWS, Azure, Google Cloud APIs\n","  - Automatisierte Ressourcenverwaltung\n","  - Monitoring und Alerting\n","\n","**4. Sicherheits-Tools**\n","\n","  - SIEM-System-Integration\n","  - Automatisierte Incident Response\n","  - Compliance-Reporting\n","\n","**5. Collaboration-Tools**\n","\n","  - Slack, Teams, Jira Integration\n","  - Automatisierte Projekt-Updates\n","  - Team-Koordination\n","\n","**Vorteile des funktionalen Ansatzes:**\n","\n","  - **Bessere Testbarkeit**: Einzelne Funktionen k√∂nnen isoliert getestet werden\n","  - **Flexiblere Komposition**: Tools k√∂nnen dynamisch kombiniert werden\n","  - **Einfachere Wartung**: Klare Trennung von Concerns\n","  - **Bessere Performance**: Keine Overhead durch Objekt-Instantiierung\n"],"metadata":{"id":"y5TOmLZ_IFCd"}},{"cell_type":"markdown","source":["# 6 | Zukunft von MCP\n","---"],"metadata":{"id":"UfLfcsxjIJLX"}},{"cell_type":"markdown","source":["\n","\n","**Entwicklungstrends:**\n","\n","**1. Erweiterte Tool-Kategorien**\n","\n","  - Computer Vision APIs\n","  - IoT-Device Integration\n","  - Blockchain/Smart Contract Tools\n","  - Robotics Control Systems\n","\n","**2. Cross-Platform Standardisierung**\n","\n","  - OpenAPI/JSON Schema Integration\n","  - GraphQL-basierte Schemas\n","  - Universelle Authentication\n","  - Multi-Cloud Orchestrierung\n","\n","**3. Enterprise-Integration**\n","\n","  - Native SAP/Oracle Connectors\n","  - Compliance-by-Design\n","  - Zero-Trust Security Models\n","  - Hybrid Cloud Architectures\n","\n","**Ausblick:**\n","MCP entwickelt sich zu einem universellen Standard f√ºr AI-System-Integration. Der funktionale Ansatz bietet dabei besondere Vorteile:\n","\n","  - **Bessere Komposierbarkeit**: Funktionen k√∂nnen flexibel kombiniert werden\n","  - **Einfachere Tests**: Isolierte Funktionen sind leichter zu testen\n","  - **Klarere Architektur**: Funktionale Programmierung f√∂rdert saubere Designs\n","  - **Bessere Performance**: Weniger Overhead durch Objekt-Management\n","\n","In den n√§chsten Jahren erwarten wir:\n","\n","  - **Standardisierung** durch W3C oder √§hnliche Organisationen\n","  - **Native Support** in allen gro√üen AI-Plattformen\n","  - **Enterprise-Grade** Sicherheit und Compliance\n","  - **√ñkosystem** von vordefinierten funktionalen Connectoren\n","  - **No-Code/Low-Code** MCP-Integration Tools\n","  - **Funktionale Komposition** als Standard-Architektur\n","\n","MCP wird die Art und Weise revolutionieren, wie AI-Systeme mit der realen Welt interagieren, und der funktionale Ansatz wird dabei eine Schl√ºsselrolle spielen.\n"],"metadata":{"id":"PA-HXNOnILtU"}},{"cell_type":"markdown","source":["# A | Aufgabe\n","---"],"metadata":{"id":"IZe7lEOaIOai"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","Teste den AI-Assistant mit eigenen Queries\n","</font></p>"],"metadata":{"id":"Aw4pvzQDITW6"}},{"cell_type":"markdown","source":["\n","\n","**Ziel**: Nutze den fertigen MCP-Assistant, um verschiedene Datei-Operationen durchzuf√ºhren.\n","\n","**Schritt 1: Einfache Queries testen**\n","\n","F√ºhre die folgenden Queries mit dem AI-Assistant aus und beobachte, wie er die MCP-Tools nutzt:"],"metadata":{"id":"dyuDt58CIYUZ"}},{"cell_type":"code","source":["# Query 1: System-Informationen\n","result = await process_user_query(\"Welches Betriebssystem l√§uft hier?\")\n","print(result)\n","\n","# Query 2: Datei erstellen\n","result = await process_user_query(\"Erstelle eine Datei 'meine_notizen.txt' mit dem Text 'Das ist mein MCP-Test'\")\n","print(result)\n","\n","# Query 3: Datei lesen\n","result = await process_user_query(\"Lies die Datei 'meine_notizen.txt' und zeige mir den Inhalt\")\n","print(result)\n","\n","# Query 4: Verzeichnis auflisten\n","result = await process_user_query(\"Welche Dateien sind im aktuellen Verzeichnis?\")\n","print(result)"],"outputs":[],"execution_count":null,"metadata":{"id":"g6IYatYx8njh"}},{"cell_type":"markdown","source":["**Schritt 2: Eigene Queries erstellen**\n","\n","Entwickle mindestens **3 eigene Queries**, die verschiedene Tool-Kombinationen nutzen:\n","\n","**Beispiele f√ºr kreative Queries:**\n","\n","  - \"Erstelle eine ToDo-Liste in der Datei 'todos.txt' mit 5 Aufgaben\"\n","  - \"Z√§hle, wie viele .txt Dateien im aktuellen Verzeichnis sind\"\n","  - \"Erstelle eine Datei mit den aktuellen Systeminformationen\"\n","  - \"Lies alle .txt Dateien und fasse ihren Inhalt zusammen\"\n","\n","**Schritt 3: Bonus-Challenge (Optional)**\n","\n","Teste den Assistant mit und ohne MCP-Modus und vergleiche die Ergebnisse:"],"metadata":{"id":"Mtt-tnNW8nji"}},{"cell_type":"code","source":["# Mit MCP\n","result_mit = await process_user_query(\"Was f√ºr Dateien sind hier?\", use_mcp=True)\n","\n","# Ohne MCP\n","result_ohne = await process_user_query(\"Was f√ºr Dateien sind hier?\", use_mcp=False)\n","\n","# Vergleiche\n","print(\"MIT MCP:\", result_mit)\n","\n","print(\"\\nOHNE MCP:\", result_ohne)"],"outputs":[],"execution_count":null,"metadata":{"id":"IeXJtuUq8nji"}},{"cell_type":"markdown","source":["**üí° Tipps:**\n","\n","  - Der Assistant interpretiert deine nat√ºrlichsprachlichen Anfragen\n","  - Er entscheidet selbst, welche MCP-Tools er nutzt\n","  - Experimentiere mit verschiedenen Formulierungen\n","  - Achte auf die Console-Ausgabe, um zu sehen, welche Tools aufgerufen werden\n","\n","**‚úÖ Erfolg:**\n","\n","Du hast die Aufgabe erfolgreich abgeschlossen, wenn:\n","\n","  - ‚úÖ Mindestens 3 eigene Queries erstellt\n","  - ‚úÖ Alle Queries liefern sinnvolle Ergebnisse\n","  - ‚úÖ Du verstehst, wie der Assistant MCP-Tools nutzt\n","\n","<!-- end list -->\n","\n","```\n","```"],"metadata":{"id":"unlqDNvU8nji"}}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["F40ApzrO9jrA","8RZw4su6Gxe3","ejQTaApP8nje","shabydbk8njg","l9ssj0Ib8njh","UfLfcsxjIJLX","IZe7lEOaIOai"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}