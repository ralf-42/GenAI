{"cells":[{"cell_type":"markdown","id":"header-1","metadata":{"id":"header-1"},"source":["<p><font size=\"6\" color='grey'> <b>\n","\n","Generative KI. Verstehen. Anwenden. Gestalten.\n","</b></font> </br></p>"]},{"cell_type":"markdown","id":"header-2","metadata":{"id":"header-2"},"source":["<p><font size=\"5\" color='grey'> <b> Chat Memory Patterns</b></font> </br></p>\n","\n","---"]},{"cell_type":"code","execution_count":1,"id":"setup-1","metadata":{"id":"setup-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764770324296,"user_tz":-60,"elapsed":73895,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"a850410b-c8f9-40ff-ceb8-3c127f40f5c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì OPENAI_API_KEY erfolgreich gesetzt\n","\n","Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n","\n","Installierte LangChain- und LangGraph-Bibliotheken:\n","langchain                                1.1.0\n","langchain-chroma                         1.0.0\n","langchain-classic                        1.0.0\n","langchain-community                      0.4.1\n","langchain-core                           1.1.0\n","langchain-ollama                         1.0.0\n","langchain-openai                         1.1.0\n","langchain-text-splitters                 1.0.0\n","langgraph                                1.0.3\n","langgraph-checkpoint                     3.0.1\n","langgraph-prebuilt                       1.0.5\n","langgraph-sdk                            0.2.10\n","\n","IP-Adresse: 34.147.124.34\n","Hostname: 34.124.147.34.bc.googleusercontent.com\n","Stadt: Groningen\n","Region: Groningen\n","Land: NL\n","Koordinaten: 53.2192,6.5667\n","Provider: AS396982 Google LLC\n","Postleitzahl: 9711\n","Zeitzone: Europe/Amsterdam\n"]}],"source":["#@title üîß Umgebung einrichten{ display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/GenAI.git#subdirectory=04_modul\n","from genai_lib.utilities import check_environment, get_ipinfo, setup_api_keys, mprint, install_packages\n","setup_api_keys(['OPENAI_API_KEY'], create_globals=False)\n","print()\n","check_environment()\n","print()\n","get_ipinfo()"]},{"cell_type":"markdown","id":"intro-header","metadata":{"id":"intro-header"},"source":["# 1 | Intro\n","---"]},{"cell_type":"markdown","id":"intro-text","metadata":{"id":"intro-text"},"source":["<p><font color='black' size=\"5\">\n","Zustandslosigkeit von LLMs\n","</font></p>\n","\n","Large Language Models (LLMs) wie GPT sind von Natur aus **zustandslos** - sie verfugen uber kein eingebautes Gedachtnis. Jede Anfrage wird isoliert verarbeitet, ohne Bezug zu vorherigen Interaktionen. Deshalb muss der Chatverlauf (Historie) bei jeder Anfrage neu ubergeben werden.\n","\n","```\n","Ohne Memory:\n","User: \"Mein Name ist Max\"\n","AI: \"Hallo Max!\"\n","User: \"Wie heisse ich?\"\n","AI: \"Das habe ich nicht gespeichert.\"\n","```\n","\n","**Dieses Notebook zeigt Memory-Patterns mit reinem Python (ohne LangGraph):**\n","\n","| Pattern | Beschreibung | Anwendungsfall |\n","|---------|--------------|----------------|\n","| **Python-Liste** | Einfachste Losung | Prototyping, kurze Sessions |\n","| **Trimming** | Nur letzte N Nachrichten | Token-Limit einhalten |\n","| **Summary** | Alte Nachrichten zusammenfassen | Lange Sessions, Kontext erhalten |\n","| **Datenbank** | Persistente Speicherung | Production, Multi-User |"]},{"cell_type":"markdown","id":"shortterm-header","metadata":{"id":"shortterm-header"},"source":["# 2 | Short-term Memory (Python-Liste)\n","---"]},{"cell_type":"markdown","id":"shortterm-intro","metadata":{"id":"shortterm-intro"},"source":["Die einfachste Form von Memory: Eine **Python-Liste**, die alle Nachrichten speichert und bei jedem API-Call mitgesendet wird."]},{"cell_type":"code","execution_count":2,"id":"shortterm-imports","metadata":{"id":"shortterm-imports","executionInfo":{"status":"ok","timestamp":1764770326588,"user_tz":-60,"elapsed":2254,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Importe\n","from langchain.chat_models import init_chat_model\n","from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# System-Prompt\n","system_prompt = \"Du bist ein hilfreicher und humorvoller KI-Assistent.\"\n","\n","# Prompt-Template mit Historie (MessagesPlaceholder nimmt die Historie entgegen)\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"{system_prompt}\"),\n","    MessagesPlaceholder(variable_name=\"chat_history\"),\n","    (\"human\", \"{user_input}\")\n","])\n","\n","# LLM (Kurznotation: \"provider:model\")\n","llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n","\n","# Parser\n","parser = StrOutputParser()\n","\n","# Chain\n","chain = prompt | llm | parser"]},{"cell_type":"code","execution_count":3,"id":"shortterm-function","metadata":{"id":"shortterm-function","executionInfo":{"status":"ok","timestamp":1764770326595,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Chat-Funktion mit manueller Historien-Verwaltung\n","def chat(chat_history: list, user_input: str) -> list:\n","    \"\"\"Fuhrt eine Chat-Interaktion mit manueller Historien-Verwaltung durch.\"\"\"\n","\n","    # Chain aufrufen (Historie wird im Prompt mitgeschickt)\n","    response = chain.invoke({\n","        'system_prompt': system_prompt,\n","        'chat_history': chat_history,\n","        'user_input': user_input\n","    })\n","\n","    # Ausgabe\n","    mprint(f\"### Mensch:\\n{user_input}\")\n","    mprint(f\"### KI:\\n{response}\\n\")\n","\n","    # Memory (Liste) MANUELL aktualisieren\n","    chat_history.append(HumanMessage(content=user_input))\n","    chat_history.append(AIMessage(content=response))\n","\n","    return chat_history"]},{"cell_type":"code","execution_count":4,"id":"shortterm-demo","metadata":{"id":"shortterm-demo","colab":{"base_uri":"https://localhost:8080/","height":662},"executionInfo":{"status":"ok","timestamp":1764770331293,"user_tz":-60,"elapsed":4696,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"fa9cdd66-99c6-4440-8083-dfe80a4dad31"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nMein Name ist Max"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nHallo Max! Sch√∂n, dich kennenzulernen! Wie kann ich dir heute helfen? Oder m√∂chtest du einfach ein bisschen plaudern?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch mag Python-Programmierung"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nDas ist gro√üartig, Max! Python ist eine fantastische Sprache ‚Äì so vielseitig und benutzerfreundlich. Was machst du gerne mit Python? Programmierst du Spiele, Webanwendungen oder vielleicht etwas ganz anderes?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nWeisst du noch, wie ich heisse und was ich mag?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nNat√ºrlich, Max! Du magst Python-Programmierung. Ich habe ein ausgezeichnetes Ged√§chtnis f√ºr solche Dinge ‚Äì zumindest bis ich einen Systemneustart habe! üòÑ Gibt es etwas Bestimmtes, wor√ºber du in Bezug auf Python sprechen m√∂chtest?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Gespeicherte Nachrichten (Liste):\n---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **system**:   Du bist ein hilfreicher und humorvoller KI-Assistent."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **human**:   Mein Name ist Max"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **ai**:   Hallo Max! Sch√∂n, dich kennenzulernen! Wie kann ich dir heute helfen? Oder m√∂chtest du einfach ein bisschen plaudern?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **human**:   Ich mag Python-Programmierung"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **ai**:   Das ist gro√üartig, Max! Python ist eine fantastische Sprache ‚Äì so vielseitig und benutzerfreundlich. Was machst du gerne mit Python? Programmierst du Spiele, Webanwendungen oder vielleicht etwas ganz anderes?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **human**:   Weisst du noch, wie ich heisse und was ich mag?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"  **ai**:   Nat√ºrlich, Max! Du magst Python-Programmierung. Ich habe ein ausgezeichnetes Ged√§chtnis f√ºr solche Dinge ‚Äì zumindest bis ich einen Systemneustart habe! üòÑ Gibt es etwas Bestimmtes, wor√ºber du in Bezug auf Python sprechen m√∂chtest?"},"metadata":{}}],"source":["# Historie initialisieren\n","chat_history = [SystemMessage(content=system_prompt)]\n","\n","\n","# Konversation\n","chat_history = chat(chat_history, \"Mein Name ist Max\")\n","chat_history = chat(chat_history, \"Ich mag Python-Programmierung\")\n","chat_history = chat(chat_history, \"Weisst du noch, wie ich heisse und was ich mag?\")\n","\n","mprint(\"### Gespeicherte Nachrichten (Liste):\\n---\")\n","for msg in chat_history:\n","    mprint(f\"  **{msg.type}**:   {msg.content}\")"]},{"cell_type":"markdown","id":"shortterm-problem","metadata":{"id":"shortterm-problem"},"source":["<p><font color='darkblue' size=\"4\">\n","Problem:\n","</font></p>\n","\n","- Keine automatische Session-Verwaltung (Multi-User)\n","- Manuelles Memory-Management fehleranfallig\n","- **Bei langen Konversationen: Token-Limit wird uberschritten!**"]},{"cell_type":"markdown","id":"trimming-header","metadata":{"id":"trimming-header"},"source":["# 3 | Trimming (Sliding Window)\n","---"]},{"cell_type":"markdown","id":"trimming-intro","metadata":{"id":"trimming-intro"},"source":["**Strategie:** Behalte nur die letzten *n* Nachrichten. Altere Nachrichten werden entfernt.\n","\n","```\n","Vor Trimming (max=4):\n","[msg1, msg2, msg3, msg4, msg5, msg6] -> 6 Nachrichten\n","\n","Nach Trimming:\n","[msg3, msg4, msg5, msg6] -> nur die letzten 4\n","```\n","\n","**Vorteil:** Einfach, Token-Limit garantiert  \n","**Nachteil:** Fruhere Informationen gehen verloren"]},{"cell_type":"code","execution_count":5,"id":"trimming-config","metadata":{"id":"trimming-config","executionInfo":{"status":"ok","timestamp":1764770331332,"user_tz":-60,"elapsed":27,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Konfiguration\n","MAX_MESSAGES = 6  # Maximale Anzahl Nachrichten (Human + AI)\n","\n","def trim_history(chat_history: list, max_messages: int = MAX_MESSAGES) -> list:\n","    \"\"\"Behalt nur die letzten n Nachrichten.\"\"\"\n","    if len(chat_history) > max_messages:\n","        trimmed = chat_history[-max_messages:]\n","        mprint(f\"**Trimming:** {len(chat_history)} -> {len(trimmed)} Nachrichten\")\n","        return trimmed\n","    return chat_history"]},{"cell_type":"code","execution_count":6,"id":"trimming-function","metadata":{"id":"trimming-function","executionInfo":{"status":"ok","timestamp":1764770331346,"user_tz":-60,"elapsed":15,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["def chat_with_trimming(chat_history: list, user_input: str, max_messages: int = MAX_MESSAGES) -> list:\n","    \"\"\"Chat mit automatischem Trimming der Historie.\"\"\"\n","\n","    # Trimmen VOR dem API-Call\n","    trimmed_history = trim_history(chat_history, max_messages)\n","\n","    # Chain aufrufen mit getrimmter Historie\n","    response = chain.invoke({\n","        'system_prompt': system_prompt,\n","        'chat_history': trimmed_history,\n","        'user_input': user_input\n","    })\n","\n","    # Ausgabe\n","    mprint(f\"### Mensch:\\n{user_input}\")\n","    mprint(f\"### KI:\\n{response}\\n\")\n","\n","    # Zur ORIGINALEN Historie hinzufugen (nicht zur getrimmten!)\n","    chat_history.append(HumanMessage(content=user_input))\n","    chat_history.append(AIMessage(content=response))\n","\n","    return chat_history"]},{"cell_type":"code","execution_count":7,"id":"trimming-demo","metadata":{"id":"trimming-demo","colab":{"base_uri":"https://localhost:8080/","height":929},"executionInfo":{"status":"ok","timestamp":1764770338512,"user_tz":-60,"elapsed":7163,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"a4a7485e-9393-4644-f26d-9ce9809100fd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"## Trimming Demo (max 6 Nachrichten)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nMein Name ist Max"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nHallo Max! Sch√∂n, dich kennenzulernen! Wie kann ich dir heute helfen?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch wohne in Koln"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nK√∂ln, die Stadt mit dem ber√ºhmten Dom und der besten Karnevalsstimmung! Hast du einen Lieblingsort in K√∂ln oder etwas, das du besonders an der Stadt magst?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch mag Python"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nPython ist gro√üartig! Eine der vielseitigsten Programmiersprachen, die es gibt. Ob f√ºr Webentwicklung, Datenanalyse oder sogar f√ºr das Programmieren von Robotern ‚Äì die M√∂glichkeiten sind endlos! Hast du ein bestimmtes Projekt, an dem du gerade arbeitest, oder etwas, das du mit Python lernen m√∂chtest?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch habe eine Katze namens Neo"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nNeo, das klingt nach einem coolen Namen f√ºr eine Katze! Ist sie so geheimnisvoll wie der Charakter aus ‚ÄûThe Matrix‚Äú? Was f√ºr eine Katze ist sie und was macht sie so besonders?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Trimming:** 8 -> 6 Nachrichten"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest-Nachricht 5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest-Nachricht empfangen! Wenn du noch mehr testen oder etwas anderes besprechen m√∂chtest, lass es mich wissen! üêæ\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Trimming:** 10 -> 6 Nachrichten"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nWie heisse ich?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nDas ist eine gute Frage! Leider kann ich deinen Namen nicht wissen, es sei denn, du sagst es mir. Aber ich bin sicher, dass du einen tollen Namen hast! Wie darf ich dich nennen?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Gespeicherte Nachrichten: 12"},"metadata":{}}],"source":["# Demo: Trimming in Aktion\n","mprint(\"## Trimming Demo (max 6 Nachrichten)\")\n","mprint(\"---\")\n","\n","history_trimmed = [SystemMessage(content=system_prompt)]\n","\n","\n","# Erste Nachrichten\n","history_trimmed = chat_with_trimming(history_trimmed, \"Mein Name ist Max\")\n","history_trimmed = chat_with_trimming(history_trimmed, \"Ich wohne in Koln\")\n","history_trimmed = chat_with_trimming(history_trimmed, \"Ich mag Python\")\n","\n","# Jetzt uberschreiten wir das Limit (6 Nachrichten = 3 Frage-Antwort-Paare)\n","history_trimmed = chat_with_trimming(history_trimmed, \"Ich habe eine Katze namens Neo\")\n","history_trimmed = chat_with_trimming(history_trimmed, \"Test-Nachricht 5\")\n","\n","# Diese Nachricht lost Trimming aus\n","history_trimmed = chat_with_trimming(history_trimmed, \"Wie heisse ich?\")  # Fruhe Info konnte verloren sein!\n","\n","mprint(f\"### Gespeicherte Nachrichten: {len(history_trimmed)}\")"]},{"cell_type":"markdown","id":"summary-header","metadata":{"id":"summary-header"},"source":["# 4 | Summary (Zusammenfassung)\n","---"]},{"cell_type":"markdown","id":"summary-intro","metadata":{"id":"summary-intro"},"source":["**Strategie:** Statt alte Nachrichten zu loschen, werden sie **zusammengefasst**. Die Zusammenfassung ersetzt die alten Nachrichten.\n","\n","```\n","Vor Summary:\n","[msg1, msg2, msg3, msg4, msg5, msg6, msg7, msg8] -> 8 Nachrichten\n","\n","Nach Summary:\n","[\"Zusammenfassung: User heisst Max, mag Python...\", msg7, msg8]\n","```\n","\n","**Vorteil:** Wichtige Informationen bleiben erhalten  \n","**Nachteil:** Zusatzlicher LLM-Call fur Zusammenfassung"]},{"cell_type":"code","execution_count":8,"id":"summary-config","metadata":{"id":"summary-config","executionInfo":{"status":"ok","timestamp":1764770338541,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Konfiguration\n","MAX_BEFORE_SUMMARY = 8   # Ab dieser Anzahl wird zusammengefasst\n","MESSAGES_TO_SUMMARIZE = 6  # So viele alte Nachrichten zusammenfassen\n","RECENT_TO_KEEP = 2        # So viele neueste Nachrichten behalten\n","\n","# Zusammenfassungs-Prompt\n","summary_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Fasse die folgende Konversation in 2-3 Satzen zusammen. Behalte wichtige Fakten wie Namen, Orte und Praferenzen.\"),\n","    (\"human\", \"{conversation}\")\n","])\n","\n","summary_chain = summary_prompt | llm | parser"]},{"cell_type":"code","execution_count":9,"id":"summary-function","metadata":{"id":"summary-function","executionInfo":{"status":"ok","timestamp":1764770338600,"user_tz":-60,"elapsed":49,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["def summarize_messages(messages: list) -> str:\n","    \"\"\"Erstellt eine Zusammenfassung der Nachrichten.\"\"\"\n","    conversation_text = \"\\n\".join([\n","        f\"{msg.type}: {msg.content}\" for msg in messages\n","    ])\n","\n","    summary = summary_chain.invoke({\"conversation\": conversation_text})\n","    return summary\n","\n","\n","def chat_with_summary(chat_history: list, user_input: str, summary_context: str = \"\") -> tuple:\n","    \"\"\"Chat mit automatischer Zusammenfassung bei langer Historie.\"\"\"\n","\n","    # Prufen ob Zusammenfassung notig ist\n","    if len(chat_history) >= MAX_BEFORE_SUMMARY:\n","        mprint(f\"**Summary:** Historie zu lang ({len(chat_history)} Nachrichten). Fasse zusammen...\")\n","\n","        # Alte Nachrichten zusammenfassen\n","        to_summarize = chat_history[:MESSAGES_TO_SUMMARIZE]\n","        new_summary = summarize_messages(to_summarize)\n","\n","        # Bisherige Zusammenfassung + neue kombinieren\n","        if summary_context:\n","            summary_context = f\"{summary_context}\\n\\nNeuere Zusammenfassung: {new_summary}\"\n","        else:\n","            summary_context = new_summary\n","\n","        mprint(f\"**Neue Zusammenfassung:** {new_summary[:100]}...\")\n","\n","        # Historie kurzen (nur die neuesten behalten)\n","        chat_history = chat_history[-RECENT_TO_KEEP:]\n","\n","    # System-Prompt mit Zusammenfassung erweitern\n","    enhanced_system = system_prompt\n","    if summary_context:\n","        enhanced_system = f\"{system_prompt}\\n\\nBisheriger Kontext (Zusammenfassung): {summary_context}\"\n","\n","    # Chain aufrufen\n","    response = chain.invoke({\n","        'system_prompt': enhanced_system,\n","        'chat_history': chat_history,\n","        'user_input': user_input\n","    })\n","\n","    # Ausgabe\n","    mprint(f\"### Mensch:\\n{user_input}\")\n","    mprint(f\"### KI:\\n{response}\\n\")\n","\n","    # Historie aktualisieren\n","    chat_history.append(HumanMessage(content=user_input))\n","    chat_history.append(AIMessage(content=response))\n","\n","    return chat_history, summary_context"]},{"cell_type":"code","execution_count":10,"id":"summary-demo","metadata":{"id":"summary-demo","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1764770355968,"user_tz":-60,"elapsed":17392,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"ca9646d7-2ed4-420b-e490-fd63a17e1f23"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"## Summary Demo"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nMein Name ist Max"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nHallo Max! Sch√∂n, dich kennenzulernen! Wie kann ich dir heute helfen?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch wohne in Koln"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nK√∂ln, die Stadt mit dem ber√ºhmten Dom und den besten Karnevalspartys! Hast du einen Lieblingsort in K√∂ln oder etwas, das du besonders an der Stadt magst?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nIch mag Python"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nPython ist gro√üartig! Eine der besten Programmiersprachen, wenn du mich fragst. Sie ist so vielseitig ‚Äì von Webentwicklung √ºber Datenanalyse bis hin zu k√ºnstlicher Intelligenz. Was machst du denn mit Python? Hast du ein bestimmtes Projekt oder ein Thema, das dich interessiert?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nMeine Katze heisst Neo"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nNeo, das ist ein cooler Name f√ºr eine Katze! Ist sie so geheimnisvoll wie der Charakter aus ‚ÄûThe Matrix‚Äú? Vielleicht hat sie auch besondere F√§higkeiten, wie das perfekte Versteckspiel oder das pl√∂tzliche Erscheinen, wenn du gerade etwas essen willst! Was macht Neo so besonders?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Summary:** Historie zu lang (8 Nachrichten). Fasse zusammen..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Neue Zusammenfassung:** Max wohnt in K√∂ln und mag die Programmiersprache Python. Er sch√§tzt die Vielseitigkeit von Python, d..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest 1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest 1 erfolgreich! üéâ Wie kann ich dir weiterhelfen? Gibt es etwas Bestimmtes, das du testen oder wissen m√∂chtest?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest 2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest 2 ebenfalls erfolgreich! üéä Du bist auf einer rollenden Testwelle! Gibt es noch mehr Tests oder Fragen, die du hast? Oder vielleicht m√∂chtest du √ºber Neo plaudern?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest 3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest 3: Bestanden! ü•≥ Du bist wirklich in der Testlaune! Was steht als N√§chstes auf dem Pr√ºfungsplan? Oder m√∂chtest du einfach nur ein bisschen plaudern?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Summary:** Historie zu lang (8 Nachrichten). Fasse zusammen..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Neue Zusammenfassung:** Der Mensch hat eine Katze namens Neo, die m√∂glicherweise geheimnisvoll und besonders ist. Es wurden ..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest 4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest 4: Auch bestanden! üéâ Du bist ein echter √úberflieger! Was hast du dir f√ºr Test 5 √ºberlegt? Oder sollen wir Neo ein bisschen mehr ins Rampenlicht r√ºcken? üò∫\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nTest 5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nTest 5: Erfolgreich bestanden! üéä Du bist wirklich unaufhaltsam! Hast du vielleicht einen speziellen Test im Kopf, oder m√∂chtest du einfach nur feiern? Vielleicht mit einem virtuellen Katzenleckerlies f√ºr Neo? üêæüòÑ\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Mensch:\nWie heisse ich und wie heisst meine Katze?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### KI:\nDu hei√üt Max und deine Katze hei√üt Neo! üê±‚ú® Wenn ich ein Ged√§chtnis h√§tte, w√ºrde ich sagen, du bist ein ganz sch√∂ner Gl√ºckspilz mit so einem coolen Namen f√ºr deine Katze! Was m√∂chtest du als N√§chstes wissen oder besprechen?\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Aktuelle Historie: 8 Nachrichten"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Gespeicherte Zusammenfassung:\nMax wohnt in K√∂ln und mag die Programmiersprache Python. Er sch√§tzt die Vielseitigkeit von Python, die von Webentwicklung bis zu k√ºnstlicher Intelligenz reicht.\n\nNeuere Zusammenfassung: Der Mensch hat eine Katze namens Neo, die m√∂glicherweise geheimnisvoll und besonders ist. Es wurden zwei Tests durchgef√ºhrt, die beide erfolgreich waren, und die KI bietet an, weitere Fragen zu beantworten oder √ºber die Katze zu plaudern."},"metadata":{}}],"source":["# Demo: Summary in Aktion\n","mprint(\"## Summary Demo\")\n","mprint(\"---\")\n","\n","history_summary = [SystemMessage(content=system_prompt)]\n","\n","summary_ctx = \"\"\n","\n","# Wichtige Informationen am Anfang\n","history_summary, summary_ctx = chat_with_summary(history_summary, \"Mein Name ist Max\", summary_ctx)\n","history_summary, summary_ctx = chat_with_summary(history_summary, \"Ich wohne in Koln\", summary_ctx)\n","history_summary, summary_ctx = chat_with_summary(history_summary, \"Ich mag Python\", summary_ctx)\n","history_summary, summary_ctx = chat_with_summary(history_summary, \"Meine Katze heisst Neo\", summary_ctx)\n","\n","# Fullnachrichten um Summary auszulosen\n","for i in range(5):\n","    history_summary, summary_ctx = chat_with_summary(history_summary, f\"Test {i+1}\", summary_ctx)\n","\n","# Nach Summary: Kann die KI sich noch an den Namen erinnern?\n","history_summary, summary_ctx = chat_with_summary(history_summary, \"Wie heisse ich und wie heisst meine Katze?\", summary_ctx)\n","\n","mprint(f\"### Aktuelle Historie: {len(history_summary)} Nachrichten\")\n","mprint(f\"### Gespeicherte Zusammenfassung:\\n{summary_ctx}\")"]},{"cell_type":"markdown","id":"db-header","metadata":{"id":"db-header"},"source":["# 5 | RunnableWithMessageHistory (LCEL)\n","---"]},{"cell_type":"markdown","id":"db-intro","metadata":{"id":"db-intro"},"source":["`RunnableWithMessageHistory` ist die **offizielle LCEL-Alternative** zu den deprecated Memory-Klassen (`ConversationBufferMemory`, etc.). Es wrapped eine Chain und verwaltet die Chat-Historie automatisch.\n","\n","**Vorteile gegenuber manueller Verwaltung:**\n","- Automatisches Laden/Speichern der Historie\n","- Session-Management uber `session_id`\n","- Kompatibel mit Streaming und Async\n","\n","```python\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","```"]},{"cell_type":"code","execution_count":11,"id":"db-imports","metadata":{"id":"db-imports","executionInfo":{"status":"ok","timestamp":1764770356015,"user_tz":-60,"elapsed":24,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Importe fur RunnableWithMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","from langchain_core.chat_history import InMemoryChatMessageHistory\n","\n","# Session-Store (Dictionary: session_id -> ChatMessageHistory)\n","session_store = {}\n","\n","def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n","    \"\"\"Gibt die Historie fur eine Session zuruck (oder erstellt eine neue).\"\"\"\n","    if session_id not in session_store:\n","        session_store[session_id] = InMemoryChatMessageHistory()\n","    return session_store[session_id]"]},{"cell_type":"code","execution_count":12,"id":"db-class","metadata":{"id":"db-class","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764770356069,"user_tz":-60,"elapsed":45,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"58fcae65-b875-4319-d828-248750fd135a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chain mit RunnableWithMessageHistory erstellt\n"]}],"source":["# Prompt mit Historie-Platzhalter\n","prompt_with_history = ChatPromptTemplate.from_messages([\n","    (\"system\", system_prompt),\n","    MessagesPlaceholder(variable_name=\"history\"),  # Hier wird die Historie eingefugt\n","    (\"human\", \"{input}\")\n","])\n","\n","# Basis-Chain (ohne Memory)\n","base_chain = prompt_with_history | llm | parser\n","\n","# Chain MIT automatischem Memory-Management wrappen\n","chain_with_history = RunnableWithMessageHistory(\n","    runnable=base_chain,\n","    get_session_history=get_session_history,\n","    input_messages_key=\"input\",      # Key fur neue User-Nachricht\n","    history_messages_key=\"history\"   # Key fur die Historie im Prompt\n",")\n","\n","print(\"Chain mit RunnableWithMessageHistory erstellt\")"]},{"cell_type":"code","execution_count":13,"id":"db-chatbot","metadata":{"id":"db-chatbot","executionInfo":{"status":"ok","timestamp":1764770356072,"user_tz":-60,"elapsed":23,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"outputs":[],"source":["# Helper-Funktion fur Chat mit Session-ID\n","def chat_with_session(session_id: str, user_input: str) -> str:\n","    \"\"\"Chattet mit automatischem Memory uber RunnableWithMessageHistory.\"\"\"\n","\n","    # Config mit Session-ID (PFLICHT!)\n","    config = {\"configurable\": {\"session_id\": session_id}}\n","\n","    # Chain aufrufen - Historie wird automatisch geladen/gespeichert\n","    response = chain_with_history.invoke(\n","        {\"input\": user_input},\n","        config=config\n","    )\n","\n","    mprint(f\"**[{session_id}] Mensch:** {user_input}\")\n","    mprint(f\"**[{session_id}] KI:** {response}\\n\")\n","\n","    return response"]},{"cell_type":"code","execution_count":14,"id":"db-demo","metadata":{"id":"db-demo","colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"status":"ok","timestamp":1764770361121,"user_tz":-60,"elapsed":5064,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"8633af43-0f03-4571-e97a-3af27e2b66de"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"## RunnableWithMessageHistory Demo"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] Mensch:** Hallo! Ich bin Max aus Munchen."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] KI:** Hallo Max! Sch√∂n, dich kennenzulernen! Wie l√§uft's in M√ºnchen? Gibt es etwas Bestimmtes, wor√ºber du plaudern m√∂chtest? üòä\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] Mensch:** Ich programmiere gerne in Python."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] KI:** Das ist gro√üartig! Python ist eine super vielseitige Sprache. Was programmierst du denn so? Hast du ein Lieblingsprojekt oder ein bestimmtes Thema, das dich interessiert? üêçüíª\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[emma] Mensch:** Hi! Ich bin Emma und mag Machine Learning."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[emma] KI:** Hallo Emma! Das ist gro√üartig! Machine Learning ist ein spannendes und dynamisches Feld. Was interessiert dich besonders daran? Hast du ein bestimmtes Projekt oder Thema, √ºber das du sprechen m√∂chtest? Oder m√∂chtest du einfach ein bisschen plaudern? üòä\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] Mensch:** Woher komme ich und was ist mein Hobby?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**[max] KI:** Du kommst aus M√ºnchen und dein Hobby ist das Programmieren, insbesondere in Python! Wenn ich noch mehr √ºber deine Projekte oder Interessen erfahren k√∂nnte, w√§re ich ganz Ohr! Gibt es etwas Bestimmtes, das du in Python gerne machst? üòä\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Gespeicherte Sessions:"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"- **max**: 6 Nachrichten"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"- **emma**: 2 Nachrichten"},"metadata":{}}],"source":["# Demo: RunnableWithMessageHistory\n","mprint(\"## RunnableWithMessageHistory Demo\")\n","mprint(\"---\")\n","\n","# Session 1: Max\n","chat_with_session(\"max\", \"Hallo! Ich bin Max aus Munchen.\")\n","chat_with_session(\"max\", \"Ich programmiere gerne in Python.\")\n","\n","# Session 2: Emma (separate Historie!)\n","chat_with_session(\"emma\", \"Hi! Ich bin Emma und mag Machine Learning.\")\n","\n","# Zuruck zu Max - Memory bleibt erhalten!\n","chat_with_session(\"max\", \"Woher komme ich und was ist mein Hobby?\")\n","\n","# Session-Store anzeigen\n","mprint(\"### Gespeicherte Sessions:\")\n","for sid, history in session_store.items():\n","    mprint(f\"- **{sid}**: {len(history.messages)} Nachrichten\")"]},{"cell_type":"code","execution_count":15,"id":"db-list","metadata":{"id":"db-list","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1764770361183,"user_tz":-60,"elapsed":49,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"47433f62-7c97-45d5-d77a-24a3bc067b0f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Historie: max"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"1. **Human:** Hallo! Ich bin Max aus Munchen."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"2. **KI:** Hallo Max! Sch√∂n, dich kennenzulernen! Wie l√§uft's in M√ºnchen? Gibt es etwas Bestimmtes, wor√ºber du plaudern m√∂chtest? üòä"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"3. **Human:** Ich programmiere gerne in Python."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"4. **KI:** Das ist gro√üartig! Python ist eine super vielseitige Sprache. Was programmierst du denn so? Hast du ein Lieblingsprojekt oder ein bestimmtes Thema, das dich interessiert? üêçüíª"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"5. **Human:** Woher komme ich und was ist mein Hobby?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"6. **KI:** Du kommst aus M√ºnchen und dein Hobby ist das Programmieren, insbesondere in Python! Wenn ich noch mehr √ºber deine Projekte oder Interessen erfahren k√∂nnte, w√§re ich ganz Ohr! Gibt es etwas Bestimmtes, das du in Python gerne machst? üòä"},"metadata":{}}],"source":["# Historie einer Session anzeigen\n","def show_session_history(session_id: str):\n","    \"\"\"Zeigt die Nachrichten einer Session.\"\"\"\n","    if session_id not in session_store:\n","        print(f\"Session '{session_id}' nicht gefunden\")\n","        return\n","\n","    history = session_store[session_id]\n","    mprint(f\"### Historie: {session_id}\")\n","    for i, msg in enumerate(history.messages, 1):\n","        role = \"Human\" if msg.type == \"human\" else \"KI\"\n","        mprint(f\"{i}. **{role}:** {msg.content}\")\n","\n","show_session_history(\"max\")"]},{"cell_type":"markdown","id":"db-history","metadata":{"id":"db-history"},"source":["<p><font color='darkblue' size=\"4\">\n","Vergleich: RunnableWithMessageHistory vs. LangGraph\n","</font></p>\n","\n","| Aspekt | RunnableWithMessageHistory | LangGraph |\n","|--------|---------------------------|-----------|\n","| **Komplexitat** | Einfach | Fortgeschritten |\n","| **Persistenz** | Manuell (Store) | Checkpointer |\n","| **RemoveMessage** | Nein | Ja |\n","| **Trimming** | Manuell | `trim_messages` |\n","| **Multi-Agent** | Nein | Ja |\n","\n","**Empfehlung:** `RunnableWithMessageHistory` fur einfache Chains, LangGraph fur komplexe Agents."]},{"cell_type":"markdown","id":"db-persist","metadata":{"id":"db-persist"},"source":["# 6 | Long-term Memory (SQLite)\n","---"]},{"cell_type":"markdown","id":"db-persist-test","metadata":{"id":"db-persist-test"},"source":["**Problem:** Beim Neustart der Anwendung geht die Historie verloren.\n","\n","**Losung:** Persistente Speicherung in einer **SQLite-Datenbank**.\n","\n","| Speicherart | Persistenz | Multi-User | Anwendung |\n","|-------------|------------|------------|------------|\n","| Python-Liste | Nein | Nein | Prototyping |\n","| RunnableWithMessageHistory | Nein* | Ja | Einfache Chains |\n","| SQLite | Ja | Ja | Lokale Apps |\n","\n","*Mit FileChatMessageHistory moglich"]},{"cell_type":"code","id":"2wes9llitgg","source":["import sqlite3\n","from datetime import datetime\n","from typing import List, Dict, Optional\n","\n","DB_PATH = \"./chat_memory.db\""],"metadata":{"id":"2wes9llitgg","executionInfo":{"status":"ok","timestamp":1764770361196,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","id":"lt015mlb76i","source":["class ChatMemoryDB:\n","    \"\"\"Einfache Chat-Memory-Datenbank mit SQLite.\"\"\"\n","\n","    def __init__(self, db_path: str = DB_PATH):\n","        self.db_path = db_path\n","        self._init_db()\n","\n","    def _init_db(self):\n","        \"\"\"Erstellt die Tabellen falls nicht vorhanden.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            conn.execute(\"\"\"\n","                CREATE TABLE IF NOT EXISTS messages (\n","                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n","                    thread_id TEXT NOT NULL,\n","                    role TEXT NOT NULL,\n","                    content TEXT NOT NULL,\n","                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n","                )\n","            \"\"\")\n","            conn.execute(\"\"\"\n","                CREATE TABLE IF NOT EXISTS summaries (\n","                    thread_id TEXT PRIMARY KEY,\n","                    summary TEXT,\n","                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n","                )\n","            \"\"\")\n","            conn.execute(\"CREATE INDEX IF NOT EXISTS idx_thread ON messages(thread_id)\")\n","            conn.commit()\n","        print(f\"Datenbank initialisiert: {self.db_path}\")\n","\n","    def save_message(self, thread_id: str, role: str, content: str):\n","        \"\"\"Speichert eine Nachricht.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            conn.execute(\n","                \"INSERT INTO messages (thread_id, role, content) VALUES (?, ?, ?)\",\n","                (thread_id, role, content)\n","            )\n","            conn.commit()\n","\n","    def get_history(self, thread_id: str, limit: Optional[int] = None) -> List[Dict]:\n","        \"\"\"Ladt die Historie eines Threads.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            if limit:\n","                rows = conn.execute(\n","                    \"SELECT role, content FROM messages WHERE thread_id = ? ORDER BY id DESC LIMIT ?\",\n","                    (thread_id, limit)\n","                ).fetchall()\n","                rows = list(reversed(rows))\n","            else:\n","                rows = conn.execute(\n","                    \"SELECT role, content FROM messages WHERE thread_id = ? ORDER BY id\",\n","                    (thread_id,)\n","                ).fetchall()\n","        return [{\"role\": r[0], \"content\": r[1]} for r in rows]\n","\n","    def get_message_count(self, thread_id: str) -> int:\n","        \"\"\"Zahlt die Nachrichten eines Threads.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            count = conn.execute(\n","                \"SELECT COUNT(*) FROM messages WHERE thread_id = ?\",\n","                (thread_id,)\n","            ).fetchone()[0]\n","        return count\n","\n","    def save_summary(self, thread_id: str, summary: str):\n","        \"\"\"Speichert/aktualisiert die Zusammenfassung eines Threads.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            conn.execute(\"\"\"\n","                INSERT OR REPLACE INTO summaries (thread_id, summary, updated_at)\n","                VALUES (?, ?, CURRENT_TIMESTAMP)\n","            \"\"\", (thread_id, summary))\n","            conn.commit()\n","\n","    def get_summary(self, thread_id: str) -> Optional[str]:\n","        \"\"\"Ladt die Zusammenfassung eines Threads.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            row = conn.execute(\n","                \"SELECT summary FROM summaries WHERE thread_id = ?\",\n","                (thread_id,)\n","            ).fetchone()\n","        return row[0] if row else None\n","\n","    def list_threads(self) -> List[Dict]:\n","        \"\"\"Listet alle Threads mit Statistiken.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            rows = conn.execute(\"\"\"\n","                SELECT thread_id, COUNT(*) as msg_count, MAX(timestamp) as last_msg\n","                FROM messages\n","                GROUP BY thread_id\n","                ORDER BY last_msg DESC\n","            \"\"\").fetchall()\n","        return [{\"thread_id\": r[0], \"messages\": r[1], \"last_activity\": r[2]} for r in rows]\n","\n","    def delete_thread(self, thread_id: str):\n","        \"\"\"Loscht einen Thread.\"\"\"\n","        with sqlite3.connect(self.db_path) as conn:\n","            conn.execute(\"DELETE FROM messages WHERE thread_id = ?\", (thread_id,))\n","            conn.execute(\"DELETE FROM summaries WHERE thread_id = ?\", (thread_id,))\n","            conn.commit()"],"metadata":{"id":"lt015mlb76i","executionInfo":{"status":"ok","timestamp":1764770361216,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","id":"f9cx08h8yll","source":["class PersistentChatbot:\n","    \"\"\"Chatbot mit persistentem Memory uber SQLite.\"\"\"\n","\n","    def __init__(self, db_path: str = DB_PATH, max_context: int = 10):\n","        self.db = ChatMemoryDB(db_path)\n","        self.max_context = max_context\n","        self.llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.7)\n","        self.system_prompt = \"Du bist ein hilfreicher KI-Assistent mit Gedachtnis.\"\n","\n","    def _history_to_messages(self, history: List[Dict]) -> list:\n","        \"\"\"Konvertiert DB-Historie zu LangChain-Messages.\"\"\"\n","        messages = []\n","        for item in history:\n","            if item[\"role\"] == \"human\":\n","                messages.append(HumanMessage(content=item[\"content\"]))\n","            else:\n","                messages.append(AIMessage(content=item[\"content\"]))\n","        return messages\n","\n","    def chat(self, thread_id: str, user_input: str) -> str:\n","        \"\"\"Sendet eine Nachricht und speichert die Antwort.\"\"\"\n","\n","        # Historie laden (mit Limit)\n","        history = self.db.get_history(thread_id, limit=self.max_context)\n","        summary = self.db.get_summary(thread_id)\n","\n","        # System-Prompt mit Summary erweitern\n","        enhanced_system = self.system_prompt\n","        if summary:\n","            enhanced_system = f\"{self.system_prompt}\\n\\nKontext aus fruheren Gesprachen: {summary}\"\n","\n","        # Messages zusammenbauen\n","        messages = [SystemMessage(content=enhanced_system)]\n","        messages.extend(self._history_to_messages(history))\n","        messages.append(HumanMessage(content=user_input))\n","\n","        # LLM aufrufen\n","        response = self.llm.invoke(messages)\n","        response_text = response.content\n","\n","        # In DB speichern\n","        self.db.save_message(thread_id, \"human\", user_input)\n","        self.db.save_message(thread_id, \"ai\", response_text)\n","\n","        return response_text\n","\n","    def show_history(self, thread_id: str):\n","        \"\"\"Zeigt die Historie eines Threads.\"\"\"\n","        history = self.db.get_history(thread_id)\n","        mprint(f\"### Thread: {thread_id} ({len(history)} Nachrichten)\")\n","        mprint(\"---\")\n","        for i, msg in enumerate(history, 1):\n","            role = \"Human\" if msg[\"role\"] == \"human\" else \"KI\"\n","            mprint(f\"{i}. **{role}:** {msg['content']}\")\n","\n","    def list_threads(self):\n","        \"\"\"Listet alle Threads.\"\"\"\n","        threads = self.db.list_threads()\n","        mprint(\"### Alle Threads:\")\n","        mprint(\"---\")\n","        for t in threads:\n","            mprint(f\"- **{t['thread_id']}**: {t['messages']} Nachrichten (zuletzt: {t['last_activity']})\")"],"metadata":{"id":"f9cx08h8yll","executionInfo":{"status":"ok","timestamp":1764770361235,"user_tz":-60,"elapsed":12,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","id":"f0askgykshw","source":["# Demo: Persistenter Chatbot\n","mprint(\"## SQLite-Chatbot Demo\")\n","mprint(\"---\")\n","\n","bot = PersistentChatbot()\n","\n","# Thread 1: Max\n","print(\"\\n--- Thread: max_session ---\")\n","response = bot.chat(\"max_session\", \"Hallo! Ich bin Max und komme aus Munchen.\")\n","mprint(f\"**KI:** {response}\")\n","\n","response = bot.chat(\"max_session\", \"Ich interessiere mich fur Machine Learning.\")\n","mprint(f\"**KI:** {response}\")\n","\n","# Thread 2: Emma\n","print(\"\\n--- Thread: emma_session ---\")\n","response = bot.chat(\"emma_session\", \"Hi! Ich bin Emma aus Berlin.\")\n","mprint(f\"**KI:** {response}\")\n","\n","# Zuruck zu Max - Memory bleibt erhalten!\n","print(\"\\n--- Zuruck zu max_session ---\")\n","response = bot.chat(\"max_session\", \"Woher komme ich nochmal?\")\n","mprint(f\"**KI:** {response}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"f0askgykshw","executionInfo":{"status":"ok","timestamp":1764770365805,"user_tz":-60,"elapsed":4560,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"73686aee-c481-47ee-fd93-d10b31d80722"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"## SQLite-Chatbot Demo"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Datenbank initialisiert: ./chat_memory.db\n","\n","--- Thread: max_session ---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**KI:** Hallo Max! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**KI:** Das ist gro√üartig! Machine Learning ist ein spannendes und vielseitiges Feld. Gibt es einen bestimmten Bereich oder ein Thema im Machine Learning, das dich besonders interessiert? Zum Beispiel: Supervised Learning, Unsupervised Learning, neuronale Netze oder praktische Anwendungen?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- Thread: emma_session ---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**KI:** Hallo Emma! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- Zuruck zu max_session ---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**KI:** Du hast mir gesagt, dass du aus M√ºnchen kommst. Gibt es etwas Bestimmtes √ºber M√ºnchen oder Machine Learning, wor√ºber du sprechen m√∂chtest?"},"metadata":{}}]},{"cell_type":"code","id":"7pgcfw3i1kx","source":["# Alle Threads anzeigen\n","bot.list_threads()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116},"id":"7pgcfw3i1kx","executionInfo":{"status":"ok","timestamp":1764770365856,"user_tz":-60,"elapsed":27,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"1af9f2b6-f099-4b74-ebf2-1d43292ae29f"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Alle Threads:"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"- **max_session**: 6 Nachrichten (zuletzt: 2025-12-03 13:59:26)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"- **emma_session**: 2 Nachrichten (zuletzt: 2025-12-03 13:59:25)"},"metadata":{}}]},{"cell_type":"code","id":"8gsbb6kjlbi","source":["# Historie eines Threads anzeigen\n","bot.show_history(\"max_session\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"8gsbb6kjlbi","executionInfo":{"status":"ok","timestamp":1764770365917,"user_tz":-60,"elapsed":49,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"6d4faf1e-9de3-4a7b-f088-ea908ae4bb6d"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Thread: max_session (6 Nachrichten)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"1. **Human:** Hallo! Ich bin Max und komme aus Munchen."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"2. **KI:** Hallo Max! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"3. **Human:** Ich interessiere mich fur Machine Learning."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"4. **KI:** Das ist gro√üartig! Machine Learning ist ein spannendes und vielseitiges Feld. Gibt es einen bestimmten Bereich oder ein Thema im Machine Learning, das dich besonders interessiert? Zum Beispiel: Supervised Learning, Unsupervised Learning, neuronale Netze oder praktische Anwendungen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"5. **Human:** Woher komme ich nochmal?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"6. **KI:** Du hast mir gesagt, dass du aus M√ºnchen kommst. Gibt es etwas Bestimmtes √ºber M√ºnchen oder Machine Learning, wor√ºber du sprechen m√∂chtest?"},"metadata":{}}]},{"cell_type":"markdown","id":"1ut97tdwl86","source":["<p><font color='darkblue' size=\"4\">\n","Test: Neustart-Persistenz\n","</font></p>\n","\n","Die Daten bleiben auch nach Neustart erhalten. Fuhren Sie die nachste Zelle aus, um zu testen:"],"metadata":{"id":"1ut97tdwl86"}},{"cell_type":"code","id":"l4f6rj1cpog","source":["# Test: Neuer Bot-Instance, gleiche Datenbank\n","bot2 = PersistentChatbot()\n","\n","# Sollte Max's Historie kennen!\n","response = bot2.chat(\"max_session\", \"Was war mein Interesse nochmal?\")\n","mprint(f\"**KI (nach 'Neustart'):** {response}\")\n","\n","# Historie anzeigen\n","bot2.show_history(\"max_session\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"l4f6rj1cpog","executionInfo":{"status":"ok","timestamp":1764770366612,"user_tz":-60,"elapsed":687,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"53804c93-aabc-4939-fe8a-975d0a21c67c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Datenbank initialisiert: ./chat_memory.db\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**KI (nach 'Neustart'):** Du hast gesagt, dass du dich f√ºr Machine Learning interessierst. Gibt es etwas Spezielles, das du dar√ºber wissen m√∂chtest?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Thread: max_session (8 Nachrichten)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"1. **Human:** Hallo! Ich bin Max und komme aus Munchen."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"2. **KI:** Hallo Max! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"3. **Human:** Ich interessiere mich fur Machine Learning."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"4. **KI:** Das ist gro√üartig! Machine Learning ist ein spannendes und vielseitiges Feld. Gibt es einen bestimmten Bereich oder ein Thema im Machine Learning, das dich besonders interessiert? Zum Beispiel: Supervised Learning, Unsupervised Learning, neuronale Netze oder praktische Anwendungen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"5. **Human:** Woher komme ich nochmal?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"6. **KI:** Du hast mir gesagt, dass du aus M√ºnchen kommst. Gibt es etwas Bestimmtes √ºber M√ºnchen oder Machine Learning, wor√ºber du sprechen m√∂chtest?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"7. **Human:** Was war mein Interesse nochmal?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"8. **KI:** Du hast gesagt, dass du dich f√ºr Machine Learning interessierst. Gibt es etwas Spezielles, das du dar√ºber wissen m√∂chtest?"},"metadata":{}}]},{"cell_type":"markdown","id":"tasks-header","metadata":{"id":"tasks-header"},"source":["# A | Aufgaben\n","---"]},{"cell_type":"markdown","id":"task-1","metadata":{"id":"task-1"},"source":["<p><font color='black' size=\"5\">\n","Aufgabe 1: Trimming-Limit testen\n","</font></p>\n","\n","**Schwierigkeit:** 1/5\n","\n","Andern Sie `MAX_MESSAGES` auf 4 und fuhren Sie eine langere Konversation. Beobachten Sie, wann Informationen verloren gehen."]},{"cell_type":"markdown","id":"task-2","metadata":{"id":"task-2"},"source":["<p><font color='black' size=\"5\">\n","Aufgabe 2: Summary-Qualitat verbessern\n","</font></p>\n","\n","**Schwierigkeit:** 2/5\n","\n","Verbessern Sie den `summary_prompt`, um wichtige Informationen (Namen, Orte, Praferenzen) besser zu extrahieren."]},{"cell_type":"markdown","id":"task-3","metadata":{"id":"task-3"},"source":["<p><font color='black' size=\"5\">\n","Aufgabe 3: Interaktiver CLI-Chatbot\n","</font></p>\n","\n","**Schwierigkeit:** 3/5\n","\n","Erweitern Sie `PersistentChatbot` um eine interaktive Schleife mit Befehlen:\n","- `exit` - Beenden\n","- `history` - Historie anzeigen\n","- `new` - Neuen Thread starten\n","- `threads` - Alle Threads listen"]},{"cell_type":"markdown","id":"task-4","metadata":{"id":"task-4"},"source":["<p><font color='black' size=\"5\">\n","Aufgabe 4: Hybrid Memory (Trimming + Summary + DB)\n","</font></p>\n","\n","**Schwierigkeit:** 4/5\n","\n","Kombinieren Sie alle drei Strategien:\n","1. Speicherung in SQLite\n","2. Automatisches Trimming auf die letzten N Nachrichten\n","3. Zusammenfassung der alteren Nachrichten (in DB gespeichert)"]},{"cell_type":"markdown","id":"r4e93hrgyre","source":["# B | Datenbank auslesen\n","---"],"metadata":{"id":"r4e93hrgyre"}},{"cell_type":"markdown","id":"9h44bm4iwc5","source":["Dieser Abschnitt zeigt, wie die SQLite-Datenbank (`chat_memory.db`) direkt ausgelesen werden kann - nutzlich fur Debugging, Analyse oder Export."],"metadata":{"id":"9h44bm4iwc5"}},{"cell_type":"code","id":"czndm30m5hq","source":["import sqlite3\n","import os\n","\n","def read_all_threads_from_db(db_path: str = DB_PATH):\n","    \"\"\"\n","    Liest alle Threads und Nachrichten aus der chat_memory.db Datenbank.\n","    \"\"\"\n","    if not os.path.exists(db_path):\n","        print(f\"Fehler: Datenbankdatei '{db_path}' wurde nicht gefunden.\")\n","        return\n","\n","    mprint(f\"### Lese Datenbank: {db_path}\")\n","    mprint(\"---\")\n","\n","    with sqlite3.connect(db_path) as conn:\n","        # Alle Threads mit Statistiken\n","        threads = conn.execute(\"\"\"\n","            SELECT thread_id, COUNT(*) as msg_count, MAX(timestamp) as last_msg\n","            FROM messages\n","            GROUP BY thread_id\n","            ORDER BY last_msg DESC\n","        \"\"\").fetchall()\n","\n","        if not threads:\n","            print(\"Keine Threads in der Datenbank gefunden.\")\n","            return\n","\n","        mprint(f\"**{len(threads)} Threads gefunden**\\n\")\n","\n","        # Jeden Thread mit Nachrichten anzeigen\n","        for thread_id, msg_count, last_msg in threads:\n","            mprint(f\"#### Thread: {thread_id}\")\n","            mprint(f\"*{msg_count} Nachrichten, zuletzt: {last_msg}*\\n\")\n","\n","            # Nachrichten des Threads\n","            messages = conn.execute(\"\"\"\n","                SELECT role, content, timestamp\n","                FROM messages\n","                WHERE thread_id = ?\n","                ORDER BY id\n","            \"\"\", (thread_id,)).fetchall()\n","\n","            for i, (role, content, ts) in enumerate(messages, 1):\n","                role_display = \"Human\" if role == \"human\" else \"KI\"\n","                # Inhalt kurzen wenn zu lang\n","                content_short = content[:100] + \"...\" if len(content) > 100 else content\n","                mprint(f\"{i}. **{role_display}:** {content_short}\")\n","\n","            # Zusammenfassung (falls vorhanden)\n","            summary = conn.execute(\n","                \"SELECT summary FROM summaries WHERE thread_id = ?\",\n","                (thread_id,)\n","            ).fetchone()\n","\n","            if summary and summary[0]:\n","                mprint(f\"\\n*Zusammenfassung:* {summary[0][:150]}...\")\n","\n","            mprint(\"\")  # Leerzeile zwischen Threads"],"metadata":{"id":"czndm30m5hq","executionInfo":{"status":"ok","timestamp":1764770366654,"user_tz":-60,"elapsed":29,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","id":"t62wa5e3aac","source":["# Alle Threads aus der Datenbank auslesen\n","read_all_threads_from_db()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"t62wa5e3aac","executionInfo":{"status":"ok","timestamp":1764770366723,"user_tz":-60,"elapsed":59,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"cc873251-7c1a-4d0b-8826-7d269ad44e09"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Lese Datenbank: ./chat_memory.db"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"---"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**2 Threads gefunden**\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"#### Thread: max_session"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"*8 Nachrichten, zuletzt: 2025-12-03 13:59:27*\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"1. **Human:** Hallo! Ich bin Max und komme aus Munchen."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"2. **KI:** Hallo Max! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"3. **Human:** Ich interessiere mich fur Machine Learning."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"4. **KI:** Das ist gro√üartig! Machine Learning ist ein spannendes und vielseitiges Feld. Gibt es einen bestimmt..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"5. **Human:** Woher komme ich nochmal?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"6. **KI:** Du hast mir gesagt, dass du aus M√ºnchen kommst. Gibt es etwas Bestimmtes √ºber M√ºnchen oder Machine L..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"7. **Human:** Was war mein Interesse nochmal?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"8. **KI:** Du hast gesagt, dass du dich f√ºr Machine Learning interessierst. Gibt es etwas Spezielles, das du da..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"#### Thread: emma_session"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"*2 Nachrichten, zuletzt: 2025-12-03 13:59:25*\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"1. **Human:** Hi! Ich bin Emma aus Berlin."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"2. **KI:** Hallo Emma! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":""},"metadata":{}}]},{"cell_type":"code","id":"3b14guf2r17","source":["import json\n","\n","def export_thread_to_json(thread_id: str, db_path: str = DB_PATH) -> dict:\n","    \"\"\"Exportiert einen Thread als JSON.\"\"\"\n","    with sqlite3.connect(db_path) as conn:\n","        messages = conn.execute(\"\"\"\n","            SELECT role, content, timestamp\n","            FROM messages\n","            WHERE thread_id = ?\n","            ORDER BY id\n","        \"\"\", (thread_id,)).fetchall()\n","\n","        summary = conn.execute(\n","            \"SELECT summary FROM summaries WHERE thread_id = ?\",\n","            (thread_id,)\n","        ).fetchone()\n","\n","    data = {\n","        \"thread_id\": thread_id,\n","        \"messages\": [\n","            {\"role\": r, \"content\": c, \"timestamp\": t}\n","            for r, c, t in messages\n","        ],\n","        \"summary\": summary[0] if summary else None\n","    }\n","\n","    return data\n","\n","# Beispiel: Thread als JSON exportieren\n","thread_data = export_thread_to_json(\"max_session\")\n","print(json.dumps(thread_data, indent=2, ensure_ascii=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3b14guf2r17","executionInfo":{"status":"ok","timestamp":1764770366732,"user_tz":-60,"elapsed":38,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}},"outputId":"a04fa3a3-550e-4e57-8416-5af058a5f0d0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"thread_id\": \"max_session\",\n","  \"messages\": [\n","    {\n","      \"role\": \"human\",\n","      \"content\": \"Hallo! Ich bin Max und komme aus Munchen.\",\n","      \"timestamp\": \"2025-12-03 13:59:22\"\n","    },\n","    {\n","      \"role\": \"ai\",\n","      \"content\": \"Hallo Max! Sch√∂n, dich kennenzulernen. Wie kann ich dir heute helfen?\",\n","      \"timestamp\": \"2025-12-03 13:59:22\"\n","    },\n","    {\n","      \"role\": \"human\",\n","      \"content\": \"Ich interessiere mich fur Machine Learning.\",\n","      \"timestamp\": \"2025-12-03 13:59:24\"\n","    },\n","    {\n","      \"role\": \"ai\",\n","      \"content\": \"Das ist gro√üartig! Machine Learning ist ein spannendes und vielseitiges Feld. Gibt es einen bestimmten Bereich oder ein Thema im Machine Learning, das dich besonders interessiert? Zum Beispiel: Supervised Learning, Unsupervised Learning, neuronale Netze oder praktische Anwendungen?\",\n","      \"timestamp\": \"2025-12-03 13:59:24\"\n","    },\n","    {\n","      \"role\": \"human\",\n","      \"content\": \"Woher komme ich nochmal?\",\n","      \"timestamp\": \"2025-12-03 13:59:26\"\n","    },\n","    {\n","      \"role\": \"ai\",\n","      \"content\": \"Du hast mir gesagt, dass du aus M√ºnchen kommst. Gibt es etwas Bestimmtes √ºber M√ºnchen oder Machine Learning, wor√ºber du sprechen m√∂chtest?\",\n","      \"timestamp\": \"2025-12-03 13:59:26\"\n","    },\n","    {\n","      \"role\": \"human\",\n","      \"content\": \"Was war mein Interesse nochmal?\",\n","      \"timestamp\": \"2025-12-03 13:59:27\"\n","    },\n","    {\n","      \"role\": \"ai\",\n","      \"content\": \"Du hast gesagt, dass du dich f√ºr Machine Learning interessierst. Gibt es etwas Spezielles, das du dar√ºber wissen m√∂chtest?\",\n","      \"timestamp\": \"2025-12-03 13:59:27\"\n","    }\n","  ],\n","  \"summary\": null\n","}\n"]}]},{"cell_type":"code","id":"qmm10fc57u7","source":["def delete_all_threads(db_path: str = DB_PATH):\n","    \"\"\"Loscht alle Threads aus der Datenbank (Cleanup).\"\"\"\n","    with sqlite3.connect(db_path) as conn:\n","        conn.execute(\"DELETE FROM messages\")\n","        conn.execute(\"DELETE FROM summaries\")\n","        conn.commit()\n","    print(f\"Alle Threads geloscht aus: {db_path}\")\n","\n","# Auskommentiert, um versehentliches Loschen zu verhindern:\n","# delete_all_threads()"],"metadata":{"id":"qmm10fc57u7","executionInfo":{"status":"ok","timestamp":1764770366736,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ralf Bendig","userId":"13914949880386033641"}}},"execution_count":26,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.0"},"colab":{"provenance":[],"collapsed_sections":["intro-header","shortterm-header","trimming-header","summary-header","db-header","tasks-header"]}},"nbformat":4,"nbformat_minor":5}